{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_XOR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyDearGreatTeacher/AI4high/blob/master/TF_XOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JqQ0MDzPtF2",
        "colab_type": "text"
      },
      "source": [
        "# 使用Tensorflow解XOR 問題\n",
        "\n",
        "\n",
        "https://www.yueye.org/2017/xor-with-tensorflow.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGoFXlRYM0Bj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684431
        },
        "outputId": "a66da09c-dbdc-429d-d817-b83d3b7186e3"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "data = tf.placeholder(tf.float32, shape=(4, 2))\n",
        "label = tf.placeholder(tf.float32, shape=(4, 1))\n",
        "\n",
        "with tf.variable_scope('layer1') as scope:\n",
        "  weight = tf.get_variable(name='weight', shape=(2, 2))\n",
        "  bias = tf.get_variable(name='bias', shape=(2,))\n",
        "  x = tf.nn.sigmoid(tf.matmul(data, weight) + bias)\n",
        "\n",
        "  with tf.variable_scope('layer2') as scope:\n",
        "  weight = tf.get_variable(name='weight', shape=(2, 1))\n",
        "  bias = tf.get_variable(name='bias', shape=(1,))\n",
        "  x = tf.matmul(x, weight) + bias\n",
        "\n",
        "  preds = tf.nn.sigmoid(x)\n",
        "\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=label, logits=x))\n",
        "\n",
        "learning_rate = tf.placeholder(tf.float32)\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "\n",
        "train_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "train_label = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for step in range(10000):\n",
        "    if step < 3000:\n",
        "      lr = 1\n",
        "    elif step < 6000:\n",
        "      lr = 0.1\n",
        "    else:\n",
        "      lr = 0.01\n",
        "    _, l, pred = sess.run([optimizer, loss, preds], feed_dict={data: train_data, label: train_label, learning_rate: lr})\n",
        "    if step % 500:\n",
        "      print('Step: {} -> Loss: {} -> Predictions: {}'.format(step, l, pred))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Step: 1 -> Loss: 1.0093204975128174 -> Predictions: [[0.8629436 ]\n",
            " [0.83861184]\n",
            " [0.8389508 ]\n",
            " [0.8170073 ]]\n",
            "Step: 2 -> Loss: 0.8817532062530518 -> Predictions: [[0.80356014]\n",
            " [0.7748477 ]\n",
            " [0.77540004]\n",
            " [0.7509618 ]]\n",
            "Step: 3 -> Loss: 0.800818145275116 -> Predictions: [[0.74367476]\n",
            " [0.712806  ]\n",
            " [0.71354145]\n",
            " [0.68835914]]\n",
            "Step: 4 -> Loss: 0.7532491683959961 -> Predictions: [[0.6903032 ]\n",
            " [0.659035  ]\n",
            " [0.65990335]\n",
            " [0.6351229 ]]\n",
            "Step: 5 -> Loss: 0.7267886400222778 -> Predictions: [[0.6467493 ]\n",
            " [0.616066  ]\n",
            " [0.61702126]\n",
            " [0.59315544]]\n",
            "Step: 6 -> Loss: 0.7125513553619385 -> Predictions: [[0.6131126 ]\n",
            " [0.58340424]\n",
            " [0.5844139 ]\n",
            " [0.56157345]]\n",
            "Step: 7 -> Loss: 0.7050167322158813 -> Predictions: [[0.5879325 ]\n",
            " [0.5592649 ]\n",
            " [0.56030786]\n",
            " [0.53841907]]\n",
            "Step: 8 -> Loss: 0.7010483741760254 -> Predictions: [[0.56938636]\n",
            " [0.5416873 ]\n",
            " [0.54275054]\n",
            " [0.52168125]]\n",
            "Step: 9 -> Loss: 0.6989490985870361 -> Predictions: [[0.55582887]\n",
            " [0.5289847 ]\n",
            " [0.5300604 ]\n",
            " [0.5096772 ]]\n",
            "Step: 10 -> Loss: 0.6978225708007812 -> Predictions: [[0.545943  ]\n",
            " [0.519841  ]\n",
            " [0.52092427]\n",
            " [0.5011125 ]]\n",
            "Step: 11 -> Loss: 0.6972011923789978 -> Predictions: [[0.5387303 ]\n",
            " [0.5132732 ]\n",
            " [0.5143609 ]\n",
            " [0.49502936]]\n",
            "Step: 12 -> Loss: 0.6968422532081604 -> Predictions: [[0.53345346]\n",
            " [0.5085625 ]\n",
            " [0.50965255]\n",
            " [0.49073067]]\n",
            "Step: 13 -> Loss: 0.6966202259063721 -> Predictions: [[0.52957475]\n",
            " [0.5051881 ]\n",
            " [0.5062793 ]\n",
            " [0.48771352]]\n",
            "Step: 14 -> Loss: 0.6964700222015381 -> Predictions: [[0.52670497]\n",
            " [0.50277466]\n",
            " [0.50386596]\n",
            " [0.4856161 ]]\n",
            "Step: 15 -> Loss: 0.6963579654693604 -> Predictions: [[0.52456295]\n",
            " [0.50105184]\n",
            " [0.5021426 ]\n",
            " [0.48417836]]\n",
            "Step: 16 -> Loss: 0.6962666511535645 -> Predictions: [[0.5229462 ]\n",
            " [0.49982536]\n",
            " [0.5009151 ]\n",
            " [0.48321363]]\n",
            "Step: 17 -> Loss: 0.6961870789527893 -> Predictions: [[0.5217086 ]\n",
            " [0.4989554 ]\n",
            " [0.5000439 ]\n",
            " [0.48258772]]\n",
            "Step: 18 -> Loss: 0.6961144208908081 -> Predictions: [[0.5207454 ]\n",
            " [0.4983416 ]\n",
            " [0.49942857]\n",
            " [0.48220423]]\n",
            "Step: 19 -> Loss: 0.6960462331771851 -> Predictions: [[0.51998067]\n",
            " [0.4979117 ]\n",
            " [0.49899697]\n",
            " [0.48199394]]\n",
            "Step: 20 -> Loss: 0.6959813237190247 -> Predictions: [[0.51936024]\n",
            " [0.49761373]\n",
            " [0.49869722]\n",
            " [0.48190704]]\n",
            "Step: 21 -> Loss: 0.6959187984466553 -> Predictions: [[0.5188448]\n",
            " [0.4974103]\n",
            " [0.4984919]\n",
            " [0.4819078]]\n",
            "Step: 22 -> Loss: 0.695858359336853 -> Predictions: [[0.51840615]\n",
            " [0.4972748 ]\n",
            " [0.49835443]\n",
            " [0.48197052]]\n",
            "Step: 23 -> Loss: 0.695799708366394 -> Predictions: [[0.5180239 ]\n",
            " [0.49718767]\n",
            " [0.49826536]\n",
            " [0.4820767 ]]\n",
            "Step: 24 -> Loss: 0.6957429051399231 -> Predictions: [[0.51768357]\n",
            " [0.49713522]\n",
            " [0.4982109 ]\n",
            " [0.48221314]]\n",
            "Step: 25 -> Loss: 0.6956875324249268 -> Predictions: [[0.5173745 ]\n",
            " [0.49710742]\n",
            " [0.49818113]\n",
            " [0.48237038]]\n",
            "Step: 26 -> Loss: 0.6956337690353394 -> Predictions: [[0.51708907]\n",
            " [0.49709716]\n",
            " [0.49816883]\n",
            " [0.48254162]]\n",
            "Step: 27 -> Loss: 0.6955814957618713 -> Predictions: [[0.51682174]\n",
            " [0.49709928]\n",
            " [0.4981689 ]\n",
            " [0.4827219 ]]\n",
            "Step: 28 -> Loss: 0.6955305337905884 -> Predictions: [[0.5165686 ]\n",
            " [0.49711013]\n",
            " [0.49817765]\n",
            " [0.48290774]]\n",
            "Step: 29 -> Loss: 0.69548100233078 -> Predictions: [[0.51632667]\n",
            " [0.49712697]\n",
            " [0.49819243]\n",
            " [0.4830968 ]]\n",
            "Step: 30 -> Loss: 0.695432722568512 -> Predictions: [[0.5160939 ]\n",
            " [0.49714795]\n",
            " [0.4982114 ]\n",
            " [0.4832872 ]]\n",
            "Step: 31 -> Loss: 0.6953856945037842 -> Predictions: [[0.51586884]\n",
            " [0.49717182]\n",
            " [0.49823314]\n",
            " [0.48347765]]\n",
            "Step: 32 -> Loss: 0.6953399181365967 -> Predictions: [[0.51565015]\n",
            " [0.49719745]\n",
            " [0.49825683]\n",
            " [0.48366743]]\n",
            "Step: 33 -> Loss: 0.6952953338623047 -> Predictions: [[0.5154372 ]\n",
            " [0.49722433]\n",
            " [0.49828157]\n",
            " [0.48385575]]\n",
            "Step: 34 -> Loss: 0.6952518820762634 -> Predictions: [[0.51522917]\n",
            " [0.4972518 ]\n",
            " [0.4983069 ]\n",
            " [0.48404232]]\n",
            "Step: 35 -> Loss: 0.6952095627784729 -> Predictions: [[0.5150258 ]\n",
            " [0.4972796 ]\n",
            " [0.4983326 ]\n",
            " [0.48422676]]\n",
            "Step: 36 -> Loss: 0.6951681971549988 -> Predictions: [[0.51482654]\n",
            " [0.49730745]\n",
            " [0.4983584 ]\n",
            " [0.48440897]]\n",
            "Step: 37 -> Loss: 0.6951279640197754 -> Predictions: [[0.5146312 ]\n",
            " [0.49733517]\n",
            " [0.49838406]\n",
            " [0.4845888 ]]\n",
            "Step: 38 -> Loss: 0.6950886845588684 -> Predictions: [[0.5144396 ]\n",
            " [0.4973627 ]\n",
            " [0.49840945]\n",
            " [0.4847661 ]]\n",
            "Step: 39 -> Loss: 0.6950504779815674 -> Predictions: [[0.5142515 ]\n",
            " [0.4973899 ]\n",
            " [0.49843457]\n",
            " [0.48494092]]\n",
            "Step: 40 -> Loss: 0.6950131058692932 -> Predictions: [[0.5140667 ]\n",
            " [0.4974168 ]\n",
            " [0.49845934]\n",
            " [0.4851133 ]]\n",
            "Step: 41 -> Loss: 0.6949767470359802 -> Predictions: [[0.51388514]\n",
            " [0.49744323]\n",
            " [0.49848363]\n",
            " [0.48528314]]\n",
            "Step: 42 -> Loss: 0.6949412822723389 -> Predictions: [[0.51370674]\n",
            " [0.4974693 ]\n",
            " [0.49850756]\n",
            " [0.48545045]]\n",
            "Step: 43 -> Loss: 0.6949065923690796 -> Predictions: [[0.5135314 ]\n",
            " [0.4974949 ]\n",
            " [0.498531  ]\n",
            " [0.48561534]]\n",
            "Step: 44 -> Loss: 0.6948726773262024 -> Predictions: [[0.5133589 ]\n",
            " [0.49752012]\n",
            " [0.49855402]\n",
            " [0.48577785]]\n",
            "Step: 45 -> Loss: 0.6948397159576416 -> Predictions: [[0.5131893 ]\n",
            " [0.49754485]\n",
            " [0.49857658]\n",
            " [0.48593795]]\n",
            "Step: 46 -> Loss: 0.6948075294494629 -> Predictions: [[0.5130225 ]\n",
            " [0.49756914]\n",
            " [0.4985987 ]\n",
            " [0.4860957 ]]\n",
            "Step: 47 -> Loss: 0.6947760581970215 -> Predictions: [[0.5128584 ]\n",
            " [0.49759308]\n",
            " [0.4986204 ]\n",
            " [0.48625124]]\n",
            "Step: 48 -> Loss: 0.6947453022003174 -> Predictions: [[0.5126969 ]\n",
            " [0.49761656]\n",
            " [0.49864167]\n",
            " [0.48640445]]\n",
            "Step: 49 -> Loss: 0.6947153210639954 -> Predictions: [[0.5125381 ]\n",
            " [0.49763966]\n",
            " [0.49866247]\n",
            " [0.4865555 ]]\n",
            "Step: 50 -> Loss: 0.6946859955787659 -> Predictions: [[0.51238173]\n",
            " [0.4976623 ]\n",
            " [0.49868295]\n",
            " [0.48670432]]\n",
            "Step: 51 -> Loss: 0.6946573257446289 -> Predictions: [[0.51222783]\n",
            " [0.4976845 ]\n",
            " [0.49870297]\n",
            " [0.48685104]]\n",
            "Step: 52 -> Loss: 0.6946293115615845 -> Predictions: [[0.5120764]\n",
            " [0.4977065]\n",
            " [0.4987226]\n",
            " [0.4869957]]\n",
            "Step: 53 -> Loss: 0.6946020126342773 -> Predictions: [[0.51192725]\n",
            " [0.497728  ]\n",
            " [0.49874184]\n",
            " [0.4871383 ]]\n",
            "Step: 54 -> Loss: 0.6945753693580627 -> Predictions: [[0.5117804 ]\n",
            " [0.49774915]\n",
            " [0.49876067]\n",
            " [0.4872789 ]]\n",
            "Step: 55 -> Loss: 0.6945492029190063 -> Predictions: [[0.51163584]\n",
            " [0.49776986]\n",
            " [0.49877918]\n",
            " [0.48741755]]\n",
            "Step: 56 -> Loss: 0.6945236921310425 -> Predictions: [[0.5114935 ]\n",
            " [0.4977903 ]\n",
            " [0.49879727]\n",
            " [0.48755425]]\n",
            "Step: 57 -> Loss: 0.6944987773895264 -> Predictions: [[0.51135325]\n",
            " [0.49781045]\n",
            " [0.498815  ]\n",
            " [0.48768914]]\n",
            "Step: 58 -> Loss: 0.6944742798805237 -> Predictions: [[0.51121515]\n",
            " [0.49783018]\n",
            " [0.49883246]\n",
            " [0.4878221 ]]\n",
            "Step: 59 -> Loss: 0.6944504976272583 -> Predictions: [[0.5110791 ]\n",
            " [0.49784958]\n",
            " [0.49884954]\n",
            " [0.48795325]]\n",
            "Step: 60 -> Loss: 0.6944271326065063 -> Predictions: [[0.5109451 ]\n",
            " [0.49786872]\n",
            " [0.49886626]\n",
            " [0.48808265]]\n",
            "Step: 61 -> Loss: 0.6944043040275574 -> Predictions: [[0.51081306]\n",
            " [0.49788752]\n",
            " [0.4988827 ]\n",
            " [0.48821023]]\n",
            "Step: 62 -> Loss: 0.6943819522857666 -> Predictions: [[0.5106829 ]\n",
            " [0.49790606]\n",
            " [0.49889886]\n",
            " [0.48833615]]\n",
            "Step: 63 -> Loss: 0.694360077381134 -> Predictions: [[0.51055473]\n",
            " [0.49792427]\n",
            " [0.49891463]\n",
            " [0.4884604 ]]\n",
            "Step: 64 -> Loss: 0.6943386793136597 -> Predictions: [[0.51042837]\n",
            " [0.49794218]\n",
            " [0.49893013]\n",
            " [0.48858303]]\n",
            "Step: 65 -> Loss: 0.6943178176879883 -> Predictions: [[0.51030374]\n",
            " [0.49795985]\n",
            " [0.4989454 ]\n",
            " [0.488704  ]]\n",
            "Step: 66 -> Loss: 0.6942973136901855 -> Predictions: [[0.510181  ]\n",
            " [0.4979772 ]\n",
            " [0.4989603 ]\n",
            " [0.48882338]]\n",
            "Step: 67 -> Loss: 0.6942772269248962 -> Predictions: [[0.51005995]\n",
            " [0.49799427]\n",
            " [0.498975  ]\n",
            " [0.48894122]]\n",
            "Step: 68 -> Loss: 0.6942576169967651 -> Predictions: [[0.5099406 ]\n",
            " [0.49801114]\n",
            " [0.49898937]\n",
            " [0.4890575 ]]\n",
            "Step: 69 -> Loss: 0.6942384243011475 -> Predictions: [[0.50982296]\n",
            " [0.49802774]\n",
            " [0.49900344]\n",
            " [0.4891724 ]]\n",
            "Step: 70 -> Loss: 0.6942195892333984 -> Predictions: [[0.5097069 ]\n",
            " [0.49804407]\n",
            " [0.49901727]\n",
            " [0.48928574]]\n",
            "Step: 71 -> Loss: 0.6942011713981628 -> Predictions: [[0.5095925 ]\n",
            " [0.4980601 ]\n",
            " [0.49903086]\n",
            " [0.48939762]]\n",
            "Step: 72 -> Loss: 0.6941831111907959 -> Predictions: [[0.50947964]\n",
            " [0.49807593]\n",
            " [0.4990442 ]\n",
            " [0.4895081 ]]\n",
            "Step: 73 -> Loss: 0.6941654086112976 -> Predictions: [[0.50936836]\n",
            " [0.4980915 ]\n",
            " [0.4990573 ]\n",
            " [0.48961723]]\n",
            "Step: 74 -> Loss: 0.694148063659668 -> Predictions: [[0.50925857]\n",
            " [0.49810687]\n",
            " [0.4990701 ]\n",
            " [0.48972493]]\n",
            "Step: 75 -> Loss: 0.6941311359405518 -> Predictions: [[0.5091502 ]\n",
            " [0.49812204]\n",
            " [0.49908277]\n",
            " [0.4898313 ]]\n",
            "Step: 76 -> Loss: 0.6941145062446594 -> Predictions: [[0.50904334]\n",
            " [0.49813694]\n",
            " [0.49909517]\n",
            " [0.4899364 ]]\n",
            "Step: 77 -> Loss: 0.6940982341766357 -> Predictions: [[0.50893784]\n",
            " [0.49815166]\n",
            " [0.49910736]\n",
            " [0.49004018]]\n",
            "Step: 78 -> Loss: 0.6940822601318359 -> Predictions: [[0.50883377]\n",
            " [0.49816617]\n",
            " [0.49911928]\n",
            " [0.4901427 ]]\n",
            "Step: 79 -> Loss: 0.69406658411026 -> Predictions: [[0.5087311 ]\n",
            " [0.49818048]\n",
            " [0.49913105]\n",
            " [0.490244  ]]\n",
            "Step: 80 -> Loss: 0.694051206111908 -> Predictions: [[0.50862974]\n",
            " [0.49819458]\n",
            " [0.49914256]\n",
            " [0.49034405]]\n",
            "Step: 81 -> Loss: 0.6940361857414246 -> Predictions: [[0.50852966]\n",
            " [0.4982084 ]\n",
            " [0.49915385]\n",
            " [0.4904429 ]]\n",
            "Step: 82 -> Loss: 0.694021463394165 -> Predictions: [[0.50843096]\n",
            " [0.49822214]\n",
            " [0.49916503]\n",
            " [0.4905406 ]]\n",
            "Step: 83 -> Loss: 0.6940069198608398 -> Predictions: [[0.50833344]\n",
            " [0.49823564]\n",
            " [0.49917597]\n",
            " [0.4906371 ]]\n",
            "Step: 84 -> Loss: 0.6939927935600281 -> Predictions: [[0.5082372 ]\n",
            " [0.4982489 ]\n",
            " [0.49918664]\n",
            " [0.49073246]]\n",
            "Step: 85 -> Loss: 0.6939789056777954 -> Predictions: [[0.5081422 ]\n",
            " [0.49826202]\n",
            " [0.4991972 ]\n",
            " [0.49082676]]\n",
            "Step: 86 -> Loss: 0.6939652562141418 -> Predictions: [[0.5080483 ]\n",
            " [0.49827498]\n",
            " [0.49920756]\n",
            " [0.49091992]]\n",
            "Step: 87 -> Loss: 0.6939518451690674 -> Predictions: [[0.5079556 ]\n",
            " [0.49828777]\n",
            " [0.49921778]\n",
            " [0.491012  ]]\n",
            "Step: 88 -> Loss: 0.6939387917518616 -> Predictions: [[0.5078641 ]\n",
            " [0.4983004 ]\n",
            " [0.49922776]\n",
            " [0.49110293]]\n",
            "Step: 89 -> Loss: 0.6939258575439453 -> Predictions: [[0.5077737 ]\n",
            " [0.49831283]\n",
            " [0.49923763]\n",
            " [0.49119297]]\n",
            "Step: 90 -> Loss: 0.6939132213592529 -> Predictions: [[0.5076844 ]\n",
            " [0.49832502]\n",
            " [0.4992473 ]\n",
            " [0.4912819 ]]\n",
            "Step: 91 -> Loss: 0.6939008235931396 -> Predictions: [[0.5075962 ]\n",
            " [0.49833715]\n",
            " [0.49925676]\n",
            " [0.49136978]]\n",
            "Step: 92 -> Loss: 0.6938886642456055 -> Predictions: [[0.50750905]\n",
            " [0.49834907]\n",
            " [0.49926615]\n",
            " [0.49145678]]\n",
            "Step: 93 -> Loss: 0.6938767433166504 -> Predictions: [[0.5074229]\n",
            " [0.4983609]\n",
            " [0.4992753]\n",
            " [0.4915428]]\n",
            "Step: 94 -> Loss: 0.6938650012016296 -> Predictions: [[0.50733787]\n",
            " [0.4983725 ]\n",
            " [0.49928433]\n",
            " [0.4916278 ]]\n",
            "Step: 95 -> Loss: 0.693853497505188 -> Predictions: [[0.5072538 ]\n",
            " [0.498384  ]\n",
            " [0.49929327]\n",
            " [0.49171185]]\n",
            "Step: 96 -> Loss: 0.6938421726226807 -> Predictions: [[0.50717074]\n",
            " [0.49839523]\n",
            " [0.499302  ]\n",
            " [0.49179497]]\n",
            "Step: 97 -> Loss: 0.6938310861587524 -> Predictions: [[0.5070886 ]\n",
            " [0.49840644]\n",
            " [0.4993106 ]\n",
            " [0.49187723]]\n",
            "Step: 98 -> Loss: 0.6938202381134033 -> Predictions: [[0.5070075 ]\n",
            " [0.49841753]\n",
            " [0.49931905]\n",
            " [0.49195856]]\n",
            "Step: 99 -> Loss: 0.6938095688819885 -> Predictions: [[0.50692725]\n",
            " [0.49842834]\n",
            " [0.49932736]\n",
            " [0.49203908]]\n",
            "Step: 100 -> Loss: 0.6937990188598633 -> Predictions: [[0.506848  ]\n",
            " [0.49843907]\n",
            " [0.49933553]\n",
            " [0.4921187 ]]\n",
            "Step: 101 -> Loss: 0.6937887668609619 -> Predictions: [[0.5067696 ]\n",
            " [0.49844974]\n",
            " [0.49934354]\n",
            " [0.49219745]]\n",
            "Step: 102 -> Loss: 0.6937786340713501 -> Predictions: [[0.5066921 ]\n",
            " [0.49846017]\n",
            " [0.49935144]\n",
            " [0.49227533]]\n",
            "Step: 103 -> Loss: 0.6937686800956726 -> Predictions: [[0.50661546]\n",
            " [0.49847052]\n",
            " [0.49935925]\n",
            " [0.49235243]]\n",
            "Step: 104 -> Loss: 0.6937589049339294 -> Predictions: [[0.5065397 ]\n",
            " [0.49848077]\n",
            " [0.49936685]\n",
            " [0.49242872]]\n",
            "Step: 105 -> Loss: 0.6937493085861206 -> Predictions: [[0.5064647 ]\n",
            " [0.49849084]\n",
            " [0.49937445]\n",
            " [0.49250424]]\n",
            "Step: 106 -> Loss: 0.6937398314476013 -> Predictions: [[0.50639063]\n",
            " [0.4985008 ]\n",
            " [0.49938184]\n",
            " [0.49257892]]\n",
            "Step: 107 -> Loss: 0.6937305927276611 -> Predictions: [[0.5063173 ]\n",
            " [0.49851063]\n",
            " [0.49938908]\n",
            " [0.49265286]]\n",
            "Step: 108 -> Loss: 0.6937214136123657 -> Predictions: [[0.50624484]\n",
            " [0.49852028]\n",
            " [0.49939626]\n",
            " [0.49272606]]\n",
            "Step: 109 -> Loss: 0.6937125325202942 -> Predictions: [[0.50617313]\n",
            " [0.49852988]\n",
            " [0.49940336]\n",
            " [0.49279842]]\n",
            "Step: 110 -> Loss: 0.6937037110328674 -> Predictions: [[0.50610214]\n",
            " [0.49853933]\n",
            " [0.4994103 ]\n",
            " [0.49287012]]\n",
            "Step: 111 -> Loss: 0.693695068359375 -> Predictions: [[0.506032  ]\n",
            " [0.4985487 ]\n",
            " [0.49941716]\n",
            " [0.49294114]]\n",
            "Step: 112 -> Loss: 0.6936865448951721 -> Predictions: [[0.50596255]\n",
            " [0.49855793]\n",
            " [0.49942392]\n",
            " [0.49301142]]\n",
            "Step: 113 -> Loss: 0.6936782002449036 -> Predictions: [[0.5058938 ]\n",
            " [0.49856704]\n",
            " [0.49943054]\n",
            " [0.49308097]]\n",
            "Step: 114 -> Loss: 0.6936699748039246 -> Predictions: [[0.5058259 ]\n",
            " [0.49857605]\n",
            " [0.49943706]\n",
            " [0.49314985]]\n",
            "Step: 115 -> Loss: 0.6936619281768799 -> Predictions: [[0.5057586 ]\n",
            " [0.49858496]\n",
            " [0.4994435 ]\n",
            " [0.49321803]]\n",
            "Step: 116 -> Loss: 0.69365394115448 -> Predictions: [[0.505692  ]\n",
            " [0.49859378]\n",
            " [0.49944985]\n",
            " [0.49328563]]\n",
            "Step: 117 -> Loss: 0.6936461925506592 -> Predictions: [[0.5056261 ]\n",
            " [0.49860248]\n",
            " [0.49945605]\n",
            " [0.49335244]]\n",
            "Step: 118 -> Loss: 0.6936385035514832 -> Predictions: [[0.5055609 ]\n",
            " [0.49861103]\n",
            " [0.49946222]\n",
            " [0.49341872]]\n",
            "Step: 119 -> Loss: 0.6936308741569519 -> Predictions: [[0.50549626]\n",
            " [0.49861956]\n",
            " [0.4994683 ]\n",
            " [0.4934843 ]]\n",
            "Step: 120 -> Loss: 0.6936234831809998 -> Predictions: [[0.50543237]\n",
            " [0.49862787]\n",
            " [0.49947426]\n",
            " [0.49354926]]\n",
            "Step: 121 -> Loss: 0.6936161518096924 -> Predictions: [[0.50536907]\n",
            " [0.49863616]\n",
            " [0.49948007]\n",
            " [0.49361363]]\n",
            "Step: 122 -> Loss: 0.6936089992523193 -> Predictions: [[0.5053064 ]\n",
            " [0.49864435]\n",
            " [0.4994859 ]\n",
            " [0.49367735]]\n",
            "Step: 123 -> Loss: 0.6936019659042358 -> Predictions: [[0.5052444 ]\n",
            " [0.4986524 ]\n",
            " [0.4994916 ]\n",
            " [0.49374053]]\n",
            "Step: 124 -> Loss: 0.6935949921607971 -> Predictions: [[0.5051829 ]\n",
            " [0.49866042]\n",
            " [0.4994972 ]\n",
            " [0.49380305]]\n",
            "Step: 125 -> Loss: 0.6935880780220032 -> Predictions: [[0.50512207]\n",
            " [0.49866828]\n",
            " [0.49950275]\n",
            " [0.49386504]]\n",
            "Step: 126 -> Loss: 0.6935813426971436 -> Predictions: [[0.5050618 ]\n",
            " [0.49867612]\n",
            " [0.4995082 ]\n",
            " [0.49392647]]\n",
            "Step: 127 -> Loss: 0.6935747265815735 -> Predictions: [[0.50500214]\n",
            " [0.49868384]\n",
            " [0.49951363]\n",
            " [0.49398732]]\n",
            "Step: 128 -> Loss: 0.693568229675293 -> Predictions: [[0.5049431 ]\n",
            " [0.4986914 ]\n",
            " [0.49951887]\n",
            " [0.49404758]]\n",
            "Step: 129 -> Loss: 0.6935617923736572 -> Predictions: [[0.50488454]\n",
            " [0.4986989 ]\n",
            " [0.4995241 ]\n",
            " [0.49410737]]\n",
            "Step: 130 -> Loss: 0.693555474281311 -> Predictions: [[0.50482655]\n",
            " [0.49870637]\n",
            " [0.49952927]\n",
            " [0.49416658]]\n",
            "Step: 131 -> Loss: 0.6935492753982544 -> Predictions: [[0.5047691 ]\n",
            " [0.4987137 ]\n",
            " [0.49953434]\n",
            " [0.49422526]]\n",
            "Step: 132 -> Loss: 0.6935431361198425 -> Predictions: [[0.50471216]\n",
            " [0.49872094]\n",
            " [0.49953938]\n",
            " [0.49428344]]\n",
            "Step: 133 -> Loss: 0.6935371160507202 -> Predictions: [[0.5046558 ]\n",
            " [0.49872813]\n",
            " [0.49954432]\n",
            " [0.49434108]]\n",
            "Step: 134 -> Loss: 0.6935311555862427 -> Predictions: [[0.50459987]\n",
            " [0.4987352 ]\n",
            " [0.4995492 ]\n",
            " [0.4943983 ]]\n",
            "Step: 135 -> Loss: 0.6935253143310547 -> Predictions: [[0.5045445 ]\n",
            " [0.49874216]\n",
            " [0.49955395]\n",
            " [0.49445495]]\n",
            "Step: 136 -> Loss: 0.6935195922851562 -> Predictions: [[0.5044896 ]\n",
            " [0.4987491 ]\n",
            " [0.49955872]\n",
            " [0.49451107]]\n",
            "Step: 137 -> Loss: 0.6935138702392578 -> Predictions: [[0.5044352 ]\n",
            " [0.49875593]\n",
            " [0.49956343]\n",
            " [0.49456677]]\n",
            "Step: 138 -> Loss: 0.6935083270072937 -> Predictions: [[0.5043813 ]\n",
            " [0.4987627 ]\n",
            " [0.49956802]\n",
            " [0.49462193]]\n",
            "Step: 139 -> Loss: 0.6935028433799744 -> Predictions: [[0.5043279 ]\n",
            " [0.4987694 ]\n",
            " [0.49957258]\n",
            " [0.4946767 ]]\n",
            "Step: 140 -> Loss: 0.6934974193572998 -> Predictions: [[0.5042749 ]\n",
            " [0.498776  ]\n",
            " [0.49957705]\n",
            " [0.49473098]]\n",
            "Step: 141 -> Loss: 0.69349205493927 -> Predictions: [[0.5042224 ]\n",
            " [0.49878252]\n",
            " [0.49958158]\n",
            " [0.49478483]]\n",
            "Step: 142 -> Loss: 0.6934868097305298 -> Predictions: [[0.50417036]\n",
            " [0.49878898]\n",
            " [0.49958593]\n",
            " [0.4948382 ]]\n",
            "Step: 143 -> Loss: 0.6934816241264343 -> Predictions: [[0.50411874]\n",
            " [0.49879533]\n",
            " [0.49959025]\n",
            " [0.49489117]]\n",
            "Step: 144 -> Loss: 0.6934764981269836 -> Predictions: [[0.5040676 ]\n",
            " [0.49880162]\n",
            " [0.49959454]\n",
            " [0.49494365]]\n",
            "Step: 145 -> Loss: 0.6934715509414673 -> Predictions: [[0.5040168 ]\n",
            " [0.4988079 ]\n",
            " [0.4995987 ]\n",
            " [0.49499577]]\n",
            "Step: 146 -> Loss: 0.6934665441513062 -> Predictions: [[0.5039665 ]\n",
            " [0.49881402]\n",
            " [0.49960288]\n",
            " [0.49504742]]\n",
            "Step: 147 -> Loss: 0.6934616565704346 -> Predictions: [[0.5039166 ]\n",
            " [0.49882013]\n",
            " [0.49960697]\n",
            " [0.4950986 ]]\n",
            "Step: 148 -> Loss: 0.6934568881988525 -> Predictions: [[0.5038671 ]\n",
            " [0.49882606]\n",
            " [0.49961102]\n",
            " [0.49514943]]\n",
            "Step: 149 -> Loss: 0.6934521198272705 -> Predictions: [[0.50381804]\n",
            " [0.498832  ]\n",
            " [0.499615  ]\n",
            " [0.49519983]]\n",
            "Step: 150 -> Loss: 0.6934474110603333 -> Predictions: [[0.50376934]\n",
            " [0.49883792]\n",
            " [0.499619  ]\n",
            " [0.4952499 ]]\n",
            "Step: 151 -> Loss: 0.6934428215026855 -> Predictions: [[0.50372106]\n",
            " [0.49884367]\n",
            " [0.49962288]\n",
            " [0.49529955]]\n",
            "Step: 152 -> Loss: 0.6934382915496826 -> Predictions: [[0.50367314]\n",
            " [0.49884942]\n",
            " [0.4996268 ]\n",
            " [0.49534878]]\n",
            "Step: 153 -> Loss: 0.6934338212013245 -> Predictions: [[0.50362563]\n",
            " [0.49885505]\n",
            " [0.4996306 ]\n",
            " [0.49539766]]\n",
            "Step: 154 -> Loss: 0.6934294700622559 -> Predictions: [[0.5035785 ]\n",
            " [0.4988607 ]\n",
            " [0.49963436]\n",
            " [0.49544615]]\n",
            "Step: 155 -> Loss: 0.6934250593185425 -> Predictions: [[0.5035317 ]\n",
            " [0.49886614]\n",
            " [0.4996381 ]\n",
            " [0.49549428]]\n",
            "Step: 156 -> Loss: 0.6934207677841187 -> Predictions: [[0.50348526]\n",
            " [0.49887162]\n",
            " [0.4996418 ]\n",
            " [0.49554205]]\n",
            "Step: 157 -> Loss: 0.6934165954589844 -> Predictions: [[0.5034392 ]\n",
            " [0.49887708]\n",
            " [0.49964535]\n",
            " [0.4955894 ]]\n",
            "Step: 158 -> Loss: 0.6934124231338501 -> Predictions: [[0.5033935]\n",
            " [0.4988824]\n",
            " [0.499649 ]\n",
            " [0.4956365]]\n",
            "Step: 159 -> Loss: 0.6934083104133606 -> Predictions: [[0.5033481 ]\n",
            " [0.49888763]\n",
            " [0.49965256]\n",
            " [0.49568316]]\n",
            "Step: 160 -> Loss: 0.6934042572975159 -> Predictions: [[0.50330305]\n",
            " [0.49889284]\n",
            " [0.49965608]\n",
            " [0.4957295 ]]\n",
            "Step: 161 -> Loss: 0.6934001445770264 -> Predictions: [[0.50325835]\n",
            " [0.49889797]\n",
            " [0.49965954]\n",
            " [0.49577558]]\n",
            "Step: 162 -> Loss: 0.6933962106704712 -> Predictions: [[0.50321394]\n",
            " [0.49890307]\n",
            " [0.499663  ]\n",
            " [0.49582124]]\n",
            "Step: 163 -> Loss: 0.6933923363685608 -> Predictions: [[0.5031699 ]\n",
            " [0.4989081 ]\n",
            " [0.49966636]\n",
            " [0.4958666 ]]\n",
            "Step: 164 -> Loss: 0.6933885216712952 -> Predictions: [[0.5031262 ]\n",
            " [0.49891302]\n",
            " [0.49966976]\n",
            " [0.49591163]]\n",
            "Step: 165 -> Loss: 0.6933847665786743 -> Predictions: [[0.50308275]\n",
            " [0.49891803]\n",
            " [0.4996731 ]\n",
            " [0.49595636]]\n",
            "Step: 166 -> Loss: 0.6933810114860535 -> Predictions: [[0.50303966]\n",
            " [0.49892282]\n",
            " [0.49967638]\n",
            " [0.4960007 ]]\n",
            "Step: 167 -> Loss: 0.6933773159980774 -> Predictions: [[0.50299686]\n",
            " [0.49892762]\n",
            " [0.49967965]\n",
            " [0.4960448 ]]\n",
            "Step: 168 -> Loss: 0.6933736801147461 -> Predictions: [[0.50295436]\n",
            " [0.4989324 ]\n",
            " [0.49968287]\n",
            " [0.4960886 ]]\n",
            "Step: 169 -> Loss: 0.6933701038360596 -> Predictions: [[0.50291216]\n",
            " [0.498937  ]\n",
            " [0.4996861 ]\n",
            " [0.49613208]]\n",
            "Step: 170 -> Loss: 0.693366527557373 -> Predictions: [[0.50287026]\n",
            " [0.49894163]\n",
            " [0.49968916]\n",
            " [0.49617526]]\n",
            "Step: 171 -> Loss: 0.6933630108833313 -> Predictions: [[0.5028286 ]\n",
            " [0.49894622]\n",
            " [0.49969232]\n",
            " [0.49621817]]\n",
            "Step: 172 -> Loss: 0.6933596134185791 -> Predictions: [[0.5027873 ]\n",
            " [0.49895072]\n",
            " [0.49969542]\n",
            " [0.49626073]]\n",
            "Step: 173 -> Loss: 0.6933561563491821 -> Predictions: [[0.5027462 ]\n",
            " [0.49895516]\n",
            " [0.49969846]\n",
            " [0.49630308]]\n",
            "Step: 174 -> Loss: 0.6933528184890747 -> Predictions: [[0.5027054 ]\n",
            " [0.49895957]\n",
            " [0.49970156]\n",
            " [0.49634513]]\n",
            "Step: 175 -> Loss: 0.6933494806289673 -> Predictions: [[0.50266486]\n",
            " [0.4989639 ]\n",
            " [0.49970454]\n",
            " [0.49638683]]\n",
            "Step: 176 -> Loss: 0.6933462023735046 -> Predictions: [[0.5026246 ]\n",
            " [0.49896824]\n",
            " [0.49970752]\n",
            " [0.4964283 ]]\n",
            "Step: 177 -> Loss: 0.693342924118042 -> Predictions: [[0.5025846 ]\n",
            " [0.49897245]\n",
            " [0.4997105 ]\n",
            " [0.49646956]]\n",
            "Step: 178 -> Loss: 0.6933397650718689 -> Predictions: [[0.5025448 ]\n",
            " [0.49897665]\n",
            " [0.49971336]\n",
            " [0.49651048]]\n",
            "Step: 179 -> Loss: 0.6933366060256958 -> Predictions: [[0.50250536]\n",
            " [0.49898076]\n",
            " [0.49971625]\n",
            " [0.49655116]]\n",
            "Step: 180 -> Loss: 0.6933333873748779 -> Predictions: [[0.5024661 ]\n",
            " [0.49898484]\n",
            " [0.4997191 ]\n",
            " [0.4965916 ]]\n",
            "Step: 181 -> Loss: 0.6933303475379944 -> Predictions: [[0.5024271 ]\n",
            " [0.4989889 ]\n",
            " [0.49972197]\n",
            " [0.4966318 ]]\n",
            "Step: 182 -> Loss: 0.6933273077011108 -> Predictions: [[0.5023883 ]\n",
            " [0.49899286]\n",
            " [0.49972478]\n",
            " [0.49667174]]\n",
            "Step: 183 -> Loss: 0.6933243274688721 -> Predictions: [[0.50234973]\n",
            " [0.4989968 ]\n",
            " [0.49972758]\n",
            " [0.49671146]]\n",
            "Step: 184 -> Loss: 0.6933213472366333 -> Predictions: [[0.50231147]\n",
            " [0.49900064]\n",
            " [0.49973032]\n",
            " [0.49675086]]\n",
            "Step: 185 -> Loss: 0.6933183670043945 -> Predictions: [[0.50227344]\n",
            " [0.49900457]\n",
            " [0.49973312]\n",
            " [0.49679005]]\n",
            "Step: 186 -> Loss: 0.6933155059814453 -> Predictions: [[0.50223553]\n",
            " [0.49900836]\n",
            " [0.4997358 ]\n",
            " [0.496829  ]]\n",
            "Step: 187 -> Loss: 0.6933125853538513 -> Predictions: [[0.5021979 ]\n",
            " [0.49901205]\n",
            " [0.49973848]\n",
            " [0.49686775]]\n",
            "Step: 188 -> Loss: 0.6933097839355469 -> Predictions: [[0.50216055]\n",
            " [0.49901572]\n",
            " [0.49974114]\n",
            " [0.49690628]]\n",
            "Step: 189 -> Loss: 0.6933069825172424 -> Predictions: [[0.50212336]\n",
            " [0.4990194 ]\n",
            " [0.49974382]\n",
            " [0.49694455]]\n",
            "Step: 190 -> Loss: 0.693304181098938 -> Predictions: [[0.50208634]\n",
            " [0.49902296]\n",
            " [0.49974644]\n",
            " [0.4969826 ]]\n",
            "Step: 191 -> Loss: 0.6933014392852783 -> Predictions: [[0.50204957]\n",
            " [0.49902654]\n",
            " [0.49974906]\n",
            " [0.49702045]]\n",
            "Step: 192 -> Loss: 0.6932986974716187 -> Predictions: [[0.50201297]\n",
            " [0.49903008]\n",
            " [0.49975157]\n",
            " [0.49705803]]\n",
            "Step: 193 -> Loss: 0.6932960748672485 -> Predictions: [[0.50197667]\n",
            " [0.49903354]\n",
            " [0.4997542 ]\n",
            " [0.4970955 ]]\n",
            "Step: 194 -> Loss: 0.6932933926582336 -> Predictions: [[0.5019404 ]\n",
            " [0.49903697]\n",
            " [0.4997567 ]\n",
            " [0.49713263]]\n",
            "Step: 195 -> Loss: 0.6932907700538635 -> Predictions: [[0.5019045 ]\n",
            " [0.4990403 ]\n",
            " [0.49975926]\n",
            " [0.49716964]]\n",
            "Step: 196 -> Loss: 0.6932881474494934 -> Predictions: [[0.50186867]\n",
            " [0.4990436 ]\n",
            " [0.49976176]\n",
            " [0.49720642]]\n",
            "Step: 197 -> Loss: 0.6932855844497681 -> Predictions: [[0.5018331 ]\n",
            " [0.49904695]\n",
            " [0.4997642 ]\n",
            " [0.49724308]]\n",
            "Step: 198 -> Loss: 0.6932830810546875 -> Predictions: [[0.5017977 ]\n",
            " [0.49905017]\n",
            " [0.4997667 ]\n",
            " [0.49727944]]\n",
            "Step: 199 -> Loss: 0.6932805776596069 -> Predictions: [[0.50176245]\n",
            " [0.49905336]\n",
            " [0.49976915]\n",
            " [0.4973156 ]]\n",
            "Step: 200 -> Loss: 0.6932780742645264 -> Predictions: [[0.5017274 ]\n",
            " [0.49905658]\n",
            " [0.4997716 ]\n",
            " [0.49735168]]\n",
            "Step: 201 -> Loss: 0.6932755708694458 -> Predictions: [[0.50169253]\n",
            " [0.49905965]\n",
            " [0.49977395]\n",
            " [0.4973874 ]]\n",
            "Step: 202 -> Loss: 0.6932731866836548 -> Predictions: [[0.5016578 ]\n",
            " [0.49906275]\n",
            " [0.49977633]\n",
            " [0.49742305]]\n",
            "Step: 203 -> Loss: 0.6932708024978638 -> Predictions: [[0.5016233 ]\n",
            " [0.49906585]\n",
            " [0.49977872]\n",
            " [0.49745858]]\n",
            "Step: 204 -> Loss: 0.6932684183120728 -> Predictions: [[0.5015889]\n",
            " [0.4990688]\n",
            " [0.4997811]\n",
            " [0.4974938]]\n",
            "Step: 205 -> Loss: 0.6932660341262817 -> Predictions: [[0.50155467]\n",
            " [0.49907178]\n",
            " [0.4997835 ]\n",
            " [0.4975289 ]]\n",
            "Step: 206 -> Loss: 0.6932637691497803 -> Predictions: [[0.50152063]\n",
            " [0.4990747 ]\n",
            " [0.4997858 ]\n",
            " [0.49756384]]\n",
            "Step: 207 -> Loss: 0.6932613849639893 -> Predictions: [[0.5014867 ]\n",
            " [0.4990776 ]\n",
            " [0.49978814]\n",
            " [0.49759856]]\n",
            "Step: 208 -> Loss: 0.6932591199874878 -> Predictions: [[0.501453  ]\n",
            " [0.4990804 ]\n",
            " [0.4997904 ]\n",
            " [0.49763316]]\n",
            "Step: 209 -> Loss: 0.6932568550109863 -> Predictions: [[0.50141937]\n",
            " [0.4990832 ]\n",
            " [0.49979267]\n",
            " [0.49766752]]\n",
            "Step: 210 -> Loss: 0.6932546496391296 -> Predictions: [[0.501386  ]\n",
            " [0.4990859 ]\n",
            " [0.49979493]\n",
            " [0.49770176]]\n",
            "Step: 211 -> Loss: 0.693252444267273 -> Predictions: [[0.50135267]\n",
            " [0.49908864]\n",
            " [0.4997972 ]\n",
            " [0.49773586]]\n",
            "Step: 212 -> Loss: 0.6932502388954163 -> Predictions: [[0.5013195 ]\n",
            " [0.4990914 ]\n",
            " [0.49979946]\n",
            " [0.49776974]]\n",
            "Step: 213 -> Loss: 0.6932480335235596 -> Predictions: [[0.50128657]\n",
            " [0.49909398]\n",
            " [0.49980173]\n",
            " [0.49780348]]\n",
            "Step: 214 -> Loss: 0.6932458877563477 -> Predictions: [[0.5012537 ]\n",
            " [0.4990966 ]\n",
            " [0.49980393]\n",
            " [0.4978371 ]]\n",
            "Step: 215 -> Loss: 0.6932437419891357 -> Predictions: [[0.501221  ]\n",
            " [0.49909922]\n",
            " [0.49980614]\n",
            " [0.49787062]]\n",
            "Step: 216 -> Loss: 0.6932416558265686 -> Predictions: [[0.5011884 ]\n",
            " [0.4991017 ]\n",
            " [0.49980825]\n",
            " [0.49790388]]\n",
            "Step: 217 -> Loss: 0.6932395100593567 -> Predictions: [[0.501156  ]\n",
            " [0.4991042 ]\n",
            " [0.49981046]\n",
            " [0.49793705]]\n",
            "Step: 218 -> Loss: 0.6932374238967896 -> Predictions: [[0.5011236 ]\n",
            " [0.4991067 ]\n",
            " [0.49981266]\n",
            " [0.49797004]]\n",
            "Step: 219 -> Loss: 0.6932353973388672 -> Predictions: [[0.5010914 ]\n",
            " [0.49910912]\n",
            " [0.4998148 ]\n",
            " [0.49800292]]\n",
            "Step: 220 -> Loss: 0.6932333707809448 -> Predictions: [[0.50105935]\n",
            " [0.49911156]\n",
            " [0.49981695]\n",
            " [0.49803567]]\n",
            "Step: 221 -> Loss: 0.6932313442230225 -> Predictions: [[0.5010274 ]\n",
            " [0.4991139 ]\n",
            " [0.49981904]\n",
            " [0.49806824]]\n",
            "Step: 222 -> Loss: 0.6932293176651001 -> Predictions: [[0.5009956 ]\n",
            " [0.4991162 ]\n",
            " [0.49982113]\n",
            " [0.49810073]]\n",
            "Step: 223 -> Loss: 0.6932273507118225 -> Predictions: [[0.50096387]\n",
            " [0.4991185 ]\n",
            " [0.49982327]\n",
            " [0.49813303]]\n",
            "Step: 224 -> Loss: 0.6932253837585449 -> Predictions: [[0.5009322 ]\n",
            " [0.49912077]\n",
            " [0.49982536]\n",
            " [0.49816522]]\n",
            "Step: 225 -> Loss: 0.6932234168052673 -> Predictions: [[0.50090075]\n",
            " [0.49912298]\n",
            " [0.49982744]\n",
            " [0.4981973 ]]\n",
            "Step: 226 -> Loss: 0.6932214498519897 -> Predictions: [[0.5008694 ]\n",
            " [0.4991252 ]\n",
            " [0.49982947]\n",
            " [0.49822924]]\n",
            "Step: 227 -> Loss: 0.6932195425033569 -> Predictions: [[0.50083816]\n",
            " [0.49912736]\n",
            " [0.49983156]\n",
            " [0.49826103]]\n",
            "Step: 228 -> Loss: 0.6932176947593689 -> Predictions: [[0.5008069 ]\n",
            " [0.4991295 ]\n",
            " [0.49983364]\n",
            " [0.49829268]]\n",
            "Step: 229 -> Loss: 0.6932157874107361 -> Predictions: [[0.5007759 ]\n",
            " [0.4991316 ]\n",
            " [0.49983567]\n",
            " [0.4983243 ]]\n",
            "Step: 230 -> Loss: 0.6932138800621033 -> Predictions: [[0.50074494]\n",
            " [0.49913365]\n",
            " [0.4998377 ]\n",
            " [0.49835575]]\n",
            "Step: 231 -> Loss: 0.6932120323181152 -> Predictions: [[0.50071406]\n",
            " [0.49913567]\n",
            " [0.49983972]\n",
            " [0.49838707]]\n",
            "Step: 232 -> Loss: 0.6932101845741272 -> Predictions: [[0.50068337]\n",
            " [0.4991377 ]\n",
            " [0.49984175]\n",
            " [0.49841833]]\n",
            "Step: 233 -> Loss: 0.6932083368301392 -> Predictions: [[0.5006527 ]\n",
            " [0.49913967]\n",
            " [0.49984372]\n",
            " [0.4984494 ]]\n",
            "Step: 234 -> Loss: 0.6932065486907959 -> Predictions: [[0.5006221 ]\n",
            " [0.49914163]\n",
            " [0.49984568]\n",
            " [0.4984804 ]]\n",
            "Step: 235 -> Loss: 0.6932046413421631 -> Predictions: [[0.50059164]\n",
            " [0.4991435 ]\n",
            " [0.4998477 ]\n",
            " [0.49851128]]\n",
            "Step: 236 -> Loss: 0.6932029128074646 -> Predictions: [[0.50056124]\n",
            " [0.49914542]\n",
            " [0.49984968]\n",
            " [0.49854204]]\n",
            "Step: 237 -> Loss: 0.6932011842727661 -> Predictions: [[0.5005309 ]\n",
            " [0.4991472 ]\n",
            " [0.4998516 ]\n",
            " [0.49857274]]\n",
            "Step: 238 -> Loss: 0.6931993365287781 -> Predictions: [[0.5005007 ]\n",
            " [0.49914905]\n",
            " [0.49985352]\n",
            " [0.4986033 ]]\n",
            "Step: 239 -> Loss: 0.6931975483894348 -> Predictions: [[0.5004705]\n",
            " [0.4991508]\n",
            " [0.4998555]\n",
            " [0.4986338]]\n",
            "Step: 240 -> Loss: 0.6931958198547363 -> Predictions: [[0.5004405 ]\n",
            " [0.4991526 ]\n",
            " [0.49985746]\n",
            " [0.4986642 ]]\n",
            "Step: 241 -> Loss: 0.6931941509246826 -> Predictions: [[0.5004105 ]\n",
            " [0.49915433]\n",
            " [0.49985936]\n",
            " [0.4986945 ]]\n",
            "Step: 242 -> Loss: 0.6931923627853394 -> Predictions: [[0.5003806 ]\n",
            " [0.49915606]\n",
            " [0.49986127]\n",
            " [0.4987246 ]]\n",
            "Step: 243 -> Loss: 0.6931906938552856 -> Predictions: [[0.5003508 ]\n",
            " [0.49915773]\n",
            " [0.49986318]\n",
            " [0.49875474]]\n",
            "Step: 244 -> Loss: 0.6931889057159424 -> Predictions: [[0.500321  ]\n",
            " [0.4991594 ]\n",
            " [0.49986508]\n",
            " [0.49878475]]\n",
            "Step: 245 -> Loss: 0.6931872367858887 -> Predictions: [[0.50029135]\n",
            " [0.49916098]\n",
            " [0.499867  ]\n",
            " [0.49881467]]\n",
            "Step: 246 -> Loss: 0.693185567855835 -> Predictions: [[0.5002617 ]\n",
            " [0.49916258]\n",
            " [0.4998689 ]\n",
            " [0.4988445 ]]\n",
            "Step: 247 -> Loss: 0.693183958530426 -> Predictions: [[0.50023216]\n",
            " [0.4991642 ]\n",
            " [0.4998708 ]\n",
            " [0.49887422]]\n",
            "Step: 248 -> Loss: 0.6931822299957275 -> Predictions: [[0.50020266]\n",
            " [0.49916574]\n",
            " [0.49987265]\n",
            " [0.4989039 ]]\n",
            "Step: 249 -> Loss: 0.6931806206703186 -> Predictions: [[0.5001733 ]\n",
            " [0.49916723]\n",
            " [0.4998745 ]\n",
            " [0.4989335 ]]\n",
            "Step: 250 -> Loss: 0.6931790113449097 -> Predictions: [[0.5001439]\n",
            " [0.4991687]\n",
            " [0.4998764]\n",
            " [0.498963 ]]\n",
            "Step: 251 -> Loss: 0.693177342414856 -> Predictions: [[0.50011456]\n",
            " [0.49917012]\n",
            " [0.4998782 ]\n",
            " [0.49899244]]\n",
            "Step: 252 -> Loss: 0.693175733089447 -> Predictions: [[0.50008535]\n",
            " [0.4991716 ]\n",
            " [0.4998801 ]\n",
            " [0.49902177]]\n",
            "Step: 253 -> Loss: 0.6931741237640381 -> Predictions: [[0.50005615]\n",
            " [0.499173  ]\n",
            " [0.4998819 ]\n",
            " [0.499051  ]]\n",
            "Step: 254 -> Loss: 0.6931725740432739 -> Predictions: [[0.50002706]\n",
            " [0.49917442]\n",
            " [0.49988374]\n",
            " [0.4990802 ]]\n",
            "Step: 255 -> Loss: 0.6931709051132202 -> Predictions: [[0.49999797]\n",
            " [0.4991758 ]\n",
            " [0.4998856 ]\n",
            " [0.49910936]]\n",
            "Step: 256 -> Loss: 0.6931692957878113 -> Predictions: [[0.4999689 ]\n",
            " [0.49917716]\n",
            " [0.49988738]\n",
            " [0.4991384 ]]\n",
            "Step: 257 -> Loss: 0.6931676864624023 -> Predictions: [[0.49993992]\n",
            " [0.49917844]\n",
            " [0.49988917]\n",
            " [0.4991674 ]]\n",
            "Step: 258 -> Loss: 0.6931661367416382 -> Predictions: [[0.49991098]\n",
            " [0.49917975]\n",
            " [0.49989095]\n",
            " [0.49919632]]\n",
            "Step: 259 -> Loss: 0.693164587020874 -> Predictions: [[0.49988213]\n",
            " [0.499181  ]\n",
            " [0.4998928 ]\n",
            " [0.49922514]]\n",
            "Step: 260 -> Loss: 0.6931630969047546 -> Predictions: [[0.49985328]\n",
            " [0.49918225]\n",
            " [0.4998946 ]\n",
            " [0.49925402]]\n",
            "Step: 261 -> Loss: 0.6931614875793457 -> Predictions: [[0.49982446]\n",
            " [0.49918345]\n",
            " [0.49989638]\n",
            " [0.49928275]]\n",
            "Step: 262 -> Loss: 0.6931599378585815 -> Predictions: [[0.49979565]\n",
            " [0.49918464]\n",
            " [0.49989817]\n",
            " [0.49931145]]\n",
            "Step: 263 -> Loss: 0.6931583881378174 -> Predictions: [[0.49976695]\n",
            " [0.49918583]\n",
            " [0.4998999 ]\n",
            " [0.49934003]]\n",
            "Step: 264 -> Loss: 0.6931568384170532 -> Predictions: [[0.49973825]\n",
            " [0.499187  ]\n",
            " [0.49990168]\n",
            " [0.49936864]]\n",
            "Step: 265 -> Loss: 0.6931552886962891 -> Predictions: [[0.4997096 ]\n",
            " [0.49918813]\n",
            " [0.49990347]\n",
            " [0.4993971 ]]\n",
            "Step: 266 -> Loss: 0.6931537389755249 -> Predictions: [[0.49968097]\n",
            " [0.49918926]\n",
            " [0.49990526]\n",
            " [0.4994256 ]]\n",
            "Step: 267 -> Loss: 0.6931521892547607 -> Predictions: [[0.4996524 ]\n",
            " [0.49919033]\n",
            " [0.49990693]\n",
            " [0.49945396]]\n",
            "Step: 268 -> Loss: 0.6931507587432861 -> Predictions: [[0.49962384]\n",
            " [0.4991914 ]\n",
            " [0.49990872]\n",
            " [0.49948233]]\n",
            "Step: 269 -> Loss: 0.693149209022522 -> Predictions: [[0.49959525]\n",
            " [0.49919248]\n",
            " [0.49991044]\n",
            " [0.49951065]]\n",
            "Step: 270 -> Loss: 0.6931477189064026 -> Predictions: [[0.49956676]\n",
            " [0.4991935 ]\n",
            " [0.49991217]\n",
            " [0.4995389 ]]\n",
            "Step: 271 -> Loss: 0.6931461691856384 -> Predictions: [[0.49953824]\n",
            " [0.4991945 ]\n",
            " [0.49991393]\n",
            " [0.49956712]]\n",
            "Step: 272 -> Loss: 0.693144679069519 -> Predictions: [[0.4995098 ]\n",
            " [0.49919546]\n",
            " [0.4999156 ]\n",
            " [0.49959525]]\n",
            "Step: 273 -> Loss: 0.6931432485580444 -> Predictions: [[0.49948138]\n",
            " [0.49919644]\n",
            " [0.49991733]\n",
            " [0.49962348]]\n",
            "Step: 274 -> Loss: 0.6931416988372803 -> Predictions: [[0.4994529 ]\n",
            " [0.49919733]\n",
            " [0.49991906]\n",
            " [0.49965155]]\n",
            "Step: 275 -> Loss: 0.6931402087211609 -> Predictions: [[0.49942452]\n",
            " [0.4991983 ]\n",
            " [0.49992073]\n",
            " [0.49967954]]\n",
            "Step: 276 -> Loss: 0.6931387782096863 -> Predictions: [[0.49939612]\n",
            " [0.49919918]\n",
            " [0.4999224 ]\n",
            " [0.49970758]]\n",
            "Step: 277 -> Loss: 0.6931372880935669 -> Predictions: [[0.49936768]\n",
            " [0.49920008]\n",
            " [0.49992412]\n",
            " [0.49973562]]\n",
            "Step: 278 -> Loss: 0.6931357979774475 -> Predictions: [[0.49933937]\n",
            " [0.49920097]\n",
            " [0.49992585]\n",
            " [0.4997635 ]]\n",
            "Step: 279 -> Loss: 0.6931343078613281 -> Predictions: [[0.49931097]\n",
            " [0.49920186]\n",
            " [0.49992752]\n",
            " [0.49979147]]\n",
            "Step: 280 -> Loss: 0.6931328773498535 -> Predictions: [[0.4992827 ]\n",
            " [0.4992027 ]\n",
            " [0.4999292 ]\n",
            " [0.49981934]]\n",
            "Step: 281 -> Loss: 0.6931313276290894 -> Predictions: [[0.49925426]\n",
            " [0.49920347]\n",
            " [0.49993086]\n",
            " [0.49984723]]\n",
            "Step: 282 -> Loss: 0.6931298971176147 -> Predictions: [[0.49922597]\n",
            " [0.49920425]\n",
            " [0.49993253]\n",
            " [0.49987498]]\n",
            "Step: 283 -> Loss: 0.6931284070014954 -> Predictions: [[0.49919763]\n",
            " [0.49920505]\n",
            " [0.4999342 ]\n",
            " [0.4999028 ]]\n",
            "Step: 284 -> Loss: 0.6931269764900208 -> Predictions: [[0.4991693 ]\n",
            " [0.49920577]\n",
            " [0.49993587]\n",
            " [0.49993062]]\n",
            "Step: 285 -> Loss: 0.6931254863739014 -> Predictions: [[0.49914098]\n",
            " [0.49920648]\n",
            " [0.49993753]\n",
            " [0.49995834]]\n",
            "Step: 286 -> Loss: 0.693123996257782 -> Predictions: [[0.49911264]\n",
            " [0.49920726]\n",
            " [0.49993914]\n",
            " [0.49998605]]\n",
            "Step: 287 -> Loss: 0.6931226253509521 -> Predictions: [[0.4990843 ]\n",
            " [0.4992079 ]\n",
            " [0.49994075]\n",
            " [0.50001377]]\n",
            "Step: 288 -> Loss: 0.6931211352348328 -> Predictions: [[0.49905598]\n",
            " [0.49920863]\n",
            " [0.49994242]\n",
            " [0.5000415 ]]\n",
            "Step: 289 -> Loss: 0.6931196451187134 -> Predictions: [[0.4990276 ]\n",
            " [0.49920934]\n",
            " [0.4999441 ]\n",
            " [0.50006914]]\n",
            "Step: 290 -> Loss: 0.6931182146072388 -> Predictions: [[0.49899927]\n",
            " [0.49921   ]\n",
            " [0.49994564]\n",
            " [0.5000968 ]]\n",
            "Step: 291 -> Loss: 0.6931167244911194 -> Predictions: [[0.49897096]\n",
            " [0.49921066]\n",
            " [0.4999473 ]\n",
            " [0.5001245 ]]\n",
            "Step: 292 -> Loss: 0.6931152939796448 -> Predictions: [[0.49894258]\n",
            " [0.49921125]\n",
            " [0.49994892]\n",
            " [0.5001521 ]]\n",
            "Step: 293 -> Loss: 0.6931138634681702 -> Predictions: [[0.4989142 ]\n",
            " [0.49921185]\n",
            " [0.49995053]\n",
            " [0.50017977]]\n",
            "Step: 294 -> Loss: 0.6931123733520508 -> Predictions: [[0.49888578]\n",
            " [0.4992125 ]\n",
            " [0.49995214]\n",
            " [0.50020736]]\n",
            "Step: 295 -> Loss: 0.6931109428405762 -> Predictions: [[0.49885738]\n",
            " [0.49921304]\n",
            " [0.49995375]\n",
            " [0.50023496]]\n",
            "Step: 296 -> Loss: 0.6931094527244568 -> Predictions: [[0.49882895]\n",
            " [0.49921364]\n",
            " [0.49995536]\n",
            " [0.50026256]]\n",
            "Step: 297 -> Loss: 0.6931080222129822 -> Predictions: [[0.49880055]\n",
            " [0.49921423]\n",
            " [0.49995697]\n",
            " [0.50029016]]\n",
            "Step: 298 -> Loss: 0.6931065320968628 -> Predictions: [[0.49877205]\n",
            " [0.49921474]\n",
            " [0.49995852]\n",
            " [0.50031775]]\n",
            "Step: 299 -> Loss: 0.6931051015853882 -> Predictions: [[0.4987436 ]\n",
            " [0.49921528]\n",
            " [0.49996012]\n",
            " [0.50034535]]\n",
            "Step: 300 -> Loss: 0.6931036710739136 -> Predictions: [[0.498715  ]\n",
            " [0.49921575]\n",
            " [0.49996173]\n",
            " [0.50037295]]\n",
            "Step: 301 -> Loss: 0.6931021809577942 -> Predictions: [[0.49868655]\n",
            " [0.49921623]\n",
            " [0.49996328]\n",
            " [0.5004005 ]]\n",
            "Step: 302 -> Loss: 0.6931006908416748 -> Predictions: [[0.49865797]\n",
            " [0.49921677]\n",
            " [0.49996483]\n",
            " [0.50042814]]\n",
            "Step: 303 -> Loss: 0.6930992603302002 -> Predictions: [[0.4986294 ]\n",
            " [0.49921724]\n",
            " [0.49996638]\n",
            " [0.50045574]]\n",
            "Step: 304 -> Loss: 0.693097710609436 -> Predictions: [[0.49860072]\n",
            " [0.49921766]\n",
            " [0.49996793]\n",
            " [0.50048333]]\n",
            "Step: 305 -> Loss: 0.6930962800979614 -> Predictions: [[0.49857208]\n",
            " [0.49921814]\n",
            " [0.49996954]\n",
            " [0.50051093]]\n",
            "Step: 306 -> Loss: 0.693094789981842 -> Predictions: [[0.49854347]\n",
            " [0.4992186 ]\n",
            " [0.4999711 ]\n",
            " [0.5005386 ]]\n",
            "Step: 307 -> Loss: 0.6930933594703674 -> Predictions: [[0.49851465]\n",
            " [0.49921903]\n",
            " [0.49997264]\n",
            " [0.5005662 ]]\n",
            "Step: 308 -> Loss: 0.693091869354248 -> Predictions: [[0.49848598]\n",
            " [0.49921945]\n",
            " [0.4999742 ]\n",
            " [0.50059384]]\n",
            "Step: 309 -> Loss: 0.6930903196334839 -> Predictions: [[0.4984572 ]\n",
            " [0.49921986]\n",
            " [0.49997574]\n",
            " [0.50062144]]\n",
            "Step: 310 -> Loss: 0.6930888891220093 -> Predictions: [[0.4984283 ]\n",
            " [0.49922028]\n",
            " [0.49997723]\n",
            " [0.50064915]]\n",
            "Step: 311 -> Loss: 0.6930874586105347 -> Predictions: [[0.49839944]\n",
            " [0.49922064]\n",
            " [0.49997878]\n",
            " [0.5006768 ]]\n",
            "Step: 312 -> Loss: 0.6930859088897705 -> Predictions: [[0.49837056]\n",
            " [0.499221  ]\n",
            " [0.49998033]\n",
            " [0.5007045 ]]\n",
            "Step: 313 -> Loss: 0.6930844187736511 -> Predictions: [[0.4983416 ]\n",
            " [0.49922135]\n",
            " [0.49998188]\n",
            " [0.50073224]]\n",
            "Step: 314 -> Loss: 0.6930829286575317 -> Predictions: [[0.4983126 ]\n",
            " [0.4992217 ]\n",
            " [0.49998337]\n",
            " [0.50075996]]\n",
            "Step: 315 -> Loss: 0.6930814385414124 -> Predictions: [[0.4982835 ]\n",
            " [0.49922207]\n",
            " [0.49998486]\n",
            " [0.50078773]]\n",
            "Step: 316 -> Loss: 0.693079948425293 -> Predictions: [[0.4982544 ]\n",
            " [0.49922237]\n",
            " [0.4999864 ]\n",
            " [0.5008155 ]]\n",
            "Step: 317 -> Loss: 0.6930783987045288 -> Predictions: [[0.4982252 ]\n",
            " [0.49922267]\n",
            " [0.4999879 ]\n",
            " [0.5008433 ]]\n",
            "Step: 318 -> Loss: 0.6930768489837646 -> Predictions: [[0.49819604]\n",
            " [0.49922302]\n",
            " [0.4999894 ]\n",
            " [0.5008711 ]]\n",
            "Step: 319 -> Loss: 0.6930753588676453 -> Predictions: [[0.49816674]\n",
            " [0.49922332]\n",
            " [0.49999088]\n",
            " [0.500899  ]]\n",
            "Step: 320 -> Loss: 0.6930738687515259 -> Predictions: [[0.49813747]\n",
            " [0.49922362]\n",
            " [0.49999237]\n",
            " [0.5009269 ]]\n",
            "Step: 321 -> Loss: 0.6930722594261169 -> Predictions: [[0.49810806]\n",
            " [0.49922383]\n",
            " [0.49999386]\n",
            " [0.5009548 ]]\n",
            "Step: 322 -> Loss: 0.6930707693099976 -> Predictions: [[0.4980786 ]\n",
            " [0.49922413]\n",
            " [0.49999535]\n",
            " [0.50098276]]\n",
            "Step: 323 -> Loss: 0.6930692195892334 -> Predictions: [[0.49804914]\n",
            " [0.49922442]\n",
            " [0.49999678]\n",
            " [0.5010107 ]]\n",
            "Step: 324 -> Loss: 0.6930676698684692 -> Predictions: [[0.49801958]\n",
            " [0.49922466]\n",
            " [0.49999833]\n",
            " [0.5010388 ]]\n",
            "Step: 325 -> Loss: 0.6930661201477051 -> Predictions: [[0.4979899 ]\n",
            " [0.4992249 ]\n",
            " [0.49999976]\n",
            " [0.5010668 ]]\n",
            "Step: 326 -> Loss: 0.6930645704269409 -> Predictions: [[0.4979602 ]\n",
            " [0.49922514]\n",
            " [0.50000125]\n",
            " [0.50109494]]\n",
            "Step: 327 -> Loss: 0.6930630207061768 -> Predictions: [[0.4979305 ]\n",
            " [0.49922538]\n",
            " [0.5000027 ]\n",
            " [0.5011231 ]]\n",
            "Step: 328 -> Loss: 0.693061351776123 -> Predictions: [[0.49790064]\n",
            " [0.49922562]\n",
            " [0.5000042 ]\n",
            " [0.5011512 ]]\n",
            "Step: 329 -> Loss: 0.6930598020553589 -> Predictions: [[0.49787074]\n",
            " [0.49922585]\n",
            " [0.5000056 ]\n",
            " [0.50117946]]\n",
            "Step: 330 -> Loss: 0.6930582523345947 -> Predictions: [[0.49784076]\n",
            " [0.49922603]\n",
            " [0.50000703]\n",
            " [0.5012077 ]]\n",
            "Step: 331 -> Loss: 0.693056583404541 -> Predictions: [[0.4978107 ]\n",
            " [0.4992262 ]\n",
            " [0.50000846]\n",
            " [0.501236  ]]\n",
            "Step: 332 -> Loss: 0.6930550336837769 -> Predictions: [[0.49778056]\n",
            " [0.49922645]\n",
            " [0.50000995]\n",
            " [0.5012644 ]]\n",
            "Step: 333 -> Loss: 0.6930534243583679 -> Predictions: [[0.49775037]\n",
            " [0.4992267 ]\n",
            " [0.5000114 ]\n",
            " [0.50129277]]\n",
            "Step: 334 -> Loss: 0.6930517554283142 -> Predictions: [[0.49772006]\n",
            " [0.4992268 ]\n",
            " [0.5000128 ]\n",
            " [0.50132126]]\n",
            "Step: 335 -> Loss: 0.6930501461029053 -> Predictions: [[0.49768972]\n",
            " [0.49922705]\n",
            " [0.50001425]\n",
            " [0.50134975]]\n",
            "Step: 336 -> Loss: 0.6930484771728516 -> Predictions: [[0.49765924]\n",
            " [0.49922717]\n",
            " [0.5000156 ]\n",
            " [0.50137836]]\n",
            "Step: 337 -> Loss: 0.6930468678474426 -> Predictions: [[0.49762866]\n",
            " [0.4992274 ]\n",
            " [0.50001705]\n",
            " [0.50140697]]\n",
            "Step: 338 -> Loss: 0.6930452585220337 -> Predictions: [[0.49759808]\n",
            " [0.49922752]\n",
            " [0.5000185 ]\n",
            " [0.50143564]]\n",
            "Step: 339 -> Loss: 0.6930435299873352 -> Predictions: [[0.49756733]\n",
            " [0.49922776]\n",
            " [0.5000199 ]\n",
            " [0.50146437]]\n",
            "Step: 340 -> Loss: 0.6930418610572815 -> Predictions: [[0.4975365 ]\n",
            " [0.49922788]\n",
            " [0.5000213 ]\n",
            " [0.50149316]]\n",
            "Step: 341 -> Loss: 0.6930401921272278 -> Predictions: [[0.4975056]\n",
            " [0.499228 ]\n",
            " [0.5000227]\n",
            " [0.501522 ]]\n",
            "Step: 342 -> Loss: 0.6930384635925293 -> Predictions: [[0.4974746 ]\n",
            " [0.49922818]\n",
            " [0.5000241 ]\n",
            " [0.5015509 ]]\n",
            "Step: 343 -> Loss: 0.6930367350578308 -> Predictions: [[0.49744347]\n",
            " [0.49922836]\n",
            " [0.50002545]\n",
            " [0.5015799 ]]\n",
            "Step: 344 -> Loss: 0.6930350661277771 -> Predictions: [[0.49741226]\n",
            " [0.49922848]\n",
            " [0.5000269 ]\n",
            " [0.50160897]]\n",
            "Step: 345 -> Loss: 0.6930333375930786 -> Predictions: [[0.49738094]\n",
            " [0.4992286 ]\n",
            " [0.50002825]\n",
            " [0.5016381 ]]\n",
            "Step: 346 -> Loss: 0.6930316686630249 -> Predictions: [[0.49734956]\n",
            " [0.49922878]\n",
            " [0.5000296 ]\n",
            " [0.5016673 ]]\n",
            "Step: 347 -> Loss: 0.6930298805236816 -> Predictions: [[0.49731806]\n",
            " [0.49922895]\n",
            " [0.500031  ]\n",
            " [0.5016966 ]]\n",
            "Step: 348 -> Loss: 0.6930280923843384 -> Predictions: [[0.4972864 ]\n",
            " [0.49922907]\n",
            " [0.50003237]\n",
            " [0.5017259 ]]\n",
            "Step: 349 -> Loss: 0.6930263638496399 -> Predictions: [[0.4972547 ]\n",
            " [0.4992292 ]\n",
            " [0.50003374]\n",
            " [0.5017553 ]]\n",
            "Step: 350 -> Loss: 0.6930245757102966 -> Predictions: [[0.49722278]\n",
            " [0.4992293 ]\n",
            " [0.5000351 ]\n",
            " [0.50178486]]\n",
            "Step: 351 -> Loss: 0.6930227279663086 -> Predictions: [[0.49719086]\n",
            " [0.49922943]\n",
            " [0.5000365 ]\n",
            " [0.50181437]]\n",
            "Step: 352 -> Loss: 0.6930209398269653 -> Predictions: [[0.4971588 ]\n",
            " [0.49922955]\n",
            " [0.50003785]\n",
            " [0.50184405]]\n",
            "Step: 353 -> Loss: 0.6930190920829773 -> Predictions: [[0.4971266 ]\n",
            " [0.49922967]\n",
            " [0.50003916]\n",
            " [0.5018738 ]]\n",
            "Step: 354 -> Loss: 0.693017303943634 -> Predictions: [[0.49709433]\n",
            " [0.4992298 ]\n",
            " [0.50004053]\n",
            " [0.5019036 ]]\n",
            "Step: 355 -> Loss: 0.693015456199646 -> Predictions: [[0.49706182]\n",
            " [0.4992299 ]\n",
            " [0.5000419 ]\n",
            " [0.5019335 ]]\n",
            "Step: 356 -> Loss: 0.6930135488510132 -> Predictions: [[0.4970293 ]\n",
            " [0.49923003]\n",
            " [0.5000432 ]\n",
            " [0.5019635 ]]\n",
            "Step: 357 -> Loss: 0.6930117011070251 -> Predictions: [[0.4969966]\n",
            " [0.4992302]\n",
            " [0.5000446]\n",
            " [0.5019936]]\n",
            "Step: 358 -> Loss: 0.6930097937583923 -> Predictions: [[0.4969638 ]\n",
            " [0.49923033]\n",
            " [0.5000459 ]\n",
            " [0.50202376]]\n",
            "Step: 359 -> Loss: 0.6930078864097595 -> Predictions: [[0.49693084]\n",
            " [0.49923044]\n",
            " [0.5000472 ]\n",
            " [0.50205404]]\n",
            "Step: 360 -> Loss: 0.6930059194564819 -> Predictions: [[0.49689776]\n",
            " [0.49923056]\n",
            " [0.5000486 ]\n",
            " [0.5020844 ]]\n",
            "Step: 361 -> Loss: 0.6930040121078491 -> Predictions: [[0.49686456]\n",
            " [0.49923068]\n",
            " [0.5000499 ]\n",
            " [0.50211483]]\n",
            "Step: 362 -> Loss: 0.6930021047592163 -> Predictions: [[0.49683124]\n",
            " [0.49923086]\n",
            " [0.5000512 ]\n",
            " [0.5021454 ]]\n",
            "Step: 363 -> Loss: 0.693000078201294 -> Predictions: [[0.4967977 ]\n",
            " [0.49923098]\n",
            " [0.5000525 ]\n",
            " [0.50217605]]\n",
            "Step: 364 -> Loss: 0.6929981112480164 -> Predictions: [[0.49676403]\n",
            " [0.4992311 ]\n",
            " [0.5000538 ]\n",
            " [0.50220686]]\n",
            "Step: 365 -> Loss: 0.692996084690094 -> Predictions: [[0.49673027]\n",
            " [0.49923122]\n",
            " [0.50005513]\n",
            " [0.5022377 ]]\n",
            "Step: 366 -> Loss: 0.6929941177368164 -> Predictions: [[0.49669638]\n",
            " [0.49923134]\n",
            " [0.50005645]\n",
            " [0.5022687 ]]\n",
            "Step: 367 -> Loss: 0.692992091178894 -> Predictions: [[0.4966623 ]\n",
            " [0.49923146]\n",
            " [0.50005776]\n",
            " [0.5022998 ]]\n",
            "Step: 368 -> Loss: 0.6929900646209717 -> Predictions: [[0.49662805]\n",
            " [0.49923164]\n",
            " [0.500059  ]\n",
            " [0.50233096]]\n",
            "Step: 369 -> Loss: 0.6929879784584045 -> Predictions: [[0.4965937 ]\n",
            " [0.49923182]\n",
            " [0.5000603 ]\n",
            " [0.50236225]]\n",
            "Step: 370 -> Loss: 0.6929858922958374 -> Predictions: [[0.4965592 ]\n",
            " [0.49923193]\n",
            " [0.50006163]\n",
            " [0.50239366]]\n",
            "Step: 371 -> Loss: 0.6929838061332703 -> Predictions: [[0.49652445]\n",
            " [0.49923205]\n",
            " [0.50006294]\n",
            " [0.5024252 ]]\n",
            "Step: 372 -> Loss: 0.6929817199707031 -> Predictions: [[0.49648967]\n",
            " [0.49923223]\n",
            " [0.5000642 ]\n",
            " [0.5024569 ]]\n",
            "Step: 373 -> Loss: 0.6929795742034912 -> Predictions: [[0.49645466]\n",
            " [0.4992324 ]\n",
            " [0.5000655 ]\n",
            " [0.5024887 ]]\n",
            "Step: 374 -> Loss: 0.6929774284362793 -> Predictions: [[0.49641946]\n",
            " [0.49923253]\n",
            " [0.50006676]\n",
            " [0.50252056]]\n",
            "Step: 375 -> Loss: 0.6929751634597778 -> Predictions: [[0.49638414]\n",
            " [0.4992327 ]\n",
            " [0.50006807]\n",
            " [0.5025526 ]]\n",
            "Step: 376 -> Loss: 0.6929730772972107 -> Predictions: [[0.4963486 ]\n",
            " [0.4992329 ]\n",
            " [0.5000693 ]\n",
            " [0.50258476]]\n",
            "Step: 377 -> Loss: 0.6929708123207092 -> Predictions: [[0.49631295]\n",
            " [0.49923313]\n",
            " [0.50007063]\n",
            " [0.50261706]]\n",
            "Step: 378 -> Loss: 0.6929686069488525 -> Predictions: [[0.496277  ]\n",
            " [0.49923325]\n",
            " [0.5000719 ]\n",
            " [0.5026494 ]]\n",
            "Step: 379 -> Loss: 0.6929662823677063 -> Predictions: [[0.49624094]\n",
            " [0.49923345]\n",
            " [0.50007313]\n",
            " [0.50268203]]\n",
            "Step: 380 -> Loss: 0.6929640173912048 -> Predictions: [[0.4962048 ]\n",
            " [0.49923363]\n",
            " [0.5000744 ]\n",
            " [0.5027147 ]]\n",
            "Step: 381 -> Loss: 0.6929616928100586 -> Predictions: [[0.49616835]\n",
            " [0.4992338 ]\n",
            " [0.5000757 ]\n",
            " [0.5027475 ]]\n",
            "Step: 382 -> Loss: 0.6929593682289124 -> Predictions: [[0.49613178]\n",
            " [0.49923405]\n",
            " [0.50007695]\n",
            " [0.50278044]]\n",
            "Step: 383 -> Loss: 0.6929570436477661 -> Predictions: [[0.4960949]\n",
            " [0.4992343]\n",
            " [0.5000782]\n",
            " [0.5028136]]\n",
            "Step: 384 -> Loss: 0.6929547190666199 -> Predictions: [[0.49605796]\n",
            " [0.49923453]\n",
            " [0.50007945]\n",
            " [0.5028468 ]]\n",
            "Step: 385 -> Loss: 0.6929523348808289 -> Predictions: [[0.49602076]\n",
            " [0.4992347 ]\n",
            " [0.5000807 ]\n",
            " [0.5028802 ]]\n",
            "Step: 386 -> Loss: 0.6929498910903931 -> Predictions: [[0.49598345]\n",
            " [0.49923494]\n",
            " [0.50008196]\n",
            " [0.5029138 ]]\n",
            "Step: 387 -> Loss: 0.6929474472999573 -> Predictions: [[0.49594587]\n",
            " [0.49923524]\n",
            " [0.5000832 ]\n",
            " [0.50294745]]\n",
            "Step: 388 -> Loss: 0.6929450035095215 -> Predictions: [[0.49590805]\n",
            " [0.49923548]\n",
            " [0.50008446]\n",
            " [0.5029813 ]]\n",
            "Step: 389 -> Loss: 0.6929425001144409 -> Predictions: [[0.49587005]\n",
            " [0.49923572]\n",
            " [0.5000857 ]\n",
            " [0.5030153 ]]\n",
            "Step: 390 -> Loss: 0.6929399371147156 -> Predictions: [[0.4958319 ]\n",
            " [0.49923602]\n",
            " [0.50008696]\n",
            " [0.5030495 ]]\n",
            "Step: 391 -> Loss: 0.692937433719635 -> Predictions: [[0.49579352]\n",
            " [0.49923632]\n",
            " [0.5000882 ]\n",
            " [0.50308377]]\n",
            "Step: 392 -> Loss: 0.6929348707199097 -> Predictions: [[0.49575484]\n",
            " [0.49923655]\n",
            " [0.50008947]\n",
            " [0.5031183 ]]\n",
            "Step: 393 -> Loss: 0.6929322481155396 -> Predictions: [[0.49571604]\n",
            " [0.4992369 ]\n",
            " [0.5000907 ]\n",
            " [0.5031529 ]]\n",
            "Step: 394 -> Loss: 0.6929296255111694 -> Predictions: [[0.4956769 ]\n",
            " [0.4992372 ]\n",
            " [0.50009197]\n",
            " [0.5031878 ]]\n",
            "Step: 395 -> Loss: 0.6929270029067993 -> Predictions: [[0.49563766]\n",
            " [0.49923757]\n",
            " [0.5000932 ]\n",
            " [0.50322276]]\n",
            "Step: 396 -> Loss: 0.6929243206977844 -> Predictions: [[0.49559814]\n",
            " [0.49923787]\n",
            " [0.5000944 ]\n",
            " [0.50325793]]\n",
            "Step: 397 -> Loss: 0.6929216384887695 -> Predictions: [[0.49555838]\n",
            " [0.49923822]\n",
            " [0.50009567]\n",
            " [0.50329334]]\n",
            "Step: 398 -> Loss: 0.6929188966751099 -> Predictions: [[0.49551845]\n",
            " [0.49923864]\n",
            " [0.5000969 ]\n",
            " [0.5033288 ]]\n",
            "Step: 399 -> Loss: 0.6929160952568054 -> Predictions: [[0.49547818]\n",
            " [0.49923906]\n",
            " [0.50009817]\n",
            " [0.5033645 ]]\n",
            "Step: 400 -> Loss: 0.692913293838501 -> Predictions: [[0.49543774]\n",
            " [0.49923941]\n",
            " [0.5000994 ]\n",
            " [0.5034004 ]]\n",
            "Step: 401 -> Loss: 0.6929104924201965 -> Predictions: [[0.49539706]\n",
            " [0.49923983]\n",
            " [0.5001007 ]\n",
            " [0.5034365 ]]\n",
            "Step: 402 -> Loss: 0.6929076313972473 -> Predictions: [[0.49535605]\n",
            " [0.49924025]\n",
            " [0.5001019 ]\n",
            " [0.5034728 ]]\n",
            "Step: 403 -> Loss: 0.6929047107696533 -> Predictions: [[0.4953148 ]\n",
            " [0.49924067]\n",
            " [0.5001032 ]\n",
            " [0.5035092 ]]\n",
            "Step: 404 -> Loss: 0.6929017305374146 -> Predictions: [[0.4952734 ]\n",
            " [0.49924108]\n",
            " [0.5001044 ]\n",
            " [0.5035459 ]]\n",
            "Step: 405 -> Loss: 0.6928988695144653 -> Predictions: [[0.49523166]\n",
            " [0.49924156]\n",
            " [0.5001057 ]\n",
            " [0.5035828 ]]\n",
            "Step: 406 -> Loss: 0.6928958296775818 -> Predictions: [[0.49518967]\n",
            " [0.49924204]\n",
            " [0.50010693]\n",
            " [0.50361985]]\n",
            "Step: 407 -> Loss: 0.6928927898406982 -> Predictions: [[0.4951474 ]\n",
            " [0.49924257]\n",
            " [0.5001081 ]\n",
            " [0.5036571 ]]\n",
            "Step: 408 -> Loss: 0.6928896903991699 -> Predictions: [[0.4951049]\n",
            " [0.4992431]\n",
            " [0.5001094]\n",
            " [0.5036946]]\n",
            "Step: 409 -> Loss: 0.6928866505622864 -> Predictions: [[0.49506208]\n",
            " [0.49924356]\n",
            " [0.5001106 ]\n",
            " [0.50373226]]\n",
            "Step: 410 -> Loss: 0.6928834915161133 -> Predictions: [[0.49501902]\n",
            " [0.49924415]\n",
            " [0.50011194]\n",
            " [0.5037701 ]]\n",
            "Step: 411 -> Loss: 0.6928802728652954 -> Predictions: [[0.49497566]\n",
            " [0.4992447 ]\n",
            " [0.5001132 ]\n",
            " [0.50380826]]\n",
            "Step: 412 -> Loss: 0.6928770542144775 -> Predictions: [[0.49493197]\n",
            " [0.4992453 ]\n",
            " [0.50011444]\n",
            " [0.5038466 ]]\n",
            "Step: 413 -> Loss: 0.6928738355636597 -> Predictions: [[0.49488807]\n",
            " [0.49924588]\n",
            " [0.5001157 ]\n",
            " [0.50388515]]\n",
            "Step: 414 -> Loss: 0.692870557308197 -> Predictions: [[0.4948438 ]\n",
            " [0.49924648]\n",
            " [0.50011694]\n",
            " [0.50392395]]\n",
            "Step: 415 -> Loss: 0.6928672194480896 -> Predictions: [[0.49479932]\n",
            " [0.49924713]\n",
            " [0.5001182 ]\n",
            " [0.50396293]]\n",
            "Step: 416 -> Loss: 0.6928638219833374 -> Predictions: [[0.4947545 ]\n",
            " [0.4992478 ]\n",
            " [0.5001195 ]\n",
            " [0.50400215]]\n",
            "Step: 417 -> Loss: 0.69286048412323 -> Predictions: [[0.49470934]\n",
            " [0.49924845]\n",
            " [0.50012076]\n",
            " [0.5040417 ]]\n",
            "Step: 418 -> Loss: 0.6928569078445435 -> Predictions: [[0.49466383]\n",
            " [0.49924916]\n",
            " [0.500122  ]\n",
            " [0.50408137]]\n",
            "Step: 419 -> Loss: 0.6928534507751465 -> Predictions: [[0.4946181 ]\n",
            " [0.49924988]\n",
            " [0.5001234 ]\n",
            " [0.5041213 ]]\n",
            "Step: 420 -> Loss: 0.6928499937057495 -> Predictions: [[0.494572  ]\n",
            " [0.49925065]\n",
            " [0.50012463]\n",
            " [0.50416154]]\n",
            "Step: 421 -> Loss: 0.6928463578224182 -> Predictions: [[0.49452558]\n",
            " [0.49925143]\n",
            " [0.50012594]\n",
            " [0.504202  ]]\n",
            "Step: 422 -> Loss: 0.6928427219390869 -> Predictions: [[0.49447885]\n",
            " [0.4992522 ]\n",
            " [0.50012726]\n",
            " [0.5042427 ]]\n",
            "Step: 423 -> Loss: 0.6928390264511108 -> Predictions: [[0.4944318 ]\n",
            " [0.49925303]\n",
            " [0.50012857]\n",
            " [0.50428367]]\n",
            "Step: 424 -> Loss: 0.6928353309631348 -> Predictions: [[0.4943844 ]\n",
            " [0.49925384]\n",
            " [0.5001299 ]\n",
            " [0.5043249 ]]\n",
            "Step: 425 -> Loss: 0.6928315758705139 -> Predictions: [[0.49433663]\n",
            " [0.49925473]\n",
            " [0.5001312 ]\n",
            " [0.5043664 ]]\n",
            "Step: 426 -> Loss: 0.6928277015686035 -> Predictions: [[0.49428856]\n",
            " [0.49925557]\n",
            " [0.5001325 ]\n",
            " [0.5044081 ]]\n",
            "Step: 427 -> Loss: 0.6928238868713379 -> Predictions: [[0.4942401 ]\n",
            " [0.49925652]\n",
            " [0.5001338 ]\n",
            " [0.5044502 ]]\n",
            "Step: 428 -> Loss: 0.6928199529647827 -> Predictions: [[0.49419126]\n",
            " [0.49925748]\n",
            " [0.5001352 ]\n",
            " [0.50449246]]\n",
            "Step: 429 -> Loss: 0.6928160190582275 -> Predictions: [[0.49414212]\n",
            " [0.49925843]\n",
            " [0.5001365 ]\n",
            " [0.5045351 ]]\n",
            "Step: 430 -> Loss: 0.6928119659423828 -> Predictions: [[0.49409258]\n",
            " [0.49925938]\n",
            " [0.50013787]\n",
            " [0.50457793]]\n",
            "Step: 431 -> Loss: 0.6928078532218933 -> Predictions: [[0.4940427 ]\n",
            " [0.49926046]\n",
            " [0.50013924]\n",
            " [0.5046211 ]]\n",
            "Step: 432 -> Loss: 0.6928037405014038 -> Predictions: [[0.49399242]\n",
            " [0.49926153]\n",
            " [0.5001406 ]\n",
            " [0.50466454]]\n",
            "Step: 433 -> Loss: 0.6927995681762695 -> Predictions: [[0.4939417]\n",
            " [0.4992626]\n",
            " [0.500142 ]\n",
            " [0.5047083]]\n",
            "Step: 434 -> Loss: 0.6927952766418457 -> Predictions: [[0.49389064]\n",
            " [0.49926364]\n",
            " [0.50014335]\n",
            " [0.50475234]]\n",
            "Step: 435 -> Loss: 0.6927910447120667 -> Predictions: [[0.49383923]\n",
            " [0.49926484]\n",
            " [0.5001448 ]\n",
            " [0.5047967 ]]\n",
            "Step: 436 -> Loss: 0.6927866339683533 -> Predictions: [[0.49378738]\n",
            " [0.49926603]\n",
            " [0.5001462 ]\n",
            " [0.5048413 ]]\n",
            "Step: 437 -> Loss: 0.6927822232246399 -> Predictions: [[0.49373505]\n",
            " [0.49926722]\n",
            " [0.5001476 ]\n",
            " [0.50488627]]\n",
            "Step: 438 -> Loss: 0.6927777528762817 -> Predictions: [[0.4936824 ]\n",
            " [0.4992684 ]\n",
            " [0.500149  ]\n",
            " [0.50493157]]\n",
            "Step: 439 -> Loss: 0.6927732229232788 -> Predictions: [[0.4936293 ]\n",
            " [0.49926972]\n",
            " [0.50015044]\n",
            " [0.50497717]]\n",
            "Step: 440 -> Loss: 0.6927686333656311 -> Predictions: [[0.49357587]\n",
            " [0.49927104]\n",
            " [0.50015193]\n",
            " [0.50502306]]\n",
            "Step: 441 -> Loss: 0.6927639245986938 -> Predictions: [[0.49352184]\n",
            " [0.49927235]\n",
            " [0.50015336]\n",
            " [0.5050694 ]]\n",
            "Step: 442 -> Loss: 0.6927591562271118 -> Predictions: [[0.4934675 ]\n",
            " [0.49927375]\n",
            " [0.50015485]\n",
            " [0.5051159 ]]\n",
            "Step: 443 -> Loss: 0.6927543878555298 -> Predictions: [[0.4934127 ]\n",
            " [0.49927518]\n",
            " [0.50015634]\n",
            " [0.50516284]]\n",
            "Step: 444 -> Loss: 0.692749559879303 -> Predictions: [[0.49335745]\n",
            " [0.4992766 ]\n",
            " [0.5001579 ]\n",
            " [0.5052101 ]]\n",
            "Step: 445 -> Loss: 0.6927446126937866 -> Predictions: [[0.49330175]\n",
            " [0.4992781 ]\n",
            " [0.5001594 ]\n",
            " [0.5052577 ]]\n",
            "Step: 446 -> Loss: 0.6927396059036255 -> Predictions: [[0.49324554]\n",
            " [0.49927965]\n",
            " [0.50016093]\n",
            " [0.50530577]]\n",
            "Step: 447 -> Loss: 0.6927344799041748 -> Predictions: [[0.49318886]\n",
            " [0.49928126]\n",
            " [0.5001625 ]\n",
            " [0.5053541 ]]\n",
            "Step: 448 -> Loss: 0.6927293539047241 -> Predictions: [[0.49313182]\n",
            " [0.4992828 ]\n",
            " [0.5001641 ]\n",
            " [0.5054028 ]]\n",
            "Step: 449 -> Loss: 0.6927241086959839 -> Predictions: [[0.49307418]\n",
            " [0.49928445]\n",
            " [0.50016564]\n",
            " [0.50545186]]\n",
            "Step: 450 -> Loss: 0.6927188038825989 -> Predictions: [[0.49301612]\n",
            " [0.49928617]\n",
            " [0.50016725]\n",
            " [0.5055013 ]]\n",
            "Step: 451 -> Loss: 0.6927133798599243 -> Predictions: [[0.49295747]\n",
            " [0.4992879 ]\n",
            " [0.50016886]\n",
            " [0.5055511 ]]\n",
            "Step: 452 -> Loss: 0.692707896232605 -> Predictions: [[0.49289837]\n",
            " [0.4992897 ]\n",
            " [0.5001705 ]\n",
            " [0.5056013 ]]\n",
            "Step: 453 -> Loss: 0.6927024722099304 -> Predictions: [[0.4928388 ]\n",
            " [0.49929154]\n",
            " [0.5001722 ]\n",
            " [0.5056519 ]]\n",
            "Step: 454 -> Loss: 0.6926968097686768 -> Predictions: [[0.4927787 ]\n",
            " [0.49929345]\n",
            " [0.5001739 ]\n",
            " [0.5057029 ]]\n",
            "Step: 455 -> Loss: 0.6926910281181335 -> Predictions: [[0.49271807]\n",
            " [0.49929538]\n",
            " [0.5001756 ]\n",
            " [0.5057543 ]]\n",
            "Step: 456 -> Loss: 0.6926852464675903 -> Predictions: [[0.49265686]\n",
            " [0.4992973 ]\n",
            " [0.5001773 ]\n",
            " [0.5058061 ]]\n",
            "Step: 457 -> Loss: 0.6926794052124023 -> Predictions: [[0.49259517]\n",
            " [0.49929932]\n",
            " [0.5001791 ]\n",
            " [0.5058583 ]]\n",
            "Step: 458 -> Loss: 0.6926734447479248 -> Predictions: [[0.49253294]\n",
            " [0.49930146]\n",
            " [0.5001809 ]\n",
            " [0.505911  ]]\n",
            "Step: 459 -> Loss: 0.6926673650741577 -> Predictions: [[0.49247012]\n",
            " [0.4993036 ]\n",
            " [0.5001827 ]\n",
            " [0.505964  ]]\n",
            "Step: 460 -> Loss: 0.6926612257957458 -> Predictions: [[0.49240676]\n",
            " [0.49930573]\n",
            " [0.50018454]\n",
            " [0.5060175 ]]\n",
            "Step: 461 -> Loss: 0.6926549673080444 -> Predictions: [[0.49234277]\n",
            " [0.499308  ]\n",
            " [0.5001864 ]\n",
            " [0.50607145]]\n",
            "Step: 462 -> Loss: 0.6926485896110535 -> Predictions: [[0.49227822]\n",
            " [0.49931026]\n",
            " [0.5001883 ]\n",
            " [0.5061258 ]]\n",
            "Step: 463 -> Loss: 0.6926421523094177 -> Predictions: [[0.49221313]\n",
            " [0.49931264]\n",
            " [0.5001902 ]\n",
            " [0.50618064]]\n",
            "Step: 464 -> Loss: 0.6926355957984924 -> Predictions: [[0.4921474 ]\n",
            " [0.49931502]\n",
            " [0.50019217]\n",
            " [0.5062359 ]]\n",
            "Step: 465 -> Loss: 0.6926289796829224 -> Predictions: [[0.49208105]\n",
            " [0.4993175 ]\n",
            " [0.50019413]\n",
            " [0.5062916 ]]\n",
            "Step: 466 -> Loss: 0.692622184753418 -> Predictions: [[0.49201408]\n",
            " [0.49932   ]\n",
            " [0.5001961 ]\n",
            " [0.50634784]]\n",
            "Step: 467 -> Loss: 0.6926153302192688 -> Predictions: [[0.49194658]\n",
            " [0.49932262]\n",
            " [0.5001981 ]\n",
            " [0.5064045 ]]\n",
            "Step: 468 -> Loss: 0.6926084160804749 -> Predictions: [[0.4918784]\n",
            " [0.4993253]\n",
            " [0.5002002]\n",
            " [0.5064617]]\n",
            "Step: 469 -> Loss: 0.6926013231277466 -> Predictions: [[0.49180952]\n",
            " [0.49932796]\n",
            " [0.5002023 ]\n",
            " [0.5065193 ]]\n",
            "Step: 470 -> Loss: 0.692594051361084 -> Predictions: [[0.49174   ]\n",
            " [0.49933082]\n",
            " [0.50020444]\n",
            " [0.5065775 ]]\n",
            "Step: 471 -> Loss: 0.6925867795944214 -> Predictions: [[0.49166983]\n",
            " [0.49933368]\n",
            " [0.50020665]\n",
            " [0.5066361 ]]\n",
            "Step: 472 -> Loss: 0.6925793290138245 -> Predictions: [[0.491599  ]\n",
            " [0.49933654]\n",
            " [0.50020885]\n",
            " [0.5066953 ]]\n",
            "Step: 473 -> Loss: 0.692571759223938 -> Predictions: [[0.49152744]\n",
            " [0.49933955]\n",
            " [0.5002111 ]\n",
            " [0.50675493]]\n",
            "Step: 474 -> Loss: 0.6925640106201172 -> Predictions: [[0.49145523]\n",
            " [0.4993426 ]\n",
            " [0.50021344]\n",
            " [0.50681514]]\n",
            "Step: 475 -> Loss: 0.6925563812255859 -> Predictions: [[0.49138227]\n",
            " [0.4993458 ]\n",
            " [0.50021577]\n",
            " [0.5068759 ]]\n",
            "Step: 476 -> Loss: 0.6925482749938965 -> Predictions: [[0.49130866]\n",
            " [0.499349  ]\n",
            " [0.50021815]\n",
            " [0.50693715]]\n",
            "Step: 477 -> Loss: 0.6925402879714966 -> Predictions: [[0.49123427]\n",
            " [0.49935228]\n",
            " [0.5002206 ]\n",
            " [0.506999  ]]\n",
            "Step: 478 -> Loss: 0.6925320625305176 -> Predictions: [[0.49115914]\n",
            " [0.49935567]\n",
            " [0.50022304]\n",
            " [0.50706136]]\n",
            "Step: 479 -> Loss: 0.6925237774848938 -> Predictions: [[0.4910833 ]\n",
            " [0.49935913]\n",
            " [0.5002256 ]\n",
            " [0.5071243 ]]\n",
            "Step: 480 -> Loss: 0.6925152540206909 -> Predictions: [[0.49100658]\n",
            " [0.49936262]\n",
            " [0.50022817]\n",
            " [0.50718784]]\n",
            "Step: 481 -> Loss: 0.6925066709518433 -> Predictions: [[0.49092925]\n",
            " [0.49936625]\n",
            " [0.5002307 ]\n",
            " [0.5072519 ]]\n",
            "Step: 482 -> Loss: 0.692497968673706 -> Predictions: [[0.49085104]\n",
            " [0.49936995]\n",
            " [0.5002334 ]\n",
            " [0.5073166 ]]\n",
            "Step: 483 -> Loss: 0.6924890279769897 -> Predictions: [[0.49077207]\n",
            " [0.49937373]\n",
            " [0.50023615]\n",
            " [0.5073819 ]]\n",
            "Step: 484 -> Loss: 0.6924799680709839 -> Predictions: [[0.49069226]\n",
            " [0.49937767]\n",
            " [0.5002389 ]\n",
            " [0.5074478 ]]\n",
            "Step: 485 -> Loss: 0.6924707293510437 -> Predictions: [[0.4906116 ]\n",
            " [0.4993816 ]\n",
            " [0.50024176]\n",
            " [0.5075143 ]]\n",
            "Step: 486 -> Loss: 0.6924612522125244 -> Predictions: [[0.49053013]\n",
            " [0.49938568]\n",
            " [0.5002447 ]\n",
            " [0.5075814 ]]\n",
            "Step: 487 -> Loss: 0.6924517750740051 -> Predictions: [[0.49044785]\n",
            " [0.49938992]\n",
            " [0.5002476 ]\n",
            " [0.5076492 ]]\n",
            "Step: 488 -> Loss: 0.6924420595169067 -> Predictions: [[0.4903647 ]\n",
            " [0.49939415]\n",
            " [0.50025064]\n",
            " [0.5077176 ]]\n",
            "Step: 489 -> Loss: 0.692432165145874 -> Predictions: [[0.4902806 ]\n",
            " [0.49939853]\n",
            " [0.5002537 ]\n",
            " [0.50778663]]\n",
            "Step: 490 -> Loss: 0.692422091960907 -> Predictions: [[0.49019563]\n",
            " [0.499403  ]\n",
            " [0.50025684]\n",
            " [0.50785637]]\n",
            "Step: 491 -> Loss: 0.6924118399620056 -> Predictions: [[0.49010983]\n",
            " [0.4994076 ]\n",
            " [0.50026006]\n",
            " [0.50792676]]\n",
            "Step: 492 -> Loss: 0.6924014687538147 -> Predictions: [[0.49002302]\n",
            " [0.49941227]\n",
            " [0.50026333]\n",
            " [0.5079979 ]]\n",
            "Step: 493 -> Loss: 0.6923908591270447 -> Predictions: [[0.48993534]\n",
            " [0.4994171 ]\n",
            " [0.5002667 ]\n",
            " [0.5080696 ]]\n",
            "Step: 494 -> Loss: 0.6923800706863403 -> Predictions: [[0.48984665]\n",
            " [0.499422  ]\n",
            " [0.5002701 ]\n",
            " [0.50814205]]\n",
            "Step: 495 -> Loss: 0.6923690438270569 -> Predictions: [[0.48975706]\n",
            " [0.49942702]\n",
            " [0.50027364]\n",
            " [0.50821525]]\n",
            "Step: 496 -> Loss: 0.6923578381538391 -> Predictions: [[0.48966637]\n",
            " [0.4994322 ]\n",
            " [0.5002772 ]\n",
            " [0.50828916]]\n",
            "Step: 497 -> Loss: 0.692346453666687 -> Predictions: [[0.48957482]\n",
            " [0.49943748]\n",
            " [0.5002809 ]\n",
            " [0.5083638 ]]\n",
            "Step: 498 -> Loss: 0.6923348307609558 -> Predictions: [[0.4894822 ]\n",
            " [0.49944285]\n",
            " [0.5002847 ]\n",
            " [0.5084392 ]]\n",
            "Step: 499 -> Loss: 0.6923230290412903 -> Predictions: [[0.48938859]\n",
            " [0.49944842]\n",
            " [0.5002885 ]\n",
            " [0.5085153 ]]\n",
            "Step: 501 -> Loss: 0.6922987699508667 -> Predictions: [[0.48919806]\n",
            " [0.49945986]\n",
            " [0.5002964 ]\n",
            " [0.50866985]]\n",
            "Step: 502 -> Loss: 0.6922862529754639 -> Predictions: [[0.48910126]\n",
            " [0.4994658 ]\n",
            " [0.5003005 ]\n",
            " [0.50874835]]\n",
            "Step: 503 -> Loss: 0.6922735571861267 -> Predictions: [[0.48900336]\n",
            " [0.49947187]\n",
            " [0.50030476]\n",
            " [0.50882757]]\n",
            "Step: 504 -> Loss: 0.6922605633735657 -> Predictions: [[0.4889043 ]\n",
            " [0.4994781 ]\n",
            " [0.50030905]\n",
            " [0.5089077 ]]\n",
            "Step: 505 -> Loss: 0.6922473907470703 -> Predictions: [[0.48880407]\n",
            " [0.49948448]\n",
            " [0.50031346]\n",
            " [0.5089886 ]]\n",
            "Step: 506 -> Loss: 0.6922339200973511 -> Predictions: [[0.48870274]\n",
            " [0.499491  ]\n",
            " [0.50031793]\n",
            " [0.50907034]]\n",
            "Step: 507 -> Loss: 0.6922202110290527 -> Predictions: [[0.48860016]\n",
            " [0.49949768]\n",
            " [0.5003226 ]\n",
            " [0.50915295]]\n",
            "Step: 508 -> Loss: 0.6922062039375305 -> Predictions: [[0.48849648]\n",
            " [0.49950457]\n",
            " [0.50032735]\n",
            " [0.5092364 ]]\n",
            "Step: 509 -> Loss: 0.6921919584274292 -> Predictions: [[0.48839152]\n",
            " [0.49951154]\n",
            " [0.5003322 ]\n",
            " [0.50932074]]\n",
            "Step: 510 -> Loss: 0.692177414894104 -> Predictions: [[0.48828536]\n",
            " [0.49951875]\n",
            " [0.5003372 ]\n",
            " [0.5094059 ]]\n",
            "Step: 511 -> Loss: 0.6921626329421997 -> Predictions: [[0.48817796]\n",
            " [0.49952605]\n",
            " [0.50034225]\n",
            " [0.50949204]]\n",
            "Step: 512 -> Loss: 0.6921475529670715 -> Predictions: [[0.48806924]\n",
            " [0.49953362]\n",
            " [0.5003475 ]\n",
            " [0.5095791 ]]\n",
            "Step: 513 -> Loss: 0.6921321153640747 -> Predictions: [[0.4879592 ]\n",
            " [0.49954128]\n",
            " [0.5003528 ]\n",
            " [0.50966704]]\n",
            "Step: 514 -> Loss: 0.6921164393424988 -> Predictions: [[0.4878479 ]\n",
            " [0.49954915]\n",
            " [0.5003583 ]\n",
            " [0.50975597]]\n",
            "Step: 515 -> Loss: 0.692100465297699 -> Predictions: [[0.48773524]\n",
            " [0.49955723]\n",
            " [0.5003639 ]\n",
            " [0.50984585]]\n",
            "Step: 516 -> Loss: 0.6920840740203857 -> Predictions: [[0.4876212 ]\n",
            " [0.4995655 ]\n",
            " [0.50036967]\n",
            " [0.5099367 ]]\n",
            "Step: 517 -> Loss: 0.6920673847198486 -> Predictions: [[0.48750576]\n",
            " [0.49957395]\n",
            " [0.50037557]\n",
            " [0.5100285 ]]\n",
            "Step: 518 -> Loss: 0.6920504570007324 -> Predictions: [[0.48738888]\n",
            " [0.49958265]\n",
            " [0.50038165]\n",
            " [0.51012135]]\n",
            "Step: 519 -> Loss: 0.6920331716537476 -> Predictions: [[0.48727065]\n",
            " [0.4995915 ]\n",
            " [0.50038785]\n",
            " [0.51021516]]\n",
            "Step: 520 -> Loss: 0.6920154690742493 -> Predictions: [[0.4871509 ]\n",
            " [0.49960062]\n",
            " [0.5003942 ]\n",
            " [0.51031005]]\n",
            "Step: 521 -> Loss: 0.6919974684715271 -> Predictions: [[0.4870296 ]\n",
            " [0.4996099 ]\n",
            " [0.5004007 ]\n",
            " [0.51040596]]\n",
            "Step: 522 -> Loss: 0.6919789910316467 -> Predictions: [[0.4869069 ]\n",
            " [0.49961942]\n",
            " [0.50040746]\n",
            " [0.51050293]]\n",
            "Step: 523 -> Loss: 0.6919602155685425 -> Predictions: [[0.4867826 ]\n",
            " [0.49962917]\n",
            " [0.5004144 ]\n",
            " [0.51060104]]\n",
            "Step: 524 -> Loss: 0.6919410228729248 -> Predictions: [[0.48665673]\n",
            " [0.49963924]\n",
            " [0.5004214 ]\n",
            " [0.51070017]]\n",
            "Step: 525 -> Loss: 0.6919214725494385 -> Predictions: [[0.48652926]\n",
            " [0.49964947]\n",
            " [0.5004286 ]\n",
            " [0.5108005 ]]\n",
            "Step: 526 -> Loss: 0.6919015049934387 -> Predictions: [[0.48640022]\n",
            " [0.49966002]\n",
            " [0.50043607]\n",
            " [0.51090187]]\n",
            "Step: 527 -> Loss: 0.6918811202049255 -> Predictions: [[0.48626944]\n",
            " [0.4996707 ]\n",
            " [0.5004437 ]\n",
            " [0.51100445]]\n",
            "Step: 528 -> Loss: 0.6918601989746094 -> Predictions: [[0.48613706]\n",
            " [0.4996818 ]\n",
            " [0.5004515 ]\n",
            " [0.5111081 ]]\n",
            "Step: 529 -> Loss: 0.6918389797210693 -> Predictions: [[0.4860029 ]\n",
            " [0.49969304]\n",
            " [0.50045955]\n",
            " [0.511213  ]]\n",
            "Step: 530 -> Loss: 0.6918172240257263 -> Predictions: [[0.48586702]\n",
            " [0.49970466]\n",
            " [0.50046784]\n",
            " [0.5113191 ]]\n",
            "Step: 531 -> Loss: 0.6917951107025146 -> Predictions: [[0.48572934]\n",
            " [0.49971643]\n",
            " [0.5004763 ]\n",
            " [0.51142645]]\n",
            "Step: 532 -> Loss: 0.6917724609375 -> Predictions: [[0.4855899]\n",
            " [0.4997286]\n",
            " [0.500485 ]\n",
            " [0.511535 ]]\n",
            "Step: 533 -> Loss: 0.6917492747306824 -> Predictions: [[0.4854486]\n",
            " [0.4997411]\n",
            " [0.5004939]\n",
            " [0.5116448]]\n",
            "Step: 534 -> Loss: 0.6917256712913513 -> Predictions: [[0.4853055 ]\n",
            " [0.49975383]\n",
            " [0.50050306]\n",
            " [0.5117559 ]]\n",
            "Step: 535 -> Loss: 0.6917014718055725 -> Predictions: [[0.48516035]\n",
            " [0.49976683]\n",
            " [0.5005125 ]\n",
            " [0.5118682 ]]\n",
            "Step: 536 -> Loss: 0.6916767954826355 -> Predictions: [[0.4850133 ]\n",
            " [0.49978027]\n",
            " [0.50052214]\n",
            " [0.5119819 ]]\n",
            "Step: 537 -> Loss: 0.6916515827178955 -> Predictions: [[0.4848644 ]\n",
            " [0.49979398]\n",
            " [0.50053203]\n",
            " [0.5120969 ]]\n",
            "Step: 538 -> Loss: 0.6916258335113525 -> Predictions: [[0.48471335]\n",
            " [0.499808  ]\n",
            " [0.5005423 ]\n",
            " [0.51221323]]\n",
            "Step: 539 -> Loss: 0.6915994882583618 -> Predictions: [[0.48456034]\n",
            " [0.49982244]\n",
            " [0.5005528 ]\n",
            " [0.51233095]]\n",
            "Step: 540 -> Loss: 0.6915726065635681 -> Predictions: [[0.48440522]\n",
            " [0.49983722]\n",
            " [0.50056356]\n",
            " [0.51245004]]\n",
            "Step: 541 -> Loss: 0.6915450692176819 -> Predictions: [[0.48424795]\n",
            " [0.49985233]\n",
            " [0.5005746 ]\n",
            " [0.51257056]]\n",
            "Step: 542 -> Loss: 0.6915169954299927 -> Predictions: [[0.48408857]\n",
            " [0.49986783]\n",
            " [0.500586  ]\n",
            " [0.5126925 ]]\n",
            "Step: 543 -> Loss: 0.6914881467819214 -> Predictions: [[0.48392692]\n",
            " [0.49988368]\n",
            " [0.5005976 ]\n",
            " [0.51281595]]\n",
            "Step: 544 -> Loss: 0.6914587616920471 -> Predictions: [[0.48376304]\n",
            " [0.4999    ]\n",
            " [0.5006096 ]\n",
            " [0.51294076]]\n",
            "Step: 545 -> Loss: 0.6914286613464355 -> Predictions: [[0.48359695]\n",
            " [0.49991667]\n",
            " [0.5006219 ]\n",
            " [0.5130672 ]]\n",
            "Step: 546 -> Loss: 0.6913979053497314 -> Predictions: [[0.48342845]\n",
            " [0.49993384]\n",
            " [0.50063455]\n",
            " [0.51319504]]\n",
            "Step: 547 -> Loss: 0.69136643409729 -> Predictions: [[0.48325762]\n",
            " [0.49995136]\n",
            " [0.5006476 ]\n",
            " [0.5133245 ]]\n",
            "Step: 548 -> Loss: 0.6913342475891113 -> Predictions: [[0.4830844 ]\n",
            " [0.49996936]\n",
            " [0.50066096]\n",
            " [0.51345545]]\n",
            "Step: 549 -> Loss: 0.6913013458251953 -> Predictions: [[0.48290864]\n",
            " [0.49998778]\n",
            " [0.50067466]\n",
            " [0.513588  ]]\n",
            "Step: 550 -> Loss: 0.6912676692008972 -> Predictions: [[0.48273045]\n",
            " [0.5000067 ]\n",
            " [0.5006888 ]\n",
            " [0.5137222 ]]\n",
            "Step: 551 -> Loss: 0.691233217716217 -> Predictions: [[0.4825497 ]\n",
            " [0.50002605]\n",
            " [0.50070333]\n",
            " [0.513858  ]]\n",
            "Step: 552 -> Loss: 0.69119793176651 -> Predictions: [[0.48236638]\n",
            " [0.50004596]\n",
            " [0.50071824]\n",
            " [0.51399547]]\n",
            "Step: 553 -> Loss: 0.6911618709564209 -> Predictions: [[0.48218033]\n",
            " [0.50006634]\n",
            " [0.5007336 ]\n",
            " [0.51413465]]\n",
            "Step: 554 -> Loss: 0.6911249160766602 -> Predictions: [[0.48199168]\n",
            " [0.5000872 ]\n",
            " [0.50074935]\n",
            " [0.5142755 ]]\n",
            "Step: 555 -> Loss: 0.6910872459411621 -> Predictions: [[0.4818002 ]\n",
            " [0.50010866]\n",
            " [0.5007656 ]\n",
            " [0.51441807]]\n",
            "Step: 556 -> Loss: 0.6910485029220581 -> Predictions: [[0.48160604]\n",
            " [0.50013065]\n",
            " [0.50078225]\n",
            " [0.51456237]]\n",
            "Step: 557 -> Loss: 0.6910089254379272 -> Predictions: [[0.4814089 ]\n",
            " [0.5001532 ]\n",
            " [0.50079936]\n",
            " [0.5147085 ]]\n",
            "Step: 558 -> Loss: 0.69096839427948 -> Predictions: [[0.48120898]\n",
            " [0.5001763 ]\n",
            " [0.500817  ]\n",
            " [0.5148564 ]]\n",
            "Step: 559 -> Loss: 0.6909269094467163 -> Predictions: [[0.481006 ]\n",
            " [0.5002   ]\n",
            " [0.5008351]\n",
            " [0.5150061]]\n",
            "Step: 560 -> Loss: 0.6908844113349915 -> Predictions: [[0.48080006]\n",
            " [0.5002243 ]\n",
            " [0.5008538 ]\n",
            " [0.51515776]]\n",
            "Step: 561 -> Loss: 0.6908408999443054 -> Predictions: [[0.48059103]\n",
            " [0.5002492 ]\n",
            " [0.50087297]\n",
            " [0.5153112 ]]\n",
            "Step: 562 -> Loss: 0.6907963752746582 -> Predictions: [[0.4803789 ]\n",
            " [0.50027484]\n",
            " [0.50089264]\n",
            " [0.5154666 ]]\n",
            "Step: 563 -> Loss: 0.6907507181167603 -> Predictions: [[0.4801636 ]\n",
            " [0.50030106]\n",
            " [0.5009129 ]\n",
            " [0.51562387]]\n",
            "Step: 564 -> Loss: 0.6907040476799011 -> Predictions: [[0.47994497]\n",
            " [0.50032794]\n",
            " [0.5009337 ]\n",
            " [0.5157831 ]]\n",
            "Step: 565 -> Loss: 0.6906560659408569 -> Predictions: [[0.4797231 ]\n",
            " [0.50035554]\n",
            " [0.50095516]\n",
            " [0.5159443 ]]\n",
            "Step: 566 -> Loss: 0.6906070709228516 -> Predictions: [[0.47949785]\n",
            " [0.50038385]\n",
            " [0.50097716]\n",
            " [0.51610756]]\n",
            "Step: 567 -> Loss: 0.6905568242073059 -> Predictions: [[0.47926918]\n",
            " [0.5004129 ]\n",
            " [0.5009998 ]\n",
            " [0.5162728 ]]\n",
            "Step: 568 -> Loss: 0.6905053853988647 -> Predictions: [[0.47903696]\n",
            " [0.5004427 ]\n",
            " [0.5010232 ]\n",
            " [0.5164401 ]]\n",
            "Step: 569 -> Loss: 0.6904525756835938 -> Predictions: [[0.47880116]\n",
            " [0.5004732 ]\n",
            " [0.50104713]\n",
            " [0.51660955]]\n",
            "Step: 570 -> Loss: 0.6903985738754272 -> Predictions: [[0.4785618 ]\n",
            " [0.50050455]\n",
            " [0.50107175]\n",
            " [0.51678103]]\n",
            "Step: 571 -> Loss: 0.6903432607650757 -> Predictions: [[0.4783187 ]\n",
            " [0.50053674]\n",
            " [0.50109714]\n",
            " [0.5169547 ]]\n",
            "Step: 572 -> Loss: 0.6902864575386047 -> Predictions: [[0.47807184]\n",
            " [0.5005697 ]\n",
            " [0.50112325]\n",
            " [0.5171306 ]]\n",
            "Step: 573 -> Loss: 0.6902283430099487 -> Predictions: [[0.47782108]\n",
            " [0.50060356]\n",
            " [0.5011501 ]\n",
            " [0.51730865]]\n",
            "Step: 574 -> Loss: 0.6901686191558838 -> Predictions: [[0.47756648]\n",
            " [0.5006383 ]\n",
            " [0.50117767]\n",
            " [0.5174889 ]]\n",
            "Step: 575 -> Loss: 0.6901075839996338 -> Predictions: [[0.4773078]\n",
            " [0.5006739]\n",
            " [0.5012061]\n",
            " [0.5176714]]\n",
            "Step: 576 -> Loss: 0.6900448799133301 -> Predictions: [[0.4770451]\n",
            " [0.5007105]\n",
            " [0.5012353]\n",
            " [0.5178562]]\n",
            "Step: 577 -> Loss: 0.6899807453155518 -> Predictions: [[0.47677824]\n",
            " [0.500748  ]\n",
            " [0.50126535]\n",
            " [0.5180433 ]]\n",
            "Step: 578 -> Loss: 0.6899149417877197 -> Predictions: [[0.4765072]\n",
            " [0.5007864]\n",
            " [0.5012962]\n",
            " [0.5182327]]\n",
            "Step: 579 -> Loss: 0.689847469329834 -> Predictions: [[0.4762318 ]\n",
            " [0.50082594]\n",
            " [0.501328  ]\n",
            " [0.5184245 ]]\n",
            "Step: 580 -> Loss: 0.689778208732605 -> Predictions: [[0.47595197]\n",
            " [0.5008664 ]\n",
            " [0.5013607 ]\n",
            " [0.5186187 ]]\n",
            "Step: 581 -> Loss: 0.6897072792053223 -> Predictions: [[0.47566774]\n",
            " [0.50090796]\n",
            " [0.50139433]\n",
            " [0.51881534]]\n",
            "Step: 582 -> Loss: 0.6896345615386963 -> Predictions: [[0.475379  ]\n",
            " [0.5009506 ]\n",
            " [0.5014289 ]\n",
            " [0.51901436]]\n",
            "Step: 583 -> Loss: 0.6895599365234375 -> Predictions: [[0.47508553]\n",
            " [0.5009943 ]\n",
            " [0.5014645 ]\n",
            " [0.5192159 ]]\n",
            "Step: 584 -> Loss: 0.6894834637641907 -> Predictions: [[0.47478732]\n",
            " [0.5010392 ]\n",
            " [0.5015011 ]\n",
            " [0.5194199 ]]\n",
            "Step: 585 -> Loss: 0.6894049644470215 -> Predictions: [[0.4744843 ]\n",
            " [0.5010853 ]\n",
            " [0.50153875]\n",
            " [0.51962644]]\n",
            "Step: 586 -> Loss: 0.6893244385719299 -> Predictions: [[0.47417638]\n",
            " [0.50113255]\n",
            " [0.5015775 ]\n",
            " [0.51983553]]\n",
            "Step: 587 -> Loss: 0.6892420053482056 -> Predictions: [[0.47386348]\n",
            " [0.501181  ]\n",
            " [0.5016173 ]\n",
            " [0.52004725]]\n",
            "Step: 588 -> Loss: 0.6891573667526245 -> Predictions: [[0.47354543]\n",
            " [0.5012308 ]\n",
            " [0.50165826]\n",
            " [0.5202615 ]]\n",
            "Step: 589 -> Loss: 0.6890705227851868 -> Predictions: [[0.47322217]\n",
            " [0.5012818 ]\n",
            " [0.50170046]\n",
            " [0.5204785 ]]\n",
            "Step: 590 -> Loss: 0.6889814138412476 -> Predictions: [[0.4728937 ]\n",
            " [0.50133413]\n",
            " [0.5017438 ]\n",
            " [0.5206981 ]]\n",
            "Step: 591 -> Loss: 0.6888900995254517 -> Predictions: [[0.47255972]\n",
            " [0.50138783]\n",
            " [0.5017884 ]\n",
            " [0.5209204 ]]\n",
            "Step: 592 -> Loss: 0.68879634141922 -> Predictions: [[0.47222033]\n",
            " [0.50144297]\n",
            " [0.50183415]\n",
            " [0.5211454 ]]\n",
            "Step: 593 -> Loss: 0.6887003183364868 -> Predictions: [[0.47187528]\n",
            " [0.5014995 ]\n",
            " [0.50188136]\n",
            " [0.52137315]]\n",
            "Step: 594 -> Loss: 0.6886016130447388 -> Predictions: [[0.47152457]\n",
            " [0.50155747]\n",
            " [0.5019298 ]\n",
            " [0.52160364]]\n",
            "Step: 595 -> Loss: 0.6885005235671997 -> Predictions: [[0.47116798]\n",
            " [0.50161695]\n",
            " [0.5019797 ]\n",
            " [0.521837  ]]\n",
            "Step: 596 -> Loss: 0.6883968114852905 -> Predictions: [[0.47080556]\n",
            " [0.501678  ]\n",
            " [0.502031  ]\n",
            " [0.5220731 ]]\n",
            "Step: 597 -> Loss: 0.6882902979850769 -> Predictions: [[0.47043702]\n",
            " [0.5017406 ]\n",
            " [0.5020837 ]\n",
            " [0.5223121 ]]\n",
            "Step: 598 -> Loss: 0.6881811618804932 -> Predictions: [[0.47006232]\n",
            " [0.50180477]\n",
            " [0.50213796]\n",
            " [0.522554  ]]\n",
            "Step: 599 -> Loss: 0.6880691051483154 -> Predictions: [[0.46968144]\n",
            " [0.50187063]\n",
            " [0.50219375]\n",
            " [0.5227987 ]]\n",
            "Step: 600 -> Loss: 0.6879542469978333 -> Predictions: [[0.46929413]\n",
            " [0.5019382 ]\n",
            " [0.502251  ]\n",
            " [0.52304643]]\n",
            "Step: 601 -> Loss: 0.6878362894058228 -> Predictions: [[0.46890026]\n",
            " [0.50200754]\n",
            " [0.50231   ]\n",
            " [0.5232971 ]]\n",
            "Step: 602 -> Loss: 0.6877153515815735 -> Predictions: [[0.46849987]\n",
            " [0.50207853]\n",
            " [0.5023706 ]\n",
            " [0.5235507 ]]\n",
            "Step: 603 -> Loss: 0.6875913143157959 -> Predictions: [[0.46809265]\n",
            " [0.5021515 ]\n",
            " [0.50243294]\n",
            " [0.5238073 ]]\n",
            "Step: 604 -> Loss: 0.6874640583992004 -> Predictions: [[0.46767855]\n",
            " [0.5022262 ]\n",
            " [0.50249696]\n",
            " [0.5240669 ]]\n",
            "Step: 605 -> Loss: 0.6873335242271423 -> Predictions: [[0.46725753]\n",
            " [0.5023028 ]\n",
            " [0.50256276]\n",
            " [0.52432954]]\n",
            "Step: 606 -> Loss: 0.687199592590332 -> Predictions: [[0.46682936]\n",
            " [0.5023814 ]\n",
            " [0.5026304 ]\n",
            " [0.52459526]]\n",
            "Step: 607 -> Loss: 0.6870622038841248 -> Predictions: [[0.4663939 ]\n",
            " [0.50246197]\n",
            " [0.5027    ]\n",
            " [0.5248641 ]]\n",
            "Step: 608 -> Loss: 0.6869212985038757 -> Predictions: [[0.46595106]\n",
            " [0.5025446 ]\n",
            " [0.50277144]\n",
            " [0.52513605]]\n",
            "Step: 609 -> Loss: 0.6867767572402954 -> Predictions: [[0.46550068]\n",
            " [0.5026293 ]\n",
            " [0.5028449 ]\n",
            " [0.5254111 ]]\n",
            "Step: 610 -> Loss: 0.686628520488739 -> Predictions: [[0.46504262]\n",
            " [0.5027161 ]\n",
            " [0.5029204 ]\n",
            " [0.52568936]]\n",
            "Step: 611 -> Loss: 0.686476469039917 -> Predictions: [[0.46457675]\n",
            " [0.5028052 ]\n",
            " [0.50299793]\n",
            " [0.52597076]]\n",
            "Step: 612 -> Loss: 0.6863205432891846 -> Predictions: [[0.46410295]\n",
            " [0.50289637]\n",
            " [0.5030776 ]\n",
            " [0.52625537]]\n",
            "Step: 613 -> Loss: 0.6861605644226074 -> Predictions: [[0.46362108]\n",
            " [0.5029899 ]\n",
            " [0.50315946]\n",
            " [0.5265432 ]]\n",
            "Step: 614 -> Loss: 0.6859965920448303 -> Predictions: [[0.46313086]\n",
            " [0.50308573]\n",
            " [0.50324357]\n",
            " [0.5268343 ]]\n",
            "Step: 615 -> Loss: 0.6858283877372742 -> Predictions: [[0.4626323 ]\n",
            " [0.50318396]\n",
            " [0.50333   ]\n",
            " [0.52712864]]\n",
            "Step: 616 -> Loss: 0.685655951499939 -> Predictions: [[0.4621252]\n",
            " [0.5032846]\n",
            " [0.5034186]\n",
            " [0.5274263]]\n",
            "Step: 617 -> Loss: 0.6854790449142456 -> Predictions: [[0.4616094 ]\n",
            " [0.5033877 ]\n",
            " [0.5035098 ]\n",
            " [0.52772725]]\n",
            "Step: 618 -> Loss: 0.6852977275848389 -> Predictions: [[0.4610847 ]\n",
            " [0.50349337]\n",
            " [0.5036034 ]\n",
            " [0.5280315 ]]\n",
            "Step: 619 -> Loss: 0.6851118803024292 -> Predictions: [[0.46055096]\n",
            " [0.5036016 ]\n",
            " [0.5036995 ]\n",
            " [0.52833915]]\n",
            "Step: 620 -> Loss: 0.6849212646484375 -> Predictions: [[0.46000808]\n",
            " [0.5037125 ]\n",
            " [0.5037981 ]\n",
            " [0.52865016]]\n",
            "Step: 621 -> Loss: 0.6847258806228638 -> Predictions: [[0.4594558 ]\n",
            " [0.503826  ]\n",
            " [0.5038994 ]\n",
            " [0.52896464]]\n",
            "Step: 622 -> Loss: 0.684525728225708 -> Predictions: [[0.45889398]\n",
            " [0.5039424 ]\n",
            " [0.5040034 ]\n",
            " [0.52928245]]\n",
            "Step: 623 -> Loss: 0.6843204498291016 -> Predictions: [[0.4583225]\n",
            " [0.5040615]\n",
            " [0.5041101]\n",
            " [0.5296037]]\n",
            "Step: 624 -> Loss: 0.6841100454330444 -> Predictions: [[0.45774114]\n",
            " [0.50418353]\n",
            " [0.50421965]\n",
            " [0.5299285 ]]\n",
            "Step: 625 -> Loss: 0.6838945150375366 -> Predictions: [[0.45714968]\n",
            " [0.5043085 ]\n",
            " [0.50433207]\n",
            " [0.5302567 ]]\n",
            "Step: 626 -> Loss: 0.683673620223999 -> Predictions: [[0.45654804]\n",
            " [0.50443643]\n",
            " [0.50444746]\n",
            " [0.53058845]]\n",
            "Step: 627 -> Loss: 0.6834473609924316 -> Predictions: [[0.45593596]\n",
            " [0.5045674 ]\n",
            " [0.50456583]\n",
            " [0.5309238 ]]\n",
            "Step: 628 -> Loss: 0.6832154393196106 -> Predictions: [[0.45531327]\n",
            " [0.50470144]\n",
            " [0.50468725]\n",
            " [0.5312627 ]]\n",
            "Step: 629 -> Loss: 0.6829778552055359 -> Predictions: [[0.45467976]\n",
            " [0.50483865]\n",
            " [0.5048119 ]\n",
            " [0.5316051 ]]\n",
            "Step: 630 -> Loss: 0.6827346086502075 -> Predictions: [[0.45403528]\n",
            " [0.50497913]\n",
            " [0.5049397 ]\n",
            " [0.53195125]]\n",
            "Step: 631 -> Loss: 0.6824853420257568 -> Predictions: [[0.45337966]\n",
            " [0.50512284]\n",
            " [0.5050707 ]\n",
            " [0.53230095]]\n",
            "Step: 632 -> Loss: 0.6822301745414734 -> Predictions: [[0.45271257]\n",
            " [0.50526994]\n",
            " [0.50520515]\n",
            " [0.5326544 ]]\n",
            "Step: 633 -> Loss: 0.6819688081741333 -> Predictions: [[0.45203394]\n",
            " [0.50542045]\n",
            " [0.50534296]\n",
            " [0.5330115 ]]\n",
            "Step: 634 -> Loss: 0.6817011833190918 -> Predictions: [[0.45134345]\n",
            " [0.5055744 ]\n",
            " [0.5054843 ]\n",
            " [0.53337234]]\n",
            "Step: 635 -> Loss: 0.6814272403717041 -> Predictions: [[0.45064098]\n",
            " [0.50573194]\n",
            " [0.5056291 ]\n",
            " [0.533737  ]]\n",
            "Step: 636 -> Loss: 0.6811467409133911 -> Predictions: [[0.44992632]\n",
            " [0.50589305]\n",
            " [0.50577766]\n",
            " [0.5341055 ]]\n",
            "Step: 637 -> Loss: 0.6808596849441528 -> Predictions: [[0.4491992 ]\n",
            " [0.50605786]\n",
            " [0.5059299 ]\n",
            " [0.5344777 ]]\n",
            "Step: 638 -> Loss: 0.6805658936500549 -> Predictions: [[0.4484594 ]\n",
            " [0.5062264 ]\n",
            " [0.50608593]\n",
            " [0.5348539 ]]\n",
            "Step: 639 -> Loss: 0.6802652478218079 -> Predictions: [[0.4477067]\n",
            " [0.5063988]\n",
            " [0.5062458]\n",
            " [0.5352339]]\n",
            "Step: 640 -> Loss: 0.6799576282501221 -> Predictions: [[0.44694087]\n",
            " [0.50657505]\n",
            " [0.5064096 ]\n",
            " [0.535618  ]]\n",
            "Step: 641 -> Loss: 0.6796428561210632 -> Predictions: [[0.44616175]\n",
            " [0.50675523]\n",
            " [0.5065775 ]\n",
            " [0.53600603]]\n",
            "Step: 642 -> Loss: 0.6793208718299866 -> Predictions: [[0.44536895]\n",
            " [0.5069395 ]\n",
            " [0.5067494 ]\n",
            " [0.5363981 ]]\n",
            "Step: 643 -> Loss: 0.6789915561676025 -> Predictions: [[0.4445624 ]\n",
            " [0.5071278 ]\n",
            " [0.5069255 ]\n",
            " [0.53679425]]\n",
            "Step: 644 -> Loss: 0.6786547899246216 -> Predictions: [[0.4437417 ]\n",
            " [0.5073203 ]\n",
            " [0.50710595]\n",
            " [0.53719455]]\n",
            "Step: 645 -> Loss: 0.6783103942871094 -> Predictions: [[0.4429067 ]\n",
            " [0.5075171 ]\n",
            " [0.50729066]\n",
            " [0.537599  ]]\n",
            "Step: 646 -> Loss: 0.6779582500457764 -> Predictions: [[0.44205713]\n",
            " [0.50771815]\n",
            " [0.5074799 ]\n",
            " [0.53800774]]\n",
            "Step: 647 -> Loss: 0.677598237991333 -> Predictions: [[0.44119278]\n",
            " [0.50792366]\n",
            " [0.50767356]\n",
            " [0.53842074]]\n",
            "Step: 648 -> Loss: 0.6772302389144897 -> Predictions: [[0.44031322]\n",
            " [0.5081336 ]\n",
            " [0.5078719 ]\n",
            " [0.5388381 ]]\n",
            "Step: 649 -> Loss: 0.6768541932106018 -> Predictions: [[0.43941835]\n",
            " [0.50834817]\n",
            " [0.50807494]\n",
            " [0.53925985]]\n",
            "Step: 650 -> Loss: 0.6764698028564453 -> Predictions: [[0.43850785]\n",
            " [0.50856733]\n",
            " [0.5082827 ]\n",
            " [0.53968614]]\n",
            "Step: 651 -> Loss: 0.676077127456665 -> Predictions: [[0.43758145]\n",
            " [0.50879127]\n",
            " [0.50849545]\n",
            " [0.54011685]]\n",
            "Step: 652 -> Loss: 0.6756758689880371 -> Predictions: [[0.43663886]\n",
            " [0.50902   ]\n",
            " [0.5087131 ]\n",
            " [0.54055226]]\n",
            "Step: 653 -> Loss: 0.6752660870552063 -> Predictions: [[0.43567985]\n",
            " [0.50925356]\n",
            " [0.50893587]\n",
            " [0.54099226]]\n",
            "Step: 654 -> Loss: 0.6748474836349487 -> Predictions: [[0.43470407]\n",
            " [0.50949216]\n",
            " [0.5091638 ]\n",
            " [0.54143703]]\n",
            "Step: 655 -> Loss: 0.6744199991226196 -> Predictions: [[0.4337113 ]\n",
            " [0.5097359 ]\n",
            " [0.509397  ]\n",
            " [0.54188657]]\n",
            "Step: 656 -> Loss: 0.6739835739135742 -> Predictions: [[0.43270117]\n",
            " [0.5099847 ]\n",
            " [0.5096355 ]\n",
            " [0.54234105]]\n",
            "Step: 657 -> Loss: 0.6735379695892334 -> Predictions: [[0.43167344]\n",
            " [0.51023877]\n",
            " [0.5098795 ]\n",
            " [0.5428005 ]]\n",
            "Step: 658 -> Loss: 0.6730830669403076 -> Predictions: [[0.43062785]\n",
            " [0.51049817]\n",
            " [0.5101291 ]\n",
            " [0.5432649 ]]\n",
            "Step: 659 -> Loss: 0.6726188659667969 -> Predictions: [[0.429564  ]\n",
            " [0.51076305]\n",
            " [0.5103844 ]\n",
            " [0.5437345 ]]\n",
            "Step: 660 -> Loss: 0.6721451282501221 -> Predictions: [[0.4284817 ]\n",
            " [0.5110335 ]\n",
            " [0.51064533]\n",
            " [0.54420924]]\n",
            "Step: 661 -> Loss: 0.6716617345809937 -> Predictions: [[0.42738056]\n",
            " [0.51130944]\n",
            " [0.5109123 ]\n",
            " [0.54468936]]\n",
            "Step: 662 -> Loss: 0.6711685657501221 -> Predictions: [[0.42626038]\n",
            " [0.5115912 ]\n",
            " [0.51118517]\n",
            " [0.5451747 ]]\n",
            "Step: 663 -> Loss: 0.6706655621528625 -> Predictions: [[0.4251207 ]\n",
            " [0.51187885]\n",
            " [0.5114642 ]\n",
            " [0.5456656 ]]\n",
            "Step: 664 -> Loss: 0.6701525449752808 -> Predictions: [[0.42396137]\n",
            " [0.51217234]\n",
            " [0.5117494 ]\n",
            " [0.54616207]]\n",
            "Step: 665 -> Loss: 0.6696293950080872 -> Predictions: [[0.422782  ]\n",
            " [0.51247185]\n",
            " [0.5120409 ]\n",
            " [0.5466642 ]]\n",
            "Step: 666 -> Loss: 0.6690959930419922 -> Predictions: [[0.4215823 ]\n",
            " [0.51277757]\n",
            " [0.51233894]\n",
            " [0.547172  ]]\n",
            "Step: 667 -> Loss: 0.6685522794723511 -> Predictions: [[0.42036197]\n",
            " [0.51308954]\n",
            " [0.51264346]\n",
            " [0.5476857 ]]\n",
            "Step: 668 -> Loss: 0.6679980754852295 -> Predictions: [[0.41912076]\n",
            " [0.5134079 ]\n",
            " [0.51295465]\n",
            " [0.54820526]]\n",
            "Step: 669 -> Loss: 0.6674332618713379 -> Predictions: [[0.4178582 ]\n",
            " [0.5137326 ]\n",
            " [0.51327264]\n",
            " [0.54873085]]\n",
            "Step: 670 -> Loss: 0.6668577790260315 -> Predictions: [[0.41657415]\n",
            " [0.51406395]\n",
            " [0.51359755]\n",
            " [0.5492626 ]]\n",
            "Step: 671 -> Loss: 0.6662715077400208 -> Predictions: [[0.41526824]\n",
            " [0.514402  ]\n",
            " [0.5139294 ]\n",
            " [0.5498005 ]]\n",
            "Step: 672 -> Loss: 0.6656743288040161 -> Predictions: [[0.4139402]\n",
            " [0.5147468]\n",
            " [0.5142685]\n",
            " [0.5503447]]\n",
            "Step: 673 -> Loss: 0.6650662422180176 -> Predictions: [[0.41258976]\n",
            " [0.5150985 ]\n",
            " [0.5146148 ]\n",
            " [0.55089533]]\n",
            "Step: 674 -> Loss: 0.6644469499588013 -> Predictions: [[0.4112166 ]\n",
            " [0.5154573 ]\n",
            " [0.5149686 ]\n",
            " [0.55145246]]\n",
            "Step: 675 -> Loss: 0.6638164520263672 -> Predictions: [[0.40982044]\n",
            " [0.5158231 ]\n",
            " [0.51532984]\n",
            " [0.5520162 ]]\n",
            "Step: 676 -> Loss: 0.6631748080253601 -> Predictions: [[0.40840095]\n",
            " [0.5161963 ]\n",
            " [0.5156987 ]\n",
            " [0.5525865 ]]\n",
            "Step: 677 -> Loss: 0.6625217199325562 -> Predictions: [[0.40695795]\n",
            " [0.5165768 ]\n",
            " [0.51607525]\n",
            " [0.55316365]]\n",
            "Step: 678 -> Loss: 0.6618571281433105 -> Predictions: [[0.4054912 ]\n",
            " [0.51696485]\n",
            " [0.5164598 ]\n",
            " [0.5537476 ]]\n",
            "Step: 679 -> Loss: 0.6611811518669128 -> Predictions: [[0.4040004 ]\n",
            " [0.51736045]\n",
            " [0.5168523 ]\n",
            " [0.5543386 ]]\n",
            "Step: 680 -> Loss: 0.6604934930801392 -> Predictions: [[0.40248528]\n",
            " [0.5177638 ]\n",
            " [0.517253  ]\n",
            " [0.5549364 ]]\n",
            "Step: 681 -> Loss: 0.6597941517829895 -> Predictions: [[0.4009457 ]\n",
            " [0.51817495]\n",
            " [0.51766187]\n",
            " [0.5555414 ]]\n",
            "Step: 682 -> Loss: 0.6590831279754639 -> Predictions: [[0.39938137]\n",
            " [0.5185941 ]\n",
            " [0.51807916]\n",
            " [0.55615354]]\n",
            "Step: 683 -> Loss: 0.6583604216575623 -> Predictions: [[0.3977921]\n",
            " [0.5190212]\n",
            " [0.5185049]\n",
            " [0.5567728]]\n",
            "Step: 684 -> Loss: 0.6576259136199951 -> Predictions: [[0.39617777]\n",
            " [0.5194566 ]\n",
            " [0.5189393 ]\n",
            " [0.55739945]]\n",
            "Step: 685 -> Loss: 0.6568794846534729 -> Predictions: [[0.39453816]\n",
            " [0.51990026]\n",
            " [0.51938236]\n",
            " [0.5580334 ]]\n",
            "Step: 686 -> Loss: 0.6561212539672852 -> Predictions: [[0.3928731 ]\n",
            " [0.52035224]\n",
            " [0.51983434]\n",
            " [0.55867475]]\n",
            "Step: 687 -> Loss: 0.6553511619567871 -> Predictions: [[0.3911825 ]\n",
            " [0.52081275]\n",
            " [0.5202952 ]\n",
            " [0.5593235 ]]\n",
            "Step: 688 -> Loss: 0.654569149017334 -> Predictions: [[0.38946626]\n",
            " [0.5212819 ]\n",
            " [0.5207651 ]\n",
            " [0.5599797 ]]\n",
            "Step: 689 -> Loss: 0.6537752151489258 -> Predictions: [[0.38772422]\n",
            " [0.52175975]\n",
            " [0.5212443 ]\n",
            " [0.56064343]]\n",
            "Step: 690 -> Loss: 0.6529694199562073 -> Predictions: [[0.38595632]\n",
            " [0.52224636]\n",
            " [0.5217326 ]\n",
            " [0.56131464]]\n",
            "Step: 691 -> Loss: 0.6521518230438232 -> Predictions: [[0.38416258]\n",
            " [0.5227419 ]\n",
            " [0.5222304 ]\n",
            " [0.5619933 ]]\n",
            "Step: 692 -> Loss: 0.6513223648071289 -> Predictions: [[0.3823429]\n",
            " [0.5232464]\n",
            " [0.5227376]\n",
            " [0.5626795]]\n",
            "Step: 693 -> Loss: 0.650481104850769 -> Predictions: [[0.3804973 ]\n",
            " [0.52375996]\n",
            " [0.5232544 ]\n",
            " [0.5633734 ]]\n",
            "Step: 694 -> Loss: 0.6496281027793884 -> Predictions: [[0.37862584]\n",
            " [0.5242827 ]\n",
            " [0.52378076]\n",
            " [0.56407464]]\n",
            "Step: 695 -> Loss: 0.6487634778022766 -> Predictions: [[0.37672856]\n",
            " [0.5248146 ]\n",
            " [0.52431685]\n",
            " [0.56478333]]\n",
            "Step: 696 -> Loss: 0.6478871703147888 -> Predictions: [[0.37480554]\n",
            " [0.5253559 ]\n",
            " [0.5248627 ]\n",
            " [0.5654995 ]]\n",
            "Step: 697 -> Loss: 0.6469993591308594 -> Predictions: [[0.37285691]\n",
            " [0.5259064 ]\n",
            " [0.52541846]\n",
            " [0.566223  ]]\n",
            "Step: 698 -> Loss: 0.6461001634597778 -> Predictions: [[0.37088275]\n",
            " [0.52646637]\n",
            " [0.5259841 ]\n",
            " [0.56695384]]\n",
            "Step: 699 -> Loss: 0.6451897025108337 -> Predictions: [[0.36888328]\n",
            " [0.5270358 ]\n",
            " [0.52655965]\n",
            " [0.567692  ]]\n",
            "Step: 700 -> Loss: 0.6442680358886719 -> Predictions: [[0.3668588 ]\n",
            " [0.52761465]\n",
            " [0.52714527]\n",
            " [0.5684372 ]]\n",
            "Step: 701 -> Loss: 0.6433354020118713 -> Predictions: [[0.3648094 ]\n",
            " [0.5282031 ]\n",
            " [0.52774084]\n",
            " [0.5691895 ]]\n",
            "Step: 702 -> Loss: 0.6423918604850769 -> Predictions: [[0.3627354 ]\n",
            " [0.528801  ]\n",
            " [0.5283465 ]\n",
            " [0.56994885]]\n",
            "Step: 703 -> Loss: 0.6414375305175781 -> Predictions: [[0.36063713]\n",
            " [0.5294086 ]\n",
            " [0.52896225]\n",
            " [0.57071495]]\n",
            "Step: 704 -> Loss: 0.6404727697372437 -> Predictions: [[0.3585149 ]\n",
            " [0.5300256 ]\n",
            " [0.52958804]\n",
            " [0.5714877 ]]\n",
            "Step: 705 -> Loss: 0.6394976377487183 -> Predictions: [[0.35636923]\n",
            " [0.53065217]\n",
            " [0.53022385]\n",
            " [0.57226706]]\n",
            "Step: 706 -> Loss: 0.6385124921798706 -> Predictions: [[0.3542003 ]\n",
            " [0.53128827]\n",
            " [0.5308698 ]\n",
            " [0.57305276]]\n",
            "Step: 707 -> Loss: 0.6375173330307007 -> Predictions: [[0.35200873]\n",
            " [0.53193384]\n",
            " [0.53152573]\n",
            " [0.5738447 ]]\n",
            "Step: 708 -> Loss: 0.6365125179290771 -> Predictions: [[0.3497949 ]\n",
            " [0.5325889 ]\n",
            " [0.53219163]\n",
            " [0.57464254]]\n",
            "Step: 709 -> Loss: 0.6354982852935791 -> Predictions: [[0.34755942]\n",
            " [0.5332534 ]\n",
            " [0.5328675 ]\n",
            " [0.5754463 ]]\n",
            "Step: 710 -> Loss: 0.6344749331474304 -> Predictions: [[0.3453028 ]\n",
            " [0.53392714]\n",
            " [0.53355324]\n",
            " [0.5762556 ]]\n",
            "Step: 711 -> Loss: 0.6334426999092102 -> Predictions: [[0.34302554]\n",
            " [0.53461015]\n",
            " [0.53424865]\n",
            " [0.5770703 ]]\n",
            "Step: 712 -> Loss: 0.6324018836021423 -> Predictions: [[0.34072834]\n",
            " [0.53530234]\n",
            " [0.5349539 ]\n",
            " [0.57789004]]\n",
            "Step: 713 -> Loss: 0.6313527226448059 -> Predictions: [[0.3384119 ]\n",
            " [0.5360036 ]\n",
            " [0.5356687 ]\n",
            " [0.57871467]]\n",
            "Step: 714 -> Loss: 0.6302956342697144 -> Predictions: [[0.3360767]\n",
            " [0.5367138]\n",
            " [0.536393 ]\n",
            " [0.5795439]]\n",
            "Step: 715 -> Loss: 0.6292308568954468 -> Predictions: [[0.3337237 ]\n",
            " [0.5374328 ]\n",
            " [0.53712666]\n",
            " [0.58037746]]\n",
            "Step: 716 -> Loss: 0.6281588077545166 -> Predictions: [[0.33135346]\n",
            " [0.53816044]\n",
            " [0.5378695 ]\n",
            " [0.581215  ]]\n",
            "Step: 717 -> Loss: 0.6270797252655029 -> Predictions: [[0.3289668]\n",
            " [0.5388967]\n",
            " [0.5386215]\n",
            " [0.5820563]]\n",
            "Step: 718 -> Loss: 0.625994086265564 -> Predictions: [[0.32656455]\n",
            " [0.53964126]\n",
            " [0.53938234]\n",
            " [0.582901  ]]\n",
            "Step: 719 -> Loss: 0.6249021291732788 -> Predictions: [[0.32414746]\n",
            " [0.54039407]\n",
            " [0.54015195]\n",
            " [0.5837488 ]]\n",
            "Step: 720 -> Loss: 0.6238042712211609 -> Predictions: [[0.32171646]\n",
            " [0.54115474]\n",
            " [0.54093003]\n",
            " [0.5845994 ]]\n",
            "Step: 721 -> Loss: 0.6227009296417236 -> Predictions: [[0.31927228]\n",
            " [0.5419233 ]\n",
            " [0.5417165 ]\n",
            " [0.58545244]]\n",
            "Step: 722 -> Loss: 0.6215925216674805 -> Predictions: [[0.31681594]\n",
            " [0.54269934]\n",
            " [0.5425111 ]\n",
            " [0.5863075 ]]\n",
            "Step: 723 -> Loss: 0.6204792857170105 -> Predictions: [[0.31434828]\n",
            " [0.5434828 ]\n",
            " [0.54331356]\n",
            " [0.5871644 ]]\n",
            "Step: 724 -> Loss: 0.6193617582321167 -> Predictions: [[0.31187016]\n",
            " [0.54427326]\n",
            " [0.5441236 ]\n",
            " [0.58802253]]\n",
            "Step: 725 -> Loss: 0.6182402968406677 -> Predictions: [[0.30938256]\n",
            " [0.54507065]\n",
            " [0.5449411 ]\n",
            " [0.5888818 ]]\n",
            "Step: 726 -> Loss: 0.6171153783798218 -> Predictions: [[0.3068864 ]\n",
            " [0.5458745 ]\n",
            " [0.5457658 ]\n",
            " [0.58974177]]\n",
            "Step: 727 -> Loss: 0.6159871816635132 -> Predictions: [[0.3043827 ]\n",
            " [0.5466848 ]\n",
            " [0.54659736]\n",
            " [0.59060186]]\n",
            "Step: 728 -> Loss: 0.6148563623428345 -> Predictions: [[0.30187237]\n",
            " [0.5475011 ]\n",
            " [0.5474354 ]\n",
            " [0.591462  ]]\n",
            "Step: 729 -> Loss: 0.6137232780456543 -> Predictions: [[0.2993564 ]\n",
            " [0.54832304]\n",
            " [0.5482798 ]\n",
            " [0.5923217 ]]\n",
            "Step: 730 -> Loss: 0.6125882267951965 -> Predictions: [[0.29683566]\n",
            " [0.5491505 ]\n",
            " [0.54913026]\n",
            " [0.5931806 ]]\n",
            "Step: 731 -> Loss: 0.6114517450332642 -> Predictions: [[0.2943112 ]\n",
            " [0.5499831 ]\n",
            " [0.5499863 ]\n",
            " [0.59403825]]\n",
            "Step: 732 -> Loss: 0.6103142499923706 -> Predictions: [[0.29178405]\n",
            " [0.55082047]\n",
            " [0.55084777]\n",
            " [0.59489447]]\n",
            "Step: 733 -> Loss: 0.6091760396957397 -> Predictions: [[0.28925505]\n",
            " [0.5516623 ]\n",
            " [0.55171436]\n",
            " [0.59574866]]\n",
            "Step: 734 -> Loss: 0.6080375909805298 -> Predictions: [[0.28672522]\n",
            " [0.5525085 ]\n",
            " [0.55258566]\n",
            " [0.5966006 ]]\n",
            "Step: 735 -> Loss: 0.6068992614746094 -> Predictions: [[0.2841955]\n",
            " [0.5533583]\n",
            " [0.5534613]\n",
            " [0.5974499]]\n",
            "Step: 736 -> Loss: 0.6057615280151367 -> Predictions: [[0.2816669 ]\n",
            " [0.55421174]\n",
            " [0.554341  ]\n",
            " [0.59829617]]\n",
            "Step: 737 -> Loss: 0.6046246290206909 -> Predictions: [[0.27914026]\n",
            " [0.5550683 ]\n",
            " [0.5552245 ]\n",
            " [0.5991392 ]]\n",
            "Step: 738 -> Loss: 0.6034891605377197 -> Predictions: [[0.27661657]\n",
            " [0.5559277 ]\n",
            " [0.55611134]\n",
            " [0.5999785 ]]\n",
            "Step: 739 -> Loss: 0.6023553609848022 -> Predictions: [[0.27409667]\n",
            " [0.5567895 ]\n",
            " [0.55700123]\n",
            " [0.6008138 ]]\n",
            "Step: 740 -> Loss: 0.6012236475944519 -> Predictions: [[0.27158153]\n",
            " [0.5576536 ]\n",
            " [0.5578939 ]\n",
            " [0.60164475]]\n",
            "Step: 741 -> Loss: 0.6000943779945374 -> Predictions: [[0.26907203]\n",
            " [0.55851936]\n",
            " [0.55878884]\n",
            " [0.60247105]]\n",
            "Step: 742 -> Loss: 0.5989679098129272 -> Predictions: [[0.26656902]\n",
            " [0.5593867 ]\n",
            " [0.5596858 ]\n",
            " [0.60329247]]\n",
            "Step: 743 -> Loss: 0.5978446006774902 -> Predictions: [[0.26407328]\n",
            " [0.560255  ]\n",
            " [0.56058455]\n",
            " [0.60410845]]\n",
            "Step: 744 -> Loss: 0.5967247486114502 -> Predictions: [[0.26158568]\n",
            " [0.5611241 ]\n",
            " [0.5614845 ]\n",
            " [0.604919  ]]\n",
            "Step: 745 -> Loss: 0.5956087112426758 -> Predictions: [[0.25910708]\n",
            " [0.5619936 ]\n",
            " [0.56238544]\n",
            " [0.6057237 ]]\n",
            "Step: 746 -> Loss: 0.5944968461990356 -> Predictions: [[0.25663817]\n",
            " [0.5628633 ]\n",
            " [0.5632872 ]\n",
            " [0.60652226]]\n",
            "Step: 747 -> Loss: 0.5933894515037537 -> Predictions: [[0.2541797 ]\n",
            " [0.5637327 ]\n",
            " [0.56418914]\n",
            " [0.60731447]]\n",
            "Step: 748 -> Loss: 0.5922867059707642 -> Predictions: [[0.2517325 ]\n",
            " [0.5646015 ]\n",
            " [0.5650912 ]\n",
            " [0.60810006]]\n",
            "Step: 749 -> Loss: 0.5911890864372253 -> Predictions: [[0.24929716]\n",
            " [0.5654694 ]\n",
            " [0.56599283]\n",
            " [0.60887885]]\n",
            "Step: 750 -> Loss: 0.5900967717170715 -> Predictions: [[0.24687439]\n",
            " [0.56633604]\n",
            " [0.5668938 ]\n",
            " [0.6096506 ]]\n",
            "Step: 751 -> Loss: 0.5890100002288818 -> Predictions: [[0.2444649 ]\n",
            " [0.56720126]\n",
            " [0.567794  ]\n",
            " [0.610415  ]]\n",
            "Step: 752 -> Loss: 0.5879291296005249 -> Predictions: [[0.24206926]\n",
            " [0.5680646 ]\n",
            " [0.5686928 ]\n",
            " [0.61117196]]\n",
            "Step: 753 -> Loss: 0.5868542194366455 -> Predictions: [[0.23968813]\n",
            " [0.56892574]\n",
            " [0.56959015]\n",
            " [0.6119212 ]]\n",
            "Step: 754 -> Loss: 0.5857857465744019 -> Predictions: [[0.23732202]\n",
            " [0.5697845 ]\n",
            " [0.5704856 ]\n",
            " [0.6126627 ]]\n",
            "Step: 755 -> Loss: 0.5847237706184387 -> Predictions: [[0.2349715 ]\n",
            " [0.57064056]\n",
            " [0.571379  ]\n",
            " [0.6133961 ]]\n",
            "Step: 756 -> Loss: 0.5836685299873352 -> Predictions: [[0.23263709]\n",
            " [0.5714937 ]\n",
            " [0.57227   ]\n",
            " [0.6141214 ]]\n",
            "Step: 757 -> Loss: 0.5826202630996704 -> Predictions: [[0.23031929]\n",
            " [0.5723435 ]\n",
            " [0.5731583 ]\n",
            " [0.61483836]]\n",
            "Step: 758 -> Loss: 0.5815790891647339 -> Predictions: [[0.22801857]\n",
            " [0.57318985]\n",
            " [0.57404375]\n",
            " [0.6155469 ]]\n",
            "Step: 759 -> Loss: 0.58054518699646 -> Predictions: [[0.22573537]\n",
            " [0.5740324 ]\n",
            " [0.57492596]\n",
            " [0.6162469 ]]\n",
            "Step: 760 -> Loss: 0.5795188546180725 -> Predictions: [[0.22347009]\n",
            " [0.57487094]\n",
            " [0.5758048 ]\n",
            " [0.6169383 ]]\n",
            "Step: 761 -> Loss: 0.5785000324249268 -> Predictions: [[0.22122315]\n",
            " [0.57570535]\n",
            " [0.5766801 ]\n",
            " [0.6176209 ]]\n",
            "Step: 762 -> Loss: 0.5774891376495361 -> Predictions: [[0.21899484]\n",
            " [0.5765352 ]\n",
            " [0.5775515 ]\n",
            " [0.61829466]]\n",
            "Step: 763 -> Loss: 0.5764859914779663 -> Predictions: [[0.21678562]\n",
            " [0.5773604 ]\n",
            " [0.5784189 ]\n",
            " [0.6189594 ]]\n",
            "Step: 764 -> Loss: 0.5754908919334412 -> Predictions: [[0.2145957 ]\n",
            " [0.57818073]\n",
            " [0.579282  ]\n",
            " [0.6196154 ]]\n",
            "Step: 765 -> Loss: 0.5745039582252502 -> Predictions: [[0.21242537]\n",
            " [0.578996  ]\n",
            " [0.5801407 ]\n",
            " [0.62026227]]\n",
            "Step: 766 -> Loss: 0.5735251903533936 -> Predictions: [[0.21027495]\n",
            " [0.5798061 ]\n",
            " [0.58099467]\n",
            " [0.6209    ]]\n",
            "Step: 767 -> Loss: 0.572554886341095 -> Predictions: [[0.20814466]\n",
            " [0.5806107 ]\n",
            " [0.5818439 ]\n",
            " [0.62152874]]\n",
            "Step: 768 -> Loss: 0.5715928077697754 -> Predictions: [[0.20603468]\n",
            " [0.58140975]\n",
            " [0.5826882 ]\n",
            " [0.6221483 ]]\n",
            "Step: 769 -> Loss: 0.5706393718719482 -> Predictions: [[0.20394522]\n",
            " [0.5822029 ]\n",
            " [0.5835274 ]\n",
            " [0.62275857]]\n",
            "Step: 770 -> Loss: 0.5696943402290344 -> Predictions: [[0.20187649]\n",
            " [0.5829903 ]\n",
            " [0.5843613 ]\n",
            " [0.6233598 ]]\n",
            "Step: 771 -> Loss: 0.568757951259613 -> Predictions: [[0.19982864]\n",
            " [0.58377165]\n",
            " [0.58518994]\n",
            " [0.62395185]]\n",
            "Step: 772 -> Loss: 0.5678302049636841 -> Predictions: [[0.19780175]\n",
            " [0.5845468 ]\n",
            " [0.58601296]\n",
            " [0.6245347 ]]\n",
            "Step: 773 -> Loss: 0.5669111013412476 -> Predictions: [[0.19579598]\n",
            " [0.5853156 ]\n",
            " [0.5868304 ]\n",
            " [0.62510854]]\n",
            "Step: 774 -> Loss: 0.5660006999969482 -> Predictions: [[0.19381139]\n",
            " [0.58607805]\n",
            " [0.587642  ]\n",
            " [0.62567306]]\n",
            "Step: 775 -> Loss: 0.5650991201400757 -> Predictions: [[0.19184804]\n",
            " [0.58683395]\n",
            " [0.58844787]\n",
            " [0.62622863]]\n",
            "Step: 776 -> Loss: 0.5642061829566956 -> Predictions: [[0.18990603]\n",
            " [0.5875833 ]\n",
            " [0.58924776]\n",
            " [0.62677497]]\n",
            "Step: 777 -> Loss: 0.5633220076560974 -> Predictions: [[0.18798542]\n",
            " [0.5883259 ]\n",
            " [0.59004176]\n",
            " [0.6273125 ]]\n",
            "Step: 778 -> Loss: 0.5624465942382812 -> Predictions: [[0.18608621]\n",
            " [0.58906174]\n",
            " [0.5908295 ]\n",
            " [0.6278409 ]]\n",
            "Step: 779 -> Loss: 0.5615799427032471 -> Predictions: [[0.1842084 ]\n",
            " [0.58979076]\n",
            " [0.5916112 ]\n",
            " [0.6283603 ]]\n",
            "Step: 780 -> Loss: 0.5607219338417053 -> Predictions: [[0.18235193]\n",
            " [0.5905128 ]\n",
            " [0.5923867 ]\n",
            " [0.6288708 ]]\n",
            "Step: 781 -> Loss: 0.5598726868629456 -> Predictions: [[0.18051688]\n",
            " [0.59122795]\n",
            " [0.593156  ]\n",
            " [0.62937254]]\n",
            "Step: 782 -> Loss: 0.559032142162323 -> Predictions: [[0.17870316]\n",
            " [0.5919361 ]\n",
            " [0.5939189 ]\n",
            " [0.6298655 ]]\n",
            "Step: 783 -> Loss: 0.5582002401351929 -> Predictions: [[0.17691074]\n",
            " [0.59263706]\n",
            " [0.5946756 ]\n",
            " [0.6303497 ]]\n",
            "Step: 784 -> Loss: 0.5573769807815552 -> Predictions: [[0.17513952]\n",
            " [0.593331  ]\n",
            " [0.5954257 ]\n",
            " [0.63082534]]\n",
            "Step: 785 -> Loss: 0.5565622448921204 -> Predictions: [[0.17338954]\n",
            " [0.59401774]\n",
            " [0.59616965]\n",
            " [0.63129234]]\n",
            "Step: 786 -> Loss: 0.5557560324668884 -> Predictions: [[0.17166059]\n",
            " [0.59469736]\n",
            " [0.5969072 ]\n",
            " [0.6317509 ]]\n",
            "Step: 787 -> Loss: 0.5549583435058594 -> Predictions: [[0.16995263]\n",
            " [0.5953697 ]\n",
            " [0.59763825]\n",
            " [0.63220096]]\n",
            "Step: 788 -> Loss: 0.5541690587997437 -> Predictions: [[0.16826558]\n",
            " [0.59603494]\n",
            " [0.5983629 ]\n",
            " [0.6326427 ]]\n",
            "Step: 789 -> Loss: 0.5533881187438965 -> Predictions: [[0.16659927]\n",
            " [0.59669286]\n",
            " [0.5990812 ]\n",
            " [0.6330762 ]]\n",
            "Step: 790 -> Loss: 0.5526156425476074 -> Predictions: [[0.1649536 ]\n",
            " [0.5973436 ]\n",
            " [0.59979296]\n",
            " [0.6335015 ]]\n",
            "Step: 791 -> Loss: 0.5518512725830078 -> Predictions: [[0.16332853]\n",
            " [0.5979872 ]\n",
            " [0.6004985 ]\n",
            " [0.63391876]]\n",
            "Step: 792 -> Loss: 0.5510951280593872 -> Predictions: [[0.16172384]\n",
            " [0.5986235 ]\n",
            " [0.60119754]\n",
            " [0.63432807]]\n",
            "Step: 793 -> Loss: 0.5503470301628113 -> Predictions: [[0.16013937]\n",
            " [0.59925264]\n",
            " [0.6018903 ]\n",
            " [0.6347294 ]]\n",
            "Step: 794 -> Loss: 0.5496070384979248 -> Predictions: [[0.15857503]\n",
            " [0.5998745 ]\n",
            " [0.6025766 ]\n",
            " [0.63512284]]\n",
            "Step: 795 -> Loss: 0.5488750338554382 -> Predictions: [[0.15703058]\n",
            " [0.60048926]\n",
            " [0.6032567 ]\n",
            " [0.6355087 ]]\n",
            "Step: 796 -> Loss: 0.5481508374214172 -> Predictions: [[0.155506  ]\n",
            " [0.6010969 ]\n",
            " [0.6039306 ]\n",
            " [0.63588685]]\n",
            "Step: 797 -> Loss: 0.5474344491958618 -> Predictions: [[0.15400106]\n",
            " [0.6016973 ]\n",
            " [0.6045982 ]\n",
            " [0.6362574 ]]\n",
            "Step: 798 -> Loss: 0.546725869178772 -> Predictions: [[0.15251553]\n",
            " [0.6022907 ]\n",
            " [0.60525966]\n",
            " [0.6366206 ]]\n",
            "Step: 799 -> Loss: 0.5460247993469238 -> Predictions: [[0.15104927]\n",
            " [0.60287696]\n",
            " [0.60591495]\n",
            " [0.63697636]]\n",
            "Step: 800 -> Loss: 0.5453314185142517 -> Predictions: [[0.14960214]\n",
            " [0.60345614]\n",
            " [0.6065641 ]\n",
            " [0.6373249 ]]\n",
            "Step: 801 -> Loss: 0.544645369052887 -> Predictions: [[0.14817391]\n",
            " [0.60402846]\n",
            " [0.60720736]\n",
            " [0.6376663 ]]\n",
            "Step: 802 -> Loss: 0.5439667701721191 -> Predictions: [[0.14676441]\n",
            " [0.6045937 ]\n",
            " [0.60784453]\n",
            " [0.63800055]]\n",
            "Step: 803 -> Loss: 0.5432953834533691 -> Predictions: [[0.14537343]\n",
            " [0.6051521 ]\n",
            " [0.60847574]\n",
            " [0.63832784]]\n",
            "Step: 804 -> Loss: 0.5426311492919922 -> Predictions: [[0.14400084]\n",
            " [0.60570353]\n",
            " [0.60910124]\n",
            " [0.63864815]]\n",
            "Step: 805 -> Loss: 0.5419740676879883 -> Predictions: [[0.14264643]\n",
            " [0.60624814]\n",
            " [0.6097208 ]\n",
            " [0.6389618 ]]\n",
            "Step: 806 -> Loss: 0.5413240194320679 -> Predictions: [[0.14130992]\n",
            " [0.60678595]\n",
            " [0.6103347 ]\n",
            " [0.63926864]]\n",
            "Step: 807 -> Loss: 0.5406807661056519 -> Predictions: [[0.1399912 ]\n",
            " [0.607317  ]\n",
            " [0.6109429 ]\n",
            " [0.63956887]]\n",
            "Step: 808 -> Loss: 0.5400444269180298 -> Predictions: [[0.13869007]\n",
            " [0.60784143]\n",
            " [0.61154556]\n",
            " [0.63986266]]\n",
            "Step: 809 -> Loss: 0.5394147038459778 -> Predictions: [[0.13740629]\n",
            " [0.6083592 ]\n",
            " [0.61214274]\n",
            " [0.64014995]]\n",
            "Step: 810 -> Loss: 0.5387916564941406 -> Predictions: [[0.1361397 ]\n",
            " [0.60887027]\n",
            " [0.61273444]\n",
            " [0.64043087]]\n",
            "Step: 811 -> Loss: 0.5381751656532288 -> Predictions: [[0.13489006]\n",
            " [0.6093749 ]\n",
            " [0.61332065]\n",
            " [0.6407056 ]]\n",
            "Step: 812 -> Loss: 0.5375649929046631 -> Predictions: [[0.1336572]\n",
            " [0.6098731]\n",
            " [0.6139017]\n",
            " [0.640974 ]]\n",
            "Step: 813 -> Loss: 0.5369611978530884 -> Predictions: [[0.13244088]\n",
            " [0.6103648 ]\n",
            " [0.61447763]\n",
            " [0.64123636]]\n",
            "Step: 814 -> Loss: 0.5363636016845703 -> Predictions: [[0.13124095]\n",
            " [0.6108501 ]\n",
            " [0.6150482 ]\n",
            " [0.64149284]]\n",
            "Step: 815 -> Loss: 0.5357720851898193 -> Predictions: [[0.13005714]\n",
            " [0.61132914]\n",
            " [0.6156139 ]\n",
            " [0.6417433 ]]\n",
            "Step: 816 -> Loss: 0.5351866483688354 -> Predictions: [[0.12888934]\n",
            " [0.6118019 ]\n",
            " [0.6161746 ]\n",
            " [0.6419879 ]]\n",
            "Step: 817 -> Loss: 0.5346070528030396 -> Predictions: [[0.1277373 ]\n",
            " [0.61226857]\n",
            " [0.6167304 ]\n",
            " [0.64222676]]\n",
            "Step: 818 -> Loss: 0.5340332984924316 -> Predictions: [[0.12660079]\n",
            " [0.612729  ]\n",
            " [0.61728144]\n",
            " [0.6424599 ]]\n",
            "Step: 819 -> Loss: 0.5334652662277222 -> Predictions: [[0.12547971]\n",
            " [0.61318344]\n",
            " [0.6178277 ]\n",
            " [0.6426875 ]]\n",
            "Step: 820 -> Loss: 0.5329028367996216 -> Predictions: [[0.12437373]\n",
            " [0.61363184]\n",
            " [0.6183695 ]\n",
            " [0.6429095 ]]\n",
            "Step: 821 -> Loss: 0.5323460102081299 -> Predictions: [[0.12328275]\n",
            " [0.61407423]\n",
            " [0.6189067 ]\n",
            " [0.64312625]]\n",
            "Step: 822 -> Loss: 0.5317944884300232 -> Predictions: [[0.12220652]\n",
            " [0.6145109 ]\n",
            " [0.6194395 ]\n",
            " [0.6433374 ]]\n",
            "Step: 823 -> Loss: 0.5312483906745911 -> Predictions: [[0.12114491]\n",
            " [0.61494154]\n",
            " [0.6199679 ]\n",
            " [0.64354336]]\n",
            "Step: 824 -> Loss: 0.5307074785232544 -> Predictions: [[0.12009764]\n",
            " [0.61536646]\n",
            " [0.6204921 ]\n",
            " [0.64374393]]\n",
            "Step: 825 -> Loss: 0.5301716327667236 -> Predictions: [[0.1190646 ]\n",
            " [0.6157857 ]\n",
            " [0.6210121 ]\n",
            " [0.64393955]]\n",
            "Step: 826 -> Loss: 0.5296409130096436 -> Predictions: [[0.11804558]\n",
            " [0.61619925]\n",
            " [0.6215281 ]\n",
            " [0.64412993]]\n",
            "Step: 827 -> Loss: 0.5291150808334351 -> Predictions: [[0.11704038]\n",
            " [0.6166073 ]\n",
            " [0.62204003]\n",
            " [0.6443153 ]]\n",
            "Step: 828 -> Loss: 0.5285940170288086 -> Predictions: [[0.11604879]\n",
            " [0.61700976]\n",
            " [0.6225482 ]\n",
            " [0.6444958 ]]\n",
            "Step: 829 -> Loss: 0.5280777215957642 -> Predictions: [[0.11507068]\n",
            " [0.6174068 ]\n",
            " [0.6230526 ]\n",
            " [0.64467126]]\n",
            "Step: 830 -> Loss: 0.527566134929657 -> Predictions: [[0.11410578]\n",
            " [0.6177983 ]\n",
            " [0.6235532 ]\n",
            " [0.64484197]]\n",
            "Step: 831 -> Loss: 0.5270589590072632 -> Predictions: [[0.11315396]\n",
            " [0.6181845 ]\n",
            " [0.6240504 ]\n",
            " [0.64500785]]\n",
            "Step: 832 -> Loss: 0.5265563130378723 -> Predictions: [[0.11221505]\n",
            " [0.6185654 ]\n",
            " [0.624544  ]\n",
            " [0.6451691 ]]\n",
            "Step: 833 -> Loss: 0.5260580778121948 -> Predictions: [[0.11128888]\n",
            " [0.6189411 ]\n",
            " [0.6250342 ]\n",
            " [0.6453256 ]]\n",
            "Step: 834 -> Loss: 0.5255639553070068 -> Predictions: [[0.11037525]\n",
            " [0.6193116 ]\n",
            " [0.6255212 ]\n",
            " [0.6454775 ]]\n",
            "Step: 835 -> Loss: 0.5250741243362427 -> Predictions: [[0.10947397]\n",
            " [0.61967695]\n",
            " [0.62600493]\n",
            " [0.6456249 ]]\n",
            "Step: 836 -> Loss: 0.5245882272720337 -> Predictions: [[0.10858493]\n",
            " [0.6200372 ]\n",
            " [0.62648565]\n",
            " [0.64576775]]\n",
            "Step: 837 -> Loss: 0.5241063237190247 -> Predictions: [[0.10770793]\n",
            " [0.62039244]\n",
            " [0.6269634 ]\n",
            " [0.64590615]]\n",
            "Step: 838 -> Loss: 0.5236283540725708 -> Predictions: [[0.1068428 ]\n",
            " [0.62074274]\n",
            " [0.6274382 ]\n",
            " [0.6460402 ]]\n",
            "Step: 839 -> Loss: 0.5231540203094482 -> Predictions: [[0.1059894 ]\n",
            " [0.62108815]\n",
            " [0.6279103 ]\n",
            " [0.64616984]]\n",
            "Step: 840 -> Loss: 0.5226835608482361 -> Predictions: [[0.1051475 ]\n",
            " [0.62142855]\n",
            " [0.62837964]\n",
            " [0.64629525]]\n",
            "Step: 841 -> Loss: 0.5222165584564209 -> Predictions: [[0.10431705]\n",
            " [0.6217643 ]\n",
            " [0.62884647]\n",
            " [0.6464163 ]]\n",
            "Step: 842 -> Loss: 0.521753191947937 -> Predictions: [[0.1034978]\n",
            " [0.6220951]\n",
            " [0.6293108]\n",
            " [0.6465332]]\n",
            "Step: 843 -> Loss: 0.5212931036949158 -> Predictions: [[0.10268962]\n",
            " [0.6224214 ]\n",
            " [0.62977266]\n",
            " [0.64664596]]\n",
            "Step: 844 -> Loss: 0.520836353302002 -> Predictions: [[0.10189234]\n",
            " [0.6227429 ]\n",
            " [0.63023245]\n",
            " [0.6467545 ]]\n",
            "Step: 845 -> Loss: 0.5203828811645508 -> Predictions: [[0.10110588]\n",
            " [0.6230598 ]\n",
            " [0.63069   ]\n",
            " [0.64685893]]\n",
            "Step: 846 -> Loss: 0.5199325084686279 -> Predictions: [[0.10033002]\n",
            " [0.62337214]\n",
            " [0.6311454 ]\n",
            " [0.6469594 ]]\n",
            "Step: 847 -> Loss: 0.5194851756095886 -> Predictions: [[0.09956463]\n",
            " [0.62368   ]\n",
            " [0.631599  ]\n",
            " [0.64705575]]\n",
            "Step: 848 -> Loss: 0.5190407633781433 -> Predictions: [[0.09880956]\n",
            " [0.62398326]\n",
            " [0.63205075]\n",
            " [0.6471482 ]]\n",
            "Step: 849 -> Loss: 0.518599271774292 -> Predictions: [[0.09806474]\n",
            " [0.6242822 ]\n",
            " [0.63250077]\n",
            " [0.64723665]]\n",
            "Step: 850 -> Loss: 0.5181605219841003 -> Predictions: [[0.09732991]\n",
            " [0.6245767 ]\n",
            " [0.6329491 ]\n",
            " [0.64732116]]\n",
            "Step: 851 -> Loss: 0.5177245140075684 -> Predictions: [[0.09660504]\n",
            " [0.6248668 ]\n",
            " [0.6333959 ]\n",
            " [0.6474018 ]]\n",
            "Step: 852 -> Loss: 0.5172909498214722 -> Predictions: [[0.09588998]\n",
            " [0.6251526 ]\n",
            " [0.63384145]\n",
            " [0.6474786 ]]\n",
            "Step: 853 -> Loss: 0.5168599486351013 -> Predictions: [[0.09518453]\n",
            " [0.62543416]\n",
            " [0.63428557]\n",
            " [0.64755136]]\n",
            "Step: 854 -> Loss: 0.5164313912391663 -> Predictions: [[0.09448859]\n",
            " [0.62571144]\n",
            " [0.63472867]\n",
            " [0.6476205 ]]\n",
            "Step: 855 -> Loss: 0.5160051584243774 -> Predictions: [[0.09380208]\n",
            " [0.6259845 ]\n",
            " [0.6351706 ]\n",
            " [0.64768577]]\n",
            "Step: 856 -> Loss: 0.5155811309814453 -> Predictions: [[0.09312479]\n",
            " [0.6262535 ]\n",
            " [0.63561153]\n",
            " [0.6477473 ]]\n",
            "Step: 857 -> Loss: 0.5151592493057251 -> Predictions: [[0.0924567 ]\n",
            " [0.62651825]\n",
            " [0.63605183]\n",
            " [0.647805  ]]\n",
            "Step: 858 -> Loss: 0.5147392749786377 -> Predictions: [[0.09179763]\n",
            " [0.62677896]\n",
            " [0.6364913 ]\n",
            " [0.6478589 ]]\n",
            "Step: 859 -> Loss: 0.5143214464187622 -> Predictions: [[0.09114743]\n",
            " [0.62703556]\n",
            " [0.63693017]\n",
            " [0.64790916]]\n",
            "Step: 860 -> Loss: 0.5139054656028748 -> Predictions: [[0.0905061 ]\n",
            " [0.6272881 ]\n",
            " [0.63736856]\n",
            " [0.6479557 ]]\n",
            "Step: 861 -> Loss: 0.513491153717041 -> Predictions: [[0.08987338]\n",
            " [0.6275367 ]\n",
            " [0.6378067 ]\n",
            " [0.6479985 ]]\n",
            "Step: 862 -> Loss: 0.5130786895751953 -> Predictions: [[0.08924924]\n",
            " [0.6277814 ]\n",
            " [0.63824457]\n",
            " [0.64803785]]\n",
            "Step: 863 -> Loss: 0.512667715549469 -> Predictions: [[0.08863357]\n",
            " [0.6280219 ]\n",
            " [0.6386823 ]\n",
            " [0.64807326]]\n",
            "Step: 864 -> Loss: 0.5122582316398621 -> Predictions: [[0.08802626]\n",
            " [0.62825865]\n",
            " [0.63912004]\n",
            " [0.6481051 ]]\n",
            "Step: 865 -> Loss: 0.5118501782417297 -> Predictions: [[0.08742718]\n",
            " [0.6284915 ]\n",
            " [0.639558  ]\n",
            " [0.6481331 ]]\n",
            "Step: 866 -> Loss: 0.5114433765411377 -> Predictions: [[0.08683624]\n",
            " [0.6287204 ]\n",
            " [0.6399962 ]\n",
            " [0.6481576 ]]\n",
            "Step: 867 -> Loss: 0.511038064956665 -> Predictions: [[0.08625336]\n",
            " [0.62894547]\n",
            " [0.64043474]\n",
            " [0.6481785 ]]\n",
            "Step: 868 -> Loss: 0.510633647441864 -> Predictions: [[0.08567841]\n",
            " [0.62916666]\n",
            " [0.64087397]\n",
            " [0.6481956 ]]\n",
            "Step: 869 -> Loss: 0.5102303624153137 -> Predictions: [[0.0851113 ]\n",
            " [0.62938416]\n",
            " [0.64131373]\n",
            " [0.6482092 ]]\n",
            "Step: 870 -> Loss: 0.5098280310630798 -> Predictions: [[0.08455194]\n",
            " [0.6295977 ]\n",
            " [0.6417544 ]\n",
            " [0.64821905]]\n",
            "Step: 871 -> Loss: 0.509426474571228 -> Predictions: [[0.08400028]\n",
            " [0.62980765]\n",
            " [0.642196  ]\n",
            " [0.64822525]]\n",
            "Step: 872 -> Loss: 0.5090258121490479 -> Predictions: [[0.0834562 ]\n",
            " [0.63001364]\n",
            " [0.6426387 ]\n",
            " [0.6482277 ]]\n",
            "Step: 873 -> Loss: 0.5086257457733154 -> Predictions: [[0.08291958]\n",
            " [0.6302159 ]\n",
            " [0.64308256]\n",
            " [0.6482265 ]]\n",
            "Step: 874 -> Loss: 0.5082262754440308 -> Predictions: [[0.08239032]\n",
            " [0.6304145 ]\n",
            " [0.6435278 ]\n",
            " [0.64822173]]\n",
            "Step: 875 -> Loss: 0.5078272819519043 -> Predictions: [[0.08186843]\n",
            " [0.6306094 ]\n",
            " [0.64397454]\n",
            " [0.64821315]]\n",
            "Step: 876 -> Loss: 0.5074287056922913 -> Predictions: [[0.08135372]\n",
            " [0.63080037]\n",
            " [0.644423  ]\n",
            " [0.6482009 ]]\n",
            "Step: 877 -> Loss: 0.5070304870605469 -> Predictions: [[0.0808462 ]\n",
            " [0.63098776]\n",
            " [0.6448732 ]\n",
            " [0.6481849 ]]\n",
            "Step: 878 -> Loss: 0.5066322684288025 -> Predictions: [[0.08034573]\n",
            " [0.63117146]\n",
            " [0.6453255 ]\n",
            " [0.64816517]]\n",
            "Step: 879 -> Loss: 0.5062342286109924 -> Predictions: [[0.07985229]\n",
            " [0.6313514 ]\n",
            " [0.64577985]\n",
            " [0.6481416 ]]\n",
            "Step: 880 -> Loss: 0.5058362483978271 -> Predictions: [[0.07936573]\n",
            " [0.63152766]\n",
            " [0.6462365 ]\n",
            " [0.6481143 ]]\n",
            "Step: 881 -> Loss: 0.5054380297660828 -> Predictions: [[0.07888603]\n",
            " [0.6317002 ]\n",
            " [0.6466955 ]\n",
            " [0.64808327]]\n",
            "Step: 882 -> Loss: 0.5050396919250488 -> Predictions: [[0.07841313]\n",
            " [0.6318691 ]\n",
            " [0.6471572 ]\n",
            " [0.6480482 ]]\n",
            "Step: 883 -> Loss: 0.5046409368515015 -> Predictions: [[0.07794691]\n",
            " [0.63203424]\n",
            " [0.64762163]\n",
            " [0.6480094 ]]\n",
            "Step: 884 -> Loss: 0.5042418241500854 -> Predictions: [[0.07748738]\n",
            " [0.63219565]\n",
            " [0.64808893]\n",
            " [0.6479666 ]]\n",
            "Step: 885 -> Loss: 0.5038421154022217 -> Predictions: [[0.07703437]\n",
            " [0.6323534 ]\n",
            " [0.64855945]\n",
            " [0.64792   ]]\n",
            "Step: 886 -> Loss: 0.5034419298171997 -> Predictions: [[0.07658792]\n",
            " [0.6325074 ]\n",
            " [0.64903307]\n",
            " [0.6478694 ]]\n",
            "Step: 887 -> Loss: 0.5030409097671509 -> Predictions: [[0.07614791]\n",
            " [0.63265765]\n",
            " [0.6495103 ]\n",
            " [0.64781475]]\n",
            "Step: 888 -> Loss: 0.5026390552520752 -> Predictions: [[0.07571431]\n",
            " [0.6328042 ]\n",
            " [0.64999115]\n",
            " [0.6477561 ]]\n",
            "Step: 889 -> Loss: 0.5022362470626831 -> Predictions: [[0.07528707]\n",
            " [0.632947  ]\n",
            " [0.65047586]\n",
            " [0.64769334]]\n",
            "Step: 890 -> Loss: 0.5018323659896851 -> Predictions: [[0.07486612]\n",
            " [0.633086  ]\n",
            " [0.65096456]\n",
            " [0.6476265 ]]\n",
            "Step: 891 -> Loss: 0.5014272928237915 -> Predictions: [[0.07445139]\n",
            " [0.63322127]\n",
            " [0.6514574 ]\n",
            " [0.6475554 ]]\n",
            "Step: 892 -> Loss: 0.5010209083557129 -> Predictions: [[0.07404286]\n",
            " [0.63335276]\n",
            " [0.65195465]\n",
            " [0.6474802 ]]\n",
            "Step: 893 -> Loss: 0.5006131529808044 -> Predictions: [[0.07364048]\n",
            " [0.6334804 ]\n",
            " [0.65245646]\n",
            " [0.6474006 ]]\n",
            "Step: 894 -> Loss: 0.5002039074897766 -> Predictions: [[0.07324415]\n",
            " [0.6336042 ]\n",
            " [0.6529631 ]\n",
            " [0.6473168 ]]\n",
            "Step: 895 -> Loss: 0.4997929036617279 -> Predictions: [[0.07285386]\n",
            " [0.6337242 ]\n",
            " [0.65347475]\n",
            " [0.6472285 ]]\n",
            "Step: 896 -> Loss: 0.4993801414966583 -> Predictions: [[0.07246958]\n",
            " [0.63384044]\n",
            " [0.6539915 ]\n",
            " [0.6471358 ]]\n",
            "Step: 897 -> Loss: 0.4989655315876007 -> Predictions: [[0.07209128]\n",
            " [0.6339526 ]\n",
            " [0.6545137 ]\n",
            " [0.6470386 ]]\n",
            "Step: 898 -> Loss: 0.4985489249229431 -> Predictions: [[0.07171887]\n",
            " [0.6340609 ]\n",
            " [0.6550415 ]\n",
            " [0.6469368 ]]\n",
            "Step: 899 -> Loss: 0.4981301724910736 -> Predictions: [[0.07135235]\n",
            " [0.6341652 ]\n",
            " [0.6555752 ]\n",
            " [0.6468303 ]]\n",
            "Step: 900 -> Loss: 0.49770909547805786 -> Predictions: [[0.07099167]\n",
            " [0.6342656 ]\n",
            " [0.6561149 ]\n",
            " [0.6467191 ]]\n",
            "Step: 901 -> Loss: 0.4972856640815735 -> Predictions: [[0.0706368 ]\n",
            " [0.6343619 ]\n",
            " [0.6566608 ]\n",
            " [0.64660317]]\n",
            "Step: 902 -> Loss: 0.49685966968536377 -> Predictions: [[0.07028772]\n",
            " [0.6344543 ]\n",
            " [0.6572132 ]\n",
            " [0.6464824 ]]\n",
            "Step: 903 -> Loss: 0.49643102288246155 -> Predictions: [[0.06994432]\n",
            " [0.6345425 ]\n",
            " [0.65777236]\n",
            " [0.6463566 ]]\n",
            "Step: 904 -> Loss: 0.4959995746612549 -> Predictions: [[0.06960671]\n",
            " [0.63462675]\n",
            " [0.65833855]\n",
            " [0.6462257 ]]\n",
            "Step: 905 -> Loss: 0.495565265417099 -> Predictions: [[0.06927476]\n",
            " [0.63470674]\n",
            " [0.65891176]\n",
            " [0.64608973]]\n",
            "Step: 906 -> Loss: 0.49512776732444763 -> Predictions: [[0.06894843]\n",
            " [0.63478255]\n",
            " [0.6594925 ]\n",
            " [0.6459485 ]]\n",
            "Step: 907 -> Loss: 0.4946870803833008 -> Predictions: [[0.0686278 ]\n",
            " [0.6348542 ]\n",
            " [0.66008085]\n",
            " [0.645802  ]]\n",
            "Step: 908 -> Loss: 0.4942430853843689 -> Predictions: [[0.0683127 ]\n",
            " [0.6349215 ]\n",
            " [0.66067713]\n",
            " [0.6456501 ]]\n",
            "Step: 909 -> Loss: 0.49379560351371765 -> Predictions: [[0.06800326]\n",
            " [0.63498455]\n",
            " [0.66128147]\n",
            " [0.6454926 ]]\n",
            "Step: 910 -> Loss: 0.4933444559574127 -> Predictions: [[0.06769937]\n",
            " [0.63504326]\n",
            " [0.6618943 ]\n",
            " [0.64532954]]\n",
            "Step: 911 -> Loss: 0.4928895831108093 -> Predictions: [[0.06740105]\n",
            " [0.6350975 ]\n",
            " [0.6625157 ]\n",
            " [0.6451608 ]]\n",
            "Step: 912 -> Loss: 0.4924306273460388 -> Predictions: [[0.06710825]\n",
            " [0.63514745]\n",
            " [0.6631461 ]\n",
            " [0.6449861 ]]\n",
            "Step: 913 -> Loss: 0.49196773767471313 -> Predictions: [[0.06682102]\n",
            " [0.6351928 ]\n",
            " [0.6637854 ]\n",
            " [0.64480543]]\n",
            "Step: 914 -> Loss: 0.49150046706199646 -> Predictions: [[0.06653925]\n",
            " [0.6352337 ]\n",
            " [0.66443425]\n",
            " [0.64461863]]\n",
            "Step: 915 -> Loss: 0.49102890491485596 -> Predictions: [[0.06626302]\n",
            " [0.6352701 ]\n",
            " [0.6650927 ]\n",
            " [0.64442575]]\n",
            "Step: 916 -> Loss: 0.490552693605423 -> Predictions: [[0.06599227]\n",
            " [0.6353018 ]\n",
            " [0.66576093]\n",
            " [0.6442264 ]]\n",
            "Step: 917 -> Loss: 0.4900718927383423 -> Predictions: [[0.06572701]\n",
            " [0.63532895]\n",
            " [0.66643935]\n",
            " [0.6440206 ]]\n",
            "Step: 918 -> Loss: 0.48958611488342285 -> Predictions: [[0.06546719]\n",
            " [0.6353513 ]\n",
            " [0.66712815]\n",
            " [0.64380807]]\n",
            "Step: 919 -> Loss: 0.48909544944763184 -> Predictions: [[0.0652129 ]\n",
            " [0.63536894]\n",
            " [0.66782755]\n",
            " [0.64358896]]\n",
            "Step: 920 -> Loss: 0.48859935998916626 -> Predictions: [[0.06496403]\n",
            " [0.6353819 ]\n",
            " [0.6685379 ]\n",
            " [0.6433627 ]]\n",
            "Step: 921 -> Loss: 0.4880980849266052 -> Predictions: [[0.06472065]\n",
            " [0.63539   ]\n",
            " [0.6692593 ]\n",
            " [0.64312947]]\n",
            "Step: 922 -> Loss: 0.4875912070274353 -> Predictions: [[0.06448274]\n",
            " [0.63539314]\n",
            " [0.6699921 ]\n",
            " [0.642889  ]]\n",
            "Step: 923 -> Loss: 0.4870786666870117 -> Predictions: [[0.0642503 ]\n",
            " [0.63539153]\n",
            " [0.67073655]\n",
            " [0.6426411 ]]\n",
            "Step: 924 -> Loss: 0.48656022548675537 -> Predictions: [[0.06402336]\n",
            " [0.63538504]\n",
            " [0.67149276]\n",
            " [0.6423856 ]]\n",
            "Step: 925 -> Loss: 0.4860358238220215 -> Predictions: [[0.06380186]\n",
            " [0.63537353]\n",
            " [0.672261  ]\n",
            " [0.64212245]]\n",
            "Step: 926 -> Loss: 0.4855051636695862 -> Predictions: [[0.06358584]\n",
            " [0.63535696]\n",
            " [0.6730417 ]\n",
            " [0.64185125]]\n",
            "Step: 927 -> Loss: 0.48496827483177185 -> Predictions: [[0.06337533]\n",
            " [0.63533545]\n",
            " [0.6738346 ]\n",
            " [0.6415721 ]]\n",
            "Step: 928 -> Loss: 0.4844247102737427 -> Predictions: [[0.06317032]\n",
            " [0.635309  ]\n",
            " [0.6746405 ]\n",
            " [0.6412845 ]]\n",
            "Step: 929 -> Loss: 0.48387449979782104 -> Predictions: [[0.0629708 ]\n",
            " [0.6352774 ]\n",
            " [0.67545927]\n",
            " [0.6409886 ]]\n",
            "Step: 930 -> Loss: 0.48331737518310547 -> Predictions: [[0.0627768 ]\n",
            " [0.63524085]\n",
            " [0.6762911 ]\n",
            " [0.64068395]]\n",
            "Step: 931 -> Loss: 0.482753187417984 -> Predictions: [[0.06258834]\n",
            " [0.6351992 ]\n",
            " [0.6771362 ]\n",
            " [0.64037037]]\n",
            "Step: 932 -> Loss: 0.4821817874908447 -> Predictions: [[0.06240543]\n",
            " [0.6351525 ]\n",
            " [0.6779947 ]\n",
            " [0.64004767]]\n",
            "Step: 933 -> Loss: 0.48160314559936523 -> Predictions: [[0.06222803]\n",
            " [0.6351007 ]\n",
            " [0.678867  ]\n",
            " [0.63971585]]\n",
            "Step: 934 -> Loss: 0.48101675510406494 -> Predictions: [[0.06205624]\n",
            " [0.635044  ]\n",
            " [0.679753  ]\n",
            " [0.6393744 ]]\n",
            "Step: 935 -> Loss: 0.4804227352142334 -> Predictions: [[0.06189002]\n",
            " [0.6349822 ]\n",
            " [0.68065304]\n",
            " [0.63902336]]\n",
            "Step: 936 -> Loss: 0.47982072830200195 -> Predictions: [[0.06172939]\n",
            " [0.6349156 ]\n",
            " [0.681567  ]\n",
            " [0.63866216]]\n",
            "Step: 937 -> Loss: 0.4792107045650482 -> Predictions: [[0.06157442]\n",
            " [0.6348441 ]\n",
            " [0.6824951 ]\n",
            " [0.638291  ]]\n",
            "Step: 938 -> Loss: 0.4785924553871155 -> Predictions: [[0.06142506]\n",
            " [0.63476765]\n",
            " [0.6834375 ]\n",
            " [0.6379095 ]]\n",
            "Step: 939 -> Loss: 0.47796574234962463 -> Predictions: [[0.06128139]\n",
            " [0.6346866 ]\n",
            " [0.68439424]\n",
            " [0.6375173 ]]\n",
            "Step: 940 -> Loss: 0.4773305058479309 -> Predictions: [[0.06114336]\n",
            " [0.6346007 ]\n",
            " [0.6853653 ]\n",
            " [0.6371142 ]]\n",
            "Step: 941 -> Loss: 0.4766865372657776 -> Predictions: [[0.06101107]\n",
            " [0.63451034]\n",
            " [0.6863509 ]\n",
            " [0.6367001 ]]\n",
            "Step: 942 -> Loss: 0.47603362798690796 -> Predictions: [[0.06088447]\n",
            " [0.63441545]\n",
            " [0.6873508 ]\n",
            " [0.6362746 ]]\n",
            "Step: 943 -> Loss: 0.47537165880203247 -> Predictions: [[0.06076363]\n",
            " [0.63431644]\n",
            " [0.68836516]\n",
            " [0.6358377 ]]\n",
            "Step: 944 -> Loss: 0.4747004210948944 -> Predictions: [[0.06064859]\n",
            " [0.63421315]\n",
            " [0.68939406]\n",
            " [0.6353888 ]]\n",
            "Step: 945 -> Loss: 0.474019855260849 -> Predictions: [[0.06053933]\n",
            " [0.63410586]\n",
            " [0.69043726]\n",
            " [0.63492787]]\n",
            "Step: 946 -> Loss: 0.4733295738697052 -> Predictions: [[0.06043586]\n",
            " [0.6339949 ]\n",
            " [0.6914947 ]\n",
            " [0.63445467]]\n",
            "Step: 947 -> Loss: 0.47262969613075256 -> Predictions: [[0.06033825]\n",
            " [0.63388026]\n",
            " [0.6925664 ]\n",
            " [0.63396895]]\n",
            "Step: 948 -> Loss: 0.4719199240207672 -> Predictions: [[0.06024651]\n",
            " [0.6337624 ]\n",
            " [0.69365215]\n",
            " [0.6334705 ]]\n",
            "Step: 949 -> Loss: 0.47120004892349243 -> Predictions: [[0.06016066]\n",
            " [0.63364154]\n",
            " [0.69475186]\n",
            " [0.6329589 ]]\n",
            "Step: 950 -> Loss: 0.4704700708389282 -> Predictions: [[0.0600807 ]\n",
            " [0.6335178 ]\n",
            " [0.6958653 ]\n",
            " [0.63243407]]\n",
            "Step: 951 -> Loss: 0.46972960233688354 -> Predictions: [[0.06000673]\n",
            " [0.6333917 ]\n",
            " [0.69699234]\n",
            " [0.63189566]]\n",
            "Step: 952 -> Loss: 0.4689786434173584 -> Predictions: [[0.05993872]\n",
            " [0.6332635 ]\n",
            " [0.6981328 ]\n",
            " [0.6313434 ]]\n",
            "Step: 953 -> Loss: 0.468217134475708 -> Predictions: [[0.05987667]\n",
            " [0.6331337 ]\n",
            " [0.6992862 ]\n",
            " [0.6307773 ]]\n",
            "Step: 954 -> Loss: 0.46744468808174133 -> Predictions: [[0.05982066]\n",
            " [0.6330025 ]\n",
            " [0.7004525 ]\n",
            " [0.63019687]]\n",
            "Step: 955 -> Loss: 0.46666112542152405 -> Predictions: [[0.05977068]\n",
            " [0.6328706 ]\n",
            " [0.7016315 ]\n",
            " [0.62960184]]\n",
            "Step: 956 -> Loss: 0.4658665657043457 -> Predictions: [[0.0597268 ]\n",
            " [0.6327383 ]\n",
            " [0.7028225 ]\n",
            " [0.62899214]]\n",
            "Step: 957 -> Loss: 0.46506065130233765 -> Predictions: [[0.059689  ]\n",
            " [0.63260615]\n",
            " [0.70402545]\n",
            " [0.62836754]]\n",
            "Step: 958 -> Loss: 0.46424317359924316 -> Predictions: [[0.05965734]\n",
            " [0.6324749 ]\n",
            " [0.7052398 ]\n",
            " [0.6277276 ]]\n",
            "Step: 959 -> Loss: 0.46341410279273987 -> Predictions: [[0.05963179]\n",
            " [0.6323449 ]\n",
            " [0.7064652 ]\n",
            " [0.6270724 ]]\n",
            "Step: 960 -> Loss: 0.4625731408596039 -> Predictions: [[0.05961243]\n",
            " [0.63221693]\n",
            " [0.7077012 ]\n",
            " [0.6264014 ]]\n",
            "Step: 961 -> Loss: 0.4617201089859009 -> Predictions: [[0.05959922]\n",
            " [0.63209164]\n",
            " [0.70894736]\n",
            " [0.62571454]]\n",
            "Step: 962 -> Loss: 0.4608548879623413 -> Predictions: [[0.05959225]\n",
            " [0.6319697 ]\n",
            " [0.7102032 ]\n",
            " [0.6250115 ]]\n",
            "Step: 963 -> Loss: 0.4599773585796356 -> Predictions: [[0.05959152]\n",
            " [0.63185203]\n",
            " [0.71146816]\n",
            " [0.6242923 ]]\n",
            "Step: 964 -> Loss: 0.459087073802948 -> Predictions: [[0.059597  ]\n",
            " [0.6317395 ]\n",
            " [0.7127417 ]\n",
            " [0.62355644]]\n",
            "Step: 965 -> Loss: 0.4581841230392456 -> Predictions: [[0.05960876]\n",
            " [0.63163275]\n",
            " [0.7140233 ]\n",
            " [0.622804  ]]\n",
            "Step: 966 -> Loss: 0.45726796984672546 -> Predictions: [[0.05962681]\n",
            " [0.63153285]\n",
            " [0.7153125 ]\n",
            " [0.62203443]]\n",
            "Step: 967 -> Loss: 0.45633864402770996 -> Predictions: [[0.05965113]\n",
            " [0.6314408 ]\n",
            " [0.71660835]\n",
            " [0.6212479 ]]\n",
            "Step: 968 -> Loss: 0.45539575815200806 -> Predictions: [[0.05968174]\n",
            " [0.63135755]\n",
            " [0.71791047]\n",
            " [0.6204439 ]]\n",
            "Step: 969 -> Loss: 0.4544391632080078 -> Predictions: [[0.05971866]\n",
            " [0.6312842 ]\n",
            " [0.7192182 ]\n",
            " [0.6196224 ]]\n",
            "Step: 970 -> Loss: 0.45346853137016296 -> Predictions: [[0.05976192]\n",
            " [0.63122207]\n",
            " [0.72053087]\n",
            " [0.61878335]]\n",
            "Step: 971 -> Loss: 0.4524836540222168 -> Predictions: [[0.05981147]\n",
            " [0.631172  ]\n",
            " [0.7218477 ]\n",
            " [0.6179263 ]]\n",
            "Step: 972 -> Loss: 0.4514840543270111 -> Predictions: [[0.05986731]\n",
            " [0.63113546]\n",
            " [0.7231681 ]\n",
            " [0.61705106]]\n",
            "Step: 973 -> Loss: 0.4504694640636444 -> Predictions: [[0.05992949]\n",
            " [0.6311139 ]\n",
            " [0.72449124]\n",
            " [0.61615753]]\n",
            "Step: 974 -> Loss: 0.44943967461586 -> Predictions: [[0.05999793]\n",
            " [0.6311084 ]\n",
            " [0.7258164 ]\n",
            " [0.6152454 ]]\n",
            "Step: 975 -> Loss: 0.44839417934417725 -> Predictions: [[0.06007268]\n",
            " [0.63112056]\n",
            " [0.72714293]\n",
            " [0.6143147 ]]\n",
            "Step: 976 -> Loss: 0.4473327398300171 -> Predictions: [[0.06015366]\n",
            " [0.6311518 ]\n",
            " [0.72847   ]\n",
            " [0.6133651 ]]\n",
            "Step: 977 -> Loss: 0.4462548494338989 -> Predictions: [[0.06024086]\n",
            " [0.6312037 ]\n",
            " [0.72979677]\n",
            " [0.6123963 ]]\n",
            "Step: 978 -> Loss: 0.4451600909233093 -> Predictions: [[0.06033428]\n",
            " [0.6312778 ]\n",
            " [0.73112243]\n",
            " [0.6114082 ]]\n",
            "Step: 979 -> Loss: 0.4440479576587677 -> Predictions: [[0.06043382]\n",
            " [0.63137585]\n",
            " [0.7324464 ]\n",
            " [0.61040044]]\n",
            "Step: 980 -> Loss: 0.4429180920124054 -> Predictions: [[0.06053945]\n",
            " [0.63149947]\n",
            " [0.7337675 ]\n",
            " [0.60937285]]\n",
            "Step: 981 -> Loss: 0.44176989793777466 -> Predictions: [[0.06065113]\n",
            " [0.6316505 ]\n",
            " [0.73508507]\n",
            " [0.6083252 ]]\n",
            "Step: 982 -> Loss: 0.4406028985977173 -> Predictions: [[0.06076877]\n",
            " [0.6318308 ]\n",
            " [0.7363983 ]\n",
            " [0.6072572 ]]\n",
            "Step: 983 -> Loss: 0.43941640853881836 -> Predictions: [[0.06089235]\n",
            " [0.6320421 ]\n",
            " [0.7377063 ]\n",
            " [0.6061683 ]]\n",
            "Step: 984 -> Loss: 0.4382098317146301 -> Predictions: [[0.06102172]\n",
            " [0.6322866 ]\n",
            " [0.7390083 ]\n",
            " [0.60505855]]\n",
            "Step: 985 -> Loss: 0.4369826316833496 -> Predictions: [[0.06115681]\n",
            " [0.63256615]\n",
            " [0.7403033 ]\n",
            " [0.60392743]]\n",
            "Step: 986 -> Loss: 0.43573421239852905 -> Predictions: [[0.06129749]\n",
            " [0.6328826 ]\n",
            " [0.7415904 ]\n",
            " [0.6027747 ]]\n",
            "Step: 987 -> Loss: 0.4344636797904968 -> Predictions: [[0.06144367]\n",
            " [0.6332383 ]\n",
            " [0.74286884]\n",
            " [0.60159975]]\n",
            "Step: 988 -> Loss: 0.43317049741744995 -> Predictions: [[0.06159516]\n",
            " [0.6336352 ]\n",
            " [0.7441377 ]\n",
            " [0.60040236]]\n",
            "Step: 989 -> Loss: 0.43185365200042725 -> Predictions: [[0.06175183]\n",
            " [0.63407564]\n",
            " [0.7453962 ]\n",
            " [0.59918183]]\n",
            "Step: 990 -> Loss: 0.4305126667022705 -> Predictions: [[0.06191352]\n",
            " [0.63456154]\n",
            " [0.7466432 ]\n",
            " [0.5979379 ]]\n",
            "Step: 991 -> Loss: 0.4291464686393738 -> Predictions: [[0.06208006]\n",
            " [0.6350953 ]\n",
            " [0.74787796]\n",
            " [0.59666973]]\n",
            "Step: 992 -> Loss: 0.42775440216064453 -> Predictions: [[0.06225119]\n",
            " [0.635679  ]\n",
            " [0.74909955]\n",
            " [0.59537697]]\n",
            "Step: 993 -> Loss: 0.4263356328010559 -> Predictions: [[0.06242676]\n",
            " [0.6363148 ]\n",
            " [0.75030714]\n",
            " [0.59405905]]\n",
            "Step: 994 -> Loss: 0.42488905787467957 -> Predictions: [[0.06260649]\n",
            " [0.637005  ]\n",
            " [0.7514999 ]\n",
            " [0.592715  ]]\n",
            "Step: 995 -> Loss: 0.4234139621257782 -> Predictions: [[0.06279016]\n",
            " [0.6377519 ]\n",
            " [0.7526767 ]\n",
            " [0.5913443 ]]\n",
            "Step: 996 -> Loss: 0.42190930247306824 -> Predictions: [[0.06297743]\n",
            " [0.6385574 ]\n",
            " [0.7538371 ]\n",
            " [0.58994603]]\n",
            "Step: 997 -> Loss: 0.42037433385849 -> Predictions: [[0.0631681 ]\n",
            " [0.63942355]\n",
            " [0.7549799 ]\n",
            " [0.58851945]]\n",
            "Step: 998 -> Loss: 0.4188079237937927 -> Predictions: [[0.06336175]\n",
            " [0.64035285]\n",
            " [0.75610435]\n",
            " [0.58706367]]\n",
            "Step: 999 -> Loss: 0.4172093868255615 -> Predictions: [[0.06355811]\n",
            " [0.64134663]\n",
            " [0.7572097 ]\n",
            " [0.5855776 ]]\n",
            "Step: 1001 -> Loss: 0.41391173005104065 -> Predictions: [[0.06395753]\n",
            " [0.64353615]\n",
            " [0.7593602 ]\n",
            " [0.5825107 ]]\n",
            "Step: 1002 -> Loss: 0.4122109115123749 -> Predictions: [[0.06415981]\n",
            " [0.64473516]\n",
            " [0.76040363]\n",
            " [0.58092755]]\n",
            "Step: 1003 -> Loss: 0.41047415137290955 -> Predictions: [[0.06436324]\n",
            " [0.64600575]\n",
            " [0.7614254 ]\n",
            " [0.5793098 ]]\n",
            "Step: 1004 -> Loss: 0.4087010324001312 -> Predictions: [[0.06456745]\n",
            " [0.64734894]\n",
            " [0.7624242 ]\n",
            " [0.57765627]]\n",
            "Step: 1005 -> Loss: 0.4068904519081116 -> Predictions: [[0.06477197]\n",
            " [0.648766  ]\n",
            " [0.76340014]\n",
            " [0.5759657 ]]\n",
            "Step: 1006 -> Loss: 0.40504178404808044 -> Predictions: [[0.06497642]\n",
            " [0.650258  ]\n",
            " [0.7643525 ]\n",
            " [0.5742365 ]]\n",
            "Step: 1007 -> Loss: 0.4031544327735901 -> Predictions: [[0.06518023]\n",
            " [0.65182525]\n",
            " [0.7652807 ]\n",
            " [0.5724675 ]]\n",
            "Step: 1008 -> Loss: 0.40122777223587036 -> Predictions: [[0.06538306]\n",
            " [0.65346843]\n",
            " [0.7661847 ]\n",
            " [0.5706572 ]]\n",
            "Step: 1009 -> Loss: 0.3992614150047302 -> Predictions: [[0.06558434]\n",
            " [0.65518755]\n",
            " [0.76706415]\n",
            " [0.56880426]]\n",
            "Step: 1010 -> Loss: 0.3972550630569458 -> Predictions: [[0.0657837 ]\n",
            " [0.65698236]\n",
            " [0.76791894]\n",
            " [0.5669074 ]]\n",
            "Step: 1011 -> Loss: 0.39520812034606934 -> Predictions: [[0.06598066]\n",
            " [0.65885264]\n",
            " [0.76874906]\n",
            " [0.5649648 ]]\n",
            "Step: 1012 -> Loss: 0.3931207060813904 -> Predictions: [[0.06617477]\n",
            " [0.6607974 ]\n",
            " [0.76955485]\n",
            " [0.56297547]]\n",
            "Step: 1013 -> Loss: 0.3909927010536194 -> Predictions: [[0.06636554]\n",
            " [0.66281575]\n",
            " [0.7703362 ]\n",
            " [0.5609377 ]]\n",
            "Step: 1014 -> Loss: 0.3888242244720459 -> Predictions: [[0.06655264]\n",
            " [0.6649062 ]\n",
            " [0.77109367]\n",
            " [0.5588505 ]]\n",
            "Step: 1015 -> Loss: 0.3866152763366699 -> Predictions: [[0.0667356 ]\n",
            " [0.66706705]\n",
            " [0.771828  ]\n",
            " [0.55671227]]\n",
            "Step: 1016 -> Loss: 0.38436636328697205 -> Predictions: [[0.0669141 ]\n",
            " [0.66929644]\n",
            " [0.7725397 ]\n",
            " [0.554522  ]]\n",
            "Step: 1017 -> Loss: 0.3820779323577881 -> Predictions: [[0.06708776]\n",
            " [0.67159194]\n",
            " [0.77322954]\n",
            " [0.5522786 ]]\n",
            "Step: 1018 -> Loss: 0.37975046038627625 -> Predictions: [[0.06725625]\n",
            " [0.6739511 ]\n",
            " [0.77389866]\n",
            " [0.54998076]]\n",
            "Step: 1019 -> Loss: 0.3773847818374634 -> Predictions: [[0.0674193 ]\n",
            " [0.6763708 ]\n",
            " [0.77454823]\n",
            " [0.547628  ]]\n",
            "Step: 1020 -> Loss: 0.37498167157173157 -> Predictions: [[0.06757664]\n",
            " [0.6788482 ]\n",
            " [0.77517945]\n",
            " [0.54521924]]\n",
            "Step: 1021 -> Loss: 0.37254196405410767 -> Predictions: [[0.06772808]\n",
            " [0.6813799 ]\n",
            " [0.77579385]\n",
            " [0.5427538 ]]\n",
            "Step: 1022 -> Loss: 0.37006691098213196 -> Predictions: [[0.06787335]\n",
            " [0.6839625 ]\n",
            " [0.7763931 ]\n",
            " [0.54023165]]\n",
            "Step: 1023 -> Loss: 0.36755773425102234 -> Predictions: [[0.06801245]\n",
            " [0.68659204]\n",
            " [0.7769791 ]\n",
            " [0.5376524 ]]\n",
            "Step: 1024 -> Loss: 0.3650154769420624 -> Predictions: [[0.06814517]\n",
            " [0.6892651 ]\n",
            " [0.77755356]\n",
            " [0.53501564]]\n",
            "Step: 1025 -> Loss: 0.3624415695667267 -> Predictions: [[0.06827146]\n",
            " [0.6919775 ]\n",
            " [0.77811855]\n",
            " [0.5323215 ]]\n",
            "Step: 1026 -> Loss: 0.35983747243881226 -> Predictions: [[0.06839126]\n",
            " [0.6947255 ]\n",
            " [0.7786763 ]\n",
            " [0.5295705 ]]\n",
            "Step: 1027 -> Loss: 0.35720473527908325 -> Predictions: [[0.06850455]\n",
            " [0.697505  ]\n",
            " [0.77922875]\n",
            " [0.5267629 ]]\n",
            "Step: 1028 -> Loss: 0.3545449376106262 -> Predictions: [[0.06861135]\n",
            " [0.7003119 ]\n",
            " [0.7797785 ]\n",
            " [0.5238994 ]]\n",
            "Step: 1029 -> Loss: 0.35185933113098145 -> Predictions: [[0.06871168]\n",
            " [0.70314246]\n",
            " [0.7803278 ]\n",
            " [0.5209805 ]]\n",
            "Step: 1030 -> Loss: 0.34915003180503845 -> Predictions: [[0.06880561]\n",
            " [0.7059925 ]\n",
            " [0.78087884]\n",
            " [0.5180077 ]]\n",
            "Step: 1031 -> Loss: 0.34641844034194946 -> Predictions: [[0.06889319]\n",
            " [0.7088585 ]\n",
            " [0.7814341 ]\n",
            " [0.51498175]]\n",
            "Step: 1032 -> Loss: 0.3436662554740906 -> Predictions: [[0.06897452]\n",
            " [0.71173656]\n",
            " [0.7819961 ]\n",
            " [0.5119041 ]]\n",
            "Step: 1033 -> Loss: 0.3408951759338379 -> Predictions: [[0.0690496 ]\n",
            " [0.714623  ]\n",
            " [0.78256685]\n",
            " [0.5087761 ]]\n",
            "Step: 1034 -> Loss: 0.3381068706512451 -> Predictions: [[0.0691186 ]\n",
            " [0.7175145 ]\n",
            " [0.7831488 ]\n",
            " [0.50559956]]\n",
            "Step: 1035 -> Loss: 0.3353028893470764 -> Predictions: [[0.06918159]\n",
            " [0.7204078 ]\n",
            " [0.78374416]\n",
            " [0.5023757 ]]\n",
            "Step: 1036 -> Loss: 0.3324850797653198 -> Predictions: [[0.06923865]\n",
            " [0.7232996 ]\n",
            " [0.78435487]\n",
            " [0.49910694]]\n",
            "Step: 1037 -> Loss: 0.3296549320220947 -> Predictions: [[0.06928987]\n",
            " [0.726187  ]\n",
            " [0.78498304]\n",
            " [0.49579445]]\n",
            "Step: 1038 -> Loss: 0.32681405544281006 -> Predictions: [[0.06933524]\n",
            " [0.72906715]\n",
            " [0.7856304 ]\n",
            " [0.49244076]]\n",
            "Step: 1039 -> Loss: 0.32396405935287476 -> Predictions: [[0.06937496]\n",
            " [0.7319375 ]\n",
            " [0.7862989 ]\n",
            " [0.4890477 ]]\n",
            "Step: 1040 -> Loss: 0.3211063742637634 -> Predictions: [[0.06940901]\n",
            " [0.7347958 ]\n",
            " [0.7869898 ]\n",
            " [0.48561716]]\n",
            "Step: 1041 -> Loss: 0.31824249029159546 -> Predictions: [[0.06943748]\n",
            " [0.73763955]\n",
            " [0.7877049 ]\n",
            " [0.4821513 ]]\n",
            "Step: 1042 -> Loss: 0.3153740167617798 -> Predictions: [[0.06946033]\n",
            " [0.7404667 ]\n",
            " [0.7884451 ]\n",
            " [0.47865245]]\n",
            "Step: 1043 -> Loss: 0.31250226497650146 -> Predictions: [[0.06947765]\n",
            " [0.7432754 ]\n",
            " [0.7892118 ]\n",
            " [0.47512266]]\n",
            "Step: 1044 -> Loss: 0.30962854623794556 -> Predictions: [[0.06948946]\n",
            " [0.7460641 ]\n",
            " [0.79000574]\n",
            " [0.47156397]]\n",
            "Step: 1045 -> Loss: 0.3067542314529419 -> Predictions: [[0.06949575]\n",
            " [0.74883115]\n",
            " [0.7908275 ]\n",
            " [0.4679784 ]]\n",
            "Step: 1046 -> Loss: 0.3038806915283203 -> Predictions: [[0.06949647]\n",
            " [0.7515751 ]\n",
            " [0.7916779 ]\n",
            " [0.46436834]]\n",
            "Step: 1047 -> Loss: 0.30100905895233154 -> Predictions: [[0.06949162]\n",
            " [0.7542949 ]\n",
            " [0.7925573 ]\n",
            " [0.46073583]]\n",
            "Step: 1048 -> Loss: 0.29814067482948303 -> Predictions: [[0.06948128]\n",
            " [0.7569893 ]\n",
            " [0.7934659 ]\n",
            " [0.457083  ]]\n",
            "Step: 1049 -> Loss: 0.2952766418457031 -> Predictions: [[0.06946531]\n",
            " [0.75965726]\n",
            " [0.79440373]\n",
            " [0.4534117 ]]\n",
            "Step: 1050 -> Loss: 0.29241812229156494 -> Predictions: [[0.06944375]\n",
            " [0.7622983 ]\n",
            " [0.7953707 ]\n",
            " [0.44972414]]\n",
            "Step: 1051 -> Loss: 0.28956618905067444 -> Predictions: [[0.06941658]\n",
            " [0.76491153]\n",
            " [0.7963668 ]\n",
            " [0.44602224]]\n",
            "Step: 1052 -> Loss: 0.28672200441360474 -> Predictions: [[0.06938373]\n",
            " [0.7674964 ]\n",
            " [0.7973914 ]\n",
            " [0.44230816]]\n",
            "Step: 1053 -> Loss: 0.28388649225234985 -> Predictions: [[0.06934525]\n",
            " [0.77005243]\n",
            " [0.79844433]\n",
            " [0.43858355]]\n",
            "Step: 1054 -> Loss: 0.28106075525283813 -> Predictions: [[0.06930104]\n",
            " [0.7725792 ]\n",
            " [0.7995245 ]\n",
            " [0.43485045]]\n",
            "Step: 1055 -> Loss: 0.2782456874847412 -> Predictions: [[0.06925108]\n",
            " [0.7750765 ]\n",
            " [0.80063176]\n",
            " [0.43111065]]\n",
            "Step: 1056 -> Loss: 0.2754421830177307 -> Predictions: [[0.06919543]\n",
            " [0.7775441 ]\n",
            " [0.8017651 ]\n",
            " [0.42736587]]\n",
            "Step: 1057 -> Loss: 0.2726513147354126 -> Predictions: [[0.06913399]\n",
            " [0.77998185]\n",
            " [0.80292356]\n",
            " [0.4236181 ]]\n",
            "Step: 1058 -> Loss: 0.2698737680912018 -> Predictions: [[0.06906684]\n",
            " [0.7823897 ]\n",
            " [0.8041061 ]\n",
            " [0.4198688 ]]\n",
            "Step: 1059 -> Loss: 0.26711052656173706 -> Predictions: [[0.06899396]\n",
            " [0.7847677 ]\n",
            " [0.80531186]\n",
            " [0.41611972]]\n",
            "Step: 1060 -> Loss: 0.2643623650074005 -> Predictions: [[0.06891529]\n",
            " [0.78711563]\n",
            " [0.8065397 ]\n",
            " [0.41237265]]\n",
            "Step: 1061 -> Loss: 0.26162999868392944 -> Predictions: [[0.06883092]\n",
            " [0.789434  ]\n",
            " [0.8077883 ]\n",
            " [0.40862876]]\n",
            "Step: 1062 -> Loss: 0.25891435146331787 -> Predictions: [[0.0687409 ]\n",
            " [0.7917227 ]\n",
            " [0.80905676]\n",
            " [0.40489024]]\n",
            "Step: 1063 -> Loss: 0.25621575117111206 -> Predictions: [[0.06864521]\n",
            " [0.79398215]\n",
            " [0.8103439 ]\n",
            " [0.40115783]]\n",
            "Step: 1064 -> Loss: 0.2535354495048523 -> Predictions: [[0.06854389]\n",
            " [0.7962122 ]\n",
            " [0.811648  ]\n",
            " [0.39743367]]\n",
            "Step: 1065 -> Loss: 0.2508736550807953 -> Predictions: [[0.06843698]\n",
            " [0.79841334]\n",
            " [0.8129685 ]\n",
            " [0.39371878]]\n",
            "Step: 1066 -> Loss: 0.24823111295700073 -> Predictions: [[0.06832459]\n",
            " [0.8005857 ]\n",
            " [0.8143036 ]\n",
            " [0.39001435]]\n",
            "Step: 1067 -> Loss: 0.2456085979938507 -> Predictions: [[0.06820676]\n",
            " [0.8027296 ]\n",
            " [0.81565225]\n",
            " [0.38632235]]\n",
            "Step: 1068 -> Loss: 0.24300646781921387 -> Predictions: [[0.06808355]\n",
            " [0.8048454 ]\n",
            " [0.81701314]\n",
            " [0.38264352]]\n",
            "Step: 1069 -> Loss: 0.24042534828186035 -> Predictions: [[0.06795502]\n",
            " [0.80693334]\n",
            " [0.8183851 ]\n",
            " [0.3789792 ]]\n",
            "Step: 1070 -> Loss: 0.23786568641662598 -> Predictions: [[0.06782135]\n",
            " [0.8089938 ]\n",
            " [0.81976694]\n",
            " [0.37533063]]\n",
            "Step: 1071 -> Loss: 0.23532801866531372 -> Predictions: [[0.06768252]\n",
            " [0.8110271 ]\n",
            " [0.8211574 ]\n",
            " [0.37169895]]\n",
            "Step: 1072 -> Loss: 0.23281273245811462 -> Predictions: [[0.06753867]\n",
            " [0.81303346]\n",
            " [0.8225553 ]\n",
            " [0.3680852 ]]\n",
            "Step: 1073 -> Loss: 0.23032036423683167 -> Predictions: [[0.06738994]\n",
            " [0.8150133 ]\n",
            " [0.82395935]\n",
            " [0.36449054]]\n",
            "Step: 1074 -> Loss: 0.22785106301307678 -> Predictions: [[0.06723639]\n",
            " [0.81696707]\n",
            " [0.8253686 ]\n",
            " [0.36091578]]\n",
            "Step: 1075 -> Loss: 0.2254054844379425 -> Predictions: [[0.06707816]\n",
            " [0.8188949 ]\n",
            " [0.82678187]\n",
            " [0.3573623 ]]\n",
            "Step: 1076 -> Loss: 0.22298362851142883 -> Predictions: [[0.06691536]\n",
            " [0.8207973 ]\n",
            " [0.8281981 ]\n",
            " [0.3538304 ]]\n",
            "Step: 1077 -> Loss: 0.2205861210823059 -> Predictions: [[0.0667481 ]\n",
            " [0.8226745 ]\n",
            " [0.8296163 ]\n",
            " [0.35032153]]\n",
            "Step: 1078 -> Loss: 0.21821299195289612 -> Predictions: [[0.06657654]\n",
            " [0.8245268 ]\n",
            " [0.83103544]\n",
            " [0.3468361 ]]\n",
            "Step: 1079 -> Loss: 0.21586455404758453 -> Predictions: [[0.0664008]\n",
            " [0.8263547]\n",
            " [0.8324546]\n",
            " [0.3433752]]\n",
            "Step: 1080 -> Loss: 0.21354103088378906 -> Predictions: [[0.06622088]\n",
            " [0.82815844]\n",
            " [0.8338729 ]\n",
            " [0.33993942]]\n",
            "Step: 1081 -> Loss: 0.21124261617660522 -> Predictions: [[0.06603713]\n",
            " [0.82993823]\n",
            " [0.83528936]\n",
            " [0.33652943]]\n",
            "Step: 1082 -> Loss: 0.20896951854228973 -> Predictions: [[0.06584957]\n",
            " [0.8316946 ]\n",
            " [0.8367032 ]\n",
            " [0.3331462 ]]\n",
            "Step: 1083 -> Loss: 0.206721693277359 -> Predictions: [[0.06565832]\n",
            " [0.8334276 ]\n",
            " [0.8381137 ]\n",
            " [0.32978973]]\n",
            "Step: 1084 -> Loss: 0.20449940860271454 -> Predictions: [[0.06546354]\n",
            " [0.83513784]\n",
            " [0.8395201 ]\n",
            " [0.32646117]]\n",
            "Step: 1085 -> Loss: 0.2023027092218399 -> Predictions: [[0.06526536]\n",
            " [0.8368255 ]\n",
            " [0.8409216 ]\n",
            " [0.32316086]]\n",
            "Step: 1086 -> Loss: 0.20013165473937988 -> Predictions: [[0.06506391]\n",
            " [0.83849084]\n",
            " [0.8423177 ]\n",
            " [0.31988943]]\n",
            "Step: 1087 -> Loss: 0.19798630475997925 -> Predictions: [[0.06485934]\n",
            " [0.840134  ]\n",
            " [0.8437075 ]\n",
            " [0.31664696]]\n",
            "Step: 1088 -> Loss: 0.195866659283638 -> Predictions: [[0.06465171]\n",
            " [0.84175557]\n",
            " [0.84509057]\n",
            " [0.3134342 ]]\n",
            "Step: 1089 -> Loss: 0.19377270340919495 -> Predictions: [[0.06444123]\n",
            " [0.8433557 ]\n",
            " [0.8464663 ]\n",
            " [0.31025153]]\n",
            "Step: 1090 -> Loss: 0.1917044222354889 -> Predictions: [[0.06422803]\n",
            " [0.8449347 ]\n",
            " [0.84783435]\n",
            " [0.3070991 ]]\n",
            "Step: 1091 -> Loss: 0.18966183066368103 -> Predictions: [[0.06401221]\n",
            " [0.84649277]\n",
            " [0.8491939 ]\n",
            " [0.30397737]]\n",
            "Step: 1092 -> Loss: 0.1876448690891266 -> Predictions: [[0.06379395]\n",
            " [0.84803015]\n",
            " [0.85054475]\n",
            " [0.30088666]]\n",
            "Step: 1093 -> Loss: 0.18565326929092407 -> Predictions: [[0.06357324]\n",
            " [0.84954727]\n",
            " [0.8518865 ]\n",
            " [0.29782695]]\n",
            "Step: 1094 -> Loss: 0.183687224984169 -> Predictions: [[0.06335039]\n",
            " [0.8510442 ]\n",
            " [0.8532185 ]\n",
            " [0.29479873]]\n",
            "Step: 1095 -> Loss: 0.18174642324447632 -> Predictions: [[0.06312533]\n",
            " [0.85252124]\n",
            " [0.8545407 ]\n",
            " [0.29180205]]\n",
            "Step: 1096 -> Loss: 0.1798308789730072 -> Predictions: [[0.0628984 ]\n",
            " [0.8539788 ]\n",
            " [0.85585254]\n",
            " [0.28883716]]\n",
            "Step: 1097 -> Loss: 0.17794036865234375 -> Predictions: [[0.06266952]\n",
            " [0.8554169 ]\n",
            " [0.8571538 ]\n",
            " [0.28590396]]\n",
            "Step: 1098 -> Loss: 0.1760747730731964 -> Predictions: [[0.06243889]\n",
            " [0.85683596]\n",
            " [0.8584442 ]\n",
            " [0.28300282]]\n",
            "Step: 1099 -> Loss: 0.17423389852046967 -> Predictions: [[0.06220666]\n",
            " [0.85823625]\n",
            " [0.8597236 ]\n",
            " [0.28013363]]\n",
            "Step: 1100 -> Loss: 0.17241764068603516 -> Predictions: [[0.06197286]\n",
            " [0.8596178 ]\n",
            " [0.86099166]\n",
            " [0.27729654]]\n",
            "Step: 1101 -> Loss: 0.17062576115131378 -> Predictions: [[0.06173765]\n",
            " [0.86098105]\n",
            " [0.8622482 ]\n",
            " [0.2744914 ]]\n",
            "Step: 1102 -> Loss: 0.16885805130004883 -> Predictions: [[0.06150114]\n",
            " [0.8623261 ]\n",
            " [0.86349297]\n",
            " [0.27171826]]\n",
            "Step: 1103 -> Loss: 0.16711436212062836 -> Predictions: [[0.06126339]\n",
            " [0.86365324]\n",
            " [0.86472595]\n",
            " [0.2689772 ]]\n",
            "Step: 1104 -> Loss: 0.16539447009563446 -> Predictions: [[0.06102455]\n",
            " [0.8649627 ]\n",
            " [0.865947  ]\n",
            " [0.266268  ]]\n",
            "Step: 1105 -> Loss: 0.16369813680648804 -> Predictions: [[0.06078471]\n",
            " [0.86625475]\n",
            " [0.86715585]\n",
            " [0.26359075]]\n",
            "Step: 1106 -> Loss: 0.16202518343925476 -> Predictions: [[0.06054395]\n",
            " [0.86752963]\n",
            " [0.86835265]\n",
            " [0.26094538]]\n",
            "Step: 1107 -> Loss: 0.16037532687187195 -> Predictions: [[0.06030236]\n",
            " [0.8687872 ]\n",
            " [0.869537  ]\n",
            " [0.25833145]]\n",
            "Step: 1108 -> Loss: 0.1587483286857605 -> Predictions: [[0.06006   ]\n",
            " [0.87002826]\n",
            " [0.87070906]\n",
            " [0.25574917]]\n",
            "Step: 1109 -> Loss: 0.1571439802646637 -> Predictions: [[0.05981703]\n",
            " [0.87125266]\n",
            " [0.8718688 ]\n",
            " [0.25319827]]\n",
            "Step: 1110 -> Loss: 0.15556205809116364 -> Predictions: [[0.05957345]\n",
            " [0.87246054]\n",
            " [0.873016  ]\n",
            " [0.25067863]]\n",
            "Step: 1111 -> Loss: 0.15400221943855286 -> Predictions: [[0.0593294 ]\n",
            " [0.87365246]\n",
            " [0.8741508 ]\n",
            " [0.24819002]]\n",
            "Step: 1112 -> Loss: 0.15246424078941345 -> Predictions: [[0.05908498]\n",
            " [0.8748285 ]\n",
            " [0.8752731 ]\n",
            " [0.24573216]]\n",
            "Step: 1113 -> Loss: 0.15094788372516632 -> Predictions: [[0.0588402 ]\n",
            " [0.8759887 ]\n",
            " [0.87638295]\n",
            " [0.24330498]]\n",
            "Step: 1114 -> Loss: 0.14945289492607117 -> Predictions: [[0.05859522]\n",
            " [0.87713337]\n",
            " [0.8774804 ]\n",
            " [0.2409083 ]]\n",
            "Step: 1115 -> Loss: 0.1479790210723877 -> Predictions: [[0.05834998]\n",
            " [0.8782628 ]\n",
            " [0.8785654 ]\n",
            " [0.23854184]]\n",
            "Step: 1116 -> Loss: 0.14652594923973083 -> Predictions: [[0.05810472]\n",
            " [0.87937725]\n",
            " [0.8796379 ]\n",
            " [0.23620546]]\n",
            "Step: 1117 -> Loss: 0.14509344100952148 -> Predictions: [[0.05785933]\n",
            " [0.8804766 ]\n",
            " [0.8806981 ]\n",
            " [0.23389858]]\n",
            "Step: 1118 -> Loss: 0.14368122816085815 -> Predictions: [[0.057614  ]\n",
            " [0.88156134]\n",
            " [0.881746  ]\n",
            " [0.23162134]]\n",
            "Step: 1119 -> Loss: 0.14228904247283936 -> Predictions: [[0.05736868]\n",
            " [0.88263154]\n",
            " [0.8827817 ]\n",
            " [0.22937337]]\n",
            "Step: 1120 -> Loss: 0.14091649651527405 -> Predictions: [[0.05712358]\n",
            " [0.8836876 ]\n",
            " [0.8838051 ]\n",
            " [0.22715405]]\n",
            "Step: 1121 -> Loss: 0.13956356048583984 -> Predictions: [[0.05687866]\n",
            " [0.88472944]\n",
            " [0.88481647]\n",
            " [0.22496374]]\n",
            "Step: 1122 -> Loss: 0.13822974264621735 -> Predictions: [[0.05663401]\n",
            " [0.8857574 ]\n",
            " [0.88581574]\n",
            " [0.22280158]]\n",
            "Step: 1123 -> Loss: 0.1369149088859558 -> Predictions: [[0.0563896 ]\n",
            " [0.88677174]\n",
            " [0.88680315]\n",
            " [0.2206677 ]]\n",
            "Step: 1124 -> Loss: 0.13561873137950897 -> Predictions: [[0.05614557]\n",
            " [0.88777256]\n",
            " [0.88777864]\n",
            " [0.21856163]]\n",
            "Step: 1125 -> Loss: 0.13434097170829773 -> Predictions: [[0.05590196]\n",
            " [0.88875985]\n",
            " [0.88874227]\n",
            " [0.2164829 ]]\n",
            "Step: 1126 -> Loss: 0.13308125734329224 -> Predictions: [[0.05565875]\n",
            " [0.8897342 ]\n",
            " [0.8896944 ]\n",
            " [0.21443145]]\n",
            "Step: 1127 -> Loss: 0.13183948397636414 -> Predictions: [[0.0554161 ]\n",
            " [0.89069563]\n",
            " [0.89063483]\n",
            " [0.21240708]]\n",
            "Step: 1128 -> Loss: 0.13061530888080597 -> Predictions: [[0.05517394]\n",
            " [0.8916442 ]\n",
            " [0.89156383]\n",
            " [0.2104092 ]]\n",
            "Step: 1129 -> Loss: 0.12940844893455505 -> Predictions: [[0.05493244]\n",
            " [0.8925802 ]\n",
            " [0.89248145]\n",
            " [0.20843752]]\n",
            "Step: 1130 -> Loss: 0.1282186359167099 -> Predictions: [[0.05469147]\n",
            " [0.8935039 ]\n",
            " [0.89338785]\n",
            " [0.2064919 ]]\n",
            "Step: 1131 -> Loss: 0.12704569101333618 -> Predictions: [[0.05445118]\n",
            " [0.8944154 ]\n",
            " [0.89428294]\n",
            " [0.20457193]]\n",
            "Step: 1132 -> Loss: 0.12588933110237122 -> Predictions: [[0.0542116 ]\n",
            " [0.8953146 ]\n",
            " [0.89516705]\n",
            " [0.20267735]]\n",
            "Step: 1133 -> Loss: 0.12474918365478516 -> Predictions: [[0.05397271]\n",
            " [0.89620215]\n",
            " [0.8960404 ]\n",
            " [0.20080777]]\n",
            "Step: 1134 -> Loss: 0.12362515181303024 -> Predictions: [[0.05373458]\n",
            " [0.8970779 ]\n",
            " [0.8969028 ]\n",
            " [0.19896302]]\n",
            "Step: 1135 -> Loss: 0.12251685559749603 -> Predictions: [[0.05349721]\n",
            " [0.89794225]\n",
            " [0.89775455]\n",
            " [0.19714251]]\n",
            "Step: 1136 -> Loss: 0.12142415344715118 -> Predictions: [[0.0532607 ]\n",
            " [0.89879537]\n",
            " [0.89859575]\n",
            " [0.19534622]]\n",
            "Step: 1137 -> Loss: 0.12034677714109421 -> Predictions: [[0.05302504]\n",
            " [0.89963704]\n",
            " [0.8994266 ]\n",
            " [0.19357365]]\n",
            "Step: 1138 -> Loss: 0.119284488260746 -> Predictions: [[0.05279029]\n",
            " [0.90046775]\n",
            " [0.90024704]\n",
            " [0.1918246 ]]\n",
            "Step: 1139 -> Loss: 0.1182369589805603 -> Predictions: [[0.05255638]\n",
            " [0.90128756]\n",
            " [0.90105736]\n",
            " [0.19009855]]\n",
            "Step: 1140 -> Loss: 0.11720405519008636 -> Predictions: [[0.05232338]\n",
            " [0.90209687]\n",
            " [0.90185744]\n",
            " [0.18839549]]\n",
            "Step: 1141 -> Loss: 0.11618548631668091 -> Predictions: [[0.05209134]\n",
            " [0.9028955 ]\n",
            " [0.90264773]\n",
            " [0.18671478]]\n",
            "Step: 1142 -> Loss: 0.11518105864524841 -> Predictions: [[0.05186026]\n",
            " [0.90368384]\n",
            " [0.9034282 ]\n",
            " [0.18505646]]\n",
            "Step: 1143 -> Loss: 0.11419050395488739 -> Predictions: [[0.05163015]\n",
            " [0.904462  ]\n",
            " [0.90419894]\n",
            " [0.18342   ]]\n",
            "Step: 1144 -> Loss: 0.1132136732339859 -> Predictions: [[0.05140111]\n",
            " [0.9052301 ]\n",
            " [0.90496016]\n",
            " [0.18180527]]\n",
            "Step: 1145 -> Loss: 0.11225022375583649 -> Predictions: [[0.05117304]\n",
            " [0.90598816]\n",
            " [0.90571195]\n",
            " [0.18021159]]\n",
            "Step: 1146 -> Loss: 0.11130005121231079 -> Predictions: [[0.05094595]\n",
            " [0.90673655]\n",
            " [0.90645427]\n",
            " [0.17863904]]\n",
            "Step: 1147 -> Loss: 0.11036291718482971 -> Predictions: [[0.05071998]\n",
            " [0.9074752 ]\n",
            " [0.9071875 ]\n",
            " [0.17708716]]\n",
            "Step: 1148 -> Loss: 0.10943856835365295 -> Predictions: [[0.05049506]\n",
            " [0.9082045 ]\n",
            " [0.90791166]\n",
            " [0.17555577]]\n",
            "Step: 1149 -> Loss: 0.10852682590484619 -> Predictions: [[0.05027121]\n",
            " [0.9089244 ]\n",
            " [0.9086268 ]\n",
            " [0.17404449]]\n",
            "Step: 1150 -> Loss: 0.10762744396924973 -> Predictions: [[0.05004849]\n",
            " [0.90963525]\n",
            " [0.9093332 ]\n",
            " [0.17255291]]\n",
            "Step: 1151 -> Loss: 0.10674028843641281 -> Predictions: [[0.04982682]\n",
            " [0.9103369 ]\n",
            " [0.9100308 ]\n",
            " [0.17108098]]\n",
            "Step: 1152 -> Loss: 0.10586509108543396 -> Predictions: [[0.0496063 ]\n",
            " [0.9110299 ]\n",
            " [0.91071975]\n",
            " [0.1696282 ]]\n",
            "Step: 1153 -> Loss: 0.10500173270702362 -> Predictions: [[0.04938687]\n",
            " [0.91171384]\n",
            " [0.9114003 ]\n",
            " [0.1681945 ]]\n",
            "Step: 1154 -> Loss: 0.1041499525308609 -> Predictions: [[0.04916862]\n",
            " [0.9123892 ]\n",
            " [0.9120725 ]\n",
            " [0.16677947]]\n",
            "Step: 1155 -> Loss: 0.10330957174301147 -> Predictions: [[0.04895151]\n",
            " [0.9130562 ]\n",
            " [0.91273654]\n",
            " [0.16538285]]\n",
            "Step: 1156 -> Loss: 0.10248041152954102 -> Predictions: [[0.04873554]\n",
            " [0.9137147 ]\n",
            " [0.91339236]\n",
            " [0.16400431]]\n",
            "Step: 1157 -> Loss: 0.10166225582361221 -> Predictions: [[0.04852073]\n",
            " [0.91436505]\n",
            " [0.91404015]\n",
            " [0.16264355]]\n",
            "Step: 1158 -> Loss: 0.10085500776767731 -> Predictions: [[0.04830708]\n",
            " [0.91500723]\n",
            " [0.91468   ]\n",
            " [0.1613006 ]]\n",
            "Step: 1159 -> Loss: 0.10005838423967361 -> Predictions: [[0.04809457]\n",
            " [0.9156414 ]\n",
            " [0.9153122 ]\n",
            " [0.15997481]]\n",
            "Step: 1160 -> Loss: 0.09927231073379517 -> Predictions: [[0.04788325]\n",
            " [0.91626775]\n",
            " [0.9159366 ]\n",
            " [0.15866621]]\n",
            "Step: 1161 -> Loss: 0.09849654138088226 -> Predictions: [[0.04767313]\n",
            " [0.91688627]\n",
            " [0.91655356]\n",
            " [0.15737443]]\n",
            "Step: 1162 -> Loss: 0.09773097187280655 -> Predictions: [[0.04746419]\n",
            " [0.9174972 ]\n",
            " [0.91716284]\n",
            " [0.15609923]]\n",
            "Step: 1163 -> Loss: 0.09697531908750534 -> Predictions: [[0.04725639]\n",
            " [0.9181007 ]\n",
            " [0.917765  ]\n",
            " [0.15484034]]\n",
            "Step: 1164 -> Loss: 0.09622958302497864 -> Predictions: [[0.04704986]\n",
            " [0.91869664]\n",
            " [0.9183598 ]\n",
            " [0.15359756]]\n",
            "Step: 1165 -> Loss: 0.09549342095851898 -> Predictions: [[0.04684444]\n",
            " [0.9192855 ]\n",
            " [0.9189475 ]\n",
            " [0.15237053]]\n",
            "Step: 1166 -> Loss: 0.09476679563522339 -> Predictions: [[0.0466403 ]\n",
            " [0.91986704]\n",
            " [0.9195281 ]\n",
            " [0.15115905]]\n",
            "Step: 1167 -> Loss: 0.09404955804347992 -> Predictions: [[0.04643729]\n",
            " [0.92044157]\n",
            " [0.9201018 ]\n",
            " [0.14996307]]\n",
            "Step: 1168 -> Loss: 0.09334148466587067 -> Predictions: [[0.04623552]\n",
            " [0.9210091 ]\n",
            " [0.9206688 ]\n",
            " [0.1487821 ]]\n",
            "Step: 1169 -> Loss: 0.09264245629310608 -> Predictions: [[0.04603493]\n",
            " [0.9215698 ]\n",
            " [0.9212289 ]\n",
            " [0.14761597]]\n",
            "Step: 1170 -> Loss: 0.09195234626531601 -> Predictions: [[0.04583552]\n",
            " [0.9221238 ]\n",
            " [0.92178243]\n",
            " [0.14646457]]\n",
            "Step: 1171 -> Loss: 0.09127096831798553 -> Predictions: [[0.04563736]\n",
            " [0.9226711 ]\n",
            " [0.9223294 ]\n",
            " [0.14532757]]\n",
            "Step: 1172 -> Loss: 0.09059825539588928 -> Predictions: [[0.04544033]\n",
            " [0.9232118 ]\n",
            " [0.9228698 ]\n",
            " [0.1442049 ]]\n",
            "Step: 1173 -> Loss: 0.08993398398160934 -> Predictions: [[0.04524455]\n",
            " [0.92374617]\n",
            " [0.9234041 ]\n",
            " [0.14309615]]\n",
            "Step: 1174 -> Loss: 0.08927801996469498 -> Predictions: [[0.0450499 ]\n",
            " [0.9242741 ]\n",
            " [0.923932  ]\n",
            " [0.14200112]]\n",
            "Step: 1175 -> Loss: 0.08863028883934021 -> Predictions: [[0.0448565 ]\n",
            " [0.92479587]\n",
            " [0.92445374]\n",
            " [0.14091973]]\n",
            "Step: 1176 -> Loss: 0.0879906415939331 -> Predictions: [[0.04466424]\n",
            " [0.92531145]\n",
            " [0.92496943]\n",
            " [0.13985182]]\n",
            "Step: 1177 -> Loss: 0.08735889196395874 -> Predictions: [[0.04447317]\n",
            " [0.92582095]\n",
            " [0.92547905]\n",
            " [0.13879691]]\n",
            "Step: 1178 -> Loss: 0.08673495799303055 -> Predictions: [[0.04428332]\n",
            " [0.9263244 ]\n",
            " [0.9259829 ]\n",
            " [0.13775499]]\n",
            "Step: 1179 -> Loss: 0.08611875027418137 -> Predictions: [[0.04409463]\n",
            " [0.9268221 ]\n",
            " [0.92648077]\n",
            " [0.13672595]]\n",
            "Step: 1180 -> Loss: 0.08551003038883209 -> Predictions: [[0.04390711]\n",
            " [0.92731404]\n",
            " [0.9269731 ]\n",
            " [0.13570938]]\n",
            "Step: 1181 -> Loss: 0.08490882813930511 -> Predictions: [[0.0437208 ]\n",
            " [0.9278002 ]\n",
            " [0.9274596 ]\n",
            " [0.13470522]]\n",
            "Step: 1182 -> Loss: 0.08431492000818253 -> Predictions: [[0.04353563]\n",
            " [0.9282808 ]\n",
            " [0.92794067]\n",
            " [0.13371333]]\n",
            "Step: 1183 -> Loss: 0.08372820913791656 -> Predictions: [[0.04335164]\n",
            " [0.9287557 ]\n",
            " [0.9284162 ]\n",
            " [0.13273333]]\n",
            "Step: 1184 -> Loss: 0.08314856886863708 -> Predictions: [[0.04316879]\n",
            " [0.9292254 ]\n",
            " [0.92888635]\n",
            " [0.1317652 ]]\n",
            "Step: 1185 -> Loss: 0.08257594704627991 -> Predictions: [[0.04298713]\n",
            " [0.9296895 ]\n",
            " [0.92935115]\n",
            " [0.1308088 ]]\n",
            "Step: 1186 -> Loss: 0.0820101797580719 -> Predictions: [[0.04280664]\n",
            " [0.9301485 ]\n",
            " [0.9298108 ]\n",
            " [0.12986383]]\n",
            "Step: 1187 -> Loss: 0.08145113289356232 -> Predictions: [[0.04262725]\n",
            " [0.9306021 ]\n",
            " [0.9302651 ]\n",
            " [0.12893002]]\n",
            "Step: 1188 -> Loss: 0.08089876174926758 -> Predictions: [[0.04244903]\n",
            " [0.93105066]\n",
            " [0.9307145 ]\n",
            " [0.1280075 ]]\n",
            "Step: 1189 -> Loss: 0.08035293966531754 -> Predictions: [[0.04227195]\n",
            " [0.9314942 ]\n",
            " [0.93115884]\n",
            " [0.12709591]]\n",
            "Step: 1190 -> Loss: 0.07981353998184204 -> Predictions: [[0.04209602]\n",
            " [0.93193275]\n",
            " [0.9315981 ]\n",
            " [0.12619501]]\n",
            "Step: 1191 -> Loss: 0.0792805403470993 -> Predictions: [[0.04192121]\n",
            " [0.9323663 ]\n",
            " [0.93203264]\n",
            " [0.12530491]]\n",
            "Step: 1192 -> Loss: 0.07875372469425201 -> Predictions: [[0.04174752]\n",
            " [0.9327951 ]\n",
            " [0.9324623 ]\n",
            " [0.12442517]]\n",
            "Step: 1193 -> Loss: 0.07823306322097778 -> Predictions: [[0.04157497]\n",
            " [0.93321913]\n",
            " [0.93288726]\n",
            " [0.12355573]]\n",
            "Step: 1194 -> Loss: 0.07771848142147064 -> Predictions: [[0.04140352]\n",
            " [0.93363845]\n",
            " [0.9333075 ]\n",
            " [0.12269655]]\n",
            "Step: 1195 -> Loss: 0.07720982283353806 -> Predictions: [[0.04123317]\n",
            " [0.9340531 ]\n",
            " [0.93372315]\n",
            " [0.12184725]]\n",
            "Step: 1196 -> Loss: 0.07670705765485764 -> Predictions: [[0.04106393]\n",
            " [0.9344633 ]\n",
            " [0.9341343 ]\n",
            " [0.1210079 ]]\n",
            "Step: 1197 -> Loss: 0.07621003687381744 -> Predictions: [[0.04089577]\n",
            " [0.93486893]\n",
            " [0.934541  ]\n",
            " [0.12017818]]\n",
            "Step: 1198 -> Loss: 0.0757187008857727 -> Predictions: [[0.04072873]\n",
            " [0.93527025]\n",
            " [0.93494326]\n",
            " [0.11935808]]\n",
            "Step: 1199 -> Loss: 0.07523297518491745 -> Predictions: [[0.04056276]\n",
            " [0.93566704]\n",
            " [0.9353411 ]\n",
            " [0.11854735]]\n",
            "Step: 1200 -> Loss: 0.07475278526544571 -> Predictions: [[0.04039781]\n",
            " [0.93605965]\n",
            " [0.9357347 ]\n",
            " [0.11774598]]\n",
            "Step: 1201 -> Loss: 0.07427795976400375 -> Predictions: [[0.04023399]\n",
            " [0.9364479 ]\n",
            " [0.9361242 ]\n",
            " [0.11695372]]\n",
            "Step: 1202 -> Loss: 0.07380855828523636 -> Predictions: [[0.04007125]\n",
            " [0.9368321 ]\n",
            " [0.93650943]\n",
            " [0.11617049]]\n",
            "Step: 1203 -> Loss: 0.07334436476230621 -> Predictions: [[0.03990956]\n",
            " [0.9372121 ]\n",
            " [0.93689054]\n",
            " [0.11539605]]\n",
            "Step: 1204 -> Loss: 0.07288539409637451 -> Predictions: [[0.0397489 ]\n",
            " [0.93758816]\n",
            " [0.9372676 ]\n",
            " [0.11463051]]\n",
            "Step: 1205 -> Loss: 0.07243149727582932 -> Predictions: [[0.03958931]\n",
            " [0.93796015]\n",
            " [0.9376409 ]\n",
            " [0.11387349]]\n",
            "Step: 1206 -> Loss: 0.07198259979486465 -> Predictions: [[0.03943074]\n",
            " [0.93832827]\n",
            " [0.93801004]\n",
            " [0.11312489]]\n",
            "Step: 1207 -> Loss: 0.07153870165348053 -> Predictions: [[0.03927323]\n",
            " [0.93869245]\n",
            " [0.9383753 ]\n",
            " [0.11238477]]\n",
            "Step: 1208 -> Loss: 0.0710996687412262 -> Predictions: [[0.03911677]\n",
            " [0.93905276]\n",
            " [0.93873686]\n",
            " [0.11165281]]\n",
            "Step: 1209 -> Loss: 0.07066547125577927 -> Predictions: [[0.03896127]\n",
            " [0.9394094 ]\n",
            " [0.9390946 ]\n",
            " [0.1109291 ]]\n",
            "Step: 1210 -> Loss: 0.070235975086689 -> Predictions: [[0.03880676]\n",
            " [0.9397621 ]\n",
            " [0.9394486 ]\n",
            " [0.11021328]]\n",
            "Step: 1211 -> Loss: 0.06981115788221359 -> Predictions: [[0.03865331]\n",
            " [0.94011134]\n",
            " [0.93979895]\n",
            " [0.10950537]]\n",
            "Step: 1212 -> Loss: 0.0693909078836441 -> Predictions: [[0.03850085]\n",
            " [0.9404569 ]\n",
            " [0.9401458 ]\n",
            " [0.10880524]]\n",
            "Step: 1213 -> Loss: 0.06897522509098053 -> Predictions: [[0.0383494 ]\n",
            " [0.940799  ]\n",
            " [0.940489  ]\n",
            " [0.10811283]]\n",
            "Step: 1214 -> Loss: 0.06856396794319153 -> Predictions: [[0.0381989 ]\n",
            " [0.9411374 ]\n",
            " [0.9408287 ]\n",
            " [0.10742784]]\n",
            "Step: 1215 -> Loss: 0.06815716624259949 -> Predictions: [[0.03804942]\n",
            " [0.9414725 ]\n",
            " [0.94116485]\n",
            " [0.10675041]]\n",
            "Step: 1216 -> Loss: 0.06775464117527008 -> Predictions: [[0.03790095]\n",
            " [0.94180405]\n",
            " [0.9414977 ]\n",
            " [0.10608018]]\n",
            "Step: 1217 -> Loss: 0.06735642999410629 -> Predictions: [[0.03775335]\n",
            " [0.94213223]\n",
            " [0.941827  ]\n",
            " [0.1054173 ]]\n",
            "Step: 1218 -> Loss: 0.06696239113807678 -> Predictions: [[0.03760677]\n",
            " [0.9424571 ]\n",
            " [0.9421532 ]\n",
            " [0.10476154]]\n",
            "Step: 1219 -> Loss: 0.06657250225543976 -> Predictions: [[0.03746114]\n",
            " [0.94277877]\n",
            " [0.94247603]\n",
            " [0.10411279]]\n",
            "Step: 1220 -> Loss: 0.06618671119213104 -> Predictions: [[0.03731641]\n",
            " [0.9430972 ]\n",
            " [0.94279563]\n",
            " [0.103471  ]]\n",
            "Step: 1221 -> Loss: 0.06580497324466705 -> Predictions: [[0.03717268]\n",
            " [0.9434123 ]\n",
            " [0.943112  ]\n",
            " [0.10283603]]\n",
            "Step: 1222 -> Loss: 0.06542713940143585 -> Predictions: [[0.03702984]\n",
            " [0.94372445]\n",
            " [0.94342536]\n",
            " [0.10220774]]\n",
            "Step: 1223 -> Loss: 0.06505326181650162 -> Predictions: [[0.03688796]\n",
            " [0.9440334 ]\n",
            " [0.9437355 ]\n",
            " [0.10158607]]\n",
            "Step: 1224 -> Loss: 0.0646832287311554 -> Predictions: [[0.03674695]\n",
            " [0.9443392 ]\n",
            " [0.9440426 ]\n",
            " [0.10097098]]\n",
            "Step: 1225 -> Loss: 0.06431698054075241 -> Predictions: [[0.03660687]\n",
            " [0.9446421 ]\n",
            " [0.94434667]\n",
            " [0.10036227]]\n",
            "Step: 1226 -> Loss: 0.06395453959703445 -> Predictions: [[0.03646773]\n",
            " [0.944942  ]\n",
            " [0.9446477 ]\n",
            " [0.09976005]]\n",
            "Step: 1227 -> Loss: 0.06359576433897018 -> Predictions: [[0.03632951]\n",
            " [0.94523895]\n",
            " [0.94494593]\n",
            " [0.09916404]]\n",
            "Step: 1228 -> Loss: 0.06324061006307602 -> Predictions: [[0.03619213]\n",
            " [0.945533  ]\n",
            " [0.9452413 ]\n",
            " [0.09857421]]\n",
            "Step: 1229 -> Loss: 0.06288904696702957 -> Predictions: [[0.03605564]\n",
            " [0.94582427]\n",
            " [0.94553375]\n",
            " [0.09799048]]\n",
            "Step: 1230 -> Loss: 0.06254106760025024 -> Predictions: [[0.03592005]\n",
            " [0.9461126 ]\n",
            " [0.9458233 ]\n",
            " [0.09741278]]\n",
            "Step: 1231 -> Loss: 0.06219654902815819 -> Predictions: [[0.03578535]\n",
            " [0.94639826]\n",
            " [0.94611   ]\n",
            " [0.09684096]]\n",
            "Step: 1232 -> Loss: 0.061855487525463104 -> Predictions: [[0.03565148]\n",
            " [0.946681  ]\n",
            " [0.9463942 ]\n",
            " [0.09627504]]\n",
            "Step: 1233 -> Loss: 0.061517830938100815 -> Predictions: [[0.0355185 ]\n",
            " [0.94696116]\n",
            " [0.9466755 ]\n",
            " [0.09571487]]\n",
            "Step: 1234 -> Loss: 0.06118350476026535 -> Predictions: [[0.03538636]\n",
            " [0.9472386 ]\n",
            " [0.9469541 ]\n",
            " [0.09516033]]\n",
            "Step: 1235 -> Loss: 0.06085250526666641 -> Predictions: [[0.03525505]\n",
            " [0.9475135 ]\n",
            " [0.94723016]\n",
            " [0.09461155]]\n",
            "Step: 1236 -> Loss: 0.06052476912736893 -> Predictions: [[0.03512463]\n",
            " [0.9477856 ]\n",
            " [0.94750357]\n",
            " [0.09406819]]\n",
            "Step: 1237 -> Loss: 0.06020020321011543 -> Predictions: [[0.03499502]\n",
            " [0.9480553 ]\n",
            " [0.94777447]\n",
            " [0.09353025]]\n",
            "Step: 1238 -> Loss: 0.05987885594367981 -> Predictions: [[0.0348662 ]\n",
            " [0.9483224 ]\n",
            " [0.9480427 ]\n",
            " [0.09299783]]\n",
            "Step: 1239 -> Loss: 0.059560589492321014 -> Predictions: [[0.03473825]\n",
            " [0.948587  ]\n",
            " [0.9483086 ]\n",
            " [0.0924706 ]]\n",
            "Step: 1240 -> Loss: 0.05924545228481293 -> Predictions: [[0.03461109]\n",
            " [0.94884914]\n",
            " [0.94857186]\n",
            " [0.09194866]]\n",
            "Step: 1241 -> Loss: 0.05893334746360779 -> Predictions: [[0.03448476]\n",
            " [0.9491089 ]\n",
            " [0.9488327 ]\n",
            " [0.09143192]]\n",
            "Step: 1242 -> Loss: 0.05862422287464142 -> Predictions: [[0.03435922]\n",
            " [0.94936615]\n",
            " [0.9490912 ]\n",
            " [0.09092022]]\n",
            "Step: 1243 -> Loss: 0.05831809341907501 -> Predictions: [[0.03423452]\n",
            " [0.9496211 ]\n",
            " [0.94934726]\n",
            " [0.09041361]]\n",
            "Step: 1244 -> Loss: 0.05801483988761902 -> Predictions: [[0.03411049]\n",
            " [0.9498737 ]\n",
            " [0.949601  ]\n",
            " [0.08991184]]\n",
            "Step: 1245 -> Loss: 0.057714518159627914 -> Predictions: [[0.03398736]\n",
            " [0.9501239 ]\n",
            " [0.9498524 ]\n",
            " [0.08941511]]\n",
            "Step: 1246 -> Loss: 0.05741700530052185 -> Predictions: [[0.03386497]\n",
            " [0.9503718 ]\n",
            " [0.95010155]\n",
            " [0.08892311]]\n",
            "Step: 1247 -> Loss: 0.05712233483791351 -> Predictions: [[0.03374336]\n",
            " [0.9506176 ]\n",
            " [0.95034844]\n",
            " [0.08843602]]\n",
            "Step: 1248 -> Loss: 0.05683041363954544 -> Predictions: [[0.03362253]\n",
            " [0.950861  ]\n",
            " [0.95059305]\n",
            " [0.08795352]]\n",
            "Step: 1249 -> Loss: 0.05654124170541763 -> Predictions: [[0.03350242]\n",
            " [0.95110226]\n",
            " [0.95083547]\n",
            " [0.08747576]]\n",
            "Step: 1250 -> Loss: 0.05625474452972412 -> Predictions: [[0.03338309]\n",
            " [0.9513414 ]\n",
            " [0.95107573]\n",
            " [0.08700246]]\n",
            "Step: 1251 -> Loss: 0.055970922112464905 -> Predictions: [[0.03326449]\n",
            " [0.9515784 ]\n",
            " [0.9513138 ]\n",
            " [0.08653379]]\n",
            "Step: 1252 -> Loss: 0.0556897297501564 -> Predictions: [[0.03314665]\n",
            " [0.9518132 ]\n",
            " [0.95154977]\n",
            " [0.08606956]]\n",
            "Step: 1253 -> Loss: 0.05541113764047623 -> Predictions: [[0.03302953]\n",
            " [0.95204604]\n",
            " [0.95178366]\n",
            " [0.08560979]]\n",
            "Step: 1254 -> Loss: 0.05513510853052139 -> Predictions: [[0.03291319]\n",
            " [0.95227665]\n",
            " [0.95201546]\n",
            " [0.08515419]]\n",
            "Step: 1255 -> Loss: 0.05486159026622772 -> Predictions: [[0.03279754]\n",
            " [0.95250535]\n",
            " [0.95224524]\n",
            " [0.08470301]]\n",
            "Step: 1256 -> Loss: 0.054590579122304916 -> Predictions: [[0.03268262]\n",
            " [0.95273197]\n",
            " [0.95247304]\n",
            " [0.08425607]]\n",
            "Step: 1257 -> Loss: 0.054322026669979095 -> Predictions: [[0.0325684 ]\n",
            " [0.95295656]\n",
            " [0.95269877]\n",
            " [0.08381333]]\n",
            "Step: 1258 -> Loss: 0.05405592545866966 -> Predictions: [[0.03245487]\n",
            " [0.9531792 ]\n",
            " [0.95292246]\n",
            " [0.0833747 ]]\n",
            "Step: 1259 -> Loss: 0.053792182356119156 -> Predictions: [[0.03234209]\n",
            " [0.9534    ]\n",
            " [0.9531443 ]\n",
            " [0.08294005]]\n",
            "Step: 1260 -> Loss: 0.05353085696697235 -> Predictions: [[0.03222999]\n",
            " [0.9536188 ]\n",
            " [0.95336425]\n",
            " [0.08250959]]\n",
            "Step: 1261 -> Loss: 0.05327184498310089 -> Predictions: [[0.03211858]\n",
            " [0.9538358 ]\n",
            " [0.9535823 ]\n",
            " [0.08208302]]\n",
            "Step: 1262 -> Loss: 0.05301513522863388 -> Predictions: [[0.03200782]\n",
            " [0.9540508 ]\n",
            " [0.95379835]\n",
            " [0.08166036]]\n",
            "Step: 1263 -> Loss: 0.05276075750589371 -> Predictions: [[0.03189777]\n",
            " [0.9542639 ]\n",
            " [0.9540127 ]\n",
            " [0.08124167]]\n",
            "Step: 1264 -> Loss: 0.052508577704429626 -> Predictions: [[0.0317884 ]\n",
            " [0.95447534]\n",
            " [0.95422506]\n",
            " [0.08082666]]\n",
            "Step: 1265 -> Loss: 0.05225864797830582 -> Predictions: [[0.03167972]\n",
            " [0.9546849 ]\n",
            " [0.9544357 ]\n",
            " [0.08041549]]\n",
            "Step: 1266 -> Loss: 0.0520109161734581 -> Predictions: [[0.03157171]\n",
            " [0.9548927 ]\n",
            " [0.95464456]\n",
            " [0.08000805]]\n",
            "Step: 1267 -> Loss: 0.05176534503698349 -> Predictions: [[0.03146429]\n",
            " [0.9550987 ]\n",
            " [0.9548517 ]\n",
            " [0.07960432]]\n",
            "Step: 1268 -> Loss: 0.051521942019462585 -> Predictions: [[0.0313576 ]\n",
            " [0.95530295]\n",
            " [0.955057  ]\n",
            " [0.0792042 ]]\n",
            "Step: 1269 -> Loss: 0.05128064751625061 -> Predictions: [[0.03125152]\n",
            " [0.95550555]\n",
            " [0.95526063]\n",
            " [0.07880774]]\n",
            "Step: 1270 -> Loss: 0.051041409373283386 -> Predictions: [[0.03114608]\n",
            " [0.9557064 ]\n",
            " [0.95546246]\n",
            " [0.07841475]]\n",
            "Step: 1271 -> Loss: 0.050804294645786285 -> Predictions: [[0.03104126]\n",
            " [0.9559056 ]\n",
            " [0.95566267]\n",
            " [0.07802534]]\n",
            "Step: 1272 -> Loss: 0.05056916922330856 -> Predictions: [[0.03093708]\n",
            " [0.95610315]\n",
            " [0.9558613 ]\n",
            " [0.07763932]]\n",
            "Step: 1273 -> Loss: 0.0503360778093338 -> Predictions: [[0.03083356]\n",
            " [0.956299  ]\n",
            " [0.95605814]\n",
            " [0.07725673]]\n",
            "Step: 1274 -> Loss: 0.05010499432682991 -> Predictions: [[0.03073068]\n",
            " [0.9564932 ]\n",
            " [0.9562534 ]\n",
            " [0.07687753]]\n",
            "Step: 1275 -> Loss: 0.049875855445861816 -> Predictions: [[0.03062839]\n",
            " [0.95668596]\n",
            " [0.9564472 ]\n",
            " [0.07650169]]\n",
            "Step: 1276 -> Loss: 0.04964865744113922 -> Predictions: [[0.03052672]\n",
            " [0.95687705]\n",
            " [0.9566393 ]\n",
            " [0.07612911]]\n",
            "Step: 1277 -> Loss: 0.049423396587371826 -> Predictions: [[0.03042567]\n",
            " [0.95706654]\n",
            " [0.9568298 ]\n",
            " [0.07575983]]\n",
            "Step: 1278 -> Loss: 0.04920002445578575 -> Predictions: [[0.03032525]\n",
            " [0.9572545 ]\n",
            " [0.95701873]\n",
            " [0.07539374]]\n",
            "Step: 1279 -> Loss: 0.0489785373210907 -> Predictions: [[0.03022536]\n",
            " [0.95744103]\n",
            " [0.95720613]\n",
            " [0.07503083]]\n",
            "Step: 1280 -> Loss: 0.04875890165567398 -> Predictions: [[0.03012611]\n",
            " [0.9576259 ]\n",
            " [0.95739204]\n",
            " [0.07467107]]\n",
            "Step: 1281 -> Loss: 0.04854107275605202 -> Predictions: [[0.03002747]\n",
            " [0.9578093 ]\n",
            " [0.9575766 ]\n",
            " [0.07431433]]\n",
            "Step: 1282 -> Loss: 0.048325080424547195 -> Predictions: [[0.02992939]\n",
            " [0.95799124]\n",
            " [0.9577593 ]\n",
            " [0.0739607 ]]\n",
            "Step: 1283 -> Loss: 0.048110850155353546 -> Predictions: [[0.02983188]\n",
            " [0.9581718 ]\n",
            " [0.9579409 ]\n",
            " [0.07361009]]\n",
            "Step: 1284 -> Loss: 0.047898389399051666 -> Predictions: [[0.02973492]\n",
            " [0.95835084]\n",
            " [0.9581209 ]\n",
            " [0.0732625 ]]\n",
            "Step: 1285 -> Loss: 0.04768773168325424 -> Predictions: [[0.02963859]\n",
            " [0.95852846]\n",
            " [0.9582994 ]\n",
            " [0.07291793]]\n",
            "Step: 1286 -> Loss: 0.04747871309518814 -> Predictions: [[0.02954277]\n",
            " [0.95870465]\n",
            " [0.95847666]\n",
            " [0.07257619]]\n",
            "Step: 1287 -> Loss: 0.047271452844142914 -> Predictions: [[0.02944758]\n",
            " [0.95887953]\n",
            " [0.9586524 ]\n",
            " [0.07223734]]\n",
            "Step: 1288 -> Loss: 0.0470658540725708 -> Predictions: [[0.02935294]\n",
            " [0.959053  ]\n",
            " [0.95882684]\n",
            " [0.07190131]]\n",
            "Step: 1289 -> Loss: 0.04686194658279419 -> Predictions: [[0.02925882]\n",
            " [0.959225  ]\n",
            " [0.9589998 ]\n",
            " [0.07156823]]\n",
            "Step: 1290 -> Loss: 0.046659670770168304 -> Predictions: [[0.02916527]\n",
            " [0.9593957 ]\n",
            " [0.95917153]\n",
            " [0.07123786]]\n",
            "Step: 1291 -> Loss: 0.04645902290940285 -> Predictions: [[0.02907231]\n",
            " [0.95956516]\n",
            " [0.95934176]\n",
            " [0.07091022]]\n",
            "Step: 1292 -> Loss: 0.046259988099336624 -> Predictions: [[0.0289798 ]\n",
            " [0.95973325]\n",
            " [0.95951086]\n",
            " [0.07058538]]\n",
            "Step: 1293 -> Loss: 0.04606255143880844 -> Predictions: [[0.02888788]\n",
            " [0.95989996]\n",
            " [0.9596785 ]\n",
            " [0.07026319]]\n",
            "Step: 1294 -> Loss: 0.04586666077375412 -> Predictions: [[0.02879649]\n",
            " [0.9600654 ]\n",
            " [0.9598448 ]\n",
            " [0.06994355]]\n",
            "Step: 1295 -> Loss: 0.04567235708236694 -> Predictions: [[0.02870564]\n",
            " [0.9602297 ]\n",
            " [0.96001005]\n",
            " [0.0696267 ]]\n",
            "Step: 1296 -> Loss: 0.04547957330942154 -> Predictions: [[0.02861529]\n",
            " [0.96039265]\n",
            " [0.96017385]\n",
            " [0.06931239]]\n",
            "Step: 1297 -> Loss: 0.045288313180208206 -> Predictions: [[0.02852544]\n",
            " [0.9605543 ]\n",
            " [0.96033645]\n",
            " [0.06900064]]\n",
            "Step: 1298 -> Loss: 0.04509853944182396 -> Predictions: [[0.02843613]\n",
            " [0.9607148 ]\n",
            " [0.96049774]\n",
            " [0.0686914 ]]\n",
            "Step: 1299 -> Loss: 0.04491027444601059 -> Predictions: [[0.02834734]\n",
            " [0.960874  ]\n",
            " [0.9606579 ]\n",
            " [0.06838477]]\n",
            "Step: 1300 -> Loss: 0.044723495841026306 -> Predictions: [[0.02825907]\n",
            " [0.9610321 ]\n",
            " [0.9608168 ]\n",
            " [0.0680806 ]]\n",
            "Step: 1301 -> Loss: 0.04453812539577484 -> Predictions: [[0.02817129]\n",
            " [0.9611889 ]\n",
            " [0.9609745 ]\n",
            " [0.0677788 ]]\n",
            "Step: 1302 -> Loss: 0.04435421898961067 -> Predictions: [[0.02808399]\n",
            " [0.96134454]\n",
            " [0.9611311 ]\n",
            " [0.06747949]]\n",
            "Step: 1303 -> Loss: 0.04417172819375992 -> Predictions: [[0.0279972 ]\n",
            " [0.96149904]\n",
            " [0.96128637]\n",
            " [0.06718256]]\n",
            "Step: 1304 -> Loss: 0.043990619480609894 -> Predictions: [[0.0279109 ]\n",
            " [0.96165246]\n",
            " [0.9614406 ]\n",
            " [0.06688802]]\n",
            "Step: 1305 -> Loss: 0.04381093382835388 -> Predictions: [[0.02782511]\n",
            " [0.9618046 ]\n",
            " [0.96159375]\n",
            " [0.06659577]]\n",
            "Step: 1306 -> Loss: 0.04363260418176651 -> Predictions: [[0.02773981]\n",
            " [0.9619557 ]\n",
            " [0.9617456 ]\n",
            " [0.0663059 ]]\n",
            "Step: 1307 -> Loss: 0.04345564916729927 -> Predictions: [[0.02765493]\n",
            " [0.9621056 ]\n",
            " [0.9618964 ]\n",
            " [0.06601834]]\n",
            "Step: 1308 -> Loss: 0.04328002780675888 -> Predictions: [[0.02757057]\n",
            " [0.96225446]\n",
            " [0.9620461 ]\n",
            " [0.06573305]]\n",
            "Step: 1309 -> Loss: 0.04310574382543564 -> Predictions: [[0.02748672]\n",
            " [0.96240216]\n",
            " [0.9621946 ]\n",
            " [0.06544994]]\n",
            "Step: 1310 -> Loss: 0.04293275624513626 -> Predictions: [[0.0274033 ]\n",
            " [0.9625488 ]\n",
            " [0.9623421 ]\n",
            " [0.06516904]]\n",
            "Step: 1311 -> Loss: 0.042761076241731644 -> Predictions: [[0.02732034]\n",
            " [0.9626945 ]\n",
            " [0.9624886 ]\n",
            " [0.06489037]]\n",
            "Step: 1312 -> Loss: 0.04259071126580238 -> Predictions: [[0.02723791]\n",
            " [0.96283895]\n",
            " [0.96263385]\n",
            " [0.06461388]]\n",
            "Step: 1313 -> Loss: 0.04242159426212311 -> Predictions: [[0.02715585]\n",
            " [0.9629824 ]\n",
            " [0.96277815]\n",
            " [0.06433951]]\n",
            "Step: 1314 -> Loss: 0.042253755033016205 -> Predictions: [[0.02707428]\n",
            " [0.96312493]\n",
            " [0.9629214 ]\n",
            " [0.06406735]]\n",
            "Step: 1315 -> Loss: 0.04208715260028839 -> Predictions: [[0.02699315]\n",
            " [0.96326625]\n",
            " [0.96306354]\n",
            " [0.06379717]]\n",
            "Step: 1316 -> Loss: 0.04192177578806877 -> Predictions: [[0.02691253]\n",
            " [0.9634066 ]\n",
            " [0.96320474]\n",
            " [0.06352911]]\n",
            "Step: 1317 -> Loss: 0.04175763577222824 -> Predictions: [[0.02683228]\n",
            " [0.963546  ]\n",
            " [0.96334493]\n",
            " [0.06326313]]\n",
            "Step: 1318 -> Loss: 0.04159471020102501 -> Predictions: [[0.02675253]\n",
            " [0.9636843 ]\n",
            " [0.9634841 ]\n",
            " [0.06299916]]\n",
            "Step: 1319 -> Loss: 0.04143296927213669 -> Predictions: [[0.02667321]\n",
            " [0.9638217 ]\n",
            " [0.9636222 ]\n",
            " [0.06273722]]\n",
            "Step: 1320 -> Loss: 0.041272394359111786 -> Predictions: [[0.02659428]\n",
            " [0.9639581 ]\n",
            " [0.96375936]\n",
            " [0.06247727]]\n",
            "Step: 1321 -> Loss: 0.041113000363111496 -> Predictions: [[0.02651582]\n",
            " [0.96409357]\n",
            " [0.9638956 ]\n",
            " [0.06221925]]\n",
            "Step: 1322 -> Loss: 0.040954768657684326 -> Predictions: [[0.02643778]\n",
            " [0.964228  ]\n",
            " [0.96403086]\n",
            " [0.06196319]]\n",
            "Step: 1323 -> Loss: 0.04079767316579819 -> Predictions: [[0.02636016]\n",
            " [0.96436155]\n",
            " [0.9641653 ]\n",
            " [0.06170909]]\n",
            "Step: 1324 -> Loss: 0.04064171761274338 -> Predictions: [[0.02628301]\n",
            " [0.96449417]\n",
            " [0.9642986 ]\n",
            " [0.06145689]]\n",
            "Step: 1325 -> Loss: 0.040486887097358704 -> Predictions: [[0.02620625]\n",
            " [0.96462584]\n",
            " [0.964431  ]\n",
            " [0.06120657]]\n",
            "Step: 1326 -> Loss: 0.040333159267902374 -> Predictions: [[0.02612991]\n",
            " [0.9647565 ]\n",
            " [0.9645625 ]\n",
            " [0.06095807]]\n",
            "Step: 1327 -> Loss: 0.0401805117726326 -> Predictions: [[0.02605395]\n",
            " [0.9648864 ]\n",
            " [0.96469307]\n",
            " [0.06071143]]\n",
            "Step: 1328 -> Loss: 0.04002898931503296 -> Predictions: [[0.02597845]\n",
            " [0.96501535]\n",
            " [0.96482277]\n",
            " [0.06046664]]\n",
            "Step: 1329 -> Loss: 0.03987852483987808 -> Predictions: [[0.02590331]\n",
            " [0.9651433 ]\n",
            " [0.96495163]\n",
            " [0.06022368]]\n",
            "Step: 1330 -> Loss: 0.03972914069890976 -> Predictions: [[0.0258286 ]\n",
            " [0.9652705 ]\n",
            " [0.96507937]\n",
            " [0.05998252]]\n",
            "Step: 1331 -> Loss: 0.03958078846335411 -> Predictions: [[0.02575427]\n",
            " [0.9653968 ]\n",
            " [0.9652065 ]\n",
            " [0.05974314]]\n",
            "Step: 1332 -> Loss: 0.03943347930908203 -> Predictions: [[0.02568036]\n",
            " [0.9655222 ]\n",
            " [0.96533257]\n",
            " [0.05950544]]\n",
            "Step: 1333 -> Loss: 0.03928723931312561 -> Predictions: [[0.02560688]\n",
            " [0.96564686]\n",
            " [0.9654579 ]\n",
            " [0.05926954]]\n",
            "Step: 1334 -> Loss: 0.03914198651909828 -> Predictions: [[0.02553373]\n",
            " [0.9657706 ]\n",
            " [0.9655824 ]\n",
            " [0.05903532]]\n",
            "Step: 1335 -> Loss: 0.03899774327874184 -> Predictions: [[0.02546101]\n",
            " [0.9658933 ]\n",
            " [0.965706  ]\n",
            " [0.05880275]]\n",
            "Step: 1336 -> Loss: 0.03885452449321747 -> Predictions: [[0.02538868]\n",
            " [0.96601546]\n",
            " [0.9658287 ]\n",
            " [0.05857193]]\n",
            "Step: 1337 -> Loss: 0.03871229663491249 -> Predictions: [[0.02531669]\n",
            " [0.96613663]\n",
            " [0.9659506 ]\n",
            " [0.05834276]]\n",
            "Step: 1338 -> Loss: 0.03857104852795601 -> Predictions: [[0.02524511]\n",
            " [0.96625704]\n",
            " [0.96607167]\n",
            " [0.05811527]]\n",
            "Step: 1339 -> Loss: 0.03843078389763832 -> Predictions: [[0.02517391]\n",
            " [0.9663767 ]\n",
            " [0.96619195]\n",
            " [0.05788941]]\n",
            "Step: 1340 -> Loss: 0.038291461765766144 -> Predictions: [[0.02510308]\n",
            " [0.9664954 ]\n",
            " [0.9663115 ]\n",
            " [0.05766513]]\n",
            "Step: 1341 -> Loss: 0.03815309703350067 -> Predictions: [[0.02503265]\n",
            " [0.9666135 ]\n",
            " [0.9664302 ]\n",
            " [0.05744241]]\n",
            "Step: 1342 -> Loss: 0.038015685975551605 -> Predictions: [[0.02496255]\n",
            " [0.96673065]\n",
            " [0.9665481 ]\n",
            " [0.05722131]]\n",
            "Step: 1343 -> Loss: 0.03787922114133835 -> Predictions: [[0.02489285]\n",
            " [0.96684706]\n",
            " [0.96666515]\n",
            " [0.05700182]]\n",
            "Step: 1344 -> Loss: 0.03774363547563553 -> Predictions: [[0.02482346]\n",
            " [0.96696275]\n",
            " [0.96678156]\n",
            " [0.05678383]]\n",
            "Step: 1345 -> Loss: 0.03760901838541031 -> Predictions: [[0.02475448]\n",
            " [0.96707773]\n",
            " [0.96689713]\n",
            " [0.05656739]]\n",
            "Step: 1346 -> Loss: 0.037475284188985825 -> Predictions: [[0.02468582]\n",
            " [0.96719176]\n",
            " [0.9670119 ]\n",
            " [0.05635247]]\n",
            "Step: 1347 -> Loss: 0.03734246641397476 -> Predictions: [[0.02461756]\n",
            " [0.9673052 ]\n",
            " [0.96712595]\n",
            " [0.05613905]]\n",
            "Step: 1348 -> Loss: 0.037210505455732346 -> Predictions: [[0.02454964]\n",
            " [0.96741784]\n",
            " [0.96723926]\n",
            " [0.05592708]]\n",
            "Step: 1349 -> Loss: 0.037079472094774246 -> Predictions: [[0.02448207]\n",
            " [0.96752965]\n",
            " [0.9673518 ]\n",
            " [0.05571666]]\n",
            "Step: 1350 -> Loss: 0.0369492769241333 -> Predictions: [[0.02441482]\n",
            " [0.96764094]\n",
            " [0.96746373]\n",
            " [0.05550764]]\n",
            "Step: 1351 -> Loss: 0.036819957196712494 -> Predictions: [[0.02434794]\n",
            " [0.9677513 ]\n",
            " [0.9675748 ]\n",
            " [0.05530006]]\n",
            "Step: 1352 -> Loss: 0.036691486835479736 -> Predictions: [[0.02428139]\n",
            " [0.9678611 ]\n",
            " [0.9676853 ]\n",
            " [0.05509394]]\n",
            "Step: 1353 -> Loss: 0.03656386584043503 -> Predictions: [[0.0242152 ]\n",
            " [0.9679702 ]\n",
            " [0.9677949 ]\n",
            " [0.05488922]]\n",
            "Step: 1354 -> Loss: 0.03643708676099777 -> Predictions: [[0.02414937]\n",
            " [0.96807843]\n",
            " [0.96790385]\n",
            " [0.05468591]]\n",
            "Step: 1355 -> Loss: 0.03631114214658737 -> Predictions: [[0.02408384]\n",
            " [0.9681862 ]\n",
            " [0.9680122 ]\n",
            " [0.054484  ]]\n",
            "Step: 1356 -> Loss: 0.03618604317307472 -> Predictions: [[0.02401866]\n",
            " [0.96829313]\n",
            " [0.9681198 ]\n",
            " [0.05428354]]\n",
            "Step: 1357 -> Loss: 0.036061741411685944 -> Predictions: [[0.02395382]\n",
            " [0.9683994 ]\n",
            " [0.96822673]\n",
            " [0.05408435]]\n",
            "Step: 1358 -> Loss: 0.03593824803829193 -> Predictions: [[0.02388929]\n",
            " [0.96850497]\n",
            " [0.9683329 ]\n",
            " [0.05388651]]\n",
            "Step: 1359 -> Loss: 0.03581554815173149 -> Predictions: [[0.02382507]\n",
            " [0.96860987]\n",
            " [0.96843845]\n",
            " [0.05369001]]\n",
            "Step: 1360 -> Loss: 0.03569364175200462 -> Predictions: [[0.02376121]\n",
            " [0.96871424]\n",
            " [0.9685434 ]\n",
            " [0.0534949 ]]\n",
            "Step: 1361 -> Loss: 0.03557254374027252 -> Predictions: [[0.02369766]\n",
            " [0.96881783]\n",
            " [0.96864766]\n",
            " [0.05330106]]\n",
            "Step: 1362 -> Loss: 0.035452187061309814 -> Predictions: [[0.02363442]\n",
            " [0.96892077]\n",
            " [0.96875125]\n",
            " [0.05310848]]\n",
            "Step: 1363 -> Loss: 0.035332657396793365 -> Predictions: [[0.02357154]\n",
            " [0.9690231 ]\n",
            " [0.9688542 ]\n",
            " [0.05291728]]\n",
            "Step: 1364 -> Loss: 0.03521384298801422 -> Predictions: [[0.02350892]\n",
            " [0.96912485]\n",
            " [0.9689565 ]\n",
            " [0.05272724]]\n",
            "Step: 1365 -> Loss: 0.035095810890197754 -> Predictions: [[0.02344666]\n",
            " [0.9692258 ]\n",
            " [0.9690581 ]\n",
            " [0.05253855]]\n",
            "Step: 1366 -> Loss: 0.034978531301021576 -> Predictions: [[0.02338469]\n",
            " [0.9693263 ]\n",
            " [0.9691591 ]\n",
            " [0.05235111]]\n",
            "Step: 1367 -> Loss: 0.03486198931932449 -> Predictions: [[0.023323  ]\n",
            " [0.9694261 ]\n",
            " [0.96925956]\n",
            " [0.0521649 ]]\n",
            "Step: 1368 -> Loss: 0.03474617749452591 -> Predictions: [[0.02326166]\n",
            " [0.9695253 ]\n",
            " [0.9693592 ]\n",
            " [0.05197985]]\n",
            "Step: 1369 -> Loss: 0.034631118178367615 -> Predictions: [[0.02320061]\n",
            " [0.9696238 ]\n",
            " [0.9694584 ]\n",
            " [0.0517961 ]]\n",
            "Step: 1370 -> Loss: 0.03451674431562424 -> Predictions: [[0.02313986]\n",
            " [0.96972185]\n",
            " [0.969557  ]\n",
            " [0.05161348]]\n",
            "Step: 1371 -> Loss: 0.034403108060359955 -> Predictions: [[0.02307942]\n",
            " [0.9698192 ]\n",
            " [0.96965504]\n",
            " [0.05143212]]\n",
            "Step: 1372 -> Loss: 0.03429018333554268 -> Predictions: [[0.02301924]\n",
            " [0.9699159 ]\n",
            " [0.9697524 ]\n",
            " [0.05125187]]\n",
            "Step: 1373 -> Loss: 0.03417796641588211 -> Predictions: [[0.02295939]\n",
            " [0.97001207]\n",
            " [0.9698491 ]\n",
            " [0.05107286]]\n",
            "Step: 1374 -> Loss: 0.03406643122434616 -> Predictions: [[0.0228998 ]\n",
            " [0.9701076 ]\n",
            " [0.9699452 ]\n",
            " [0.05089494]]\n",
            "Step: 1375 -> Loss: 0.033955611288547516 -> Predictions: [[0.02284056]\n",
            " [0.9702027 ]\n",
            " [0.9700408 ]\n",
            " [0.05071826]]\n",
            "Step: 1376 -> Loss: 0.033845432102680206 -> Predictions: [[0.02278154]\n",
            " [0.97029716]\n",
            " [0.9701359 ]\n",
            " [0.05054264]]\n",
            "Step: 1377 -> Loss: 0.033735986799001694 -> Predictions: [[0.02272288]\n",
            " [0.9703911 ]\n",
            " [0.9702303 ]\n",
            " [0.05036822]]\n",
            "Step: 1378 -> Loss: 0.03362718224525452 -> Predictions: [[0.02266446]\n",
            " [0.97048426]\n",
            " [0.9703242 ]\n",
            " [0.05019484]]\n",
            "Step: 1379 -> Loss: 0.03351905196905136 -> Predictions: [[0.02260634]\n",
            " [0.9705771 ]\n",
            " [0.9704175 ]\n",
            " [0.05002264]]\n",
            "Step: 1380 -> Loss: 0.03341158851981163 -> Predictions: [[0.02254849]\n",
            " [0.9706693 ]\n",
            " [0.97051024]\n",
            " [0.04985149]]\n",
            "Step: 1381 -> Loss: 0.03330479934811592 -> Predictions: [[0.02249094]\n",
            " [0.9707609 ]\n",
            " [0.9706024 ]\n",
            " [0.04968149]]\n",
            "Step: 1382 -> Loss: 0.03319861739873886 -> Predictions: [[0.02243363]\n",
            " [0.970852  ]\n",
            " [0.97069407]\n",
            " [0.04951254]]\n",
            "Step: 1383 -> Loss: 0.033093106001615524 -> Predictions: [[0.02237665]\n",
            " [0.97094256]\n",
            " [0.97078514]\n",
            " [0.04934459]]\n",
            "Step: 1384 -> Loss: 0.03298822045326233 -> Predictions: [[0.02231987]\n",
            " [0.9710326 ]\n",
            " [0.97087574]\n",
            " [0.04917778]]\n",
            "Step: 1385 -> Loss: 0.03288396820425987 -> Predictions: [[0.02226344]\n",
            " [0.9711221 ]\n",
            " [0.97096586]\n",
            " [0.04901196]]\n",
            "Step: 1386 -> Loss: 0.03278034180402756 -> Predictions: [[0.02220723]\n",
            " [0.971211  ]\n",
            " [0.9710553 ]\n",
            " [0.04884721]]\n",
            "Step: 1387 -> Loss: 0.03267733007669449 -> Predictions: [[0.02215132]\n",
            " [0.9712995 ]\n",
            " [0.9711444 ]\n",
            " [0.04868344]]\n",
            "Step: 1388 -> Loss: 0.032574962824583054 -> Predictions: [[0.02209565]\n",
            " [0.9713875 ]\n",
            " [0.9712327 ]\n",
            " [0.04852078]]\n",
            "Step: 1389 -> Loss: 0.032473184168338776 -> Predictions: [[0.02204026]\n",
            " [0.9714749 ]\n",
            " [0.9713207 ]\n",
            " [0.04835906]]\n",
            "Step: 1390 -> Loss: 0.03237202763557434 -> Predictions: [[0.02198516]\n",
            " [0.97156173]\n",
            " [0.9714082 ]\n",
            " [0.04819842]]\n",
            "Step: 1391 -> Loss: 0.03227144852280617 -> Predictions: [[0.02193029]\n",
            " [0.97164816]\n",
            " [0.97149503]\n",
            " [0.04803869]]\n",
            "Step: 1392 -> Loss: 0.032171476632356644 -> Predictions: [[0.02187569]\n",
            " [0.97173405]\n",
            " [0.9715816 ]\n",
            " [0.04788002]]\n",
            "Step: 1393 -> Loss: 0.032072100788354874 -> Predictions: [[0.02182136]\n",
            " [0.9718195 ]\n",
            " [0.9716674 ]\n",
            " [0.04772231]]\n",
            "Step: 1394 -> Loss: 0.031973302364349365 -> Predictions: [[0.02176726]\n",
            " [0.9719044 ]\n",
            " [0.9717529 ]\n",
            " [0.04756551]]\n",
            "Step: 1395 -> Loss: 0.03187507390975952 -> Predictions: [[0.02171344]\n",
            " [0.97198886]\n",
            " [0.97183776]\n",
            " [0.04740963]]\n",
            "Step: 1396 -> Loss: 0.03177743777632713 -> Predictions: [[0.02165984]\n",
            " [0.9720728 ]\n",
            " [0.97192234]\n",
            " [0.04725486]]\n",
            "Step: 1397 -> Loss: 0.031680356711149216 -> Predictions: [[0.02160653]\n",
            " [0.9721562 ]\n",
            " [0.9720062 ]\n",
            " [0.04710091]]\n",
            "Step: 1398 -> Loss: 0.03158384561538696 -> Predictions: [[0.02155344]\n",
            " [0.9722392 ]\n",
            " [0.97208965]\n",
            " [0.0469479 ]]\n",
            "Step: 1399 -> Loss: 0.03148788958787918 -> Predictions: [[0.02150059]\n",
            " [0.9723218 ]\n",
            " [0.9721727 ]\n",
            " [0.04679583]]\n",
            "Step: 1400 -> Loss: 0.031392503529787064 -> Predictions: [[0.02144802]\n",
            " [0.9724038 ]\n",
            " [0.9722553 ]\n",
            " [0.04664472]]\n",
            "Step: 1401 -> Loss: 0.03129767253994942 -> Predictions: [[0.02139569]\n",
            " [0.9724855 ]\n",
            " [0.97233737]\n",
            " [0.04649454]]\n",
            "Step: 1402 -> Loss: 0.03120335564017296 -> Predictions: [[0.02134358]\n",
            " [0.97256655]\n",
            " [0.97241896]\n",
            " [0.04634513]]\n",
            "Step: 1403 -> Loss: 0.031109601259231567 -> Predictions: [[0.02129171]\n",
            " [0.97264713]\n",
            " [0.9725001 ]\n",
            " [0.04619674]]\n",
            "Step: 1404 -> Loss: 0.031016387045383453 -> Predictions: [[0.02124011]\n",
            " [0.97272736]\n",
            " [0.97258085]\n",
            " [0.04604917]]\n",
            "Step: 1405 -> Loss: 0.030923711135983467 -> Predictions: [[0.02118872]\n",
            " [0.9728072 ]\n",
            " [0.97266114]\n",
            " [0.04590254]]\n",
            "Step: 1406 -> Loss: 0.030831562355160713 -> Predictions: [[0.02113759]\n",
            " [0.9728865 ]\n",
            " [0.9727409 ]\n",
            " [0.04575677]]\n",
            "Step: 1407 -> Loss: 0.0307399183511734 -> Predictions: [[0.02108666]\n",
            " [0.9729654 ]\n",
            " [0.9728203 ]\n",
            " [0.04561184]]\n",
            "Step: 1408 -> Loss: 0.030648808926343918 -> Predictions: [[0.02103598]\n",
            " [0.97304386]\n",
            " [0.97289914]\n",
            " [0.04546779]]\n",
            "Step: 1409 -> Loss: 0.03055821731686592 -> Predictions: [[0.02098556]\n",
            " [0.9731218 ]\n",
            " [0.9729777 ]\n",
            " [0.04532453]]\n",
            "Step: 1410 -> Loss: 0.030468132346868515 -> Predictions: [[0.02093531]\n",
            " [0.97319937]\n",
            " [0.97305566]\n",
            " [0.04518218]]\n",
            "Step: 1411 -> Loss: 0.0303785540163517 -> Predictions: [[0.02088533]\n",
            " [0.9732765 ]\n",
            " [0.9731333 ]\n",
            " [0.04504062]]\n",
            "Step: 1412 -> Loss: 0.030289489775896072 -> Predictions: [[0.02083558]\n",
            " [0.9733532 ]\n",
            " [0.9732106 ]\n",
            " [0.04489997]]\n",
            "Step: 1413 -> Loss: 0.030200902372598648 -> Predictions: [[0.02078605]\n",
            " [0.97342956]\n",
            " [0.97328734]\n",
            " [0.04476003]]\n",
            "Step: 1414 -> Loss: 0.030112821608781815 -> Predictions: [[0.02073676]\n",
            " [0.97350544]\n",
            " [0.9733636 ]\n",
            " [0.04462095]]\n",
            "Step: 1415 -> Loss: 0.030025245621800423 -> Predictions: [[0.02068767]\n",
            " [0.97358096]\n",
            " [0.9734396 ]\n",
            " [0.04448272]]\n",
            "Step: 1416 -> Loss: 0.02993812784552574 -> Predictions: [[0.02063878]\n",
            " [0.973656  ]\n",
            " [0.9735151 ]\n",
            " [0.04434524]]\n",
            "Step: 1417 -> Loss: 0.029851507395505905 -> Predictions: [[0.02059014]\n",
            " [0.97373056]\n",
            " [0.9735902 ]\n",
            " [0.04420857]]\n",
            "Step: 1418 -> Loss: 0.029765356332063675 -> Predictions: [[0.02054172]\n",
            " [0.97380483]\n",
            " [0.9736649 ]\n",
            " [0.04407268]]\n",
            "Step: 1419 -> Loss: 0.029679711908102036 -> Predictions: [[0.02049355]\n",
            " [0.9738787 ]\n",
            " [0.97373915]\n",
            " [0.04393761]]\n",
            "Step: 1420 -> Loss: 0.029594507068395615 -> Predictions: [[0.02044552]\n",
            " [0.9739522 ]\n",
            " [0.97381306]\n",
            " [0.04380331]]\n",
            "Step: 1421 -> Loss: 0.0295097678899765 -> Predictions: [[0.02039776]\n",
            " [0.9740252 ]\n",
            " [0.97388655]\n",
            " [0.04366971]]\n",
            "Step: 1422 -> Loss: 0.029425492510199547 -> Predictions: [[0.02035014]\n",
            " [0.9740979 ]\n",
            " [0.97395974]\n",
            " [0.04353694]]\n",
            "Step: 1423 -> Loss: 0.02934170886874199 -> Predictions: [[0.02030281]\n",
            " [0.9741701 ]\n",
            " [0.97403246]\n",
            " [0.04340494]]\n",
            "Step: 1424 -> Loss: 0.029258359223604202 -> Predictions: [[0.02025568]\n",
            " [0.9742421 ]\n",
            " [0.9741047 ]\n",
            " [0.04327362]]\n",
            "Step: 1425 -> Loss: 0.02917545661330223 -> Predictions: [[0.02020874]\n",
            " [0.97431356]\n",
            " [0.97417665]\n",
            " [0.04314308]]\n",
            "Step: 1426 -> Loss: 0.029093028977513313 -> Predictions: [[0.02016201]\n",
            " [0.97438467]\n",
            " [0.9742483 ]\n",
            " [0.04301333]]\n",
            "Step: 1427 -> Loss: 0.02901102602481842 -> Predictions: [[0.02011547]\n",
            " [0.9744554 ]\n",
            " [0.97431934]\n",
            " [0.04288423]]\n",
            "Step: 1428 -> Loss: 0.028929468244314194 -> Predictions: [[0.02006915]\n",
            " [0.9745258 ]\n",
            " [0.9743902 ]\n",
            " [0.04275592]]\n",
            "Step: 1429 -> Loss: 0.02884834259748459 -> Predictions: [[0.02002303]\n",
            " [0.9745958 ]\n",
            " [0.9744606 ]\n",
            " [0.04262828]]\n",
            "Step: 1430 -> Loss: 0.028767671436071396 -> Predictions: [[0.01997714]\n",
            " [0.9746654 ]\n",
            " [0.9745307 ]\n",
            " [0.04250139]]\n",
            "Step: 1431 -> Loss: 0.02868742123246193 -> Predictions: [[0.01993146]\n",
            " [0.9747347 ]\n",
            " [0.97460043]\n",
            " [0.0423752 ]]\n",
            "Step: 1432 -> Loss: 0.02860759012401104 -> Predictions: [[0.01988592]\n",
            " [0.97480357]\n",
            " [0.9746697 ]\n",
            " [0.04224971]]\n",
            "Step: 1433 -> Loss: 0.02852819859981537 -> Predictions: [[0.01984062]\n",
            " [0.9748721 ]\n",
            " [0.9747387 ]\n",
            " [0.04212493]]\n",
            "Step: 1434 -> Loss: 0.02844921499490738 -> Predictions: [[0.01979551]\n",
            " [0.97494036]\n",
            " [0.9748073 ]\n",
            " [0.0420008 ]]\n",
            "Step: 1435 -> Loss: 0.028370656073093414 -> Predictions: [[0.01975058]\n",
            " [0.9750082 ]\n",
            " [0.9748755 ]\n",
            " [0.0418774 ]]\n",
            "Step: 1436 -> Loss: 0.028292519971728325 -> Predictions: [[0.01970585]\n",
            " [0.97507566]\n",
            " [0.9749435 ]\n",
            " [0.04175466]]\n",
            "Step: 1437 -> Loss: 0.02821478247642517 -> Predictions: [[0.01966133]\n",
            " [0.9751428 ]\n",
            " [0.97501105]\n",
            " [0.04163257]]\n",
            "Step: 1438 -> Loss: 0.02813744731247425 -> Predictions: [[0.01961701]\n",
            " [0.97520953]\n",
            " [0.9750783 ]\n",
            " [0.04151116]]\n",
            "Step: 1439 -> Loss: 0.028060533106327057 -> Predictions: [[0.01957286]\n",
            " [0.975276  ]\n",
            " [0.97514504]\n",
            " [0.04139042]]\n",
            "Step: 1440 -> Loss: 0.027984021231532097 -> Predictions: [[0.0195289 ]\n",
            " [0.9753421 ]\n",
            " [0.97521156]\n",
            " [0.04127037]]\n",
            "Step: 1441 -> Loss: 0.027907904237508774 -> Predictions: [[0.01948515]\n",
            " [0.97540784]\n",
            " [0.9752778 ]\n",
            " [0.04115092]]\n",
            "Step: 1442 -> Loss: 0.027832187712192535 -> Predictions: [[0.01944157]\n",
            " [0.9754733 ]\n",
            " [0.9753435 ]\n",
            " [0.04103217]]\n",
            "Step: 1443 -> Loss: 0.02775687165558338 -> Predictions: [[0.01939818]\n",
            " [0.97553843]\n",
            " [0.9754091 ]\n",
            " [0.04091406]]\n",
            "Step: 1444 -> Loss: 0.027681924402713776 -> Predictions: [[0.01935497]\n",
            " [0.9756032 ]\n",
            " [0.9754742 ]\n",
            " [0.04079654]]\n",
            "Step: 1445 -> Loss: 0.02760738879442215 -> Predictions: [[0.01931192]\n",
            " [0.97566754]\n",
            " [0.9755391 ]\n",
            " [0.0406797 ]]\n",
            "Step: 1446 -> Loss: 0.02753322198987007 -> Predictions: [[0.0192691 ]\n",
            " [0.9757317 ]\n",
            " [0.9756035 ]\n",
            " [0.04056348]]\n",
            "Step: 1447 -> Loss: 0.02745944634079933 -> Predictions: [[0.01922646]\n",
            " [0.97579545]\n",
            " [0.9756678 ]\n",
            " [0.04044786]]\n",
            "Step: 1448 -> Loss: 0.027386046946048737 -> Predictions: [[0.01918396]\n",
            " [0.9758589 ]\n",
            " [0.97573155]\n",
            " [0.04033289]]\n",
            "Step: 1449 -> Loss: 0.027313027530908585 -> Predictions: [[0.01914167]\n",
            " [0.97592205]\n",
            " [0.9757951 ]\n",
            " [0.04021852]]\n",
            "Step: 1450 -> Loss: 0.027240373194217682 -> Predictions: [[0.01909953]\n",
            " [0.97598493]\n",
            " [0.97585833]\n",
            " [0.0401048 ]]\n",
            "Step: 1451 -> Loss: 0.027168093249201775 -> Predictions: [[0.01905761]\n",
            " [0.9760474 ]\n",
            " [0.9759212 ]\n",
            " [0.03999165]]\n",
            "Step: 1452 -> Loss: 0.027096189558506012 -> Predictions: [[0.01901583]\n",
            " [0.9761096 ]\n",
            " [0.9759838 ]\n",
            " [0.03987911]]\n",
            "Step: 1453 -> Loss: 0.027024628594517708 -> Predictions: [[0.01897424]\n",
            " [0.97617155]\n",
            " [0.976046  ]\n",
            " [0.03976714]]\n",
            "Step: 1454 -> Loss: 0.026953455060720444 -> Predictions: [[0.01893284]\n",
            " [0.9762331 ]\n",
            " [0.976108  ]\n",
            " [0.03965578]]\n",
            "Step: 1455 -> Loss: 0.026882633566856384 -> Predictions: [[0.01889161]\n",
            " [0.97629434]\n",
            " [0.9761697 ]\n",
            " [0.03954503]]\n",
            "Step: 1456 -> Loss: 0.026812171563506126 -> Predictions: [[0.01885051]\n",
            " [0.9763554 ]\n",
            " [0.97623104]\n",
            " [0.03943488]]\n",
            "Step: 1457 -> Loss: 0.02674204856157303 -> Predictions: [[0.01880964]\n",
            " [0.97641593]\n",
            " [0.9762921 ]\n",
            " [0.0393252 ]]\n",
            "Step: 1458 -> Loss: 0.026672296226024628 -> Predictions: [[0.01876893]\n",
            " [0.9764764 ]\n",
            " [0.9763529 ]\n",
            " [0.0392162 ]]\n",
            "Step: 1459 -> Loss: 0.026602884754538536 -> Predictions: [[0.01872837]\n",
            " [0.9765364 ]\n",
            " [0.9764133 ]\n",
            " [0.03910776]]\n",
            "Step: 1460 -> Loss: 0.026533804833889008 -> Predictions: [[0.01868794]\n",
            " [0.97659624]\n",
            " [0.97647345]\n",
            " [0.03899981]]\n",
            "Step: 1461 -> Loss: 0.026465080678462982 -> Predictions: [[0.01864773]\n",
            " [0.97665566]\n",
            " [0.97653323]\n",
            " [0.03889247]]\n",
            "Step: 1462 -> Loss: 0.02639671042561531 -> Predictions: [[0.01860769]\n",
            " [0.9767149 ]\n",
            " [0.9765928 ]\n",
            " [0.03878571]]\n",
            "Step: 1463 -> Loss: 0.0263286754488945 -> Predictions: [[0.0185678 ]\n",
            " [0.97677386]\n",
            " [0.976652  ]\n",
            " [0.03867949]]\n",
            "Step: 1464 -> Loss: 0.02626096084713936 -> Predictions: [[0.01852807]\n",
            " [0.97683245]\n",
            " [0.9767111 ]\n",
            " [0.03857379]]\n",
            "Step: 1465 -> Loss: 0.02619360201060772 -> Predictions: [[0.0184885 ]\n",
            " [0.9768908 ]\n",
            " [0.97676975]\n",
            " [0.03846866]]\n",
            "Step: 1466 -> Loss: 0.026126552373170853 -> Predictions: [[0.0184491 ]\n",
            " [0.9769488 ]\n",
            " [0.9768282 ]\n",
            " [0.03836406]]\n",
            "Step: 1467 -> Loss: 0.026059839874505997 -> Predictions: [[0.01840986]\n",
            " [0.9770066 ]\n",
            " [0.97688633]\n",
            " [0.03825999]]\n",
            "Step: 1468 -> Loss: 0.025993451476097107 -> Predictions: [[0.01837078]\n",
            " [0.9770642 ]\n",
            " [0.97694427]\n",
            " [0.03815646]]\n",
            "Step: 1469 -> Loss: 0.025927390903234482 -> Predictions: [[0.01833185]\n",
            " [0.9771213 ]\n",
            " [0.97700185]\n",
            " [0.03805345]]\n",
            "Step: 1470 -> Loss: 0.025861673057079315 -> Predictions: [[0.01829309]\n",
            " [0.9771782 ]\n",
            " [0.97705907]\n",
            " [0.03795099]]\n",
            "Step: 1471 -> Loss: 0.02579626441001892 -> Predictions: [[0.01825449]\n",
            " [0.9772349 ]\n",
            " [0.9771161 ]\n",
            " [0.03784906]]\n",
            "Step: 1472 -> Loss: 0.025731170549988747 -> Predictions: [[0.01821603]\n",
            " [0.9772914 ]\n",
            " [0.97717285]\n",
            " [0.03774765]]\n",
            "Step: 1473 -> Loss: 0.025666389614343643 -> Predictions: [[0.01817775]\n",
            " [0.97734755]\n",
            " [0.97722936]\n",
            " [0.03764672]]\n",
            "Step: 1474 -> Loss: 0.025601912289857864 -> Predictions: [[0.0181396 ]\n",
            " [0.97740346]\n",
            " [0.97728556]\n",
            " [0.03754631]]\n",
            "Step: 1475 -> Loss: 0.025537759065628052 -> Predictions: [[0.01810163]\n",
            " [0.977459  ]\n",
            " [0.9773415 ]\n",
            " [0.03744638]]\n",
            "Step: 1476 -> Loss: 0.02547392249107361 -> Predictions: [[0.01806379]\n",
            " [0.9775144 ]\n",
            " [0.97739714]\n",
            " [0.037347  ]]\n",
            "Step: 1477 -> Loss: 0.025410383939743042 -> Predictions: [[0.01802613]\n",
            " [0.9775694 ]\n",
            " [0.97745264]\n",
            " [0.03724808]]\n",
            "Step: 1478 -> Loss: 0.025347141548991203 -> Predictions: [[0.01798858]\n",
            " [0.9776242 ]\n",
            " [0.97750777]\n",
            " [0.03714968]]\n",
            "Step: 1479 -> Loss: 0.025284212082624435 -> Predictions: [[0.01795121]\n",
            " [0.9776788 ]\n",
            " [0.97756267]\n",
            " [0.03705174]]\n",
            "Step: 1480 -> Loss: 0.0252215638756752 -> Predictions: [[0.01791397]\n",
            " [0.97773314]\n",
            " [0.9776174 ]\n",
            " [0.03695427]]\n",
            "Step: 1481 -> Loss: 0.025159241631627083 -> Predictions: [[0.01787691]\n",
            " [0.97778714]\n",
            " [0.9776717 ]\n",
            " [0.03685735]]\n",
            "Step: 1482 -> Loss: 0.0250971969217062 -> Predictions: [[0.01783998]\n",
            " [0.97784096]\n",
            " [0.9777258 ]\n",
            " [0.03676084]]\n",
            "Step: 1483 -> Loss: 0.025035448372364044 -> Predictions: [[0.01780318]\n",
            " [0.97789454]\n",
            " [0.97777975]\n",
            " [0.03666484]]\n",
            "Step: 1484 -> Loss: 0.024973995983600616 -> Predictions: [[0.01776656]\n",
            " [0.9779479 ]\n",
            " [0.9778334 ]\n",
            " [0.03656933]]\n",
            "Step: 1485 -> Loss: 0.024912837892770767 -> Predictions: [[0.01773007]\n",
            " [0.9780009 ]\n",
            " [0.97788674]\n",
            " [0.03647428]]\n",
            "Step: 1486 -> Loss: 0.024851970374584198 -> Predictions: [[0.01769372]\n",
            " [0.9780537 ]\n",
            " [0.9779399 ]\n",
            " [0.03637971]]\n",
            "Step: 1487 -> Loss: 0.024791371077299118 -> Predictions: [[0.01765751]\n",
            " [0.97810626]\n",
            " [0.9779928 ]\n",
            " [0.03628558]]\n",
            "Step: 1488 -> Loss: 0.02473107911646366 -> Predictions: [[0.01762144]\n",
            " [0.9781586 ]\n",
            " [0.97804534]\n",
            " [0.03619193]]\n",
            "Step: 1489 -> Loss: 0.024671051651239395 -> Predictions: [[0.01758551]\n",
            " [0.9782106 ]\n",
            " [0.9780978 ]\n",
            " [0.03609871]]\n",
            "Step: 1490 -> Loss: 0.024611307308077812 -> Predictions: [[0.01754974]\n",
            " [0.97826254]\n",
            " [0.97815007]\n",
            " [0.03600596]]\n",
            "Step: 1491 -> Loss: 0.02455185353755951 -> Predictions: [[0.01751409]\n",
            " [0.9783141 ]\n",
            " [0.9782019 ]\n",
            " [0.03591369]]\n",
            "Step: 1492 -> Loss: 0.024492662400007248 -> Predictions: [[0.0174786]\n",
            " [0.9783654]\n",
            " [0.9782536]\n",
            " [0.0358218]]\n",
            "Step: 1493 -> Loss: 0.024433758109807968 -> Predictions: [[0.01744323]\n",
            " [0.97841656]\n",
            " [0.9783051 ]\n",
            " [0.03573041]]\n",
            "Step: 1494 -> Loss: 0.024375109001994133 -> Predictions: [[0.01740801]\n",
            " [0.97846746]\n",
            " [0.9783562 ]\n",
            " [0.03563939]]\n",
            "Step: 1495 -> Loss: 0.024316752329468727 -> Predictions: [[0.01737293]\n",
            " [0.9785181 ]\n",
            " [0.9784072 ]\n",
            " [0.03554892]]\n",
            "Step: 1496 -> Loss: 0.024258654564619064 -> Predictions: [[0.01733796]\n",
            " [0.9785686 ]\n",
            " [0.978458  ]\n",
            " [0.03545881]]\n",
            "Step: 1497 -> Loss: 0.02420082315802574 -> Predictions: [[0.01730316]\n",
            " [0.9786188 ]\n",
            " [0.97850853]\n",
            " [0.03536917]]\n",
            "Step: 1498 -> Loss: 0.02414325252175331 -> Predictions: [[0.01726846]\n",
            " [0.9786688 ]\n",
            " [0.9785588 ]\n",
            " [0.03527996]]\n",
            "Step: 1499 -> Loss: 0.024085938930511475 -> Predictions: [[0.01723392]\n",
            " [0.97871864]\n",
            " [0.9786089 ]\n",
            " [0.03519115]]\n",
            "Step: 1501 -> Loss: 0.02397211454808712 -> Predictions: [[0.01716524]\n",
            " [0.9788175 ]\n",
            " [0.97870845]\n",
            " [0.03501483]]\n",
            "Step: 1502 -> Loss: 0.02391558326780796 -> Predictions: [[0.01713109]\n",
            " [0.9788665 ]\n",
            " [0.9787578 ]\n",
            " [0.03492726]]\n",
            "Step: 1503 -> Loss: 0.023859331384301186 -> Predictions: [[0.01709709]\n",
            " [0.9789154 ]\n",
            " [0.97880703]\n",
            " [0.03484016]]\n",
            "Step: 1504 -> Loss: 0.023803308606147766 -> Predictions: [[0.01706318]\n",
            " [0.9789641 ]\n",
            " [0.9788559 ]\n",
            " [0.0347534 ]]\n",
            "Step: 1505 -> Loss: 0.02374756895005703 -> Predictions: [[0.01702943]\n",
            " [0.9790125 ]\n",
            " [0.97890466]\n",
            " [0.03466714]]\n",
            "Step: 1506 -> Loss: 0.0236920528113842 -> Predictions: [[0.01699581]\n",
            " [0.9790607 ]\n",
            " [0.97895324]\n",
            " [0.03458123]]\n",
            "Step: 1507 -> Loss: 0.023636799305677414 -> Predictions: [[0.01696232]\n",
            " [0.97910875]\n",
            " [0.9790015 ]\n",
            " [0.0344957 ]]\n",
            "Step: 1508 -> Loss: 0.02358178049325943 -> Predictions: [[0.01692893]\n",
            " [0.9791566 ]\n",
            " [0.9790496 ]\n",
            " [0.03441061]]\n",
            "Step: 1509 -> Loss: 0.023527024313807487 -> Predictions: [[0.01689568]\n",
            " [0.9792042 ]\n",
            " [0.97909755]\n",
            " [0.03432592]]\n",
            "Step: 1510 -> Loss: 0.023472484201192856 -> Predictions: [[0.01686257]\n",
            " [0.9792516 ]\n",
            " [0.97914517]\n",
            " [0.03424157]]\n",
            "Step: 1511 -> Loss: 0.02341821789741516 -> Predictions: [[0.01682959]\n",
            " [0.97929883]\n",
            " [0.9791926 ]\n",
            " [0.03415768]]\n",
            "Step: 1512 -> Loss: 0.023364203050732613 -> Predictions: [[0.01679672]\n",
            " [0.9793457 ]\n",
            " [0.97923994]\n",
            " [0.03407418]]\n",
            "Step: 1513 -> Loss: 0.023310385644435883 -> Predictions: [[0.01676396]\n",
            " [0.9793926 ]\n",
            " [0.979287  ]\n",
            " [0.03399102]]\n",
            "Step: 1514 -> Loss: 0.023256834596395493 -> Predictions: [[0.01673135]\n",
            " [0.9794391 ]\n",
            " [0.9793338 ]\n",
            " [0.03390829]]\n",
            "Step: 1515 -> Loss: 0.023203518241643906 -> Predictions: [[0.01669884]\n",
            " [0.97948545]\n",
            " [0.9793804 ]\n",
            " [0.03382592]]\n",
            "Step: 1516 -> Loss: 0.023150449618697166 -> Predictions: [[0.01666647]\n",
            " [0.97953165]\n",
            " [0.97942686]\n",
            " [0.03374395]]\n",
            "Step: 1517 -> Loss: 0.023097602650523186 -> Predictions: [[0.01663421]\n",
            " [0.9795775 ]\n",
            " [0.9794732 ]\n",
            " [0.03366235]]\n",
            "Step: 1518 -> Loss: 0.023044975474476814 -> Predictions: [[0.01660207]\n",
            " [0.97962326]\n",
            " [0.9795192 ]\n",
            " [0.03358105]]\n",
            "Step: 1519 -> Loss: 0.022992605343461037 -> Predictions: [[0.01657004]\n",
            " [0.9796688 ]\n",
            " [0.979565  ]\n",
            " [0.03350022]]\n",
            "Step: 1520 -> Loss: 0.02294044941663742 -> Predictions: [[0.01653815]\n",
            " [0.9797142 ]\n",
            " [0.9796107 ]\n",
            " [0.03341971]]\n",
            "Step: 1521 -> Loss: 0.02288852259516716 -> Predictions: [[0.01650636]\n",
            " [0.9797594 ]\n",
            " [0.9796561 ]\n",
            " [0.03333959]]\n",
            "Step: 1522 -> Loss: 0.022836819291114807 -> Predictions: [[0.0164747 ]\n",
            " [0.9798043 ]\n",
            " [0.9797014 ]\n",
            " [0.03325979]]\n",
            "Step: 1523 -> Loss: 0.022785339504480362 -> Predictions: [[0.01644315]\n",
            " [0.97984916]\n",
            " [0.97974634]\n",
            " [0.03318037]]\n",
            "Step: 1524 -> Loss: 0.022734105587005615 -> Predictions: [[0.0164117 ]\n",
            " [0.9798937 ]\n",
            " [0.9797912 ]\n",
            " [0.03310139]]\n",
            "Step: 1525 -> Loss: 0.022683076560497284 -> Predictions: [[0.01638042]\n",
            " [0.9799381 ]\n",
            " [0.979836  ]\n",
            " [0.0330227 ]]\n",
            "Step: 1526 -> Loss: 0.022632267326116562 -> Predictions: [[0.01634922]\n",
            " [0.97998226]\n",
            " [0.9798804 ]\n",
            " [0.03294434]]\n",
            "Step: 1527 -> Loss: 0.022581685334444046 -> Predictions: [[0.01631811]\n",
            " [0.98002636]\n",
            " [0.9799247 ]\n",
            " [0.03286636]]\n",
            "Step: 1528 -> Loss: 0.022531326860189438 -> Predictions: [[0.01628715]\n",
            " [0.98007005]\n",
            " [0.9799687 ]\n",
            " [0.03278874]]\n",
            "Step: 1529 -> Loss: 0.022481154650449753 -> Predictions: [[0.0162563 ]\n",
            " [0.9801138 ]\n",
            " [0.9800127 ]\n",
            " [0.03271146]]\n",
            "Step: 1530 -> Loss: 0.022431228309869766 -> Predictions: [[0.01622556]\n",
            " [0.98015726]\n",
            " [0.98005646]\n",
            " [0.03263455]]\n",
            "Step: 1531 -> Loss: 0.022381503134965897 -> Predictions: [[0.01619493]\n",
            " [0.9802005 ]\n",
            " [0.9801    ]\n",
            " [0.03255793]]\n",
            "Step: 1532 -> Loss: 0.022331994026899338 -> Predictions: [[0.01616443]\n",
            " [0.98024356]\n",
            " [0.98014337]\n",
            " [0.03248168]]\n",
            "Step: 1533 -> Loss: 0.02228270098567009 -> Predictions: [[0.01613402]\n",
            " [0.98028654]\n",
            " [0.9801865 ]\n",
            " [0.03240579]]\n",
            "Step: 1534 -> Loss: 0.02223360724747181 -> Predictions: [[0.01610373]\n",
            " [0.9803293 ]\n",
            " [0.9802296 ]\n",
            " [0.03233021]]\n",
            "Step: 1535 -> Loss: 0.02218472771346569 -> Predictions: [[0.01607354]\n",
            " [0.9803718 ]\n",
            " [0.98027235]\n",
            " [0.03225497]]\n",
            "Step: 1536 -> Loss: 0.022136058658361435 -> Predictions: [[0.01604348]\n",
            " [0.98041415]\n",
            " [0.9803151 ]\n",
            " [0.03218008]]\n",
            "Step: 1537 -> Loss: 0.022087596356868744 -> Predictions: [[0.01601352]\n",
            " [0.9804565 ]\n",
            " [0.98035747]\n",
            " [0.03210552]]\n",
            "Step: 1538 -> Loss: 0.022039320319890976 -> Predictions: [[0.01598367]\n",
            " [0.9804985 ]\n",
            " [0.9803997 ]\n",
            " [0.03203126]]\n",
            "Step: 1539 -> Loss: 0.02199125848710537 -> Predictions: [[0.01595391]\n",
            " [0.98054034]\n",
            " [0.9804419 ]\n",
            " [0.03195731]]\n",
            "Step: 1540 -> Loss: 0.021943408995866776 -> Predictions: [[0.01592429]\n",
            " [0.98058194]\n",
            " [0.98048383]\n",
            " [0.03188375]]\n",
            "Step: 1541 -> Loss: 0.02189575508236885 -> Predictions: [[0.01589471]\n",
            " [0.98062354]\n",
            " [0.98052555]\n",
            " [0.03181049]]\n",
            "Step: 1542 -> Loss: 0.021848298609256744 -> Predictions: [[0.0158653 ]\n",
            " [0.98066485]\n",
            " [0.98056716]\n",
            " [0.03173753]]\n",
            "Step: 1543 -> Loss: 0.021801043301820755 -> Predictions: [[0.01583598]\n",
            " [0.980706  ]\n",
            " [0.9806085 ]\n",
            " [0.03166489]]\n",
            "Step: 1544 -> Loss: 0.02175399847328663 -> Predictions: [[0.01580676]\n",
            " [0.98074704]\n",
            " [0.9806498 ]\n",
            " [0.03159259]]\n",
            "Step: 1545 -> Loss: 0.02170712873339653 -> Predictions: [[0.01577764]\n",
            " [0.9807879 ]\n",
            " [0.98069096]\n",
            " [0.03152058]]\n",
            "Step: 1546 -> Loss: 0.0216604582965374 -> Predictions: [[0.01574863]\n",
            " [0.98082846]\n",
            " [0.9807318 ]\n",
            " [0.03144888]]\n",
            "Step: 1547 -> Loss: 0.02161398157477379 -> Predictions: [[0.0157197 ]\n",
            " [0.98086894]\n",
            " [0.9807726 ]\n",
            " [0.03137746]]\n",
            "Step: 1548 -> Loss: 0.021567702293395996 -> Predictions: [[0.01569089]\n",
            " [0.98090935]\n",
            " [0.9808132 ]\n",
            " [0.03130643]]\n",
            "Step: 1549 -> Loss: 0.02152162231504917 -> Predictions: [[0.01566219]\n",
            " [0.98094946]\n",
            " [0.98085356]\n",
            " [0.03123567]]\n",
            "Step: 1550 -> Loss: 0.021475717425346375 -> Predictions: [[0.01563358]\n",
            " [0.9809895 ]\n",
            " [0.98089385]\n",
            " [0.0311652 ]]\n",
            "Step: 1551 -> Loss: 0.02143000066280365 -> Predictions: [[0.01560509]\n",
            " [0.98102933]\n",
            " [0.98093385]\n",
            " [0.031095  ]]\n",
            "Step: 1552 -> Loss: 0.021384472027420998 -> Predictions: [[0.01557668]\n",
            " [0.981069  ]\n",
            " [0.9809738 ]\n",
            " [0.03102516]]\n",
            "Step: 1553 -> Loss: 0.021339137107133865 -> Predictions: [[0.01554836]\n",
            " [0.9811085 ]\n",
            " [0.9810136 ]\n",
            " [0.03095561]]\n",
            "Step: 1554 -> Loss: 0.021293994039297104 -> Predictions: [[0.01552018]\n",
            " [0.9811478 ]\n",
            " [0.9810532 ]\n",
            " [0.03088636]]\n",
            "Step: 1555 -> Loss: 0.02124902606010437 -> Predictions: [[0.01549208]\n",
            " [0.9811871 ]\n",
            " [0.98109263]\n",
            " [0.03081737]]\n",
            "Step: 1556 -> Loss: 0.021204248070716858 -> Predictions: [[0.01546407]\n",
            " [0.9812261 ]\n",
            " [0.9811319 ]\n",
            " [0.03074873]]\n",
            "Step: 1557 -> Loss: 0.021159641444683075 -> Predictions: [[0.01543615]\n",
            " [0.981265  ]\n",
            " [0.981171  ]\n",
            " [0.03068033]]\n",
            "Step: 1558 -> Loss: 0.021115221083164215 -> Predictions: [[0.01540837]\n",
            " [0.9813037 ]\n",
            " [0.98121005]\n",
            " [0.03061223]]\n",
            "Step: 1559 -> Loss: 0.021070988848805428 -> Predictions: [[0.01538067]\n",
            " [0.98134226]\n",
            " [0.98124886]\n",
            " [0.03054445]]\n",
            "Step: 1560 -> Loss: 0.02102692425251007 -> Predictions: [[0.01535303]\n",
            " [0.98138076]\n",
            " [0.98128754]\n",
            " [0.03047694]]\n",
            "Step: 1561 -> Loss: 0.020983044058084488 -> Predictions: [[0.01532551]\n",
            " [0.98141897]\n",
            " [0.981326  ]\n",
            " [0.03040969]]\n",
            "Step: 1562 -> Loss: 0.020939338952302933 -> Predictions: [[0.0152981 ]\n",
            " [0.9814571 ]\n",
            " [0.9813643 ]\n",
            " [0.03034275]]\n",
            "Step: 1563 -> Loss: 0.0208958201110363 -> Predictions: [[0.01527078]\n",
            " [0.9814951 ]\n",
            " [0.9814026 ]\n",
            " [0.0302761 ]]\n",
            "Step: 1564 -> Loss: 0.02085246704518795 -> Predictions: [[0.01524354]\n",
            " [0.9815329 ]\n",
            " [0.98144054]\n",
            " [0.03020972]]\n",
            "Step: 1565 -> Loss: 0.020809277892112732 -> Predictions: [[0.01521641]\n",
            " [0.98157054]\n",
            " [0.9814786 ]\n",
            " [0.0301436 ]]\n",
            "Step: 1566 -> Loss: 0.020766261965036392 -> Predictions: [[0.01518935]\n",
            " [0.9816081 ]\n",
            " [0.98151624]\n",
            " [0.03007776]]\n",
            "Step: 1567 -> Loss: 0.020723428577184677 -> Predictions: [[0.01516242]\n",
            " [0.98164546]\n",
            " [0.9815539 ]\n",
            " [0.03001216]]\n",
            "Step: 1568 -> Loss: 0.020680762827396393 -> Predictions: [[0.01513554]\n",
            " [0.98168266]\n",
            " [0.98159134]\n",
            " [0.02994689]]\n",
            "Step: 1569 -> Loss: 0.020638270303606987 -> Predictions: [[0.01510877]\n",
            " [0.9817198 ]\n",
            " [0.98162866]\n",
            " [0.02988187]]\n",
            "Step: 1570 -> Loss: 0.02059594728052616 -> Predictions: [[0.0150821 ]\n",
            " [0.98175675]\n",
            " [0.9816658 ]\n",
            " [0.02981714]]\n",
            "Step: 1571 -> Loss: 0.02055378630757332 -> Predictions: [[0.01505552]\n",
            " [0.9817935 ]\n",
            " [0.9817028 ]\n",
            " [0.02975263]]\n",
            "Step: 1572 -> Loss: 0.020511802285909653 -> Predictions: [[0.01502903]\n",
            " [0.9818302 ]\n",
            " [0.98173964]\n",
            " [0.02968842]]\n",
            "Step: 1573 -> Loss: 0.020469971001148224 -> Predictions: [[0.01500263]\n",
            " [0.98186666]\n",
            " [0.9817764 ]\n",
            " [0.02962446]]\n",
            "Step: 1574 -> Loss: 0.020428314805030823 -> Predictions: [[0.0149763 ]\n",
            " [0.9819031 ]\n",
            " [0.98181295]\n",
            " [0.02956078]]\n",
            "Step: 1575 -> Loss: 0.020386813208460808 -> Predictions: [[0.01495008]\n",
            " [0.98193926]\n",
            " [0.9818494 ]\n",
            " [0.02949733]]\n",
            "Step: 1576 -> Loss: 0.02034549042582512 -> Predictions: [[0.01492393]\n",
            " [0.98197526]\n",
            " [0.98188573]\n",
            " [0.02943418]]\n",
            "Step: 1577 -> Loss: 0.020304307341575623 -> Predictions: [[0.01489787]\n",
            " [0.9820112 ]\n",
            " [0.9819219 ]\n",
            " [0.02937127]]\n",
            "Step: 1578 -> Loss: 0.020263303071260452 -> Predictions: [[0.01487194]\n",
            " [0.9820471 ]\n",
            " [0.9819579 ]\n",
            " [0.02930857]]\n",
            "Step: 1579 -> Loss: 0.02022244967520237 -> Predictions: [[0.01484607]\n",
            " [0.9820827 ]\n",
            " [0.98199373]\n",
            " [0.02924619]]\n",
            "Step: 1580 -> Loss: 0.020181767642498016 -> Predictions: [[0.0148203 ]\n",
            " [0.98211825]\n",
            " [0.9820295 ]\n",
            " [0.02918407]]\n",
            "Step: 1581 -> Loss: 0.0201412420719862 -> Predictions: [[0.01479459]\n",
            " [0.98215365]\n",
            " [0.98206514]\n",
            " [0.02912217]]\n",
            "Step: 1582 -> Loss: 0.020100856199860573 -> Predictions: [[0.01476897]\n",
            " [0.9821889 ]\n",
            " [0.98210055]\n",
            " [0.02906052]]\n",
            "Step: 1583 -> Loss: 0.020060647279024124 -> Predictions: [[0.01474344]\n",
            " [0.9822239 ]\n",
            " [0.98213583]\n",
            " [0.02899911]]\n",
            "Step: 1584 -> Loss: 0.02002057619392872 -> Predictions: [[0.01471802]\n",
            " [0.98225904]\n",
            " [0.9821712 ]\n",
            " [0.02893794]]\n",
            "Step: 1585 -> Loss: 0.019980669021606445 -> Predictions: [[0.01469268]\n",
            " [0.9822939 ]\n",
            " [0.9822062 ]\n",
            " [0.02887707]]\n",
            "Step: 1586 -> Loss: 0.01994090899825096 -> Predictions: [[0.0146674]\n",
            " [0.9823286]\n",
            " [0.9822411]\n",
            " [0.0288164]]\n",
            "Step: 1587 -> Loss: 0.019901322200894356 -> Predictions: [[0.01464224]\n",
            " [0.9823631 ]\n",
            " [0.98227596]\n",
            " [0.02875601]]\n",
            "Step: 1588 -> Loss: 0.019861871376633644 -> Predictions: [[0.01461711]\n",
            " [0.9823976 ]\n",
            " [0.98231053]\n",
            " [0.02869583]]\n",
            "Step: 1589 -> Loss: 0.01982257328927517 -> Predictions: [[0.01459211]\n",
            " [0.98243195]\n",
            " [0.98234516]\n",
            " [0.02863589]]\n",
            "Step: 1590 -> Loss: 0.01978343538939953 -> Predictions: [[0.01456717]\n",
            " [0.9824661 ]\n",
            " [0.98237956]\n",
            " [0.02857623]]\n",
            "Step: 1591 -> Loss: 0.019744444638490677 -> Predictions: [[0.01454234]\n",
            " [0.98250014]\n",
            " [0.9824139 ]\n",
            " [0.02851678]]\n",
            "Step: 1592 -> Loss: 0.01970558986067772 -> Predictions: [[0.01451756]\n",
            " [0.9825341 ]\n",
            " [0.9824479 ]\n",
            " [0.02845753]]\n",
            "Step: 1593 -> Loss: 0.019666897132992744 -> Predictions: [[0.01449288]\n",
            " [0.98256797]\n",
            " [0.98248196]\n",
            " [0.02839855]]\n",
            "Step: 1594 -> Loss: 0.019628334790468216 -> Predictions: [[0.01446826]\n",
            " [0.98260164]\n",
            " [0.9825158 ]\n",
            " [0.02833977]]\n",
            "Step: 1595 -> Loss: 0.01958993636071682 -> Predictions: [[0.01444377]\n",
            " [0.98263514]\n",
            " [0.98254967]\n",
            " [0.02828128]]\n",
            "Step: 1596 -> Loss: 0.019551662728190422 -> Predictions: [[0.0144193 ]\n",
            " [0.98266864]\n",
            " [0.9825832 ]\n",
            " [0.02822298]]\n",
            "Step: 1597 -> Loss: 0.019513549283146858 -> Predictions: [[0.01439495]\n",
            " [0.98270196]\n",
            " [0.9826167 ]\n",
            " [0.02816492]]\n",
            "Step: 1598 -> Loss: 0.019475577399134636 -> Predictions: [[0.01437064]\n",
            " [0.9827351 ]\n",
            " [0.9826501 ]\n",
            " [0.02810709]]\n",
            "Step: 1599 -> Loss: 0.019437752664089203 -> Predictions: [[0.01434644]\n",
            " [0.98276824]\n",
            " [0.9826834 ]\n",
            " [0.0280495 ]]\n",
            "Step: 1600 -> Loss: 0.01940006949007511 -> Predictions: [[0.01432233]\n",
            " [0.9828012 ]\n",
            " [0.98271656]\n",
            " [0.02799211]]\n",
            "Step: 1601 -> Loss: 0.019362518563866615 -> Predictions: [[0.01429828]\n",
            " [0.982834  ]\n",
            " [0.9827496 ]\n",
            " [0.02793494]]\n",
            "Step: 1602 -> Loss: 0.019325120374560356 -> Predictions: [[0.01427431]\n",
            " [0.9828667 ]\n",
            " [0.98278254]\n",
            " [0.02787805]]\n",
            "Step: 1603 -> Loss: 0.019287848845124245 -> Predictions: [[0.0142504 ]\n",
            " [0.9828993 ]\n",
            " [0.9828152 ]\n",
            " [0.02782134]]\n",
            "Step: 1604 -> Loss: 0.01925072818994522 -> Predictions: [[0.01422659]\n",
            " [0.9829317 ]\n",
            " [0.9828479 ]\n",
            " [0.02776484]]\n",
            "Step: 1605 -> Loss: 0.01921374909579754 -> Predictions: [[0.01420286]\n",
            " [0.98296404]\n",
            " [0.9828804 ]\n",
            " [0.0277086 ]]\n",
            "Step: 1606 -> Loss: 0.019176896661520004 -> Predictions: [[0.01417923]\n",
            " [0.9829963 ]\n",
            " [0.9829129 ]\n",
            " [0.02765255]]\n",
            "Step: 1607 -> Loss: 0.019140183925628662 -> Predictions: [[0.01415564]\n",
            " [0.9830284 ]\n",
            " [0.98294514]\n",
            " [0.02759675]]\n",
            "Step: 1608 -> Loss: 0.019103597849607468 -> Predictions: [[0.01413214]\n",
            " [0.9830603 ]\n",
            " [0.9829774 ]\n",
            " [0.0275411 ]]\n",
            "Step: 1609 -> Loss: 0.01906716451048851 -> Predictions: [[0.01410871]\n",
            " [0.98309225]\n",
            " [0.9830094 ]\n",
            " [0.02748569]]\n",
            "Step: 1610 -> Loss: 0.01903085596859455 -> Predictions: [[0.01408535]\n",
            " [0.9831239 ]\n",
            " [0.9830413 ]\n",
            " [0.02743051]]\n",
            "Step: 1611 -> Loss: 0.018994683399796486 -> Predictions: [[0.01406208]\n",
            " [0.9831556 ]\n",
            " [0.98307323]\n",
            " [0.02737554]]\n",
            "Step: 1612 -> Loss: 0.018958650529384613 -> Predictions: [[0.01403887]\n",
            " [0.9831871 ]\n",
            " [0.9831049 ]\n",
            " [0.02732079]]\n",
            "Step: 1613 -> Loss: 0.01892274059355259 -> Predictions: [[0.01401575]\n",
            " [0.9832185 ]\n",
            " [0.9831365 ]\n",
            " [0.0272662 ]]\n",
            "Step: 1614 -> Loss: 0.01888696663081646 -> Predictions: [[0.01399269]\n",
            " [0.9832497 ]\n",
            " [0.98316795]\n",
            " [0.02721187]]\n",
            "Step: 1615 -> Loss: 0.018851324915885925 -> Predictions: [[0.01396972]\n",
            " [0.98328096]\n",
            " [0.98319936]\n",
            " [0.02715775]]\n",
            "Step: 1616 -> Loss: 0.018815800547599792 -> Predictions: [[0.01394681]\n",
            " [0.983312  ]\n",
            " [0.9832306 ]\n",
            " [0.02710377]]\n",
            "Step: 1617 -> Loss: 0.018780425190925598 -> Predictions: [[0.01392399]\n",
            " [0.983343  ]\n",
            " [0.9832617 ]\n",
            " [0.02705006]]\n",
            "Step: 1618 -> Loss: 0.018745169043540955 -> Predictions: [[0.01390123]\n",
            " [0.9833739 ]\n",
            " [0.98329276]\n",
            " [0.02699653]]\n",
            "Step: 1619 -> Loss: 0.018710045143961906 -> Predictions: [[0.01387853]\n",
            " [0.9834046 ]\n",
            " [0.98332375]\n",
            " [0.02694321]]\n",
            "Step: 1620 -> Loss: 0.018675047904253006 -> Predictions: [[0.01385592]\n",
            " [0.9834352 ]\n",
            " [0.9833545 ]\n",
            " [0.02689009]]\n",
            "Step: 1621 -> Loss: 0.018640168011188507 -> Predictions: [[0.01383335]\n",
            " [0.9834657 ]\n",
            " [0.9833852 ]\n",
            " [0.02683716]]\n",
            "Step: 1622 -> Loss: 0.01860542967915535 -> Predictions: [[0.01381088]\n",
            " [0.98349607]\n",
            " [0.9834157 ]\n",
            " [0.02678446]]\n",
            "Step: 1623 -> Loss: 0.018570806831121445 -> Predictions: [[0.01378846]\n",
            " [0.9835264 ]\n",
            " [0.9834463 ]\n",
            " [0.02673192]]\n",
            "Step: 1624 -> Loss: 0.018536314368247986 -> Predictions: [[0.01376615]\n",
            " [0.9835566 ]\n",
            " [0.98347664]\n",
            " [0.02667961]]\n",
            "Step: 1625 -> Loss: 0.018501946702599525 -> Predictions: [[0.0137439 ]\n",
            " [0.9835866 ]\n",
            " [0.9835069 ]\n",
            " [0.02662748]]\n",
            "Step: 1626 -> Loss: 0.018467698246240616 -> Predictions: [[0.01372172]\n",
            " [0.9836166 ]\n",
            " [0.983537  ]\n",
            " [0.02657553]]\n",
            "Step: 1627 -> Loss: 0.018433574587106705 -> Predictions: [[0.0136996 ]\n",
            " [0.98364645]\n",
            " [0.9835671 ]\n",
            " [0.0265238 ]]\n",
            "Step: 1628 -> Loss: 0.018399571999907494 -> Predictions: [[0.01367755]\n",
            " [0.98367625]\n",
            " [0.983597  ]\n",
            " [0.02647224]]\n",
            "Step: 1629 -> Loss: 0.018365690484642982 -> Predictions: [[0.01365556]\n",
            " [0.9837059 ]\n",
            " [0.98362684]\n",
            " [0.02642088]]\n",
            "Step: 1630 -> Loss: 0.01833193562924862 -> Predictions: [[0.01363366]\n",
            " [0.98373556]\n",
            " [0.98365664]\n",
            " [0.02636973]]\n",
            "Step: 1631 -> Loss: 0.018298301845788956 -> Predictions: [[0.01361182]\n",
            " [0.98376495]\n",
            " [0.98368627]\n",
            " [0.02631875]]\n",
            "Step: 1632 -> Loss: 0.018264776095747948 -> Predictions: [[0.01359004]\n",
            " [0.9837943 ]\n",
            " [0.98371583]\n",
            " [0.02626794]]\n",
            "Step: 1633 -> Loss: 0.01823137328028679 -> Predictions: [[0.01356832]\n",
            " [0.98382354]\n",
            " [0.9837452 ]\n",
            " [0.02621734]]\n",
            "Step: 1634 -> Loss: 0.018198097124695778 -> Predictions: [[0.01354668]\n",
            " [0.9838526 ]\n",
            " [0.98377454]\n",
            " [0.02616694]]\n",
            "Step: 1635 -> Loss: 0.01816493272781372 -> Predictions: [[0.01352508]\n",
            " [0.9838817 ]\n",
            " [0.9838037 ]\n",
            " [0.02611671]]\n",
            "Step: 1636 -> Loss: 0.018131878226995468 -> Predictions: [[0.01350357]\n",
            " [0.98391056]\n",
            " [0.9838328 ]\n",
            " [0.02606664]]\n",
            "Step: 1637 -> Loss: 0.01809895783662796 -> Predictions: [[0.01348215]\n",
            " [0.9839394 ]\n",
            " [0.98386186]\n",
            " [0.0260168 ]]\n",
            "Step: 1638 -> Loss: 0.018066149204969406 -> Predictions: [[0.01346078]\n",
            " [0.98396814]\n",
            " [0.9838907 ]\n",
            " [0.02596712]]\n",
            "Step: 1639 -> Loss: 0.018033450469374657 -> Predictions: [[0.01343947]\n",
            " [0.9839968 ]\n",
            " [0.98391956]\n",
            " [0.02591764]]\n",
            "Step: 1640 -> Loss: 0.018000856041908264 -> Predictions: [[0.01341824]\n",
            " [0.9840254 ]\n",
            " [0.9839483 ]\n",
            " [0.02586831]]\n",
            "Step: 1641 -> Loss: 0.01796838454902172 -> Predictions: [[0.01339707]\n",
            " [0.9840538 ]\n",
            " [0.98397684]\n",
            " [0.02581918]]\n",
            "Step: 1642 -> Loss: 0.017936034128069878 -> Predictions: [[0.01337596]\n",
            " [0.9840822 ]\n",
            " [0.98400545]\n",
            " [0.02577024]]\n",
            "Step: 1643 -> Loss: 0.017903786152601242 -> Predictions: [[0.01335491]\n",
            " [0.98411036]\n",
            " [0.9840338 ]\n",
            " [0.02572146]]\n",
            "Step: 1644 -> Loss: 0.017871661111712456 -> Predictions: [[0.01333393]\n",
            " [0.98413855]\n",
            " [0.98406214]\n",
            " [0.02567286]]\n",
            "Step: 1645 -> Loss: 0.017839638516306877 -> Predictions: [[0.013313  ]\n",
            " [0.9841666 ]\n",
            " [0.9840904 ]\n",
            " [0.02562444]]\n",
            "Step: 1646 -> Loss: 0.017807720229029655 -> Predictions: [[0.01329214]\n",
            " [0.9841945 ]\n",
            " [0.98411846]\n",
            " [0.02557616]]\n",
            "Step: 1647 -> Loss: 0.01777592860162258 -> Predictions: [[0.01327136]\n",
            " [0.98422235]\n",
            " [0.98414654]\n",
            " [0.02552813]]\n",
            "Step: 1648 -> Loss: 0.017744235694408417 -> Predictions: [[0.01325064]\n",
            " [0.9842502 ]\n",
            " [0.98417443]\n",
            " [0.02548021]]\n",
            "Step: 1649 -> Loss: 0.017712663859128952 -> Predictions: [[0.01322997]\n",
            " [0.9842778 ]\n",
            " [0.98420227]\n",
            " [0.02543247]]\n",
            "Step: 1650 -> Loss: 0.017681194469332695 -> Predictions: [[0.01320938]\n",
            " [0.9843054 ]\n",
            " [0.98423   ]\n",
            " [0.02538491]]\n",
            "Step: 1651 -> Loss: 0.017649836838245392 -> Predictions: [[0.01318884]\n",
            " [0.9843329 ]\n",
            " [0.9842576 ]\n",
            " [0.02533752]]\n",
            "Step: 1652 -> Loss: 0.017618589103221893 -> Predictions: [[0.01316837]\n",
            " [0.9843603 ]\n",
            " [0.9842852 ]\n",
            " [0.02529033]]\n",
            "Step: 1653 -> Loss: 0.017587443813681602 -> Predictions: [[0.01314794]\n",
            " [0.9843875 ]\n",
            " [0.9843127 ]\n",
            " [0.02524327]]\n",
            "Step: 1654 -> Loss: 0.017556406557559967 -> Predictions: [[0.0131276 ]\n",
            " [0.9844148 ]\n",
            " [0.9843401 ]\n",
            " [0.02519637]]\n",
            "Step: 1655 -> Loss: 0.017525481060147285 -> Predictions: [[0.0131073 ]\n",
            " [0.9844418 ]\n",
            " [0.9843673 ]\n",
            " [0.02514965]]\n",
            "Step: 1656 -> Loss: 0.017494643107056618 -> Predictions: [[0.01308706]\n",
            " [0.9844689 ]\n",
            " [0.9843945 ]\n",
            " [0.02510312]]\n",
            "Step: 1657 -> Loss: 0.017463920637965202 -> Predictions: [[0.0130669 ]\n",
            " [0.98449576]\n",
            " [0.9844216 ]\n",
            " [0.02505674]]\n",
            "Step: 1658 -> Loss: 0.01743330806493759 -> Predictions: [[0.01304677]\n",
            " [0.9845227 ]\n",
            " [0.98444855]\n",
            " [0.02501051]]\n",
            "Step: 1659 -> Loss: 0.017402801662683487 -> Predictions: [[0.01302673]\n",
            " [0.9845494 ]\n",
            " [0.98447543]\n",
            " [0.02496446]]\n",
            "Step: 1660 -> Loss: 0.017372392117977142 -> Predictions: [[0.01300674]\n",
            " [0.9845761 ]\n",
            " [0.98450226]\n",
            " [0.02491857]]\n",
            "Step: 1661 -> Loss: 0.017342088744044304 -> Predictions: [[0.01298682]\n",
            " [0.9846027 ]\n",
            " [0.9845291 ]\n",
            " [0.02487285]]\n",
            "Step: 1662 -> Loss: 0.017311889678239822 -> Predictions: [[0.01296694]\n",
            " [0.98462915]\n",
            " [0.98455566]\n",
            " [0.02482729]]\n",
            "Step: 1663 -> Loss: 0.017281794920563698 -> Predictions: [[0.01294712]\n",
            " [0.9846555 ]\n",
            " [0.98458225]\n",
            " [0.02478188]]\n",
            "Step: 1664 -> Loss: 0.017251787707209587 -> Predictions: [[0.01292736]\n",
            " [0.9846817 ]\n",
            " [0.9846087 ]\n",
            " [0.02473661]]\n",
            "Step: 1665 -> Loss: 0.017221901565790176 -> Predictions: [[0.01290768]\n",
            " [0.98470795]\n",
            " [0.98463506]\n",
            " [0.02469153]]\n",
            "Step: 1666 -> Loss: 0.017192108556628227 -> Predictions: [[0.01288806]\n",
            " [0.9847341 ]\n",
            " [0.9846613 ]\n",
            " [0.0246466 ]]\n",
            "Step: 1667 -> Loss: 0.017162401229143143 -> Predictions: [[0.01286847]\n",
            " [0.9847601 ]\n",
            " [0.9846875 ]\n",
            " [0.0246018 ]]\n",
            "Step: 1668 -> Loss: 0.017132805660367012 -> Predictions: [[0.01284895]\n",
            " [0.9847861 ]\n",
            " [0.9847136 ]\n",
            " [0.02455718]]\n",
            "Step: 1669 -> Loss: 0.01710330694913864 -> Predictions: [[0.01282949]\n",
            " [0.9848119 ]\n",
            " [0.98473966]\n",
            " [0.0245127 ]]\n",
            "Step: 1670 -> Loss: 0.017073919996619225 -> Predictions: [[0.01281008]\n",
            " [0.98483765]\n",
            " [0.9847655 ]\n",
            " [0.02446843]]\n",
            "Step: 1671 -> Loss: 0.017044607549905777 -> Predictions: [[0.01279073]\n",
            " [0.98486346]\n",
            " [0.98479146]\n",
            " [0.02442424]]\n",
            "Step: 1672 -> Loss: 0.017015404999256134 -> Predictions: [[0.01277144]\n",
            " [0.98488903]\n",
            " [0.9848172 ]\n",
            " [0.02438023]]\n",
            "Step: 1673 -> Loss: 0.016986312344670296 -> Predictions: [[0.01275222]\n",
            " [0.98491454]\n",
            " [0.9848429 ]\n",
            " [0.0243364 ]]\n",
            "Step: 1674 -> Loss: 0.016957294195890427 -> Predictions: [[0.01273303]\n",
            " [0.98494   ]\n",
            " [0.9848684 ]\n",
            " [0.02429271]]\n",
            "Step: 1675 -> Loss: 0.01692838780581951 -> Predictions: [[0.0127139 ]\n",
            " [0.9849653 ]\n",
            " [0.984894  ]\n",
            " [0.02424916]]\n",
            "Step: 1676 -> Loss: 0.016899563372135162 -> Predictions: [[0.01269483]\n",
            " [0.98499066]\n",
            " [0.9849194 ]\n",
            " [0.02420576]]\n",
            "Step: 1677 -> Loss: 0.01687084510922432 -> Predictions: [[0.01267584]\n",
            " [0.98501587]\n",
            " [0.98494476]\n",
            " [0.02416252]]\n",
            "Step: 1678 -> Loss: 0.016842225566506386 -> Predictions: [[0.01265688]\n",
            " [0.98504096]\n",
            " [0.98497   ]\n",
            " [0.02411941]]\n",
            "Step: 1679 -> Loss: 0.01681368425488472 -> Predictions: [[0.01263798]\n",
            " [0.98506594]\n",
            " [0.9849952 ]\n",
            " [0.02407645]]\n",
            "Step: 1680 -> Loss: 0.01678524725139141 -> Predictions: [[0.01261916]\n",
            " [0.985091  ]\n",
            " [0.9850203 ]\n",
            " [0.02403365]]\n",
            "Step: 1681 -> Loss: 0.016756899654865265 -> Predictions: [[0.01260035]\n",
            " [0.9851158 ]\n",
            " [0.98504525]\n",
            " [0.02399099]]\n",
            "Step: 1682 -> Loss: 0.01672864705324173 -> Predictions: [[0.01258163]\n",
            " [0.98514056]\n",
            " [0.9850702 ]\n",
            " [0.02394848]]\n",
            "Step: 1683 -> Loss: 0.016700483858585358 -> Predictions: [[0.01256294]\n",
            " [0.98516536]\n",
            " [0.98509514]\n",
            " [0.02390611]]\n",
            "Step: 1684 -> Loss: 0.016672421246767044 -> Predictions: [[0.01254432]\n",
            " [0.98519   ]\n",
            " [0.9851199 ]\n",
            " [0.02386389]]\n",
            "Step: 1685 -> Loss: 0.01664445549249649 -> Predictions: [[0.01252576]\n",
            " [0.98521453]\n",
            " [0.9851445 ]\n",
            " [0.02382183]]\n",
            "Step: 1686 -> Loss: 0.01661655679345131 -> Predictions: [[0.01250724]\n",
            " [0.9852389 ]\n",
            " [0.9851692 ]\n",
            " [0.02377986]]\n",
            "Step: 1687 -> Loss: 0.01658877357840538 -> Predictions: [[0.0124888 ]\n",
            " [0.98526335]\n",
            " [0.98519367]\n",
            " [0.02373808]]\n",
            "Step: 1688 -> Loss: 0.01656106486916542 -> Predictions: [[0.01247037]\n",
            " [0.98528767]\n",
            " [0.9852182 ]\n",
            " [0.02369642]]\n",
            "Step: 1689 -> Loss: 0.016533460468053818 -> Predictions: [[0.01245202]\n",
            " [0.98531187]\n",
            " [0.98524255]\n",
            " [0.02365492]]\n",
            "Step: 1690 -> Loss: 0.016505923122167587 -> Predictions: [[0.01243371]\n",
            " [0.985336  ]\n",
            " [0.9852669 ]\n",
            " [0.02361353]]\n",
            "Step: 1691 -> Loss: 0.016478488221764565 -> Predictions: [[0.01241546]\n",
            " [0.9853601 ]\n",
            " [0.9852911 ]\n",
            " [0.02357228]]\n",
            "Step: 1692 -> Loss: 0.0164511576294899 -> Predictions: [[0.01239726]\n",
            " [0.98538417]\n",
            " [0.9853152 ]\n",
            " [0.02353122]]\n",
            "Step: 1693 -> Loss: 0.016423892229795456 -> Predictions: [[0.01237909]\n",
            " [0.985408  ]\n",
            " [0.9853393 ]\n",
            " [0.02349025]]\n",
            "Step: 1694 -> Loss: 0.016396721825003624 -> Predictions: [[0.01236099]\n",
            " [0.98543185]\n",
            " [0.98536336]\n",
            " [0.02344942]]\n",
            "Step: 1695 -> Loss: 0.016369635239243507 -> Predictions: [[0.01234294]\n",
            " [0.9854557 ]\n",
            " [0.9853872 ]\n",
            " [0.02340872]]\n",
            "Step: 1696 -> Loss: 0.0163426473736763 -> Predictions: [[0.01232496]\n",
            " [0.98547935]\n",
            " [0.98541105]\n",
            " [0.0233682 ]]\n",
            "Step: 1697 -> Loss: 0.016315743327140808 -> Predictions: [[0.01230702]\n",
            " [0.98550296]\n",
            " [0.9854348 ]\n",
            " [0.02332778]]\n",
            "Step: 1698 -> Loss: 0.016288921236991882 -> Predictions: [[0.01228914]\n",
            " [0.98552656]\n",
            " [0.9854585 ]\n",
            " [0.02328749]]\n",
            "Step: 1699 -> Loss: 0.016262182965874672 -> Predictions: [[0.01227128]\n",
            " [0.98555   ]\n",
            " [0.9854821 ]\n",
            " [0.02324734]]\n",
            "Step: 1700 -> Loss: 0.016235530376434326 -> Predictions: [[0.0122535 ]\n",
            " [0.9855735 ]\n",
            " [0.98550564]\n",
            " [0.02320733]]\n",
            "Step: 1701 -> Loss: 0.016208957880735397 -> Predictions: [[0.01223575]\n",
            " [0.9855967 ]\n",
            " [0.9855291 ]\n",
            " [0.02316744]]\n",
            "Step: 1702 -> Loss: 0.016182485967874527 -> Predictions: [[0.01221806]\n",
            " [0.98562   ]\n",
            " [0.9855525 ]\n",
            " [0.0231277 ]]\n",
            "Step: 1703 -> Loss: 0.016156086698174477 -> Predictions: [[0.01220044]\n",
            " [0.98564315]\n",
            " [0.9855759 ]\n",
            " [0.02308808]]\n",
            "Step: 1704 -> Loss: 0.016129767522215843 -> Predictions: [[0.01218285]\n",
            " [0.98566633]\n",
            " [0.98559904]\n",
            " [0.02304859]]\n",
            "Step: 1705 -> Loss: 0.016103535890579224 -> Predictions: [[0.01216531]\n",
            " [0.9856893 ]\n",
            " [0.9856222 ]\n",
            " [0.02300921]]\n",
            "Step: 1706 -> Loss: 0.01607738621532917 -> Predictions: [[0.0121478 ]\n",
            " [0.98571235]\n",
            " [0.98564535]\n",
            " [0.02296998]]\n",
            "Step: 1707 -> Loss: 0.016051314771175385 -> Predictions: [[0.01213035]\n",
            " [0.9857351 ]\n",
            " [0.9856684 ]\n",
            " [0.02293087]]\n",
            "Step: 1708 -> Loss: 0.01602534018456936 -> Predictions: [[0.01211297]\n",
            " [0.98575795]\n",
            " [0.98569137]\n",
            " [0.02289193]]\n",
            "Step: 1709 -> Loss: 0.015999434515833855 -> Predictions: [[0.01209563]\n",
            " [0.9857808 ]\n",
            " [0.9857143 ]\n",
            " [0.02285308]]\n",
            "Step: 1710 -> Loss: 0.015973620116710663 -> Predictions: [[0.01207833]\n",
            " [0.9858035 ]\n",
            " [0.9857371 ]\n",
            " [0.02281439]]\n",
            "Step: 1711 -> Loss: 0.015947874635457993 -> Predictions: [[0.01206108]\n",
            " [0.9858261 ]\n",
            " [0.9857598 ]\n",
            " [0.02277579]]\n",
            "Step: 1712 -> Loss: 0.015922218561172485 -> Predictions: [[0.01204389]\n",
            " [0.98584855]\n",
            " [0.9857825 ]\n",
            " [0.02273733]]\n",
            "Step: 1713 -> Loss: 0.015896646305918694 -> Predictions: [[0.01202675]\n",
            " [0.985871  ]\n",
            " [0.9858051 ]\n",
            " [0.02269898]]\n",
            "Step: 1714 -> Loss: 0.01587114855647087 -> Predictions: [[0.01200965]\n",
            " [0.98589337]\n",
            " [0.98582757]\n",
            " [0.02266076]]\n",
            "Step: 1715 -> Loss: 0.015845725312829018 -> Predictions: [[0.01199258]\n",
            " [0.9859158 ]\n",
            " [0.98585004]\n",
            " [0.02262265]]\n",
            "Step: 1716 -> Loss: 0.01582038588821888 -> Predictions: [[0.01197557]\n",
            " [0.985938  ]\n",
            " [0.98587245]\n",
            " [0.02258469]]\n",
            "Step: 1717 -> Loss: 0.015795119106769562 -> Predictions: [[0.01195861]\n",
            " [0.98596025]\n",
            " [0.9858948 ]\n",
            " [0.02254683]]\n",
            "Step: 1718 -> Loss: 0.015769941732287407 -> Predictions: [[0.01194169]\n",
            " [0.98598236]\n",
            " [0.98591703]\n",
            " [0.02250911]]\n",
            "Step: 1719 -> Loss: 0.015744833275675774 -> Predictions: [[0.01192483]\n",
            " [0.9860044 ]\n",
            " [0.98593926]\n",
            " [0.0224715 ]]\n",
            "Step: 1720 -> Loss: 0.015719812363386154 -> Predictions: [[0.01190802]\n",
            " [0.9860264 ]\n",
            " [0.98596144]\n",
            " [0.02243405]]\n",
            "Step: 1721 -> Loss: 0.015694864094257355 -> Predictions: [[0.01189123]\n",
            " [0.98604834]\n",
            " [0.98598343]\n",
            " [0.02239668]]\n",
            "Step: 1722 -> Loss: 0.015669982880353928 -> Predictions: [[0.01187449]\n",
            " [0.9860701 ]\n",
            " [0.9860054 ]\n",
            " [0.02235941]]\n",
            "Step: 1723 -> Loss: 0.015645194798707962 -> Predictions: [[0.01185781]\n",
            " [0.9860919 ]\n",
            " [0.98602736]\n",
            " [0.02232231]]\n",
            "Step: 1724 -> Loss: 0.01562048215419054 -> Predictions: [[0.01184118]\n",
            " [0.9861137 ]\n",
            " [0.9860491 ]\n",
            " [0.02228529]]\n",
            "Step: 1725 -> Loss: 0.015595827251672745 -> Predictions: [[0.01182458]\n",
            " [0.98613536]\n",
            " [0.98607093]\n",
            " [0.0222484 ]]\n",
            "Step: 1726 -> Loss: 0.015571268275380135 -> Predictions: [[0.01180803]\n",
            " [0.98615694]\n",
            " [0.9860926 ]\n",
            " [0.02221165]]\n",
            "Step: 1727 -> Loss: 0.015546763315796852 -> Predictions: [[0.01179153]\n",
            " [0.9861785 ]\n",
            " [0.98611426]\n",
            " [0.02217497]]\n",
            "Step: 1728 -> Loss: 0.015522357076406479 -> Predictions: [[0.01177507]\n",
            " [0.9862    ]\n",
            " [0.98613584]\n",
            " [0.02213847]]\n",
            "Step: 1729 -> Loss: 0.015498006716370583 -> Predictions: [[0.01175867]\n",
            " [0.9862213 ]\n",
            " [0.9861574 ]\n",
            " [0.02210204]]\n",
            "Step: 1730 -> Loss: 0.0154737439006567 -> Predictions: [[0.01174231]\n",
            " [0.98624265]\n",
            " [0.9861789 ]\n",
            " [0.02206576]]\n",
            "Step: 1731 -> Loss: 0.01544955000281334 -> Predictions: [[0.01172599]\n",
            " [0.986264  ]\n",
            " [0.98620033]\n",
            " [0.02202954]]\n",
            "Step: 1732 -> Loss: 0.015425431542098522 -> Predictions: [[0.0117097]\n",
            " [0.9862852]\n",
            " [0.9862217]\n",
            " [0.0219935]]\n",
            "Step: 1733 -> Loss: 0.015401370823383331 -> Predictions: [[0.01169347]\n",
            " [0.9863063 ]\n",
            " [0.9862429 ]\n",
            " [0.02195751]]\n",
            "Step: 1734 -> Loss: 0.0153774069622159 -> Predictions: [[0.01167729]\n",
            " [0.9863274 ]\n",
            " [0.9862641 ]\n",
            " [0.02192166]]\n",
            "Step: 1735 -> Loss: 0.015353500843048096 -> Predictions: [[0.01166114]\n",
            " [0.9863484 ]\n",
            " [0.9862852 ]\n",
            " [0.02188592]]\n",
            "Step: 1736 -> Loss: 0.015329666435718536 -> Predictions: [[0.01164503]\n",
            " [0.9863694 ]\n",
            " [0.9863063 ]\n",
            " [0.0218503 ]]\n",
            "Step: 1737 -> Loss: 0.015305910259485245 -> Predictions: [[0.01162898]\n",
            " [0.98639023]\n",
            " [0.9863273 ]\n",
            " [0.02181479]]\n",
            "Step: 1738 -> Loss: 0.015282226726412773 -> Predictions: [[0.01161296]\n",
            " [0.98641104]\n",
            " [0.9863483 ]\n",
            " [0.02177941]]\n",
            "Step: 1739 -> Loss: 0.015258608385920525 -> Predictions: [[0.011597  ]\n",
            " [0.9864318 ]\n",
            " [0.98636913]\n",
            " [0.02174411]]\n",
            "Step: 1740 -> Loss: 0.015235068276524544 -> Predictions: [[0.01158106]\n",
            " [0.9864525 ]\n",
            " [0.98638994]\n",
            " [0.02170893]]\n",
            "Step: 1741 -> Loss: 0.01521159429103136 -> Predictions: [[0.01156518]\n",
            " [0.9864732 ]\n",
            " [0.9864108 ]\n",
            " [0.02167386]]\n",
            "Step: 1742 -> Loss: 0.015188202261924744 -> Predictions: [[0.01154934]\n",
            " [0.9864937 ]\n",
            " [0.9864314 ]\n",
            " [0.02163894]]\n",
            "Step: 1743 -> Loss: 0.015164868906140327 -> Predictions: [[0.01153354]\n",
            " [0.9865143 ]\n",
            " [0.9864521 ]\n",
            " [0.02160407]]\n",
            "Step: 1744 -> Loss: 0.015141603536903858 -> Predictions: [[0.01151779]\n",
            " [0.98653466]\n",
            " [0.9864726 ]\n",
            " [0.02156934]]\n",
            "Step: 1745 -> Loss: 0.015118401497602463 -> Predictions: [[0.01150205]\n",
            " [0.9865551 ]\n",
            " [0.9864932 ]\n",
            " [0.02153469]]\n",
            "Step: 1746 -> Loss: 0.01509528886526823 -> Predictions: [[0.01148639]\n",
            " [0.9865754 ]\n",
            " [0.9865137 ]\n",
            " [0.02150017]]\n",
            "Step: 1747 -> Loss: 0.015072234906256199 -> Predictions: [[0.01147076]\n",
            " [0.9865957 ]\n",
            " [0.986534  ]\n",
            " [0.02146575]]\n",
            "Step: 1748 -> Loss: 0.015049245208501816 -> Predictions: [[0.01145516]\n",
            " [0.9866159 ]\n",
            " [0.9865544 ]\n",
            " [0.02143143]]\n",
            "Step: 1749 -> Loss: 0.015026329085230827 -> Predictions: [[0.01143962]\n",
            " [0.9866361 ]\n",
            " [0.9865746 ]\n",
            " [0.02139721]]\n",
            "Step: 1750 -> Loss: 0.015003478154540062 -> Predictions: [[0.0114241 ]\n",
            " [0.9866562 ]\n",
            " [0.9865949 ]\n",
            " [0.02136311]]\n",
            "Step: 1751 -> Loss: 0.014980698935687542 -> Predictions: [[0.01140863]\n",
            " [0.9866763 ]\n",
            " [0.986615  ]\n",
            " [0.0213291 ]]\n",
            "Step: 1752 -> Loss: 0.014957984909415245 -> Predictions: [[0.01139321]\n",
            " [0.9866962 ]\n",
            " [0.986635  ]\n",
            " [0.02129522]]\n",
            "Step: 1753 -> Loss: 0.014935337007045746 -> Predictions: [[0.01137783]\n",
            " [0.98671615]\n",
            " [0.9866551 ]\n",
            " [0.02126143]]\n",
            "Step: 1754 -> Loss: 0.014912750571966171 -> Predictions: [[0.01136248]\n",
            " [0.986736  ]\n",
            " [0.9866751 ]\n",
            " [0.02122774]]\n",
            "Step: 1755 -> Loss: 0.014890230260789394 -> Predictions: [[0.01134717]\n",
            " [0.9867557 ]\n",
            " [0.98669505]\n",
            " [0.02119415]]\n",
            "Step: 1756 -> Loss: 0.014867786318063736 -> Predictions: [[0.01133191]\n",
            " [0.9867756 ]\n",
            " [0.9867149 ]\n",
            " [0.02116066]]\n",
            "Step: 1757 -> Loss: 0.014845399186015129 -> Predictions: [[0.01131669]\n",
            " [0.98679525]\n",
            " [0.98673475]\n",
            " [0.02112728]]\n",
            "Step: 1758 -> Loss: 0.014823080971837044 -> Predictions: [[0.0113015 ]\n",
            " [0.98681486]\n",
            " [0.9867545 ]\n",
            " [0.021094  ]]\n",
            "Step: 1759 -> Loss: 0.014800835400819778 -> Predictions: [[0.01128636]\n",
            " [0.98683447]\n",
            " [0.9867742 ]\n",
            " [0.02106084]]\n",
            "Step: 1760 -> Loss: 0.014778653159737587 -> Predictions: [[0.01127125]\n",
            " [0.98685396]\n",
            " [0.9867938 ]\n",
            " [0.02102777]]\n",
            "Step: 1761 -> Loss: 0.01475652027875185 -> Predictions: [[0.01125619]\n",
            " [0.98687345]\n",
            " [0.9868134 ]\n",
            " [0.02099476]]\n",
            "Step: 1762 -> Loss: 0.01473446749150753 -> Predictions: [[0.01124117]\n",
            " [0.9868929 ]\n",
            " [0.9868329 ]\n",
            " [0.02096189]]\n",
            "Step: 1763 -> Loss: 0.014712478965520859 -> Predictions: [[0.01122619]\n",
            " [0.98691225]\n",
            " [0.98685235]\n",
            " [0.02092912]]\n",
            "Step: 1764 -> Loss: 0.014690548181533813 -> Predictions: [[0.01121123]\n",
            " [0.9869315 ]\n",
            " [0.98687184]\n",
            " [0.02089646]]\n",
            "Step: 1765 -> Loss: 0.01466868445277214 -> Predictions: [[0.01119632]\n",
            " [0.9869508 ]\n",
            " [0.9868911 ]\n",
            " [0.02086387]]\n",
            "Step: 1766 -> Loss: 0.014646876603364944 -> Predictions: [[0.01118145]\n",
            " [0.98696995]\n",
            " [0.9869105 ]\n",
            " [0.02083137]]\n",
            "Step: 1767 -> Loss: 0.01462513580918312 -> Predictions: [[0.01116662]\n",
            " [0.98698914]\n",
            " [0.98692966]\n",
            " [0.02079899]]\n",
            "Step: 1768 -> Loss: 0.014603463001549244 -> Predictions: [[0.01115184]\n",
            " [0.98700815]\n",
            " [0.9869489 ]\n",
            " [0.02076672]]\n",
            "Step: 1769 -> Loss: 0.014581847935914993 -> Predictions: [[0.01113709]\n",
            " [0.9870272 ]\n",
            " [0.986968  ]\n",
            " [0.0207345 ]]\n",
            "Step: 1770 -> Loss: 0.01456029899418354 -> Predictions: [[0.01112237]\n",
            " [0.9870461 ]\n",
            " [0.9869871 ]\n",
            " [0.02070243]]\n",
            "Step: 1771 -> Loss: 0.014538816176354885 -> Predictions: [[0.01110769]\n",
            " [0.9870651 ]\n",
            " [0.9870062 ]\n",
            " [0.02067043]]\n",
            "Step: 1772 -> Loss: 0.014517383649945259 -> Predictions: [[0.01109302]\n",
            " [0.9870839 ]\n",
            " [0.98702514]\n",
            " [0.02063852]]\n",
            "Step: 1773 -> Loss: 0.01449601911008358 -> Predictions: [[0.01107844]\n",
            " [0.9871027 ]\n",
            " [0.98704404]\n",
            " [0.02060671]]\n",
            "Step: 1774 -> Loss: 0.014474712312221527 -> Predictions: [[0.01106386]\n",
            " [0.9871215 ]\n",
            " [0.9870629 ]\n",
            " [0.02057498]]\n",
            "Step: 1775 -> Loss: 0.014453471638262272 -> Predictions: [[0.01104933]\n",
            " [0.9871401 ]\n",
            " [0.98708165]\n",
            " [0.02054336]]\n",
            "Step: 1776 -> Loss: 0.014432292431592941 -> Predictions: [[0.01103485]\n",
            " [0.9871588 ]\n",
            " [0.98710036]\n",
            " [0.02051184]]\n",
            "Step: 1777 -> Loss: 0.014411170035600662 -> Predictions: [[0.01102039]\n",
            " [0.9871774 ]\n",
            " [0.9871191 ]\n",
            " [0.02048042]]\n",
            "Step: 1778 -> Loss: 0.014390110969543457 -> Predictions: [[0.01100596]\n",
            " [0.98719597]\n",
            " [0.9871378 ]\n",
            " [0.02044909]]\n",
            "Step: 1779 -> Loss: 0.014369108714163303 -> Predictions: [[0.01099159]\n",
            " [0.98721445]\n",
            " [0.9871564 ]\n",
            " [0.02041783]]\n",
            "Step: 1780 -> Loss: 0.014348175376653671 -> Predictions: [[0.01097725]\n",
            " [0.9872328 ]\n",
            " [0.9871749 ]\n",
            " [0.02038671]]\n",
            "Step: 1781 -> Loss: 0.014327287673950195 -> Predictions: [[0.01096292]\n",
            " [0.9872513 ]\n",
            " [0.9871934 ]\n",
            " [0.02035564]]\n",
            "Step: 1782 -> Loss: 0.014306459575891495 -> Predictions: [[0.01094866]\n",
            " [0.98726964]\n",
            " [0.9872119 ]\n",
            " [0.02032465]]\n",
            "Step: 1783 -> Loss: 0.014285702258348465 -> Predictions: [[0.01093441]\n",
            " [0.9872879 ]\n",
            " [0.98723024]\n",
            " [0.02029379]]\n",
            "Step: 1784 -> Loss: 0.014264993369579315 -> Predictions: [[0.01092022]\n",
            " [0.9873061 ]\n",
            " [0.9872486 ]\n",
            " [0.02026301]]\n",
            "Step: 1785 -> Loss: 0.014244348742067814 -> Predictions: [[0.01090606]\n",
            " [0.98732424]\n",
            " [0.98726684]\n",
            " [0.0202323 ]]\n",
            "Step: 1786 -> Loss: 0.014223754405975342 -> Predictions: [[0.01089193]\n",
            " [0.98734236]\n",
            " [0.9872851 ]\n",
            " [0.02020168]]\n",
            "Step: 1787 -> Loss: 0.014203221537172794 -> Predictions: [[0.01087785]\n",
            " [0.98736054]\n",
            " [0.9873033 ]\n",
            " [0.02017114]]\n",
            "Step: 1788 -> Loss: 0.014182751066982746 -> Predictions: [[0.01086381]\n",
            " [0.98737854]\n",
            " [0.98732144]\n",
            " [0.02014071]]\n",
            "Step: 1789 -> Loss: 0.014162329956889153 -> Predictions: [[0.01084977]\n",
            " [0.98739654]\n",
            " [0.9873395 ]\n",
            " [0.02011036]]\n",
            "Step: 1790 -> Loss: 0.01414197962731123 -> Predictions: [[0.0108358 ]\n",
            " [0.9874144 ]\n",
            " [0.9873576 ]\n",
            " [0.02008014]]\n",
            "Step: 1791 -> Loss: 0.014121683314442635 -> Predictions: [[0.01082187]\n",
            " [0.98743236]\n",
            " [0.9873755 ]\n",
            " [0.02004997]]\n",
            "Step: 1792 -> Loss: 0.014101436361670494 -> Predictions: [[0.01080796]\n",
            " [0.9874501 ]\n",
            " [0.9873934 ]\n",
            " [0.02001987]]\n",
            "Step: 1793 -> Loss: 0.014081239700317383 -> Predictions: [[0.01079407]\n",
            " [0.9874679 ]\n",
            " [0.9874113 ]\n",
            " [0.01998989]]\n",
            "Step: 1794 -> Loss: 0.014061115682125092 -> Predictions: [[0.01078024]\n",
            " [0.9874857 ]\n",
            " [0.9874292 ]\n",
            " [0.01996   ]]\n",
            "Step: 1795 -> Loss: 0.014041032642126083 -> Predictions: [[0.01076642]\n",
            " [0.98750335]\n",
            " [0.98744696]\n",
            " [0.01993017]]\n",
            "Step: 1796 -> Loss: 0.014021014794707298 -> Predictions: [[0.01075263]\n",
            " [0.98752093]\n",
            " [0.98746467]\n",
            " [0.01990044]]\n",
            "Step: 1797 -> Loss: 0.014001051895320415 -> Predictions: [[0.01073891]\n",
            " [0.9875386 ]\n",
            " [0.9874824 ]\n",
            " [0.0198708 ]]\n",
            "Step: 1798 -> Loss: 0.01398114301264286 -> Predictions: [[0.01072522]\n",
            " [0.98755616]\n",
            " [0.9875    ]\n",
            " [0.01984124]]\n",
            "Step: 1799 -> Loss: 0.013961288146674633 -> Predictions: [[0.01071155]\n",
            " [0.98757356]\n",
            " [0.98751765]\n",
            " [0.01981176]]\n",
            "Step: 1800 -> Loss: 0.013941492885351181 -> Predictions: [[0.01069792]\n",
            " [0.987591  ]\n",
            " [0.98753524]\n",
            " [0.01978237]]\n",
            "Step: 1801 -> Loss: 0.01392175443470478 -> Predictions: [[0.0106843 ]\n",
            " [0.98760843]\n",
            " [0.98755264]\n",
            " [0.01975308]]\n",
            "Step: 1802 -> Loss: 0.013902056962251663 -> Predictions: [[0.01067073]\n",
            " [0.9876258 ]\n",
            " [0.9875701 ]\n",
            " [0.01972383]]\n",
            "Step: 1803 -> Loss: 0.013882428407669067 -> Predictions: [[0.01065721]\n",
            " [0.9876431 ]\n",
            " [0.9875875 ]\n",
            " [0.01969469]]\n",
            "Step: 1804 -> Loss: 0.013862842693924904 -> Predictions: [[0.0106437 ]\n",
            " [0.98766035]\n",
            " [0.98760486]\n",
            " [0.01966563]]\n",
            "Step: 1805 -> Loss: 0.01384331937879324 -> Predictions: [[0.01063024]\n",
            " [0.9876775 ]\n",
            " [0.9876222 ]\n",
            " [0.01963667]]\n",
            "Step: 1806 -> Loss: 0.013823840767145157 -> Predictions: [[0.0106168 ]\n",
            " [0.98769474]\n",
            " [0.98763937]\n",
            " [0.01960776]]\n",
            "Step: 1807 -> Loss: 0.013804426416754723 -> Predictions: [[0.01060341]\n",
            " [0.98771185]\n",
            " [0.9876566 ]\n",
            " [0.01957897]]\n",
            "Step: 1808 -> Loss: 0.013785060495138168 -> Predictions: [[0.01059004]\n",
            " [0.98772883]\n",
            " [0.9876738 ]\n",
            " [0.01955024]]\n",
            "Step: 1809 -> Loss: 0.013765743002295494 -> Predictions: [[0.01057671]\n",
            " [0.98774594]\n",
            " [0.9876909 ]\n",
            " [0.01952161]]\n",
            "Step: 1810 -> Loss: 0.013746481388807297 -> Predictions: [[0.0105634 ]\n",
            " [0.98776287]\n",
            " [0.987708  ]\n",
            " [0.01949303]]\n",
            "Step: 1811 -> Loss: 0.01372726820409298 -> Predictions: [[0.01055013]\n",
            " [0.98777974]\n",
            " [0.98772496]\n",
            " [0.01946454]]\n",
            "Step: 1812 -> Loss: 0.013708112761378288 -> Predictions: [[0.0105369 ]\n",
            " [0.9877966 ]\n",
            " [0.98774195]\n",
            " [0.01943613]]\n",
            "Step: 1813 -> Loss: 0.013689011335372925 -> Predictions: [[0.01052369]\n",
            " [0.9878135 ]\n",
            " [0.98775893]\n",
            " [0.01940781]]\n",
            "Step: 1814 -> Loss: 0.01366996206343174 -> Predictions: [[0.01051051]\n",
            " [0.9878302 ]\n",
            " [0.9877758 ]\n",
            " [0.01937958]]\n",
            "Step: 1815 -> Loss: 0.013650951907038689 -> Predictions: [[0.01049737]\n",
            " [0.987847  ]\n",
            " [0.9877927 ]\n",
            " [0.01935139]]\n",
            "Step: 1816 -> Loss: 0.013632013462483883 -> Predictions: [[0.01048426]\n",
            " [0.9878637 ]\n",
            " [0.9878094 ]\n",
            " [0.01932332]]\n",
            "Step: 1817 -> Loss: 0.013613111339509487 -> Predictions: [[0.0104712 ]\n",
            " [0.9878804 ]\n",
            " [0.98782617]\n",
            " [0.01929531]]\n",
            "Step: 1818 -> Loss: 0.013594267889857292 -> Predictions: [[0.01045814]\n",
            " [0.98789704]\n",
            " [0.9878429 ]\n",
            " [0.01926739]]\n",
            "Step: 1819 -> Loss: 0.013575462624430656 -> Predictions: [[0.01044513]\n",
            " [0.98791355]\n",
            " [0.98785955]\n",
            " [0.01923955]]\n",
            "Step: 1820 -> Loss: 0.013556724414229393 -> Predictions: [[0.01043215]\n",
            " [0.98793006]\n",
            " [0.9878762 ]\n",
            " [0.0192118 ]]\n",
            "Step: 1821 -> Loss: 0.013538018800318241 -> Predictions: [[0.0104192 ]\n",
            " [0.98794657]\n",
            " [0.9878928 ]\n",
            " [0.01918408]]\n",
            "Step: 1822 -> Loss: 0.013519376516342163 -> Predictions: [[0.01040629]\n",
            " [0.98796296]\n",
            " [0.9879094 ]\n",
            " [0.01915647]]\n",
            "Step: 1823 -> Loss: 0.013500786386430264 -> Predictions: [[0.0103934 ]\n",
            " [0.9879794 ]\n",
            " [0.9879259 ]\n",
            " [0.01912893]]\n",
            "Step: 1824 -> Loss: 0.013482246547937393 -> Predictions: [[0.01038054]\n",
            " [0.9879958 ]\n",
            " [0.9879423 ]\n",
            " [0.01910147]]\n",
            "Step: 1825 -> Loss: 0.013463744893670082 -> Predictions: [[0.0103677 ]\n",
            " [0.9880121 ]\n",
            " [0.98795867]\n",
            " [0.01907407]]\n",
            "Step: 1826 -> Loss: 0.013445302844047546 -> Predictions: [[0.01035492]\n",
            " [0.9880283 ]\n",
            " [0.987975  ]\n",
            " [0.01904676]]\n",
            "Step: 1827 -> Loss: 0.013426907360553741 -> Predictions: [[0.01034215]\n",
            " [0.98804456]\n",
            " [0.9879913 ]\n",
            " [0.01901951]]\n",
            "Step: 1828 -> Loss: 0.013408564031124115 -> Predictions: [[0.01032942]\n",
            " [0.9880607 ]\n",
            " [0.98800755]\n",
            " [0.01899236]]\n",
            "Step: 1829 -> Loss: 0.01339026726782322 -> Predictions: [[0.01031671]\n",
            " [0.9880768 ]\n",
            " [0.9880238 ]\n",
            " [0.01896527]]\n",
            "Step: 1830 -> Loss: 0.013372024521231651 -> Predictions: [[0.01030406]\n",
            " [0.98809284]\n",
            " [0.9880399 ]\n",
            " [0.01893826]]\n",
            "Step: 1831 -> Loss: 0.013353820890188217 -> Predictions: [[0.01029143]\n",
            " [0.98810893]\n",
            " [0.98805606]\n",
            " [0.01891132]]\n",
            "Step: 1832 -> Loss: 0.013335667550563812 -> Predictions: [[0.01027883]\n",
            " [0.98812497]\n",
            " [0.9880723 ]\n",
            " [0.01888446]]\n",
            "Step: 1833 -> Loss: 0.013317566365003586 -> Predictions: [[0.01026627]\n",
            " [0.98814094]\n",
            " [0.9880883 ]\n",
            " [0.01885769]]\n",
            "Step: 1834 -> Loss: 0.013299505226314068 -> Predictions: [[0.01025371]\n",
            " [0.98815686]\n",
            " [0.9881043 ]\n",
            " [0.01883096]]\n",
            "Step: 1835 -> Loss: 0.013281498104333878 -> Predictions: [[0.0102412 ]\n",
            " [0.9881727 ]\n",
            " [0.9881203 ]\n",
            " [0.01880429]]\n",
            "Step: 1836 -> Loss: 0.013263542205095291 -> Predictions: [[0.01022871]\n",
            " [0.98818856]\n",
            " [0.9881362 ]\n",
            " [0.01877774]]\n",
            "Step: 1837 -> Loss: 0.013245628215372562 -> Predictions: [[0.01021625]\n",
            " [0.98820436]\n",
            " [0.9881521 ]\n",
            " [0.01875125]]\n",
            "Step: 1838 -> Loss: 0.013227758929133415 -> Predictions: [[0.01020383]\n",
            " [0.9882201 ]\n",
            " [0.98816794]\n",
            " [0.01872482]]\n",
            "Step: 1839 -> Loss: 0.013209938071668148 -> Predictions: [[0.01019143]\n",
            " [0.98823583]\n",
            " [0.9881838 ]\n",
            " [0.01869847]]\n",
            "Step: 1840 -> Loss: 0.013192170299589634 -> Predictions: [[0.01017908]\n",
            " [0.9882515 ]\n",
            " [0.9881995 ]\n",
            " [0.01867222]]\n",
            "Step: 1841 -> Loss: 0.01317443884909153 -> Predictions: [[0.01016672]\n",
            " [0.9882671 ]\n",
            " [0.9882152 ]\n",
            " [0.01864599]]\n",
            "Step: 1842 -> Loss: 0.013156767934560776 -> Predictions: [[0.01015441]\n",
            " [0.98828274]\n",
            " [0.98823094]\n",
            " [0.01861988]]\n",
            "Step: 1843 -> Loss: 0.013139137998223305 -> Predictions: [[0.01014215]\n",
            " [0.9882983 ]\n",
            " [0.9882465 ]\n",
            " [0.01859381]]\n",
            "Step: 1844 -> Loss: 0.013121550902724266 -> Predictions: [[0.01012989]\n",
            " [0.9883138 ]\n",
            " [0.9882621 ]\n",
            " [0.01856781]]\n",
            "Step: 1845 -> Loss: 0.013104011304676533 -> Predictions: [[0.01011767]\n",
            " [0.9883293 ]\n",
            " [0.98827773]\n",
            " [0.01854187]]\n",
            "Step: 1846 -> Loss: 0.01308651827275753 -> Predictions: [[0.01010548]\n",
            " [0.98834467]\n",
            " [0.98829323]\n",
            " [0.01851602]]\n",
            "Step: 1847 -> Loss: 0.013069065287709236 -> Predictions: [[0.01009331]\n",
            " [0.98836005]\n",
            " [0.98830867]\n",
            " [0.01849024]]\n",
            "Step: 1848 -> Loss: 0.013051662594079971 -> Predictions: [[0.01008118]\n",
            " [0.9883754 ]\n",
            " [0.98832417]\n",
            " [0.01846451]]\n",
            "Step: 1849 -> Loss: 0.013034306466579437 -> Predictions: [[0.01006908]\n",
            " [0.9883908 ]\n",
            " [0.98833954]\n",
            " [0.01843887]]\n",
            "Step: 1850 -> Loss: 0.013017000630497932 -> Predictions: [[0.010057  ]\n",
            " [0.98840606]\n",
            " [0.9883549 ]\n",
            " [0.01841333]]\n",
            "Step: 1851 -> Loss: 0.012999728322029114 -> Predictions: [[0.01004494]\n",
            " [0.9884213 ]\n",
            " [0.9883702 ]\n",
            " [0.01838779]]\n",
            "Step: 1852 -> Loss: 0.012982497923076153 -> Predictions: [[0.01003292]\n",
            " [0.98843646]\n",
            " [0.98838556]\n",
            " [0.01836236]]\n",
            "Step: 1853 -> Loss: 0.012965323403477669 -> Predictions: [[0.01002094]\n",
            " [0.9884516 ]\n",
            " [0.9884008 ]\n",
            " [0.01833698]]\n",
            "Step: 1854 -> Loss: 0.012948192656040192 -> Predictions: [[0.01000897]\n",
            " [0.98846674]\n",
            " [0.98841596]\n",
            " [0.0183117 ]]\n",
            "Step: 1855 -> Loss: 0.01293109729886055 -> Predictions: [[0.00999704]\n",
            " [0.9884819 ]\n",
            " [0.9884311 ]\n",
            " [0.01828644]]\n",
            "Step: 1856 -> Loss: 0.012914050370454788 -> Predictions: [[0.00998513]\n",
            " [0.9884969 ]\n",
            " [0.98844624]\n",
            " [0.01826127]]\n",
            "Step: 1857 -> Loss: 0.012897045351564884 -> Predictions: [[0.00997325]\n",
            " [0.9885119 ]\n",
            " [0.9884614 ]\n",
            " [0.01823617]]\n",
            "Step: 1858 -> Loss: 0.01288008876144886 -> Predictions: [[0.00996141]\n",
            " [0.9885268 ]\n",
            " [0.9884764 ]\n",
            " [0.01821113]]\n",
            "Step: 1859 -> Loss: 0.012863174080848694 -> Predictions: [[0.00994958]\n",
            " [0.9885417 ]\n",
            " [0.9884914 ]\n",
            " [0.01818617]]\n",
            "Step: 1860 -> Loss: 0.01284630224108696 -> Predictions: [[0.00993777]\n",
            " [0.9885566 ]\n",
            " [0.98850644]\n",
            " [0.01816127]]\n",
            "Step: 1861 -> Loss: 0.012829470448195934 -> Predictions: [[0.00992601]\n",
            " [0.98857147]\n",
            " [0.98852134]\n",
            " [0.01813642]]\n",
            "Step: 1862 -> Loss: 0.01281268335878849 -> Predictions: [[0.00991426]\n",
            " [0.98858637]\n",
            " [0.98853624]\n",
            " [0.01811166]]\n",
            "Step: 1863 -> Loss: 0.012795941904187202 -> Predictions: [[0.00990253]\n",
            " [0.988601  ]\n",
            " [0.9885511 ]\n",
            " [0.01808695]]\n",
            "Step: 1864 -> Loss: 0.012779245153069496 -> Predictions: [[0.00989085]\n",
            " [0.9886158 ]\n",
            " [0.98856586]\n",
            " [0.01806232]]\n",
            "Step: 1865 -> Loss: 0.012762581929564476 -> Predictions: [[0.00987919]\n",
            " [0.98863053]\n",
            " [0.98858064]\n",
            " [0.01803773]]\n",
            "Step: 1866 -> Loss: 0.012745971791446209 -> Predictions: [[0.00986755]\n",
            " [0.9886452 ]\n",
            " [0.9885954 ]\n",
            " [0.01801323]]\n",
            "Step: 1867 -> Loss: 0.012729402631521225 -> Predictions: [[0.00985595]\n",
            " [0.98865974]\n",
            " [0.98861015]\n",
            " [0.01798879]]\n",
            "Step: 1868 -> Loss: 0.012712872587144375 -> Predictions: [[0.00984437]\n",
            " [0.98867434]\n",
            " [0.9886248 ]\n",
            " [0.01796438]]\n",
            "Step: 1869 -> Loss: 0.012696372345089912 -> Predictions: [[0.00983279]\n",
            " [0.9886889 ]\n",
            " [0.9886395 ]\n",
            " [0.01794007]]\n",
            "Step: 1870 -> Loss: 0.012679931707680225 -> Predictions: [[0.00982126]\n",
            " [0.9887034 ]\n",
            " [0.9886541 ]\n",
            " [0.01791582]]\n",
            "Step: 1871 -> Loss: 0.012663530185818672 -> Predictions: [[0.00980977]\n",
            " [0.9887179 ]\n",
            " [0.9886686 ]\n",
            " [0.01789163]]\n",
            "Step: 1872 -> Loss: 0.012647159397602081 -> Predictions: [[0.0097983 ]\n",
            " [0.98873234]\n",
            " [0.98868316]\n",
            " [0.01786748]]\n",
            "Step: 1873 -> Loss: 0.01263083890080452 -> Predictions: [[0.00978686]\n",
            " [0.9887468 ]\n",
            " [0.98869765]\n",
            " [0.01784342]]\n",
            "Step: 1874 -> Loss: 0.012614558450877666 -> Predictions: [[0.00977543]\n",
            " [0.9887611 ]\n",
            " [0.9887121 ]\n",
            " [0.01781944]]\n",
            "Step: 1875 -> Loss: 0.012598318047821522 -> Predictions: [[0.00976404]\n",
            " [0.9887755 ]\n",
            " [0.98872656]\n",
            " [0.01779549]]\n",
            "Step: 1876 -> Loss: 0.012582122348248959 -> Predictions: [[0.00975268]\n",
            " [0.9887898 ]\n",
            " [0.98874086]\n",
            " [0.01777163]]\n",
            "Step: 1877 -> Loss: 0.012565962970256805 -> Predictions: [[0.00974132]\n",
            " [0.98880404]\n",
            " [0.9887552 ]\n",
            " [0.01774781]]\n",
            "Step: 1878 -> Loss: 0.01254984363913536 -> Predictions: [[0.00973   ]\n",
            " [0.9888182 ]\n",
            " [0.98876953]\n",
            " [0.01772407]]\n",
            "Step: 1879 -> Loss: 0.012533765286207199 -> Predictions: [[0.0097187 ]\n",
            " [0.9888325 ]\n",
            " [0.9887839 ]\n",
            " [0.01770038]]\n",
            "Step: 1880 -> Loss: 0.012517725117504597 -> Predictions: [[0.00970746]\n",
            " [0.9888467 ]\n",
            " [0.9887981 ]\n",
            " [0.01767674]]\n",
            "Step: 1881 -> Loss: 0.012501727789640427 -> Predictions: [[0.00969619]\n",
            " [0.9888608 ]\n",
            " [0.9888122 ]\n",
            " [0.01765317]]\n",
            "Step: 1882 -> Loss: 0.012485770508646965 -> Predictions: [[0.00968499]\n",
            " [0.9888749 ]\n",
            " [0.9888264 ]\n",
            " [0.01762966]]\n",
            "Step: 1883 -> Loss: 0.012469856068491936 -> Predictions: [[0.00967379]\n",
            " [0.9888889 ]\n",
            " [0.9888405 ]\n",
            " [0.01760622]]\n",
            "Step: 1884 -> Loss: 0.012453977018594742 -> Predictions: [[0.00966263]\n",
            " [0.98890287]\n",
            " [0.98885465]\n",
            " [0.01758283]]\n",
            "Step: 1885 -> Loss: 0.012438137084245682 -> Predictions: [[0.00965149]\n",
            " [0.9889169 ]\n",
            " [0.9888687 ]\n",
            " [0.01755949]]\n",
            "Step: 1886 -> Loss: 0.01242233905941248 -> Predictions: [[0.00964038]\n",
            " [0.9889309 ]\n",
            " [0.9888827 ]\n",
            " [0.01753623]]\n",
            "Step: 1887 -> Loss: 0.012406573630869389 -> Predictions: [[0.00962929]\n",
            " [0.9889447 ]\n",
            " [0.9888967 ]\n",
            " [0.01751303]]\n",
            "Step: 1888 -> Loss: 0.012390855699777603 -> Predictions: [[0.00961824]\n",
            " [0.9889586 ]\n",
            " [0.9889107 ]\n",
            " [0.01748988]]\n",
            "Step: 1889 -> Loss: 0.012375172227621078 -> Predictions: [[0.00960718]\n",
            " [0.9889725 ]\n",
            " [0.9889247 ]\n",
            " [0.0174668 ]]\n",
            "Step: 1890 -> Loss: 0.012359531596302986 -> Predictions: [[0.00959617]\n",
            " [0.9889864 ]\n",
            " [0.98893857]\n",
            " [0.01744378]]\n",
            "Step: 1891 -> Loss: 0.012343920767307281 -> Predictions: [[0.00958518]\n",
            " [0.98900014]\n",
            " [0.98895246]\n",
            " [0.01742081]]\n",
            "Step: 1892 -> Loss: 0.012328360229730606 -> Predictions: [[0.00957421]\n",
            " [0.98901385]\n",
            " [0.98896617]\n",
            " [0.0173979 ]]\n",
            "Step: 1893 -> Loss: 0.012312833219766617 -> Predictions: [[0.00956328]\n",
            " [0.9890275 ]\n",
            " [0.98897994]\n",
            " [0.01737504]]\n",
            "Step: 1894 -> Loss: 0.012297342531383038 -> Predictions: [[0.00955235]\n",
            " [0.98904127]\n",
            " [0.9889937 ]\n",
            " [0.01735227]]\n",
            "Step: 1895 -> Loss: 0.012281888164579868 -> Predictions: [[0.00954147]\n",
            " [0.9890549 ]\n",
            " [0.9890075 ]\n",
            " [0.01732951]]\n",
            "Step: 1896 -> Loss: 0.012266485951840878 -> Predictions: [[0.00953061]\n",
            " [0.98906845]\n",
            " [0.9890211 ]\n",
            " [0.01730687]]\n",
            "Step: 1897 -> Loss: 0.012251097708940506 -> Predictions: [[0.00951976]\n",
            " [0.9890821 ]\n",
            " [0.9890349 ]\n",
            " [0.01728423]]\n",
            "Step: 1898 -> Loss: 0.01223576720803976 -> Predictions: [[0.00950893]\n",
            " [0.9890956 ]\n",
            " [0.9890484 ]\n",
            " [0.01726167]]\n",
            "Step: 1899 -> Loss: 0.012220468372106552 -> Predictions: [[0.00949815]\n",
            " [0.98910916]\n",
            " [0.989062  ]\n",
            " [0.01723916]]\n",
            "Step: 1900 -> Loss: 0.012205207720398903 -> Predictions: [[0.00948738]\n",
            " [0.98912257]\n",
            " [0.98907554]\n",
            " [0.01721672]]\n",
            "Step: 1901 -> Loss: 0.012189971283078194 -> Predictions: [[0.00947664]\n",
            " [0.9891361 ]\n",
            " [0.9890891 ]\n",
            " [0.01719431]]\n",
            "Step: 1902 -> Loss: 0.012174786999821663 -> Predictions: [[0.00946592]\n",
            " [0.9891495 ]\n",
            " [0.9891026 ]\n",
            " [0.01717199]]\n",
            "Step: 1903 -> Loss: 0.012159628793597221 -> Predictions: [[0.00945522]\n",
            " [0.9891629 ]\n",
            " [0.989116  ]\n",
            " [0.01714971]]\n",
            "Step: 1904 -> Loss: 0.01214451901614666 -> Predictions: [[0.00944454]\n",
            " [0.9891762 ]\n",
            " [0.9891294 ]\n",
            " [0.01712748]]\n",
            "Step: 1905 -> Loss: 0.012129439041018486 -> Predictions: [[0.00943389]\n",
            " [0.9891895 ]\n",
            " [0.98914284]\n",
            " [0.01710532]]\n",
            "Step: 1906 -> Loss: 0.01211440097540617 -> Predictions: [[0.00942328]\n",
            " [0.9892028 ]\n",
            " [0.98915625]\n",
            " [0.0170832 ]]\n",
            "Step: 1907 -> Loss: 0.012099392712116241 -> Predictions: [[0.00941265]\n",
            " [0.9892161 ]\n",
            " [0.98916954]\n",
            " [0.01706114]]\n",
            "Step: 1908 -> Loss: 0.01208442635834217 -> Predictions: [[0.00940207]\n",
            " [0.98922926]\n",
            " [0.9891829 ]\n",
            " [0.01703914]]\n",
            "Step: 1909 -> Loss: 0.012069489806890488 -> Predictions: [[0.00939151]\n",
            " [0.9892425 ]\n",
            " [0.9891962 ]\n",
            " [0.01701721]]\n",
            "Step: 1910 -> Loss: 0.01205459889024496 -> Predictions: [[0.00938099]\n",
            " [0.98925567]\n",
            " [0.98920935]\n",
            " [0.01699531]]\n",
            "Step: 1911 -> Loss: 0.012039730325341225 -> Predictions: [[0.00937047]\n",
            " [0.98926884]\n",
            " [0.9892225 ]\n",
            " [0.01697347]]\n",
            "Step: 1912 -> Loss: 0.012024911120533943 -> Predictions: [[0.00935999]\n",
            " [0.9892819 ]\n",
            " [0.9892357 ]\n",
            " [0.01695169]]\n",
            "Step: 1913 -> Loss: 0.012010125443339348 -> Predictions: [[0.00934953]\n",
            " [0.98929495]\n",
            " [0.9892489 ]\n",
            " [0.01692995]]\n",
            "Step: 1914 -> Loss: 0.011995363980531693 -> Predictions: [[0.00933907]\n",
            " [0.98930806]\n",
            " [0.989262  ]\n",
            " [0.01690828]]\n",
            "Step: 1915 -> Loss: 0.011980649083852768 -> Predictions: [[0.00932867]\n",
            " [0.989321  ]\n",
            " [0.98927516]\n",
            " [0.01688666]]\n",
            "Step: 1916 -> Loss: 0.01196596771478653 -> Predictions: [[0.00931827]\n",
            " [0.9893339 ]\n",
            " [0.9892881 ]\n",
            " [0.01686509]]\n",
            "Step: 1917 -> Loss: 0.011951318010687828 -> Predictions: [[0.0093079 ]\n",
            " [0.9893469 ]\n",
            " [0.98930115]\n",
            " [0.01684357]]\n",
            "Step: 1918 -> Loss: 0.01193670742213726 -> Predictions: [[0.00929754]\n",
            " [0.98935986]\n",
            " [0.9893141 ]\n",
            " [0.01682212]]\n",
            "Step: 1919 -> Loss: 0.01192212849855423 -> Predictions: [[0.00928721]\n",
            " [0.9893727 ]\n",
            " [0.9893271 ]\n",
            " [0.01680071]]\n",
            "Step: 1920 -> Loss: 0.011907583102583885 -> Predictions: [[0.00927691]\n",
            " [0.98938555]\n",
            " [0.98934   ]\n",
            " [0.01677936]]\n",
            "Step: 1921 -> Loss: 0.011893077753484249 -> Predictions: [[0.00926663]\n",
            " [0.98939836]\n",
            " [0.98935294]\n",
            " [0.01675808]]\n",
            "Step: 1922 -> Loss: 0.01187860406935215 -> Predictions: [[0.00925636]\n",
            " [0.9894112 ]\n",
            " [0.9893658 ]\n",
            " [0.01673683]]\n",
            "Step: 1923 -> Loss: 0.011864171363413334 -> Predictions: [[0.00924613]\n",
            " [0.98942393]\n",
            " [0.98937863]\n",
            " [0.01671563]]\n",
            "Step: 1924 -> Loss: 0.011849766597151756 -> Predictions: [[0.00923593]\n",
            " [0.9894366 ]\n",
            " [0.9893913 ]\n",
            " [0.01669448]]\n",
            "Step: 1925 -> Loss: 0.011835389770567417 -> Predictions: [[0.00922573]\n",
            " [0.9894493 ]\n",
            " [0.9894042 ]\n",
            " [0.01667339]]\n",
            "Step: 1926 -> Loss: 0.01182105764746666 -> Predictions: [[0.00921555]\n",
            " [0.9894621 ]\n",
            " [0.9894169 ]\n",
            " [0.01665235]]\n",
            "Step: 1927 -> Loss: 0.011806742288172245 -> Predictions: [[0.00920539]\n",
            " [0.98947465]\n",
            " [0.98942965]\n",
            " [0.01663134]]\n",
            "Step: 1928 -> Loss: 0.011792482808232307 -> Predictions: [[0.00919528]\n",
            " [0.9894873 ]\n",
            " [0.9894422 ]\n",
            " [0.0166104 ]]\n",
            "Step: 1929 -> Loss: 0.011778246611356735 -> Predictions: [[0.00918517]\n",
            " [0.98949987]\n",
            " [0.9894549 ]\n",
            " [0.01658953]]\n",
            "Step: 1930 -> Loss: 0.01176404394209385 -> Predictions: [[0.00917508]\n",
            " [0.9895124 ]\n",
            " [0.98946756]\n",
            " [0.01656869]]\n",
            "Step: 1931 -> Loss: 0.011749876663088799 -> Predictions: [[0.00916501]\n",
            " [0.98952484]\n",
            " [0.98948014]\n",
            " [0.01654789]]\n",
            "Step: 1932 -> Loss: 0.011735741049051285 -> Predictions: [[0.00915497]\n",
            " [0.9895375 ]\n",
            " [0.9894928 ]\n",
            " [0.01652717]]\n",
            "Step: 1933 -> Loss: 0.011721642687916756 -> Predictions: [[0.00914496]\n",
            " [0.9895499 ]\n",
            " [0.98950523]\n",
            " [0.01650647]]\n",
            "Step: 1934 -> Loss: 0.011707562953233719 -> Predictions: [[0.00913495]\n",
            " [0.98956233]\n",
            " [0.98951775]\n",
            " [0.01648582]]\n",
            "Step: 1935 -> Loss: 0.011693529784679413 -> Predictions: [[0.00912497]\n",
            " [0.98957473]\n",
            " [0.98953027]\n",
            " [0.01646524]]\n",
            "Step: 1936 -> Loss: 0.011679530143737793 -> Predictions: [[0.00911502]\n",
            " [0.98958707]\n",
            " [0.9895427 ]\n",
            " [0.01644471]]\n",
            "Step: 1937 -> Loss: 0.011665558442473412 -> Predictions: [[0.00910509]\n",
            " [0.98959947]\n",
            " [0.9895551 ]\n",
            " [0.01642421]]\n",
            "Step: 1938 -> Loss: 0.01165162306278944 -> Predictions: [[0.00909518]\n",
            " [0.98961174]\n",
            " [0.98956746]\n",
            " [0.01640377]]\n",
            "Step: 1939 -> Loss: 0.01163772214204073 -> Predictions: [[0.00908528]\n",
            " [0.9896241 ]\n",
            " [0.98957986]\n",
            " [0.01638341]]\n",
            "Step: 1940 -> Loss: 0.01162385381758213 -> Predictions: [[0.00907541]\n",
            " [0.98963636]\n",
            " [0.9895921 ]\n",
            " [0.01636308]]\n",
            "Step: 1941 -> Loss: 0.011610003188252449 -> Predictions: [[0.00906556]\n",
            " [0.98964864]\n",
            " [0.9896045 ]\n",
            " [0.01634276]]\n",
            "Step: 1942 -> Loss: 0.011596198193728924 -> Predictions: [[0.00905574]\n",
            " [0.98966074]\n",
            " [0.98961675]\n",
            " [0.01632253]]\n",
            "Step: 1943 -> Loss: 0.01158242765814066 -> Predictions: [[0.00904592]\n",
            " [0.9896729 ]\n",
            " [0.989629  ]\n",
            " [0.01630235]]\n",
            "Step: 1944 -> Loss: 0.011568686924874783 -> Predictions: [[0.00903613]\n",
            " [0.98968506]\n",
            " [0.98964125]\n",
            " [0.01628222]]\n",
            "Step: 1945 -> Loss: 0.01155497319996357 -> Predictions: [[0.00902636]\n",
            " [0.98969716]\n",
            " [0.9896534 ]\n",
            " [0.01626212]]\n",
            "Step: 1946 -> Loss: 0.011541293002665043 -> Predictions: [[0.00901664]\n",
            " [0.9897093 ]\n",
            " [0.98966557]\n",
            " [0.01624207]]\n",
            "Step: 1947 -> Loss: 0.011527644470334053 -> Predictions: [[0.00900691]\n",
            " [0.98972136]\n",
            " [0.98967767]\n",
            " [0.01622207]]\n",
            "Step: 1948 -> Loss: 0.011514026671648026 -> Predictions: [[0.00899721]\n",
            " [0.9897334 ]\n",
            " [0.9896898 ]\n",
            " [0.01620214]]\n",
            "Step: 1949 -> Loss: 0.011500444263219833 -> Predictions: [[0.00898752]\n",
            " [0.98974544]\n",
            " [0.98970187]\n",
            " [0.01618224]]\n",
            "Step: 1950 -> Loss: 0.011486886069178581 -> Predictions: [[0.00897786]\n",
            " [0.9897574 ]\n",
            " [0.989714  ]\n",
            " [0.01616237]]\n",
            "Step: 1951 -> Loss: 0.011473359540104866 -> Predictions: [[0.00896821]\n",
            " [0.98976934]\n",
            " [0.9897259 ]\n",
            " [0.01614255]]\n",
            "Step: 1952 -> Loss: 0.011459864675998688 -> Predictions: [[0.00895859]\n",
            " [0.98978126]\n",
            " [0.9897379 ]\n",
            " [0.01612279]]\n",
            "Step: 1953 -> Loss: 0.011446408927440643 -> Predictions: [[0.00894899]\n",
            " [0.9897932 ]\n",
            " [0.98974997]\n",
            " [0.01610309]]\n",
            "Step: 1954 -> Loss: 0.011432981118559837 -> Predictions: [[0.00893943]\n",
            " [0.9898051 ]\n",
            " [0.9897619 ]\n",
            " [0.01608342]]\n",
            "Step: 1955 -> Loss: 0.011419584043323994 -> Predictions: [[0.00892985]\n",
            " [0.9898169 ]\n",
            " [0.9897738 ]\n",
            " [0.01606382]]\n",
            "Step: 1956 -> Loss: 0.011406220495700836 -> Predictions: [[0.00892032]\n",
            " [0.98982877]\n",
            " [0.9897857 ]\n",
            " [0.01604425]]\n",
            "Step: 1957 -> Loss: 0.011392878368496895 -> Predictions: [[0.00891079]\n",
            " [0.98984057]\n",
            " [0.9897975 ]\n",
            " [0.01602471]]\n",
            "Step: 1958 -> Loss: 0.011379573494195938 -> Predictions: [[0.0089013 ]\n",
            " [0.98985225]\n",
            " [0.9898094 ]\n",
            " [0.01600523]]\n",
            "Step: 1959 -> Loss: 0.01136629469692707 -> Predictions: [[0.00889182]\n",
            " [0.98986405]\n",
            " [0.9898212 ]\n",
            " [0.01598579]]\n",
            "Step: 1960 -> Loss: 0.011353053152561188 -> Predictions: [[0.00888235]\n",
            " [0.98987573]\n",
            " [0.989833  ]\n",
            " [0.01596643]]\n",
            "Step: 1961 -> Loss: 0.011339833959937096 -> Predictions: [[0.00887292]\n",
            " [0.9898874 ]\n",
            " [0.9898447 ]\n",
            " [0.01594708]]\n",
            "Step: 1962 -> Loss: 0.011326652020215988 -> Predictions: [[0.0088635 ]\n",
            " [0.9898991 ]\n",
            " [0.9898565 ]\n",
            " [0.01592778]]\n",
            "Step: 1963 -> Loss: 0.011313488706946373 -> Predictions: [[0.00885409]\n",
            " [0.9899108 ]\n",
            " [0.98986816]\n",
            " [0.01590853]]\n",
            "Step: 1964 -> Loss: 0.011300369165837765 -> Predictions: [[0.00884471]\n",
            " [0.98992234]\n",
            " [0.98987985]\n",
            " [0.01588932]]\n",
            "Step: 1965 -> Loss: 0.011287275701761246 -> Predictions: [[0.00883536]\n",
            " [0.9899339 ]\n",
            " [0.9898915 ]\n",
            " [0.01587017]]\n",
            "Step: 1966 -> Loss: 0.011274205520749092 -> Predictions: [[0.008826  ]\n",
            " [0.9899455 ]\n",
            " [0.9899031 ]\n",
            " [0.01585104]]\n",
            "Step: 1967 -> Loss: 0.011261163279414177 -> Predictions: [[0.00881667]\n",
            " [0.98995703]\n",
            " [0.98991466]\n",
            " [0.01583197]]\n",
            "Step: 1968 -> Loss: 0.01124816108494997 -> Predictions: [[0.00880736]\n",
            " [0.9899685 ]\n",
            " [0.9899262 ]\n",
            " [0.01581294]]\n",
            "Step: 1969 -> Loss: 0.011235189624130726 -> Predictions: [[0.00879809]\n",
            " [0.98998   ]\n",
            " [0.9899378 ]\n",
            " [0.01579396]]\n",
            "Step: 1970 -> Loss: 0.011222236789762974 -> Predictions: [[0.00878882]\n",
            " [0.98999155]\n",
            " [0.98994935]\n",
            " [0.01577503]]\n",
            "Step: 1971 -> Loss: 0.011209317483007908 -> Predictions: [[0.00877958]\n",
            " [0.9900029 ]\n",
            " [0.9899608 ]\n",
            " [0.01575613]]\n",
            "Step: 1972 -> Loss: 0.011196423321962357 -> Predictions: [[0.00877035]\n",
            " [0.9900143 ]\n",
            " [0.98997223]\n",
            " [0.01573728]]\n",
            "Step: 1973 -> Loss: 0.01118356455117464 -> Predictions: [[0.00876113]\n",
            " [0.99002564]\n",
            " [0.9899837 ]\n",
            " [0.01571849]]\n",
            "Step: 1974 -> Loss: 0.011170728132128716 -> Predictions: [[0.00875195]\n",
            " [0.9900371 ]\n",
            " [0.9899951 ]\n",
            " [0.01569972]]\n",
            "Step: 1975 -> Loss: 0.0111579280346632 -> Predictions: [[0.00874278]\n",
            " [0.9900483 ]\n",
            " [0.99000645]\n",
            " [0.01568099]]\n",
            "Step: 1976 -> Loss: 0.011145155876874924 -> Predictions: [[0.00873364]\n",
            " [0.9900596 ]\n",
            " [0.99001795]\n",
            " [0.01566233]]\n",
            "Step: 1977 -> Loss: 0.011132407933473587 -> Predictions: [[0.00872451]\n",
            " [0.990071  ]\n",
            " [0.9900293 ]\n",
            " [0.01564369]]\n",
            "Step: 1978 -> Loss: 0.01111969631165266 -> Predictions: [[0.0087154 ]\n",
            " [0.9900822 ]\n",
            " [0.9900406 ]\n",
            " [0.01562513]]\n",
            "Step: 1979 -> Loss: 0.011107001453638077 -> Predictions: [[0.0087063 ]\n",
            " [0.9900934 ]\n",
            " [0.9900518 ]\n",
            " [0.01560657]]\n",
            "Step: 1980 -> Loss: 0.011094346642494202 -> Predictions: [[0.00869724]\n",
            " [0.9901046 ]\n",
            " [0.99006313]\n",
            " [0.01558807]]\n",
            "Step: 1981 -> Loss: 0.011081709526479244 -> Predictions: [[0.00868817]\n",
            " [0.9901158 ]\n",
            " [0.99007434]\n",
            " [0.01556961]]\n",
            "Step: 1982 -> Loss: 0.011069102212786674 -> Predictions: [[0.00867913]\n",
            " [0.99012697]\n",
            " [0.9900856 ]\n",
            " [0.01555118]]\n",
            "Step: 1983 -> Loss: 0.011056528426706791 -> Predictions: [[0.00867011]\n",
            " [0.99013805]\n",
            " [0.9900968 ]\n",
            " [0.01553282]]\n",
            "Step: 1984 -> Loss: 0.011043976061046124 -> Predictions: [[0.00866111]\n",
            " [0.99014914]\n",
            " [0.9901079 ]\n",
            " [0.01551447]]\n",
            "Step: 1985 -> Loss: 0.011031458154320717 -> Predictions: [[0.00865213]\n",
            " [0.9901603 ]\n",
            " [0.990119  ]\n",
            " [0.01549617]]\n",
            "Step: 1986 -> Loss: 0.011018967255949974 -> Predictions: [[0.00864315]\n",
            " [0.9901714 ]\n",
            " [0.9901301 ]\n",
            " [0.01547794]]\n",
            "Step: 1987 -> Loss: 0.011006500571966171 -> Predictions: [[0.00863421]\n",
            " [0.99018234]\n",
            " [0.9901412 ]\n",
            " [0.01545971]]\n",
            "Step: 1988 -> Loss: 0.010994059965014458 -> Predictions: [[0.00862529]\n",
            " [0.9901933 ]\n",
            " [0.9901523 ]\n",
            " [0.01544154]]\n",
            "Step: 1989 -> Loss: 0.01098165288567543 -> Predictions: [[0.00861637]\n",
            " [0.99020433]\n",
            " [0.9901634 ]\n",
            " [0.01542343]]\n",
            "Step: 1990 -> Loss: 0.010969272814691067 -> Predictions: [[0.00860749]\n",
            " [0.9902153 ]\n",
            " [0.9901744 ]\n",
            " [0.01540535]]\n",
            "Step: 1991 -> Loss: 0.010956915095448494 -> Predictions: [[0.00859861]\n",
            " [0.9902262 ]\n",
            " [0.9901854 ]\n",
            " [0.0153873 ]]\n",
            "Step: 1992 -> Loss: 0.010944589041173458 -> Predictions: [[0.00858976]\n",
            " [0.9902372 ]\n",
            " [0.99019635]\n",
            " [0.0153693 ]]\n",
            "Step: 1993 -> Loss: 0.010932289063930511 -> Predictions: [[0.00858093]\n",
            " [0.990248  ]\n",
            " [0.99020725]\n",
            " [0.01535132]]\n",
            "Step: 1994 -> Loss: 0.010920017957687378 -> Predictions: [[0.00857211]\n",
            " [0.99025893]\n",
            " [0.9902182 ]\n",
            " [0.01533342]]\n",
            "Step: 1995 -> Loss: 0.010907771065831184 -> Predictions: [[0.0085633 ]\n",
            " [0.99026966]\n",
            " [0.9902291 ]\n",
            " [0.01531553]]\n",
            "Step: 1996 -> Loss: 0.010895542800426483 -> Predictions: [[0.0085545 ]\n",
            " [0.9902805 ]\n",
            " [0.99024   ]\n",
            " [0.01529769]]\n",
            "Step: 1997 -> Loss: 0.010883353650569916 -> Predictions: [[0.00854573]\n",
            " [0.9902913 ]\n",
            " [0.9902508 ]\n",
            " [0.0152799 ]]\n",
            "Step: 1998 -> Loss: 0.010871187783777714 -> Predictions: [[0.00853699]\n",
            " [0.990302  ]\n",
            " [0.99026173]\n",
            " [0.01526214]]\n",
            "Step: 1999 -> Loss: 0.010859047994017601 -> Predictions: [[0.00852826]\n",
            " [0.9903128 ]\n",
            " [0.99027246]\n",
            " [0.01524443]]\n",
            "Step: 2001 -> Loss: 0.010834848508238792 -> Predictions: [[0.00851084]\n",
            " [0.9903342 ]\n",
            " [0.990294  ]\n",
            " [0.0152091 ]]\n",
            "Step: 2002 -> Loss: 0.010822786949574947 -> Predictions: [[0.00850216]\n",
            " [0.99034494]\n",
            " [0.9903047 ]\n",
            " [0.01519151]]\n",
            "Step: 2003 -> Loss: 0.010810750536620617 -> Predictions: [[0.0084935 ]\n",
            " [0.9903556 ]\n",
            " [0.9903155 ]\n",
            " [0.01517395]]\n",
            "Step: 2004 -> Loss: 0.010798749513924122 -> Predictions: [[0.00848485]\n",
            " [0.9903662 ]\n",
            " [0.9903261 ]\n",
            " [0.01515644]]\n",
            "Step: 2005 -> Loss: 0.010786759667098522 -> Predictions: [[0.00847621]\n",
            " [0.9903768 ]\n",
            " [0.9903368 ]\n",
            " [0.01513896]]\n",
            "Step: 2006 -> Loss: 0.010774804279208183 -> Predictions: [[0.0084676 ]\n",
            " [0.9903874 ]\n",
            " [0.9903474 ]\n",
            " [0.01512151]]\n",
            "Step: 2007 -> Loss: 0.010762875899672508 -> Predictions: [[0.00845901]\n",
            " [0.99039793]\n",
            " [0.99035805]\n",
            " [0.0151041 ]]\n",
            "Step: 2008 -> Loss: 0.010750968009233475 -> Predictions: [[0.00845044]\n",
            " [0.9904084 ]\n",
            " [0.99036866]\n",
            " [0.01508673]]\n",
            "Step: 2009 -> Loss: 0.010739092715084553 -> Predictions: [[0.00844187]\n",
            " [0.990419  ]\n",
            " [0.9903792 ]\n",
            " [0.01506942]]\n",
            "Step: 2010 -> Loss: 0.010727239772677422 -> Predictions: [[0.00843334]\n",
            " [0.9904295 ]\n",
            " [0.99038976]\n",
            " [0.01505213]]\n",
            "Step: 2011 -> Loss: 0.010715413838624954 -> Predictions: [[0.0084248 ]\n",
            " [0.99044   ]\n",
            " [0.99040025]\n",
            " [0.01503489]]\n",
            "Step: 2012 -> Loss: 0.010703611187636852 -> Predictions: [[0.00841629]\n",
            " [0.99045044]\n",
            " [0.9904108 ]\n",
            " [0.01501768]]\n",
            "Step: 2013 -> Loss: 0.010691829025745392 -> Predictions: [[0.00840781]\n",
            " [0.9904608 ]\n",
            " [0.9904213 ]\n",
            " [0.01500051]]\n",
            "Step: 2014 -> Loss: 0.010680090636014938 -> Predictions: [[0.00839934]\n",
            " [0.99047124]\n",
            " [0.9904317 ]\n",
            " [0.0149834 ]]\n",
            "Step: 2015 -> Loss: 0.01066836528480053 -> Predictions: [[0.00839087]\n",
            " [0.9904817 ]\n",
            " [0.9904422 ]\n",
            " [0.01496631]]\n",
            "Step: 2016 -> Loss: 0.010656660422682762 -> Predictions: [[0.00838243]\n",
            " [0.9904919 ]\n",
            " [0.99045265]\n",
            " [0.01494925]]\n",
            "Step: 2017 -> Loss: 0.010644984431564808 -> Predictions: [[0.00837402]\n",
            " [0.99050236]\n",
            " [0.9904631 ]\n",
            " [0.01493223]]\n",
            "Step: 2018 -> Loss: 0.010633338242769241 -> Predictions: [[0.00836561]\n",
            " [0.99051267]\n",
            " [0.99047333]\n",
            " [0.01491525]]\n",
            "Step: 2019 -> Loss: 0.010621710680425167 -> Predictions: [[0.00835722]\n",
            " [0.9905229 ]\n",
            " [0.99048376]\n",
            " [0.01489829]]\n",
            "Step: 2020 -> Loss: 0.010610113851726055 -> Predictions: [[0.00834885]\n",
            " [0.99053323]\n",
            " [0.9904941 ]\n",
            " [0.0148814 ]]\n",
            "Step: 2021 -> Loss: 0.01059853844344616 -> Predictions: [[0.00834049]\n",
            " [0.9905434 ]\n",
            " [0.9905043 ]\n",
            " [0.01486452]]\n",
            "Step: 2022 -> Loss: 0.010586985386908054 -> Predictions: [[0.00833215]\n",
            " [0.9905537 ]\n",
            " [0.99051464]\n",
            " [0.0148477 ]]\n",
            "Step: 2023 -> Loss: 0.010575462132692337 -> Predictions: [[0.00832384]\n",
            " [0.99056387]\n",
            " [0.99052495]\n",
            " [0.0148309 ]]\n",
            "Step: 2024 -> Loss: 0.010563962161540985 -> Predictions: [[0.00831552]\n",
            " [0.99057406]\n",
            " [0.9905351 ]\n",
            " [0.01481415]]\n",
            "Step: 2025 -> Loss: 0.010552484542131424 -> Predictions: [[0.00830723]\n",
            " [0.99058425]\n",
            " [0.9905454 ]\n",
            " [0.01479744]]\n",
            "Step: 2026 -> Loss: 0.010541025549173355 -> Predictions: [[0.00829895]\n",
            " [0.9905944 ]\n",
            " [0.9905556 ]\n",
            " [0.01478075]]\n",
            "Step: 2027 -> Loss: 0.01052960567176342 -> Predictions: [[0.00829069]\n",
            " [0.99060446]\n",
            " [0.9905657 ]\n",
            " [0.01476411]]\n",
            "Step: 2028 -> Loss: 0.01051819697022438 -> Predictions: [[0.00828243]\n",
            " [0.99061465]\n",
            " [0.9905759 ]\n",
            " [0.01474751]]\n",
            "Step: 2029 -> Loss: 0.010506817139685154 -> Predictions: [[0.00827421]\n",
            " [0.9906247 ]\n",
            " [0.990586  ]\n",
            " [0.01473093]]\n",
            "Step: 2030 -> Loss: 0.010495461523532867 -> Predictions: [[0.008266  ]\n",
            " [0.99063474]\n",
            " [0.9905962 ]\n",
            " [0.01471438]]\n",
            "Step: 2031 -> Loss: 0.010484132915735245 -> Predictions: [[0.00825782]\n",
            " [0.9906447 ]\n",
            " [0.99060625]\n",
            " [0.01469789]]\n",
            "Step: 2032 -> Loss: 0.010472822934389114 -> Predictions: [[0.00824963]\n",
            " [0.99065477]\n",
            " [0.99061626]\n",
            " [0.01468142]]\n",
            "Step: 2033 -> Loss: 0.010461544618010521 -> Predictions: [[0.00824148]\n",
            " [0.9906647 ]\n",
            " [0.99062634]\n",
            " [0.014665  ]]\n",
            "Step: 2034 -> Loss: 0.01045028306543827 -> Predictions: [[0.00823333]\n",
            " [0.9906748 ]\n",
            " [0.9906364 ]\n",
            " [0.0146486 ]]\n",
            "Step: 2035 -> Loss: 0.01043904572725296 -> Predictions: [[0.00822519]\n",
            " [0.99068475]\n",
            " [0.99064636]\n",
            " [0.01463224]]\n",
            "Step: 2036 -> Loss: 0.010427835397422314 -> Predictions: [[0.00821709]\n",
            " [0.9906945 ]\n",
            " [0.99065644]\n",
            " [0.01461591]]\n",
            "Step: 2037 -> Loss: 0.010416645556688309 -> Predictions: [[0.00820898]\n",
            " [0.9907045 ]\n",
            " [0.99066633]\n",
            " [0.01459962]]\n",
            "Step: 2038 -> Loss: 0.010405478999018669 -> Predictions: [[0.0082009 ]\n",
            " [0.99071443]\n",
            " [0.9906763 ]\n",
            " [0.01458338]]\n",
            "Step: 2039 -> Loss: 0.010394344106316566 -> Predictions: [[0.00819283]\n",
            " [0.99072427]\n",
            " [0.9906861 ]\n",
            " [0.01456718]]\n",
            "Step: 2040 -> Loss: 0.01038321666419506 -> Predictions: [[0.00818477]\n",
            " [0.9907341 ]\n",
            " [0.9906961 ]\n",
            " [0.01455097]]\n",
            "Step: 2041 -> Loss: 0.010372127406299114 -> Predictions: [[0.00817673]\n",
            " [0.99074394]\n",
            " [0.9907059 ]\n",
            " [0.01453483]]\n",
            "Step: 2042 -> Loss: 0.010361053980886936 -> Predictions: [[0.00816872]\n",
            " [0.99075377]\n",
            " [0.99071586]\n",
            " [0.01451872]]\n",
            "Step: 2043 -> Loss: 0.01035001128911972 -> Predictions: [[0.00816071]\n",
            " [0.9907636 ]\n",
            " [0.9907257 ]\n",
            " [0.01450267]]\n",
            "Step: 2044 -> Loss: 0.010338978841900826 -> Predictions: [[0.00815271]\n",
            " [0.9907733 ]\n",
            " [0.9907355 ]\n",
            " [0.01448662]]\n",
            "Step: 2045 -> Loss: 0.010327978059649467 -> Predictions: [[0.00814473]\n",
            " [0.99078304]\n",
            " [0.9907453 ]\n",
            " [0.01447062]]\n",
            "Step: 2046 -> Loss: 0.010316998697817326 -> Predictions: [[0.00813678]\n",
            " [0.9907928 ]\n",
            " [0.990755  ]\n",
            " [0.01445465]]\n",
            "Step: 2047 -> Loss: 0.0103060407564044 -> Predictions: [[0.00812883]\n",
            " [0.9908025 ]\n",
            " [0.99076486]\n",
            " [0.0144387 ]]\n",
            "Step: 2048 -> Loss: 0.01029510609805584 -> Predictions: [[0.0081209 ]\n",
            " [0.9908121 ]\n",
            " [0.9907746 ]\n",
            " [0.01442279]]\n",
            "Step: 2049 -> Loss: 0.010284201242029667 -> Predictions: [[0.008113  ]\n",
            " [0.99082184]\n",
            " [0.9907843 ]\n",
            " [0.01440692]]\n",
            "Step: 2050 -> Loss: 0.01027330756187439 -> Predictions: [[0.00810509]\n",
            " [0.99083143]\n",
            " [0.990794  ]\n",
            " [0.01439109]]\n",
            "Step: 2051 -> Loss: 0.010262440890073776 -> Predictions: [[0.0080972 ]\n",
            " [0.99084115]\n",
            " [0.9908036 ]\n",
            " [0.01437529]]\n",
            "Step: 2052 -> Loss: 0.010251596570014954 -> Predictions: [[0.00808933]\n",
            " [0.99085075]\n",
            " [0.9908133 ]\n",
            " [0.01435952]]\n",
            "Step: 2053 -> Loss: 0.010240775533020496 -> Predictions: [[0.00808147]\n",
            " [0.9908602 ]\n",
            " [0.9908229 ]\n",
            " [0.01434378]]\n",
            "Step: 2054 -> Loss: 0.010229983367025852 -> Predictions: [[0.00807365]\n",
            " [0.9908698 ]\n",
            " [0.9908325 ]\n",
            " [0.01432809]]\n",
            "Step: 2055 -> Loss: 0.010219204239547253 -> Predictions: [[0.00806583]\n",
            " [0.9908794 ]\n",
            " [0.9908421 ]\n",
            " [0.01431241]]\n",
            "Step: 2056 -> Loss: 0.010208448395133018 -> Predictions: [[0.00805802]\n",
            " [0.99088895]\n",
            " [0.9908517 ]\n",
            " [0.01429678]]\n",
            "Step: 2057 -> Loss: 0.010197712108492851 -> Predictions: [[0.00805023]\n",
            " [0.99089855]\n",
            " [0.9908613 ]\n",
            " [0.01428117]]\n",
            "Step: 2058 -> Loss: 0.010187006555497646 -> Predictions: [[0.00804246]\n",
            " [0.990908  ]\n",
            " [0.9908709 ]\n",
            " [0.01426561]]\n",
            "Step: 2059 -> Loss: 0.010176315903663635 -> Predictions: [[0.00803469]\n",
            " [0.9909175 ]\n",
            " [0.99088037]\n",
            " [0.01425008]]\n",
            "Step: 2060 -> Loss: 0.010165650397539139 -> Predictions: [[0.00802694]\n",
            " [0.99092686]\n",
            " [0.99088985]\n",
            " [0.01423457]]\n",
            "Step: 2061 -> Loss: 0.01015501283109188 -> Predictions: [[0.0080192 ]\n",
            " [0.99093634]\n",
            " [0.9908993 ]\n",
            " [0.01421912]]\n",
            "Step: 2062 -> Loss: 0.01014438085258007 -> Predictions: [[0.00801148]\n",
            " [0.9909457 ]\n",
            " [0.9909088 ]\n",
            " [0.01420365]]\n",
            "Step: 2063 -> Loss: 0.010133783333003521 -> Predictions: [[0.00800376]\n",
            " [0.99095505]\n",
            " [0.9909183 ]\n",
            " [0.01418826]]\n",
            "Step: 2064 -> Loss: 0.010123209096491337 -> Predictions: [[0.00799608]\n",
            " [0.9909644 ]\n",
            " [0.9909277 ]\n",
            " [0.01417289]]\n",
            "Step: 2065 -> Loss: 0.01011265255510807 -> Predictions: [[0.0079884 ]\n",
            " [0.9909738 ]\n",
            " [0.99093705]\n",
            " [0.01415757]]\n",
            "Step: 2066 -> Loss: 0.01010211557149887 -> Predictions: [[0.00798073]\n",
            " [0.9909831 ]\n",
            " [0.99094653]\n",
            " [0.01414226]]\n",
            "Step: 2067 -> Loss: 0.01009160652756691 -> Predictions: [[0.00797309]\n",
            " [0.99099255]\n",
            " [0.99095577]\n",
            " [0.01412698]]\n",
            "Step: 2068 -> Loss: 0.010081104934215546 -> Predictions: [[0.00796545]\n",
            " [0.9910018 ]\n",
            " [0.9909651 ]\n",
            " [0.01411173]]\n",
            "Step: 2069 -> Loss: 0.010070642456412315 -> Predictions: [[0.00795784]\n",
            " [0.991011  ]\n",
            " [0.9909745 ]\n",
            " [0.01409652]]\n",
            "Step: 2070 -> Loss: 0.010060190223157406 -> Predictions: [[0.00795022]\n",
            " [0.99102026]\n",
            " [0.99098384]\n",
            " [0.01408135]]\n",
            "Step: 2071 -> Loss: 0.010049760341644287 -> Predictions: [[0.00794263]\n",
            " [0.9910295 ]\n",
            " [0.9909931 ]\n",
            " [0.0140662 ]]\n",
            "Step: 2072 -> Loss: 0.010039351880550385 -> Predictions: [[0.00793507]\n",
            " [0.99103874]\n",
            " [0.9910024 ]\n",
            " [0.01405107]]\n",
            "Step: 2073 -> Loss: 0.010028964839875698 -> Predictions: [[0.0079275 ]\n",
            " [0.99104804]\n",
            " [0.9910116 ]\n",
            " [0.014036  ]]\n",
            "Step: 2074 -> Loss: 0.010018600150942802 -> Predictions: [[0.00791995]\n",
            " [0.99105716]\n",
            " [0.99102086]\n",
            " [0.01402095]]\n",
            "Step: 2075 -> Loss: 0.010008256882429123 -> Predictions: [[0.00791242]\n",
            " [0.9910663 ]\n",
            " [0.9910301 ]\n",
            " [0.01400592]]\n",
            "Step: 2076 -> Loss: 0.009997935965657234 -> Predictions: [[0.00790489]\n",
            " [0.9910755 ]\n",
            " [0.9910392 ]\n",
            " [0.01399096]]\n",
            "Step: 2077 -> Loss: 0.009987636469304562 -> Predictions: [[0.00789739]\n",
            " [0.9910846 ]\n",
            " [0.99104846]\n",
            " [0.01397599]]\n",
            "Step: 2078 -> Loss: 0.009977349080145359 -> Predictions: [[0.00788989]\n",
            " [0.9910937 ]\n",
            " [0.99105763]\n",
            " [0.01396105]]\n",
            "Step: 2079 -> Loss: 0.00996709056198597 -> Predictions: [[0.00788241]\n",
            " [0.9911028 ]\n",
            " [0.99106675]\n",
            " [0.01394617]]\n",
            "Step: 2080 -> Loss: 0.009956851601600647 -> Predictions: [[0.00787495]\n",
            " [0.9911118 ]\n",
            " [0.9910759 ]\n",
            " [0.0139313 ]]\n",
            "Step: 2081 -> Loss: 0.009946631267666817 -> Predictions: [[0.0078675 ]\n",
            " [0.991121  ]\n",
            " [0.991085  ]\n",
            " [0.01391645]]\n",
            "Step: 2082 -> Loss: 0.009936431422829628 -> Predictions: [[0.00786006]\n",
            " [0.99113   ]\n",
            " [0.99109405]\n",
            " [0.01390165]]\n",
            "Step: 2083 -> Loss: 0.009926257655024529 -> Predictions: [[0.00785264]\n",
            " [0.991139  ]\n",
            " [0.9911032 ]\n",
            " [0.01388689]]\n",
            "Step: 2084 -> Loss: 0.009916096925735474 -> Predictions: [[0.00784523]\n",
            " [0.991148  ]\n",
            " [0.9911122 ]\n",
            " [0.01387214]]\n",
            "Step: 2085 -> Loss: 0.009905962273478508 -> Predictions: [[0.00783784]\n",
            " [0.99115705]\n",
            " [0.9911212 ]\n",
            " [0.01385744]]\n",
            "Step: 2086 -> Loss: 0.009895844385027885 -> Predictions: [[0.00783045]\n",
            " [0.99116594]\n",
            " [0.99113023]\n",
            " [0.01384276]]\n",
            "Step: 2087 -> Loss: 0.009885748848319054 -> Predictions: [[0.00782308]\n",
            " [0.99117494]\n",
            " [0.99113923]\n",
            " [0.01382812]]\n",
            "Step: 2088 -> Loss: 0.009875666350126266 -> Predictions: [[0.00781573]\n",
            " [0.9911839 ]\n",
            " [0.99114823]\n",
            " [0.01381348]]\n",
            "Step: 2089 -> Loss: 0.009865602478384972 -> Predictions: [[0.00780839]\n",
            " [0.99119276]\n",
            " [0.9911572 ]\n",
            " [0.01379889]]\n",
            "Step: 2090 -> Loss: 0.00985557958483696 -> Predictions: [[0.00780107]\n",
            " [0.99120164]\n",
            " [0.9911662 ]\n",
            " [0.01378435]]\n",
            "Step: 2091 -> Loss: 0.009845557622611523 -> Predictions: [[0.00779376]\n",
            " [0.9912106 ]\n",
            " [0.99117506]\n",
            " [0.0137698 ]]\n",
            "Step: 2092 -> Loss: 0.009835565462708473 -> Predictions: [[0.00778647]\n",
            " [0.99121934]\n",
            " [0.991184  ]\n",
            " [0.01375531]]\n",
            "Step: 2093 -> Loss: 0.009825584478676319 -> Predictions: [[0.00777919]\n",
            " [0.9912282 ]\n",
            " [0.9911929 ]\n",
            " [0.01374083]]\n",
            "Step: 2094 -> Loss: 0.00981562677770853 -> Predictions: [[0.00777191]\n",
            " [0.99123704]\n",
            " [0.99120176]\n",
            " [0.0137264 ]]\n",
            "Step: 2095 -> Loss: 0.009805689565837383 -> Predictions: [[0.00776465]\n",
            " [0.9912458 ]\n",
            " [0.9912106 ]\n",
            " [0.01371199]]\n",
            "Step: 2096 -> Loss: 0.009795775637030602 -> Predictions: [[0.00775742]\n",
            " [0.9912547 ]\n",
            " [0.99121946]\n",
            " [0.01369761]]\n",
            "Step: 2097 -> Loss: 0.009785877540707588 -> Predictions: [[0.00775017]\n",
            " [0.9912634 ]\n",
            " [0.9912282 ]\n",
            " [0.01368325]]\n",
            "Step: 2098 -> Loss: 0.009776001796126366 -> Predictions: [[0.00774296]\n",
            " [0.99127215]\n",
            " [0.99123704]\n",
            " [0.01366894]]\n",
            "Step: 2099 -> Loss: 0.009766144677996635 -> Predictions: [[0.00773575]\n",
            " [0.991281  ]\n",
            " [0.9912458 ]\n",
            " [0.01365465]]\n",
            "Step: 2100 -> Loss: 0.009756306186318398 -> Predictions: [[0.00772856]\n",
            " [0.9912896 ]\n",
            " [0.99125457]\n",
            " [0.01364038]]\n",
            "Step: 2101 -> Loss: 0.009746484458446503 -> Predictions: [[0.00772139]\n",
            " [0.9912984 ]\n",
            " [0.9912634 ]\n",
            " [0.01362614]]\n",
            "Step: 2102 -> Loss: 0.009736677631735802 -> Predictions: [[0.00771422]\n",
            " [0.9913071 ]\n",
            " [0.99127203]\n",
            " [0.01361193]]\n",
            "Step: 2103 -> Loss: 0.009726900607347488 -> Predictions: [[0.00770707]\n",
            " [0.9913157 ]\n",
            " [0.99128085]\n",
            " [0.01359775]]\n",
            "Step: 2104 -> Loss: 0.00971713662147522 -> Predictions: [[0.00769992]\n",
            " [0.9913244 ]\n",
            " [0.9912895 ]\n",
            " [0.01358361]]\n",
            "Step: 2105 -> Loss: 0.009707393124699593 -> Predictions: [[0.0076928 ]\n",
            " [0.99133295]\n",
            " [0.9912982 ]\n",
            " [0.01356947]]\n",
            "Step: 2106 -> Loss: 0.00969767291098833 -> Predictions: [[0.00768568]\n",
            " [0.99134165]\n",
            " [0.99130684]\n",
            " [0.0135554 ]]\n",
            "Step: 2107 -> Loss: 0.009687967598438263 -> Predictions: [[0.00767859]\n",
            " [0.9913502 ]\n",
            " [0.9913155 ]\n",
            " [0.01354134]]\n",
            "Step: 2108 -> Loss: 0.009678284637629986 -> Predictions: [[0.0076715 ]\n",
            " [0.9913589 ]\n",
            " [0.9913242 ]\n",
            " [0.01352731]]\n",
            "Step: 2109 -> Loss: 0.009668616577982903 -> Predictions: [[0.00766443]\n",
            " [0.9913674 ]\n",
            " [0.9913327 ]\n",
            " [0.01351331]]\n",
            "Step: 2110 -> Loss: 0.009658971801400185 -> Predictions: [[0.00765737]\n",
            " [0.991376  ]\n",
            " [0.9913414 ]\n",
            " [0.01349934]]\n",
            "Step: 2111 -> Loss: 0.009649340994656086 -> Predictions: [[0.00765032]\n",
            " [0.9913845 ]\n",
            " [0.99134994]\n",
            " [0.01348538]]\n",
            "Step: 2112 -> Loss: 0.009639733470976353 -> Predictions: [[0.00764328]\n",
            " [0.9913931 ]\n",
            " [0.9913585 ]\n",
            " [0.01347146]]\n",
            "Step: 2113 -> Loss: 0.009630139917135239 -> Predictions: [[0.00763626]\n",
            " [0.9914015 ]\n",
            " [0.99136704]\n",
            " [0.01345756]]\n",
            "Step: 2114 -> Loss: 0.00962057150900364 -> Predictions: [[0.00762924]\n",
            " [0.9914101 ]\n",
            " [0.9913756 ]\n",
            " [0.0134437 ]]\n",
            "Step: 2115 -> Loss: 0.009611018002033234 -> Predictions: [[0.00762225]\n",
            " [0.9914185 ]\n",
            " [0.99138415]\n",
            " [0.01342987]]\n",
            "Step: 2116 -> Loss: 0.00960148498415947 -> Predictions: [[0.00761527]\n",
            " [0.99142694]\n",
            " [0.9913926 ]\n",
            " [0.01341605]]\n",
            "Step: 2117 -> Loss: 0.009591963142156601 -> Predictions: [[0.0076083 ]\n",
            " [0.99143535]\n",
            " [0.99140114]\n",
            " [0.01340226]]\n",
            "Step: 2118 -> Loss: 0.009582461789250374 -> Predictions: [[0.00760134]\n",
            " [0.9914438 ]\n",
            " [0.9914096 ]\n",
            " [0.0133885 ]]\n",
            "Step: 2119 -> Loss: 0.009572979062795639 -> Predictions: [[0.00759438]\n",
            " [0.9914522 ]\n",
            " [0.991418  ]\n",
            " [0.01337477]]\n",
            "Step: 2120 -> Loss: 0.009563520550727844 -> Predictions: [[0.00758745]\n",
            " [0.99146056]\n",
            " [0.99142647]\n",
            " [0.01336107]]\n",
            "Step: 2121 -> Loss: 0.009554081596434116 -> Predictions: [[0.00758052]\n",
            " [0.991469  ]\n",
            " [0.9914349 ]\n",
            " [0.01334742]]\n",
            "Step: 2122 -> Loss: 0.009544655680656433 -> Predictions: [[0.00757361]\n",
            " [0.9914773 ]\n",
            " [0.99144334]\n",
            " [0.01333376]]\n",
            "Step: 2123 -> Loss: 0.00953525397926569 -> Predictions: [[0.00756672]\n",
            " [0.99148566]\n",
            " [0.9914517 ]\n",
            " [0.01332016]]\n",
            "Step: 2124 -> Loss: 0.009525863453745842 -> Predictions: [[0.00755983]\n",
            " [0.99149394]\n",
            " [0.9914601 ]\n",
            " [0.01330656]]\n",
            "Step: 2125 -> Loss: 0.009516492486000061 -> Predictions: [[0.00755296]\n",
            " [0.9915023 ]\n",
            " [0.9914684 ]\n",
            " [0.01329299]]\n",
            "Step: 2126 -> Loss: 0.009507139213383198 -> Predictions: [[0.00754609]\n",
            " [0.99151057]\n",
            " [0.9914767 ]\n",
            " [0.01327946]]\n",
            "Step: 2127 -> Loss: 0.009497806429862976 -> Predictions: [[0.00753924]\n",
            " [0.9915189 ]\n",
            " [0.99148506]\n",
            " [0.01326595]]\n",
            "Step: 2128 -> Loss: 0.009488491341471672 -> Predictions: [[0.00753241]\n",
            " [0.99152714]\n",
            " [0.99149334]\n",
            " [0.01325247]]\n",
            "Step: 2129 -> Loss: 0.009479192085564137 -> Predictions: [[0.00752559]\n",
            " [0.9915354 ]\n",
            " [0.9915017 ]\n",
            " [0.013239  ]]\n",
            "Step: 2130 -> Loss: 0.009469911456108093 -> Predictions: [[0.00751877]\n",
            " [0.99154365]\n",
            " [0.9915099 ]\n",
            " [0.01322557]]\n",
            "Step: 2131 -> Loss: 0.009460650384426117 -> Predictions: [[0.00751196]\n",
            " [0.9915519 ]\n",
            " [0.9915182 ]\n",
            " [0.01321218]]\n",
            "Step: 2132 -> Loss: 0.009451406076550484 -> Predictions: [[0.00750519]\n",
            " [0.99156004]\n",
            " [0.9915264 ]\n",
            " [0.0131988 ]]\n",
            "Step: 2133 -> Loss: 0.009442177601158619 -> Predictions: [[0.00749841]\n",
            " [0.99156827]\n",
            " [0.99153465]\n",
            " [0.01318546]]\n",
            "Step: 2134 -> Loss: 0.009432969614863396 -> Predictions: [[0.00749166]\n",
            " [0.9915764 ]\n",
            " [0.9915428 ]\n",
            " [0.01317213]]\n",
            "Step: 2135 -> Loss: 0.009423777461051941 -> Predictions: [[0.0074849 ]\n",
            " [0.99158454]\n",
            " [0.99155104]\n",
            " [0.01315883]]\n",
            "Step: 2136 -> Loss: 0.00941460020840168 -> Predictions: [[0.00747816]\n",
            " [0.99159265]\n",
            " [0.9915592 ]\n",
            " [0.01314555]]\n",
            "Step: 2137 -> Loss: 0.009405448101460934 -> Predictions: [[0.00747143]\n",
            " [0.9916009 ]\n",
            " [0.99156743]\n",
            " [0.01313233]]\n",
            "Step: 2138 -> Loss: 0.009396303445100784 -> Predictions: [[0.00746472]\n",
            " [0.9916089 ]\n",
            " [0.99157554]\n",
            " [0.01311909]]\n",
            "Step: 2139 -> Loss: 0.009387192316353321 -> Predictions: [[0.00745802]\n",
            " [0.991617  ]\n",
            " [0.9915837 ]\n",
            " [0.0131059 ]]\n",
            "Step: 2140 -> Loss: 0.009378084912896156 -> Predictions: [[0.00745132]\n",
            " [0.99162513]\n",
            " [0.9915918 ]\n",
            " [0.01309274]]\n",
            "Step: 2141 -> Loss: 0.00936899520456791 -> Predictions: [[0.00744464]\n",
            " [0.99163306]\n",
            " [0.9915999 ]\n",
            " [0.01307959]]\n",
            "Step: 2142 -> Loss: 0.009359929710626602 -> Predictions: [[0.00743797]\n",
            " [0.99164116]\n",
            " [0.991608  ]\n",
            " [0.01306648]]\n",
            "Step: 2143 -> Loss: 0.009350869804620743 -> Predictions: [[0.00743131]\n",
            " [0.99164927]\n",
            " [0.9916161 ]\n",
            " [0.01305338]]\n",
            "Step: 2144 -> Loss: 0.009341837838292122 -> Predictions: [[0.00742467]\n",
            " [0.99165726]\n",
            " [0.9916242 ]\n",
            " [0.01304032]]\n",
            "Step: 2145 -> Loss: 0.009332818910479546 -> Predictions: [[0.00741803]\n",
            " [0.9916652 ]\n",
            " [0.99163216]\n",
            " [0.01302728]]\n",
            "Step: 2146 -> Loss: 0.00932382047176361 -> Predictions: [[0.00741142]\n",
            " [0.9916732 ]\n",
            " [0.9916402 ]\n",
            " [0.01301427]]\n",
            "Step: 2147 -> Loss: 0.009314834140241146 -> Predictions: [[0.0074048 ]\n",
            " [0.99168116]\n",
            " [0.9916482 ]\n",
            " [0.01300126]]\n",
            "Step: 2148 -> Loss: 0.009305869229137897 -> Predictions: [[0.00739821]\n",
            " [0.99168915]\n",
            " [0.9916562 ]\n",
            " [0.01298833]]\n",
            "Step: 2149 -> Loss: 0.009296916425228119 -> Predictions: [[0.00739162]\n",
            " [0.9916971 ]\n",
            " [0.9916643 ]\n",
            " [0.01297538]]\n",
            "Step: 2150 -> Loss: 0.009287983179092407 -> Predictions: [[0.00738505]\n",
            " [0.99170506]\n",
            " [0.9916722 ]\n",
            " [0.01296247]]\n",
            "Step: 2151 -> Loss: 0.00927906483411789 -> Predictions: [[0.00737848]\n",
            " [0.9917129 ]\n",
            " [0.9916801 ]\n",
            " [0.01294956]]\n",
            "Step: 2152 -> Loss: 0.009270166046917439 -> Predictions: [[0.00737193]\n",
            " [0.9917208 ]\n",
            " [0.9916881 ]\n",
            " [0.01293671]]\n",
            "Step: 2153 -> Loss: 0.009261290542781353 -> Predictions: [[0.0073654 ]\n",
            " [0.9917287 ]\n",
            " [0.99169606]\n",
            " [0.01292388]]\n",
            "Step: 2154 -> Loss: 0.00925242155790329 -> Predictions: [[0.00735886]\n",
            " [0.9917366 ]\n",
            " [0.99170387]\n",
            " [0.01291106]]\n",
            "Step: 2155 -> Loss: 0.009243568405508995 -> Predictions: [[0.00735234]\n",
            " [0.99174446]\n",
            " [0.99171174]\n",
            " [0.01289828]]\n",
            "Step: 2156 -> Loss: 0.009234737604856491 -> Predictions: [[0.00734584]\n",
            " [0.9917523 ]\n",
            " [0.9917197 ]\n",
            " [0.01288551]]\n",
            "Step: 2157 -> Loss: 0.00922592543065548 -> Predictions: [[0.00733935]\n",
            " [0.9917601 ]\n",
            " [0.9917276 ]\n",
            " [0.01287279]]\n",
            "Step: 2158 -> Loss: 0.009217118844389915 -> Predictions: [[0.00733286]\n",
            " [0.9917679 ]\n",
            " [0.9917354 ]\n",
            " [0.01286005]]\n",
            "Step: 2159 -> Loss: 0.009208339266479015 -> Predictions: [[0.00732639]\n",
            " [0.99177563]\n",
            " [0.99174315]\n",
            " [0.01284737]]\n",
            "Step: 2160 -> Loss: 0.00919957086443901 -> Predictions: [[0.00731993]\n",
            " [0.9917835 ]\n",
            " [0.991751  ]\n",
            " [0.01283469]]\n",
            "Step: 2161 -> Loss: 0.00919082760810852 -> Predictions: [[0.00731348]\n",
            " [0.99179125]\n",
            " [0.9917589 ]\n",
            " [0.01282206]]\n",
            "Step: 2162 -> Loss: 0.009182093665003777 -> Predictions: [[0.00730704]\n",
            " [0.991799  ]\n",
            " [0.99176663]\n",
            " [0.01280946]]\n",
            "Step: 2163 -> Loss: 0.009173376485705376 -> Predictions: [[0.00730062]\n",
            " [0.99180675]\n",
            " [0.9917744 ]\n",
            " [0.01279687]]\n",
            "Step: 2164 -> Loss: 0.009164674207568169 -> Predictions: [[0.0072942 ]\n",
            " [0.99181443]\n",
            " [0.9917822 ]\n",
            " [0.01278429]]\n",
            "Step: 2165 -> Loss: 0.009155986830592155 -> Predictions: [[0.00728779]\n",
            " [0.99182206]\n",
            " [0.99178994]\n",
            " [0.01277173]]\n",
            "Step: 2166 -> Loss: 0.009147314354777336 -> Predictions: [[0.0072814 ]\n",
            " [0.9918298 ]\n",
            " [0.9917977 ]\n",
            " [0.01275922]]\n",
            "Step: 2167 -> Loss: 0.009138664230704308 -> Predictions: [[0.00727501]\n",
            " [0.99183756]\n",
            " [0.9918053 ]\n",
            " [0.01274673]]\n",
            "Step: 2168 -> Loss: 0.00913002248853445 -> Predictions: [[0.00726864]\n",
            " [0.9918452 ]\n",
            " [0.99181306]\n",
            " [0.01273426]]\n",
            "Step: 2169 -> Loss: 0.009121406823396683 -> Predictions: [[0.00726229]\n",
            " [0.9918528 ]\n",
            " [0.9918208 ]\n",
            " [0.01272181]]\n",
            "Step: 2170 -> Loss: 0.009112800471484661 -> Predictions: [[0.00725594]\n",
            " [0.99186045]\n",
            " [0.99182844]\n",
            " [0.01270938]]\n",
            "Step: 2171 -> Loss: 0.009104211814701557 -> Predictions: [[0.00724959]\n",
            " [0.9918681 ]\n",
            " [0.99183613]\n",
            " [0.01269699]]\n",
            "Step: 2172 -> Loss: 0.009095638059079647 -> Predictions: [[0.00724327]\n",
            " [0.99187565]\n",
            " [0.99184376]\n",
            " [0.01268461]]\n",
            "Step: 2173 -> Loss: 0.009087080135941505 -> Predictions: [[0.00723695]\n",
            " [0.9918833 ]\n",
            " [0.9918514 ]\n",
            " [0.01267225]]\n",
            "Step: 2174 -> Loss: 0.009078538976609707 -> Predictions: [[0.00723065]\n",
            " [0.9918908 ]\n",
            " [0.991859  ]\n",
            " [0.01265992]]\n",
            "Step: 2175 -> Loss: 0.009070014581084251 -> Predictions: [[0.00722436]\n",
            " [0.9918984 ]\n",
            " [0.99186665]\n",
            " [0.01264761]]\n",
            "Step: 2176 -> Loss: 0.009061509743332863 -> Predictions: [[0.00721807]\n",
            " [0.9919059 ]\n",
            " [0.99187416]\n",
            " [0.01263533]]\n",
            "Step: 2177 -> Loss: 0.009053009562194347 -> Predictions: [[0.0072118 ]\n",
            " [0.99191356]\n",
            " [0.9918818 ]\n",
            " [0.01262308]]\n",
            "Step: 2178 -> Loss: 0.009044533595442772 -> Predictions: [[0.00720554]\n",
            " [0.99192107]\n",
            " [0.9918894 ]\n",
            " [0.01261084]]\n",
            "Step: 2179 -> Loss: 0.009036065079271793 -> Predictions: [[0.00719927]\n",
            " [0.9919286 ]\n",
            " [0.9918969 ]\n",
            " [0.01259862]]\n",
            "Step: 2180 -> Loss: 0.00902762170881033 -> Predictions: [[0.00719304]\n",
            " [0.9919361 ]\n",
            " [0.99190444]\n",
            " [0.01258643]]\n",
            "Step: 2181 -> Loss: 0.009019188582897186 -> Predictions: [[0.0071868 ]\n",
            " [0.9919436 ]\n",
            " [0.9919119 ]\n",
            " [0.01257426]]\n",
            "Step: 2182 -> Loss: 0.009010767564177513 -> Predictions: [[0.00718058]\n",
            " [0.991951  ]\n",
            " [0.9919195 ]\n",
            " [0.01256211]]\n",
            "Step: 2183 -> Loss: 0.009002371691167355 -> Predictions: [[0.00717437]\n",
            " [0.9919585 ]\n",
            " [0.9919269 ]\n",
            " [0.01255   ]]\n",
            "Step: 2184 -> Loss: 0.008993981406092644 -> Predictions: [[0.00716817]\n",
            " [0.9919659 ]\n",
            " [0.9919344 ]\n",
            " [0.01253789]]\n",
            "Step: 2185 -> Loss: 0.008985614404082298 -> Predictions: [[0.00716199]\n",
            " [0.9919734 ]\n",
            " [0.9919419 ]\n",
            " [0.01252582]]\n",
            "Step: 2186 -> Loss: 0.008977257646620274 -> Predictions: [[0.00715581]\n",
            " [0.9919808 ]\n",
            " [0.9919493 ]\n",
            " [0.01251377]]\n",
            "Step: 2187 -> Loss: 0.008968915790319443 -> Predictions: [[0.00714964]\n",
            " [0.9919882 ]\n",
            " [0.99195683]\n",
            " [0.01250173]]\n",
            "Step: 2188 -> Loss: 0.008960588835179806 -> Predictions: [[0.00714347]\n",
            " [0.9919956 ]\n",
            " [0.9919642 ]\n",
            " [0.01248971]]\n",
            "Step: 2189 -> Loss: 0.00895228423178196 -> Predictions: [[0.00713734]\n",
            " [0.99200296]\n",
            " [0.9919716 ]\n",
            " [0.01247773]]\n",
            "Step: 2190 -> Loss: 0.008943986147642136 -> Predictions: [[0.00713119]\n",
            " [0.99201035]\n",
            " [0.9919791 ]\n",
            " [0.01246577]]\n",
            "Step: 2191 -> Loss: 0.008935706689953804 -> Predictions: [[0.00712507]\n",
            " [0.9920176 ]\n",
            " [0.9919864 ]\n",
            " [0.01245382]]\n",
            "Step: 2192 -> Loss: 0.008927443996071815 -> Predictions: [[0.00711895]\n",
            " [0.992025  ]\n",
            " [0.9919938 ]\n",
            " [0.01244191]]\n",
            "Step: 2193 -> Loss: 0.008919190615415573 -> Predictions: [[0.00711285]\n",
            " [0.9920323 ]\n",
            " [0.9920012 ]\n",
            " [0.01243   ]]\n",
            "Step: 2194 -> Loss: 0.008910964243113995 -> Predictions: [[0.00710676]\n",
            " [0.99203956]\n",
            " [0.99200857]\n",
            " [0.01241815]]\n",
            "Step: 2195 -> Loss: 0.008902737870812416 -> Predictions: [[0.00710067]\n",
            " [0.99204695]\n",
            " [0.99201584]\n",
            " [0.01240629]]\n",
            "Step: 2196 -> Loss: 0.008894532918930054 -> Predictions: [[0.00709459]\n",
            " [0.9920542 ]\n",
            " [0.9920232 ]\n",
            " [0.01239447]]\n",
            "Step: 2197 -> Loss: 0.008886341005563736 -> Predictions: [[0.00708852]\n",
            " [0.9920615 ]\n",
            " [0.9920305 ]\n",
            " [0.01238264]]\n",
            "Step: 2198 -> Loss: 0.008878171443939209 -> Predictions: [[0.00708248]\n",
            " [0.99206877]\n",
            " [0.9920378 ]\n",
            " [0.01237086]]\n",
            "Step: 2199 -> Loss: 0.008870008401572704 -> Predictions: [[0.00707643]\n",
            " [0.9920759 ]\n",
            " [0.99204504]\n",
            " [0.01235909]]\n",
            "Step: 2200 -> Loss: 0.008861866779625416 -> Predictions: [[0.0070704 ]\n",
            " [0.9920832 ]\n",
            " [0.9920523 ]\n",
            " [0.01234737]]\n",
            "Step: 2201 -> Loss: 0.008853734470903873 -> Predictions: [[0.00706437]\n",
            " [0.99209034]\n",
            " [0.9920596 ]\n",
            " [0.01233564]]\n",
            "Step: 2202 -> Loss: 0.008845619857311249 -> Predictions: [[0.00705836]\n",
            " [0.9920976 ]\n",
            " [0.99206686]\n",
            " [0.01232394]]\n",
            "Step: 2203 -> Loss: 0.008837517350912094 -> Predictions: [[0.00705236]\n",
            " [0.99210477]\n",
            " [0.992074  ]\n",
            " [0.01231226]]\n",
            "Step: 2204 -> Loss: 0.008829434402287006 -> Predictions: [[0.00704636]\n",
            " [0.9921119 ]\n",
            " [0.9920813 ]\n",
            " [0.0123006 ]]\n",
            "Step: 2205 -> Loss: 0.008821353316307068 -> Predictions: [[0.00704037]\n",
            " [0.9921191 ]\n",
            " [0.99208844]\n",
            " [0.01228896]]\n",
            "Step: 2206 -> Loss: 0.008813298307359219 -> Predictions: [[0.00703439]\n",
            " [0.9921262 ]\n",
            " [0.99209565]\n",
            " [0.01227735]]\n",
            "Step: 2207 -> Loss: 0.008805250748991966 -> Predictions: [[0.00702843]\n",
            " [0.9921334 ]\n",
            " [0.9921029 ]\n",
            " [0.01226575]]\n",
            "Step: 2208 -> Loss: 0.008797229267656803 -> Predictions: [[0.00702248]\n",
            " [0.9921406 ]\n",
            " [0.9921101 ]\n",
            " [0.01225419]]\n",
            "Step: 2209 -> Loss: 0.008789213374257088 -> Predictions: [[0.00701654]\n",
            " [0.99214774]\n",
            " [0.9921172 ]\n",
            " [0.01224264]]\n",
            "Step: 2210 -> Loss: 0.008781210519373417 -> Predictions: [[0.0070106 ]\n",
            " [0.9921548 ]\n",
            " [0.99212426]\n",
            " [0.01223111]]\n",
            "Step: 2211 -> Loss: 0.00877322442829609 -> Predictions: [[0.00700469]\n",
            " [0.9921619 ]\n",
            " [0.9921314 ]\n",
            " [0.0122196 ]]\n",
            "Step: 2212 -> Loss: 0.008765248581767082 -> Predictions: [[0.00699877]\n",
            " [0.99216896]\n",
            " [0.99213856]\n",
            " [0.01220812]]\n",
            "Step: 2213 -> Loss: 0.008757300674915314 -> Predictions: [[0.00699287]\n",
            " [0.992176  ]\n",
            " [0.9921456 ]\n",
            " [0.01219666]]\n",
            "Step: 2214 -> Loss: 0.008749349974095821 -> Predictions: [[0.00698697]\n",
            " [0.992183  ]\n",
            " [0.99215275]\n",
            " [0.01218521]]\n",
            "Step: 2215 -> Loss: 0.008741425350308418 -> Predictions: [[0.00698109]\n",
            " [0.99219006]\n",
            " [0.9921598 ]\n",
            " [0.01217379]]\n",
            "Step: 2216 -> Loss: 0.008733504451811314 -> Predictions: [[0.00697521]\n",
            " [0.99219716]\n",
            " [0.9921669 ]\n",
            " [0.01216238]]\n",
            "Step: 2217 -> Loss: 0.008725604973733425 -> Predictions: [[0.00696934]\n",
            " [0.9922042 ]\n",
            " [0.9921739 ]\n",
            " [0.01215101]]\n",
            "Step: 2218 -> Loss: 0.008717716671526432 -> Predictions: [[0.00696349]\n",
            " [0.9922112 ]\n",
            " [0.99218094]\n",
            " [0.01213965]]\n",
            "Step: 2219 -> Loss: 0.008709844201803207 -> Predictions: [[0.00695765]\n",
            " [0.99221814]\n",
            " [0.992188  ]\n",
            " [0.01212831]]\n",
            "Step: 2220 -> Loss: 0.008701982907950878 -> Predictions: [[0.0069518 ]\n",
            " [0.99222517]\n",
            " [0.992195  ]\n",
            " [0.012117  ]]\n",
            "Step: 2221 -> Loss: 0.008694136515259743 -> Predictions: [[0.00694598]\n",
            " [0.9922321 ]\n",
            " [0.99220204]\n",
            " [0.0121057 ]]\n",
            "Step: 2222 -> Loss: 0.008686313405632973 -> Predictions: [[0.00694018]\n",
            " [0.992239  ]\n",
            " [0.99220896]\n",
            " [0.01209443]]\n",
            "Step: 2223 -> Loss: 0.008678488433361053 -> Predictions: [[0.00693436]\n",
            " [0.992246  ]\n",
            " [0.99221605]\n",
            " [0.01208316]]\n",
            "Step: 2224 -> Loss: 0.008670682087540627 -> Predictions: [[0.00692856]\n",
            " [0.9922529 ]\n",
            " [0.99222296]\n",
            " [0.01207192]]\n",
            "Step: 2225 -> Loss: 0.008662899024784565 -> Predictions: [[0.00692277]\n",
            " [0.9922598 ]\n",
            " [0.9922299 ]\n",
            " [0.01206071]]\n",
            "Step: 2226 -> Loss: 0.008655118755996227 -> Predictions: [[0.006917 ]\n",
            " [0.9922667]\n",
            " [0.9922369]\n",
            " [0.0120495]]\n",
            "Step: 2227 -> Loss: 0.008647354319691658 -> Predictions: [[0.00691122]\n",
            " [0.9922736 ]\n",
            " [0.9922438 ]\n",
            " [0.01203834]]\n",
            "Step: 2228 -> Loss: 0.008639607578516006 -> Predictions: [[0.00690547]\n",
            " [0.9922805 ]\n",
            " [0.99225074]\n",
            " [0.01202719]]\n",
            "Step: 2229 -> Loss: 0.008631875738501549 -> Predictions: [[0.00689972]\n",
            " [0.9922874 ]\n",
            " [0.9922576 ]\n",
            " [0.01201607]]\n",
            "Step: 2230 -> Loss: 0.008624154143035412 -> Predictions: [[0.006894  ]\n",
            " [0.9922942 ]\n",
            " [0.9922645 ]\n",
            " [0.01200494]]\n",
            "Step: 2231 -> Loss: 0.008616444654762745 -> Predictions: [[0.00688826]\n",
            " [0.9923011 ]\n",
            " [0.9922714 ]\n",
            " [0.01199385]]\n",
            "Step: 2232 -> Loss: 0.008608746342360973 -> Predictions: [[0.00688252]\n",
            " [0.9923079 ]\n",
            " [0.9922782 ]\n",
            " [0.01198279]]\n",
            "Step: 2233 -> Loss: 0.00860106572508812 -> Predictions: [[0.00687682]\n",
            " [0.99231476]\n",
            " [0.99228513]\n",
            " [0.01197172]]\n",
            "Step: 2234 -> Loss: 0.008593394421041012 -> Predictions: [[0.00687112]\n",
            " [0.99232155]\n",
            " [0.992292  ]\n",
            " [0.01196068]]\n",
            "Step: 2235 -> Loss: 0.008585745468735695 -> Predictions: [[0.00686543]\n",
            " [0.99232835]\n",
            " [0.9922988 ]\n",
            " [0.01194968]]\n",
            "Step: 2236 -> Loss: 0.00857810489833355 -> Predictions: [[0.00685974]\n",
            " [0.99233514]\n",
            " [0.9923056 ]\n",
            " [0.01193868]]\n",
            "Step: 2237 -> Loss: 0.0085704755038023 -> Predictions: [[0.00685406]\n",
            " [0.9923419 ]\n",
            " [0.9923124 ]\n",
            " [0.01192769]]\n",
            "Step: 2238 -> Loss: 0.008562861010432243 -> Predictions: [[0.00684841]\n",
            " [0.9923487 ]\n",
            " [0.99231917]\n",
            " [0.01191675]]\n",
            "Step: 2239 -> Loss: 0.00855526328086853 -> Predictions: [[0.00684275]\n",
            " [0.99235547]\n",
            " [0.992326  ]\n",
            " [0.01190582]]\n",
            "Step: 2240 -> Loss: 0.008547678589820862 -> Predictions: [[0.00683711]\n",
            " [0.99236214]\n",
            " [0.9923328 ]\n",
            " [0.01189491]]\n",
            "Step: 2241 -> Loss: 0.00854010134935379 -> Predictions: [[0.00683146]\n",
            " [0.9923689 ]\n",
            " [0.9923395 ]\n",
            " [0.01188401]]\n",
            "Step: 2242 -> Loss: 0.008532539010047913 -> Predictions: [[0.00682584]\n",
            " [0.9923757 ]\n",
            " [0.9923463 ]\n",
            " [0.01187313]]\n",
            "Step: 2243 -> Loss: 0.008524995297193527 -> Predictions: [[0.00682021]\n",
            " [0.99238235]\n",
            " [0.992353  ]\n",
            " [0.01186228]]\n",
            "Step: 2244 -> Loss: 0.008517453446984291 -> Predictions: [[0.0068146 ]\n",
            " [0.992389  ]\n",
            " [0.9923598 ]\n",
            " [0.01185143]]\n",
            "Step: 2245 -> Loss: 0.008509935811161995 -> Predictions: [[0.00680901]\n",
            " [0.99239576]\n",
            " [0.9923665 ]\n",
            " [0.01184062]]\n",
            "Step: 2246 -> Loss: 0.008502424694597721 -> Predictions: [[0.00680341]\n",
            " [0.99240243]\n",
            " [0.99237317]\n",
            " [0.01182982]]\n",
            "Step: 2247 -> Loss: 0.00849493220448494 -> Predictions: [[0.00679783]\n",
            " [0.992409  ]\n",
            " [0.9923799 ]\n",
            " [0.01181905]]\n",
            "Step: 2248 -> Loss: 0.008487445302307606 -> Predictions: [[0.00679226]\n",
            " [0.99241567]\n",
            " [0.9923866 ]\n",
            " [0.01180828]]\n",
            "Step: 2249 -> Loss: 0.008479978889226913 -> Predictions: [[0.0067867 ]\n",
            " [0.9924223 ]\n",
            " [0.99239326]\n",
            " [0.01179754]]\n",
            "Step: 2250 -> Loss: 0.008472521789371967 -> Predictions: [[0.00678114]\n",
            " [0.99242896]\n",
            " [0.9923999 ]\n",
            " [0.01178682]]\n",
            "Step: 2251 -> Loss: 0.008465076796710491 -> Predictions: [[0.0067756 ]\n",
            " [0.9924355 ]\n",
            " [0.99240655]\n",
            " [0.01177611]]\n",
            "Step: 2252 -> Loss: 0.008457643911242485 -> Predictions: [[0.00677005]\n",
            " [0.99244213]\n",
            " [0.9924132 ]\n",
            " [0.01176543]]\n",
            "Step: 2253 -> Loss: 0.008450228720903397 -> Predictions: [[0.00676453]\n",
            " [0.9924487 ]\n",
            " [0.9924198 ]\n",
            " [0.01175477]]\n",
            "Step: 2254 -> Loss: 0.008442817255854607 -> Predictions: [[0.00675901]\n",
            " [0.99245536]\n",
            " [0.9924264 ]\n",
            " [0.01174412]]\n",
            "Step: 2255 -> Loss: 0.008435428142547607 -> Predictions: [[0.0067535 ]\n",
            " [0.99246186]\n",
            " [0.9924331 ]\n",
            " [0.0117335 ]]\n",
            "Step: 2256 -> Loss: 0.008428050205111504 -> Predictions: [[0.006748  ]\n",
            " [0.9924684 ]\n",
            " [0.9924396 ]\n",
            " [0.01172289]]\n",
            "Step: 2257 -> Loss: 0.00842068251222372 -> Predictions: [[0.0067425 ]\n",
            " [0.992475  ]\n",
            " [0.99244624]\n",
            " [0.0117123 ]]\n",
            "Step: 2258 -> Loss: 0.008413320407271385 -> Predictions: [[0.00673701]\n",
            " [0.9924816 ]\n",
            " [0.9924528 ]\n",
            " [0.01170171]]\n",
            "Step: 2259 -> Loss: 0.008405983448028564 -> Predictions: [[0.00673154]\n",
            " [0.992488  ]\n",
            " [0.99245924]\n",
            " [0.01169117]]\n",
            "Step: 2260 -> Loss: 0.008398651145398617 -> Predictions: [[0.00672608]\n",
            " [0.9924946 ]\n",
            " [0.99246585]\n",
            " [0.01168063]]\n",
            "Step: 2261 -> Loss: 0.008391335606575012 -> Predictions: [[0.00672062]\n",
            " [0.9925011 ]\n",
            " [0.9924724 ]\n",
            " [0.01167012]]\n",
            "Step: 2262 -> Loss: 0.008384027518332005 -> Predictions: [[0.00671517]\n",
            " [0.9925075 ]\n",
            " [0.99247885]\n",
            " [0.01165962]]\n",
            "Step: 2263 -> Loss: 0.008376738987863064 -> Predictions: [[0.00670972]\n",
            " [0.9925141 ]\n",
            " [0.99248546]\n",
            " [0.01164916]]\n",
            "Step: 2264 -> Loss: 0.008369458839297295 -> Predictions: [[0.00670429]\n",
            " [0.9925206 ]\n",
            " [0.9924919 ]\n",
            " [0.01163869]]\n",
            "Step: 2265 -> Loss: 0.008362190797924995 -> Predictions: [[0.00669887]\n",
            " [0.9925269 ]\n",
            " [0.99249846]\n",
            " [0.01162825]]\n",
            "Step: 2266 -> Loss: 0.008354943245649338 -> Predictions: [[0.00669345]\n",
            " [0.9925333 ]\n",
            " [0.99250495]\n",
            " [0.01161784]]\n",
            "Step: 2267 -> Loss: 0.008347699418663979 -> Predictions: [[0.00668805]\n",
            " [0.9925398 ]\n",
            " [0.9925114 ]\n",
            " [0.01160742]]\n",
            "Step: 2268 -> Loss: 0.008340463973581791 -> Predictions: [[0.00668265]\n",
            " [0.99254626]\n",
            " [0.9925178 ]\n",
            " [0.01159703]]\n",
            "Step: 2269 -> Loss: 0.00833324808627367 -> Predictions: [[0.00667726]\n",
            " [0.99255264]\n",
            " [0.9925243 ]\n",
            " [0.01158666]]\n",
            "Step: 2270 -> Loss: 0.008326040580868721 -> Predictions: [[0.00667187]\n",
            " [0.9925591 ]\n",
            " [0.99253064]\n",
            " [0.0115763 ]]\n",
            "Step: 2271 -> Loss: 0.00831884890794754 -> Predictions: [[0.0066665 ]\n",
            " [0.9925654 ]\n",
            " [0.9925371 ]\n",
            " [0.01156597]]\n",
            "Step: 2272 -> Loss: 0.008311664685606956 -> Predictions: [[0.00666114]\n",
            " [0.9925719 ]\n",
            " [0.9925436 ]\n",
            " [0.01155565]]\n",
            "Step: 2273 -> Loss: 0.008304496295750141 -> Predictions: [[0.00665578]\n",
            " [0.9925782 ]\n",
            " [0.9925499 ]\n",
            " [0.01154537]]\n",
            "Step: 2274 -> Loss: 0.00829734094440937 -> Predictions: [[0.00665044]\n",
            " [0.9925845 ]\n",
            " [0.9925564 ]\n",
            " [0.01153507]]\n",
            "Step: 2275 -> Loss: 0.00829019583761692 -> Predictions: [[0.0066451 ]\n",
            " [0.9925909 ]\n",
            " [0.9925627 ]\n",
            " [0.01152482]]\n",
            "Step: 2276 -> Loss: 0.008283060044050217 -> Predictions: [[0.00663976]\n",
            " [0.9925972 ]\n",
            " [0.992569  ]\n",
            " [0.01151458]]\n",
            "Step: 2277 -> Loss: 0.008275941014289856 -> Predictions: [[0.00663445]\n",
            " [0.9926036 ]\n",
            " [0.9925754 ]\n",
            " [0.01150435]]\n",
            "Step: 2278 -> Loss: 0.008268832229077816 -> Predictions: [[0.00662914]\n",
            " [0.9926099 ]\n",
            " [0.99258184]\n",
            " [0.01149415]]\n",
            "Step: 2279 -> Loss: 0.008261742070317268 -> Predictions: [[0.00662384]\n",
            " [0.9926162 ]\n",
            " [0.9925881 ]\n",
            " [0.01148396]]\n",
            "Step: 2280 -> Loss: 0.008254652842879295 -> Predictions: [[0.00661853]\n",
            " [0.9926225 ]\n",
            " [0.9925944 ]\n",
            " [0.01147379]]\n",
            "Step: 2281 -> Loss: 0.008247582241892815 -> Predictions: [[0.00661325]\n",
            " [0.9926288 ]\n",
            " [0.99260074]\n",
            " [0.01146364]]\n",
            "Step: 2282 -> Loss: 0.008240521885454655 -> Predictions: [[0.00660797]\n",
            " [0.9926351 ]\n",
            " [0.9926071 ]\n",
            " [0.01145349]]\n",
            "Step: 2283 -> Loss: 0.008233471773564816 -> Predictions: [[0.0066027 ]\n",
            " [0.99264127]\n",
            " [0.9926133 ]\n",
            " [0.01144338]]\n",
            "Step: 2284 -> Loss: 0.008226435631513596 -> Predictions: [[0.00659744]\n",
            " [0.9926475 ]\n",
            " [0.9926197 ]\n",
            " [0.01143327]]\n",
            "Step: 2285 -> Loss: 0.008219409734010696 -> Predictions: [[0.00659219]\n",
            " [0.99265385]\n",
            " [0.9926259 ]\n",
            " [0.01142319]]\n",
            "Step: 2286 -> Loss: 0.008212395012378693 -> Predictions: [[0.00658693]\n",
            " [0.9926601 ]\n",
            " [0.9926322 ]\n",
            " [0.01141312]]\n",
            "Step: 2287 -> Loss: 0.008205391466617584 -> Predictions: [[0.00658169]\n",
            " [0.9926663 ]\n",
            " [0.99263847]\n",
            " [0.01140307]]\n",
            "Step: 2288 -> Loss: 0.00819840282201767 -> Predictions: [[0.00657646]\n",
            " [0.9926725 ]\n",
            " [0.99264467]\n",
            " [0.01139303]]\n",
            "Step: 2289 -> Loss: 0.008191422559320927 -> Predictions: [[0.00657125]\n",
            " [0.99267864]\n",
            " [0.9926509 ]\n",
            " [0.01138302]]\n",
            "Step: 2290 -> Loss: 0.008184460923075676 -> Predictions: [[0.00656603]\n",
            " [0.99268484]\n",
            " [0.9926571 ]\n",
            " [0.01137302]]\n",
            "Step: 2291 -> Loss: 0.008177502080798149 -> Predictions: [[0.00656082]\n",
            " [0.9926911 ]\n",
            " [0.9926634 ]\n",
            " [0.01136304]]\n",
            "Step: 2292 -> Loss: 0.008170554414391518 -> Predictions: [[0.00655562]\n",
            " [0.9926972 ]\n",
            " [0.9926696 ]\n",
            " [0.01135307]]\n",
            "Step: 2293 -> Loss: 0.008163625374436378 -> Predictions: [[0.00655044]\n",
            " [0.99270344]\n",
            " [0.9926757 ]\n",
            " [0.01134312]]\n",
            "Step: 2294 -> Loss: 0.00815670657902956 -> Predictions: [[0.00654525]\n",
            " [0.9927095 ]\n",
            " [0.9926819 ]\n",
            " [0.0113332 ]]\n",
            "Step: 2295 -> Loss: 0.008149798028171062 -> Predictions: [[0.00654009]\n",
            " [0.99271566]\n",
            " [0.9926882 ]\n",
            " [0.01132329]]\n",
            "Step: 2296 -> Loss: 0.008142905309796333 -> Predictions: [[0.00653493]\n",
            " [0.99272174]\n",
            " [0.99269426]\n",
            " [0.0113134 ]]\n",
            "Step: 2297 -> Loss: 0.008136018179357052 -> Predictions: [[0.00652977]\n",
            " [0.992728  ]\n",
            " [0.9927004 ]\n",
            " [0.01130353]]\n",
            "Step: 2298 -> Loss: 0.008129142224788666 -> Predictions: [[0.00652461]\n",
            " [0.9927341 ]\n",
            " [0.9927066 ]\n",
            " [0.01129366]]\n",
            "Step: 2299 -> Loss: 0.008122279308736324 -> Predictions: [[0.00651948]\n",
            " [0.9927401 ]\n",
            " [0.9927127 ]\n",
            " [0.01128381]]\n",
            "Step: 2300 -> Loss: 0.008115429431200027 -> Predictions: [[0.00651434]\n",
            " [0.9927462 ]\n",
            " [0.9927188 ]\n",
            " [0.01127399]]\n",
            "Step: 2301 -> Loss: 0.008108589798212051 -> Predictions: [[0.00650922]\n",
            " [0.9927523 ]\n",
            " [0.9927249 ]\n",
            " [0.01126418]]\n",
            "Step: 2302 -> Loss: 0.008101759478449821 -> Predictions: [[0.0065041 ]\n",
            " [0.9927584 ]\n",
            " [0.99273103]\n",
            " [0.01125438]]\n",
            "Step: 2303 -> Loss: 0.008094936609268188 -> Predictions: [[0.00649899]\n",
            " [0.9927644 ]\n",
            " [0.9927371 ]\n",
            " [0.01124459]]\n",
            "Step: 2304 -> Loss: 0.008088132366538048 -> Predictions: [[0.00649389]\n",
            " [0.9927705 ]\n",
            " [0.99274325]\n",
            " [0.01123483]]\n",
            "Step: 2305 -> Loss: 0.008081337437033653 -> Predictions: [[0.00648879]\n",
            " [0.9927765 ]\n",
            " [0.9927492 ]\n",
            " [0.01122509]]\n",
            "Step: 2306 -> Loss: 0.008074553683400154 -> Predictions: [[0.00648371]\n",
            " [0.9927825 ]\n",
            " [0.99275535]\n",
            " [0.01121537]]\n",
            "Step: 2307 -> Loss: 0.008067778311669827 -> Predictions: [[0.00647863]\n",
            " [0.9927886 ]\n",
            " [0.9927614 ]\n",
            " [0.01120565]]\n",
            "Step: 2308 -> Loss: 0.008061019703745842 -> Predictions: [[0.00647356]\n",
            " [0.9927946 ]\n",
            " [0.99276745]\n",
            " [0.01119596]]\n",
            "Step: 2309 -> Loss: 0.00805426761507988 -> Predictions: [[0.0064685 ]\n",
            " [0.9928006 ]\n",
            " [0.9927735 ]\n",
            " [0.01118629]]\n",
            "Step: 2310 -> Loss: 0.008047536015510559 -> Predictions: [[0.00646345]\n",
            " [0.99280655]\n",
            " [0.99277943]\n",
            " [0.01117663]]\n",
            "Step: 2311 -> Loss: 0.008040803484618664 -> Predictions: [[0.0064584 ]\n",
            " [0.9928126 ]\n",
            " [0.99278545]\n",
            " [0.01116698]]\n",
            "Step: 2312 -> Loss: 0.008034083060920238 -> Predictions: [[0.00645337]\n",
            " [0.9928186 ]\n",
            " [0.99279153]\n",
            " [0.01115734]]\n",
            "Step: 2313 -> Loss: 0.008027379401028156 -> Predictions: [[0.00644834]\n",
            " [0.99282444]\n",
            " [0.99279743]\n",
            " [0.01114773]]\n",
            "Step: 2314 -> Loss: 0.008020685985684395 -> Predictions: [[0.00644331]\n",
            " [0.99283046]\n",
            " [0.9928034 ]\n",
            " [0.01113814]]\n",
            "Step: 2315 -> Loss: 0.008013999089598656 -> Predictions: [[0.00643829]\n",
            " [0.9928364 ]\n",
            " [0.9928094 ]\n",
            " [0.01112855]]\n",
            "Step: 2316 -> Loss: 0.008007325232028961 -> Predictions: [[0.00643328]\n",
            " [0.9928423 ]\n",
            " [0.9928154 ]\n",
            " [0.011119  ]]\n",
            "Step: 2317 -> Loss: 0.00800066627562046 -> Predictions: [[0.00642829]\n",
            " [0.99284816]\n",
            " [0.9928214 ]\n",
            " [0.01110944]]\n",
            "Step: 2318 -> Loss: 0.007994016632437706 -> Predictions: [[0.0064233 ]\n",
            " [0.9928542 ]\n",
            " [0.99282724]\n",
            " [0.01109991]]\n",
            "Step: 2319 -> Loss: 0.007987375371158123 -> Predictions: [[0.00641832]\n",
            " [0.99286   ]\n",
            " [0.99283326]\n",
            " [0.01109039]]\n",
            "Step: 2320 -> Loss: 0.007980745285749435 -> Predictions: [[0.00641334]\n",
            " [0.9928659 ]\n",
            " [0.99283916]\n",
            " [0.0110809 ]]\n",
            "Step: 2321 -> Loss: 0.007974128238856792 -> Predictions: [[0.00640836]\n",
            " [0.9928718 ]\n",
            " [0.992845  ]\n",
            " [0.01107141]]\n",
            "Step: 2322 -> Loss: 0.007967517711222172 -> Predictions: [[0.00640339]\n",
            " [0.99287766]\n",
            " [0.992851  ]\n",
            " [0.01106194]]\n",
            "Step: 2323 -> Loss: 0.00796092301607132 -> Predictions: [[0.00639845]\n",
            " [0.99288356]\n",
            " [0.99285686]\n",
            " [0.01105247]]\n",
            "Step: 2324 -> Loss: 0.00795433484017849 -> Predictions: [[0.0063935 ]\n",
            " [0.9928894 ]\n",
            " [0.99286276]\n",
            " [0.01104304]]\n",
            "Step: 2325 -> Loss: 0.00794775877147913 -> Predictions: [[0.00638856]\n",
            " [0.9928953 ]\n",
            " [0.9928686 ]\n",
            " [0.01103362]]\n",
            "Step: 2326 -> Loss: 0.007941195741295815 -> Predictions: [[0.00638363]\n",
            " [0.9929011 ]\n",
            " [0.9928745 ]\n",
            " [0.01102421]]\n",
            "Step: 2327 -> Loss: 0.007934640161693096 -> Predictions: [[0.00637871]\n",
            " [0.9929069 ]\n",
            " [0.9928804 ]\n",
            " [0.01101482]]\n",
            "Step: 2328 -> Loss: 0.007928093895316124 -> Predictions: [[0.00637379]\n",
            " [0.9929127 ]\n",
            " [0.9928861 ]\n",
            " [0.01100545]]\n",
            "Step: 2329 -> Loss: 0.007921560667455196 -> Predictions: [[0.00636889]\n",
            " [0.99291855]\n",
            " [0.992892  ]\n",
            " [0.01099608]]\n",
            "Step: 2330 -> Loss: 0.007915038615465164 -> Predictions: [[0.00636398]\n",
            " [0.99292433]\n",
            " [0.99289787]\n",
            " [0.01098674]]\n",
            "Step: 2331 -> Loss: 0.007908523082733154 -> Predictions: [[0.00635909]\n",
            " [0.9929301 ]\n",
            " [0.99290365]\n",
            " [0.01097739]]\n",
            "Step: 2332 -> Loss: 0.007902028039097786 -> Predictions: [[0.0063542 ]\n",
            " [0.99293596]\n",
            " [0.9929095 ]\n",
            " [0.0109681 ]]\n",
            "Step: 2333 -> Loss: 0.007895533926784992 -> Predictions: [[0.00634933]\n",
            " [0.99294174]\n",
            " [0.9929153 ]\n",
            " [0.01095879]]\n",
            "Step: 2334 -> Loss: 0.007889051921665668 -> Predictions: [[0.00634445]\n",
            " [0.99294746]\n",
            " [0.99292105]\n",
            " [0.01094951]]\n",
            "Step: 2335 -> Loss: 0.007882577367126942 -> Predictions: [[0.00633959]\n",
            " [0.99295324]\n",
            " [0.9929268 ]\n",
            " [0.01094023]]\n",
            "Step: 2336 -> Loss: 0.007876122370362282 -> Predictions: [[0.00633473]\n",
            " [0.9929589 ]\n",
            " [0.9929327 ]\n",
            " [0.01093098]]\n",
            "Step: 2337 -> Loss: 0.007869675755500793 -> Predictions: [[0.00632988]\n",
            " [0.9929646 ]\n",
            " [0.99293834]\n",
            " [0.01092174]]\n",
            "Step: 2338 -> Loss: 0.007863234728574753 -> Predictions: [[0.00632504]\n",
            " [0.9929704 ]\n",
            " [0.99294406]\n",
            " [0.01091252]]\n",
            "Step: 2339 -> Loss: 0.007856805808842182 -> Predictions: [[0.00632021]\n",
            " [0.9929762 ]\n",
            " [0.99294984]\n",
            " [0.01090331]]\n",
            "Step: 2340 -> Loss: 0.007850389927625656 -> Predictions: [[0.00631538]\n",
            " [0.9929818 ]\n",
            " [0.99295557]\n",
            " [0.01089412]]\n",
            "Step: 2341 -> Loss: 0.007843979634344578 -> Predictions: [[0.00631055]\n",
            " [0.9929876 ]\n",
            " [0.99296135]\n",
            " [0.01088494]]\n",
            "Step: 2342 -> Loss: 0.007837584242224693 -> Predictions: [[0.00630574]\n",
            " [0.9929932 ]\n",
            " [0.992967  ]\n",
            " [0.01087578]]\n",
            "Step: 2343 -> Loss: 0.007831194438040257 -> Predictions: [[0.00630094]\n",
            " [0.99299884]\n",
            " [0.99297273]\n",
            " [0.01086663]]\n",
            "Step: 2344 -> Loss: 0.007824819535017014 -> Predictions: [[0.00629613]\n",
            " [0.9930045 ]\n",
            " [0.9929784 ]\n",
            " [0.01085751]]\n",
            "Step: 2345 -> Loss: 0.007818452082574368 -> Predictions: [[0.00629135]\n",
            " [0.9930102 ]\n",
            " [0.9929842 ]\n",
            " [0.01084839]]\n",
            "Step: 2346 -> Loss: 0.007812089286744595 -> Predictions: [[0.00628656]\n",
            " [0.9930159 ]\n",
            " [0.9929898 ]\n",
            " [0.01083929]]\n",
            "Step: 2347 -> Loss: 0.007805746514350176 -> Predictions: [[0.00628179]\n",
            " [0.99302155]\n",
            " [0.99299556]\n",
            " [0.0108302 ]]\n",
            "Step: 2348 -> Loss: 0.0077994102612137794 -> Predictions: [[0.00627702]\n",
            " [0.99302715]\n",
            " [0.9930012 ]\n",
            " [0.01082114]]\n",
            "Step: 2349 -> Loss: 0.007793087977916002 -> Predictions: [[0.00627227]\n",
            " [0.9930328 ]\n",
            " [0.9930068 ]\n",
            " [0.01081208]]\n",
            "Step: 2350 -> Loss: 0.007786769885569811 -> Predictions: [[0.00626751]\n",
            " [0.99303836]\n",
            " [0.9930125 ]\n",
            " [0.01080304]]\n",
            "Step: 2351 -> Loss: 0.007780461106449366 -> Predictions: [[0.00626275]\n",
            " [0.99304396]\n",
            " [0.99301815]\n",
            " [0.01079401]]\n",
            "Step: 2352 -> Loss: 0.007774164900183678 -> Predictions: [[0.00625802]\n",
            " [0.9930496 ]\n",
            " [0.99302375]\n",
            " [0.010785  ]]\n",
            "Step: 2353 -> Loss: 0.007767877075821161 -> Predictions: [[0.00625328]\n",
            " [0.99305516]\n",
            " [0.9930293 ]\n",
            " [0.01077599]]\n",
            "Step: 2354 -> Loss: 0.007761609274893999 -> Predictions: [[0.00624856]\n",
            " [0.9930608 ]\n",
            " [0.99303496]\n",
            " [0.01076703]]\n",
            "Step: 2355 -> Loss: 0.0077553363516926765 -> Predictions: [[0.00624383]\n",
            " [0.9930663 ]\n",
            " [0.99304056]\n",
            " [0.01075804]]\n",
            "Step: 2356 -> Loss: 0.007749080657958984 -> Predictions: [[0.00623912]\n",
            " [0.99307185]\n",
            " [0.9930461 ]\n",
            " [0.0107491 ]]\n",
            "Step: 2357 -> Loss: 0.007742835208773613 -> Predictions: [[0.00623442]\n",
            " [0.9930775 ]\n",
            " [0.99305177]\n",
            " [0.01074016]]\n",
            "Step: 2358 -> Loss: 0.007736600004136562 -> Predictions: [[0.00622971]\n",
            " [0.993083  ]\n",
            " [0.99305725]\n",
            " [0.01073124]]\n",
            "Step: 2359 -> Loss: 0.007730370853096247 -> Predictions: [[0.00622502]\n",
            " [0.99308854]\n",
            " [0.9930629 ]\n",
            " [0.01072233]]\n",
            "Step: 2360 -> Loss: 0.007724156137555838 -> Predictions: [[0.00622034]\n",
            " [0.9930941 ]\n",
            " [0.99306846]\n",
            " [0.01071345]]\n",
            "Step: 2361 -> Loss: 0.0077179474756121635 -> Predictions: [[0.00621566]\n",
            " [0.9930996 ]\n",
            " [0.99307394]\n",
            " [0.01070456]]\n",
            "Step: 2362 -> Loss: 0.007711751852184534 -> Predictions: [[0.00621099]\n",
            " [0.9931051 ]\n",
            " [0.9930795 ]\n",
            " [0.01069571]]\n",
            "Step: 2363 -> Loss: 0.007705561816692352 -> Predictions: [[0.00620632]\n",
            " [0.99311066]\n",
            " [0.993085  ]\n",
            " [0.01068685]]\n",
            "Step: 2364 -> Loss: 0.007699386216700077 -> Predictions: [[0.00620167]\n",
            " [0.9931161 ]\n",
            " [0.99309057]\n",
            " [0.01067802]]\n",
            "Step: 2365 -> Loss: 0.0076932222582399845 -> Predictions: [[0.00619703]\n",
            " [0.99312156]\n",
            " [0.99309605]\n",
            " [0.01066919]]\n",
            "Step: 2366 -> Loss: 0.007687062956392765 -> Predictions: [[0.00619238]\n",
            " [0.9931271 ]\n",
            " [0.9931016 ]\n",
            " [0.0106604 ]]\n",
            "Step: 2367 -> Loss: 0.007680915296077728 -> Predictions: [[0.00618775]\n",
            " [0.99313253]\n",
            " [0.99310714]\n",
            " [0.0106516 ]]\n",
            "Step: 2368 -> Loss: 0.007674776017665863 -> Predictions: [[0.00618312]\n",
            " [0.993138  ]\n",
            " [0.9931125 ]\n",
            " [0.01064282]]\n",
            "Step: 2369 -> Loss: 0.007668647915124893 -> Predictions: [[0.00617849]\n",
            " [0.99314344]\n",
            " [0.99311805]\n",
            " [0.01063407]]\n",
            "Step: 2370 -> Loss: 0.0076625291258096695 -> Predictions: [[0.00617387]\n",
            " [0.99314886]\n",
            " [0.9931235 ]\n",
            " [0.01062532]]\n",
            "Step: 2371 -> Loss: 0.00765641825273633 -> Predictions: [[0.00616926]\n",
            " [0.9931543 ]\n",
            " [0.993129  ]\n",
            " [0.01061659]]\n",
            "Step: 2372 -> Loss: 0.007650317624211311 -> Predictions: [[0.00616466]\n",
            " [0.9931598 ]\n",
            " [0.9931344 ]\n",
            " [0.01060786]]\n",
            "Step: 2373 -> Loss: 0.007644226774573326 -> Predictions: [[0.00616006]\n",
            " [0.9931652 ]\n",
            " [0.9931399 ]\n",
            " [0.01059915]]\n",
            "Step: 2374 -> Loss: 0.007638148032128811 -> Predictions: [[0.00615547]\n",
            " [0.9931706 ]\n",
            " [0.99314535]\n",
            " [0.01059045]]\n",
            "Step: 2375 -> Loss: 0.00763207720592618 -> Predictions: [[0.00615089]\n",
            " [0.9931759 ]\n",
            " [0.9931507 ]\n",
            " [0.01058178]]\n",
            "Step: 2376 -> Loss: 0.007626015692949295 -> Predictions: [[0.00614633]\n",
            " [0.9931813 ]\n",
            " [0.99315614]\n",
            " [0.01057311]]\n",
            "Step: 2377 -> Loss: 0.007619959302246571 -> Predictions: [[0.00614175]\n",
            " [0.9931867 ]\n",
            " [0.99316156]\n",
            " [0.01056445]]\n",
            "Step: 2378 -> Loss: 0.007613916881382465 -> Predictions: [[0.00613719]\n",
            " [0.99319214]\n",
            " [0.993167  ]\n",
            " [0.01055582]]\n",
            "Step: 2379 -> Loss: 0.007607883773744106 -> Predictions: [[0.00613264]\n",
            " [0.99319756]\n",
            " [0.99317235]\n",
            " [0.01054718]]\n",
            "Step: 2380 -> Loss: 0.007601860444992781 -> Predictions: [[0.00612808]\n",
            " [0.9932028 ]\n",
            " [0.9931778 ]\n",
            " [0.01053858]]\n",
            "Step: 2381 -> Loss: 0.0075958482921123505 -> Predictions: [[0.00612355]\n",
            " [0.9932082 ]\n",
            " [0.9931831 ]\n",
            " [0.01052999]]\n",
            "Step: 2382 -> Loss: 0.007589838467538357 -> Predictions: [[0.00611901]\n",
            " [0.99321353]\n",
            " [0.9931885 ]\n",
            " [0.0105214 ]]\n",
            "Step: 2383 -> Loss: 0.007583840284496546 -> Predictions: [[0.00611448]\n",
            " [0.99321884]\n",
            " [0.99319386]\n",
            " [0.01051284]]\n",
            "Step: 2384 -> Loss: 0.007577856071293354 -> Predictions: [[0.00610996]\n",
            " [0.99322426]\n",
            " [0.99319917]\n",
            " [0.01050428]]\n",
            "Step: 2385 -> Loss: 0.007571876980364323 -> Predictions: [[0.00610544]\n",
            " [0.9932295 ]\n",
            " [0.9932046 ]\n",
            " [0.01049574]]\n",
            "Step: 2386 -> Loss: 0.0075659072026610374 -> Predictions: [[0.00610093]\n",
            " [0.9932348 ]\n",
            " [0.9932099 ]\n",
            " [0.01048721]]\n",
            "Step: 2387 -> Loss: 0.007559949532151222 -> Predictions: [[0.00609643]\n",
            " [0.9932401 ]\n",
            " [0.9932152 ]\n",
            " [0.01047869]]\n",
            "Step: 2388 -> Loss: 0.007554002106189728 -> Predictions: [[0.00609194]\n",
            " [0.9932454 ]\n",
            " [0.99322057]\n",
            " [0.01047019]]\n",
            "Step: 2389 -> Loss: 0.007548056542873383 -> Predictions: [[0.00608745]\n",
            " [0.99325067]\n",
            " [0.9932259 ]\n",
            " [0.01046169]]\n",
            "Step: 2390 -> Loss: 0.007542128674685955 -> Predictions: [[0.00608297]\n",
            " [0.993256  ]\n",
            " [0.9932312 ]\n",
            " [0.01045322]]\n",
            "Step: 2391 -> Loss: 0.007536205928772688 -> Predictions: [[0.00607849]\n",
            " [0.9932613 ]\n",
            " [0.9932365 ]\n",
            " [0.01044477]]\n",
            "Step: 2392 -> Loss: 0.007530289702117443 -> Predictions: [[0.00607402]\n",
            " [0.9932666 ]\n",
            " [0.9932417 ]\n",
            " [0.01043631]]\n",
            "Step: 2393 -> Loss: 0.007524388842284679 -> Predictions: [[0.00606956]\n",
            " [0.99327177]\n",
            " [0.99324703]\n",
            " [0.01042788]]\n",
            "Step: 2394 -> Loss: 0.007518494036048651 -> Predictions: [[0.00606511]\n",
            " [0.993277  ]\n",
            " [0.9932522 ]\n",
            " [0.01041946]]\n",
            "Step: 2395 -> Loss: 0.007512608077377081 -> Predictions: [[0.00606066]\n",
            " [0.9932822 ]\n",
            " [0.9932575 ]\n",
            " [0.01041105]]\n",
            "Step: 2396 -> Loss: 0.007506724447011948 -> Predictions: [[0.00605621]\n",
            " [0.9932875 ]\n",
            " [0.9932628 ]\n",
            " [0.01040266]]\n",
            "Step: 2397 -> Loss: 0.007500861771404743 -> Predictions: [[0.00605178]\n",
            " [0.9932927 ]\n",
            " [0.9932681 ]\n",
            " [0.01039427]]\n",
            "Step: 2398 -> Loss: 0.007495003752410412 -> Predictions: [[0.00604735]\n",
            " [0.9932979 ]\n",
            " [0.99327326]\n",
            " [0.0103859 ]]\n",
            "Step: 2399 -> Loss: 0.007489153649657965 -> Predictions: [[0.00604292]\n",
            " [0.9933031 ]\n",
            " [0.99327856]\n",
            " [0.01037755]]\n",
            "Step: 2400 -> Loss: 0.007483311928808689 -> Predictions: [[0.0060385 ]\n",
            " [0.9933083 ]\n",
            " [0.99328375]\n",
            " [0.0103692 ]]\n",
            "Step: 2401 -> Loss: 0.0074774837121367455 -> Predictions: [[0.0060341 ]\n",
            " [0.9933135 ]\n",
            " [0.99328893]\n",
            " [0.01036088]]\n",
            "Step: 2402 -> Loss: 0.007471662014722824 -> Predictions: [[0.00602969]\n",
            " [0.9933187 ]\n",
            " [0.99329424]\n",
            " [0.01035256]]\n",
            "Step: 2403 -> Loss: 0.007465842179954052 -> Predictions: [[0.00602529]\n",
            " [0.99332386]\n",
            " [0.99329937]\n",
            " [0.01034426]]\n",
            "Step: 2404 -> Loss: 0.0074600400403141975 -> Predictions: [[0.0060209 ]\n",
            " [0.99332905]\n",
            " [0.99330455]\n",
            " [0.01033597]]\n",
            "Step: 2405 -> Loss: 0.007454241625964642 -> Predictions: [[0.00601651]\n",
            " [0.9933342 ]\n",
            " [0.99330974]\n",
            " [0.01032769]]\n",
            "Step: 2406 -> Loss: 0.007448453456163406 -> Predictions: [[0.00601212]\n",
            " [0.99333936]\n",
            " [0.9933149 ]\n",
            " [0.01031943]]\n",
            "Step: 2407 -> Loss: 0.007442676927894354 -> Predictions: [[0.00600775]\n",
            " [0.9933444 ]\n",
            " [0.9933201 ]\n",
            " [0.01031119]]\n",
            "Step: 2408 -> Loss: 0.007436906918883324 -> Predictions: [[0.00600338]\n",
            " [0.9933496 ]\n",
            " [0.99332523]\n",
            " [0.01030295]]\n",
            "Step: 2409 -> Loss: 0.007431145757436752 -> Predictions: [[0.00599902]\n",
            " [0.9933547 ]\n",
            " [0.9933304 ]\n",
            " [0.01029473]]\n",
            "Step: 2410 -> Loss: 0.007425391580909491 -> Predictions: [[0.00599467]\n",
            " [0.99335986]\n",
            " [0.9933355 ]\n",
            " [0.0102865 ]]\n",
            "Step: 2411 -> Loss: 0.007419649977236986 -> Predictions: [[0.00599032]\n",
            " [0.99336493]\n",
            " [0.9933407 ]\n",
            " [0.01027832]]\n",
            "Step: 2412 -> Loss: 0.007413908839225769 -> Predictions: [[0.00598598]\n",
            " [0.99337006]\n",
            " [0.99334586]\n",
            " [0.01027011]]\n",
            "Step: 2413 -> Loss: 0.007408183999359608 -> Predictions: [[0.00598163]\n",
            " [0.9933751 ]\n",
            " [0.9933509 ]\n",
            " [0.01026195]]\n",
            "Step: 2414 -> Loss: 0.0074024684727191925 -> Predictions: [[0.0059773]\n",
            " [0.9933802]\n",
            " [0.9933561]\n",
            " [0.0102538]]\n",
            "Step: 2415 -> Loss: 0.0073967594653368 -> Predictions: [[0.00597297]\n",
            " [0.9933854 ]\n",
            " [0.9933611 ]\n",
            " [0.01024565]]\n",
            "Step: 2416 -> Loss: 0.007391057442873716 -> Predictions: [[0.00596865]\n",
            " [0.99339044]\n",
            " [0.9933662 ]\n",
            " [0.01023751]]\n",
            "Step: 2417 -> Loss: 0.007385367061942816 -> Predictions: [[0.00596434]\n",
            " [0.9933955 ]\n",
            " [0.99337137]\n",
            " [0.01022939]]\n",
            "Step: 2418 -> Loss: 0.007379685528576374 -> Predictions: [[0.00596004]\n",
            " [0.9934006 ]\n",
            " [0.99337643]\n",
            " [0.01022128]]\n",
            "Step: 2419 -> Loss: 0.007374010980129242 -> Predictions: [[0.00595574]\n",
            " [0.9934056 ]\n",
            " [0.9933815 ]\n",
            " [0.01021318]]\n",
            "Step: 2420 -> Loss: 0.0073683420196175575 -> Predictions: [[0.00595144]\n",
            " [0.99341065]\n",
            " [0.99338657]\n",
            " [0.0102051 ]]\n",
            "Step: 2421 -> Loss: 0.0073626842349767685 -> Predictions: [[0.00594715]\n",
            " [0.9934156 ]\n",
            " [0.99339163]\n",
            " [0.01019702]]\n",
            "Step: 2422 -> Loss: 0.0073570432141423225 -> Predictions: [[0.00594288]\n",
            " [0.99342066]\n",
            " [0.99339664]\n",
            " [0.01018898]]\n",
            "Step: 2423 -> Loss: 0.0073514049872756 -> Predictions: [[0.0059386 ]\n",
            " [0.9934257 ]\n",
            " [0.9934017 ]\n",
            " [0.01018092]]\n",
            "Step: 2424 -> Loss: 0.007345765829086304 -> Predictions: [[0.00593433]\n",
            " [0.9934307 ]\n",
            " [0.9934068 ]\n",
            " [0.01017287]]\n",
            "Step: 2425 -> Loss: 0.00734014343470335 -> Predictions: [[0.00593007]\n",
            " [0.99343574]\n",
            " [0.9934117 ]\n",
            " [0.01016484]]\n",
            "Step: 2426 -> Loss: 0.007334533147513866 -> Predictions: [[0.00592581]\n",
            " [0.9934407 ]\n",
            " [0.9934168 ]\n",
            " [0.01015684]]\n",
            "Step: 2427 -> Loss: 0.007328931242227554 -> Predictions: [[0.00592157]\n",
            " [0.9934457 ]\n",
            " [0.99342185]\n",
            " [0.01014885]]\n",
            "Step: 2428 -> Loss: 0.007323333062231541 -> Predictions: [[0.00591733]\n",
            " [0.99345064]\n",
            " [0.9934268 ]\n",
            " [0.01014086]]\n",
            "Step: 2429 -> Loss: 0.007317746989428997 -> Predictions: [[0.0059131 ]\n",
            " [0.9934556 ]\n",
            " [0.99343187]\n",
            " [0.01013289]]\n",
            "Step: 2430 -> Loss: 0.007312157656997442 -> Predictions: [[0.00590887]\n",
            " [0.99346066]\n",
            " [0.99343675]\n",
            " [0.01012492]]\n",
            "Step: 2431 -> Loss: 0.007306587416678667 -> Predictions: [[0.00590464]\n",
            " [0.9934656 ]\n",
            " [0.9934417 ]\n",
            " [0.01011698]]\n",
            "Step: 2432 -> Loss: 0.007301020435988903 -> Predictions: [[0.0059004 ]\n",
            " [0.99347055]\n",
            " [0.99344677]\n",
            " [0.01010904]]\n",
            "Step: 2433 -> Loss: 0.007295471150428057 -> Predictions: [[0.0058962 ]\n",
            " [0.9934755 ]\n",
            " [0.9934517 ]\n",
            " [0.01010111]]\n",
            "Step: 2434 -> Loss: 0.007289920933544636 -> Predictions: [[0.00589198]\n",
            " [0.99348044]\n",
            " [0.99345666]\n",
            " [0.0100932 ]]\n",
            "Step: 2435 -> Loss: 0.007284379564225674 -> Predictions: [[0.00588777]\n",
            " [0.9934853 ]\n",
            " [0.9934616 ]\n",
            " [0.0100853 ]]\n",
            "Step: 2436 -> Loss: 0.007278848439455032 -> Predictions: [[0.00588357]\n",
            " [0.9934902 ]\n",
            " [0.99346656]\n",
            " [0.01007742]]\n",
            "Step: 2437 -> Loss: 0.007273329421877861 -> Predictions: [[0.00587938]\n",
            " [0.99349517]\n",
            " [0.9934715 ]\n",
            " [0.01006955]]\n",
            "Step: 2438 -> Loss: 0.007267812266945839 -> Predictions: [[0.0058752 ]\n",
            " [0.99350005]\n",
            " [0.99347645]\n",
            " [0.01006166]]\n",
            "Step: 2439 -> Loss: 0.007262306287884712 -> Predictions: [[0.00587101]\n",
            " [0.9935049 ]\n",
            " [0.9934814 ]\n",
            " [0.01005382]]\n",
            "Step: 2440 -> Loss: 0.007256805431097746 -> Predictions: [[0.00586684]\n",
            " [0.9935098 ]\n",
            " [0.9934863 ]\n",
            " [0.01004599]]\n",
            "Step: 2441 -> Loss: 0.007251316215842962 -> Predictions: [[0.00586268]\n",
            " [0.9935148 ]\n",
            " [0.9934911 ]\n",
            " [0.01003816]]\n",
            "Step: 2442 -> Loss: 0.007245832122862339 -> Predictions: [[0.00585852]\n",
            " [0.9935196 ]\n",
            " [0.99349606]\n",
            " [0.01003034]]\n",
            "Step: 2443 -> Loss: 0.0072403596714138985 -> Predictions: [[0.00585436]\n",
            " [0.99352455]\n",
            " [0.993501  ]\n",
            " [0.01002254]]\n",
            "Step: 2444 -> Loss: 0.00723489373922348 -> Predictions: [[0.0058502 ]\n",
            " [0.9935294 ]\n",
            " [0.99350584]\n",
            " [0.01001474]]\n",
            "Step: 2445 -> Loss: 0.007229443173855543 -> Predictions: [[0.00584606]\n",
            " [0.9935342 ]\n",
            " [0.9935108 ]\n",
            " [0.01000696]]\n",
            "Step: 2446 -> Loss: 0.007223993074148893 -> Predictions: [[0.00584192]\n",
            " [0.99353904]\n",
            " [0.9935156 ]\n",
            " [0.0099992 ]]\n",
            "Step: 2447 -> Loss: 0.007218548096716404 -> Predictions: [[0.00583778]\n",
            " [0.99354386]\n",
            " [0.99352044]\n",
            " [0.00999143]]\n",
            "Step: 2448 -> Loss: 0.007213117554783821 -> Predictions: [[0.00583365]\n",
            " [0.9935487 ]\n",
            " [0.9935254 ]\n",
            " [0.0099837 ]]\n",
            "Step: 2449 -> Loss: 0.007207693997770548 -> Predictions: [[0.00582954]\n",
            " [0.99355364]\n",
            " [0.9935302 ]\n",
            " [0.00997598]]\n",
            "Step: 2450 -> Loss: 0.007202276960015297 -> Predictions: [[0.00582541]\n",
            " [0.99355835]\n",
            " [0.99353504]\n",
            " [0.00996826]]\n",
            "Step: 2451 -> Loss: 0.00719686783850193 -> Predictions: [[0.0058213 ]\n",
            " [0.9935632 ]\n",
            " [0.99353987]\n",
            " [0.00996054]]\n",
            "Step: 2452 -> Loss: 0.0071914708241820335 -> Predictions: [[0.0058172 ]\n",
            " [0.993568  ]\n",
            " [0.9935447 ]\n",
            " [0.00995284]]\n",
            "Step: 2453 -> Loss: 0.007186072412878275 -> Predictions: [[0.0058131 ]\n",
            " [0.99357283]\n",
            " [0.9935495 ]\n",
            " [0.00994515]]\n",
            "Step: 2454 -> Loss: 0.007180689834058285 -> Predictions: [[0.00580901]\n",
            " [0.9935776 ]\n",
            " [0.99355435]\n",
            " [0.00993748]]\n",
            "Step: 2455 -> Loss: 0.007175315171480179 -> Predictions: [[0.00580493]\n",
            " [0.9935823 ]\n",
            " [0.9935592 ]\n",
            " [0.00992982]]\n",
            "Step: 2456 -> Loss: 0.007169943302869797 -> Predictions: [[0.00580085]\n",
            " [0.99358714]\n",
            " [0.99356395]\n",
            " [0.00992217]]\n",
            "Step: 2457 -> Loss: 0.007164583541452885 -> Predictions: [[0.00579677]\n",
            " [0.99359196]\n",
            " [0.9935688 ]\n",
            " [0.00991454]]\n",
            "Step: 2458 -> Loss: 0.007159228902310133 -> Predictions: [[0.00579271]\n",
            " [0.9935967 ]\n",
            " [0.9935735 ]\n",
            " [0.0099069 ]]\n",
            "Step: 2459 -> Loss: 0.0071538882330060005 -> Predictions: [[0.00578865]\n",
            " [0.9936015 ]\n",
            " [0.9935783 ]\n",
            " [0.00989929]]\n",
            "Step: 2460 -> Loss: 0.007148545701056719 -> Predictions: [[0.00578459]\n",
            " [0.9936062 ]\n",
            " [0.99358314]\n",
            " [0.00989167]]\n",
            "Step: 2461 -> Loss: 0.007143219001591206 -> Predictions: [[0.00578055]\n",
            " [0.9936109 ]\n",
            " [0.99358785]\n",
            " [0.00988408]]\n",
            "Step: 2462 -> Loss: 0.007137895096093416 -> Predictions: [[0.0057765 ]\n",
            " [0.99361575]\n",
            " [0.9935927 ]\n",
            " [0.0098765 ]]\n",
            "Step: 2463 -> Loss: 0.007132581435143948 -> Predictions: [[0.00577247]\n",
            " [0.99362046]\n",
            " [0.9935974 ]\n",
            " [0.00986893]]\n",
            "Step: 2464 -> Loss: 0.0071272775530815125 -> Predictions: [[0.00576843]\n",
            " [0.99362516]\n",
            " [0.9936021 ]\n",
            " [0.00986138]]\n",
            "Step: 2465 -> Loss: 0.007121980655938387 -> Predictions: [[0.00576439]\n",
            " [0.9936299 ]\n",
            " [0.9936069 ]\n",
            " [0.00985383]]\n",
            "Step: 2466 -> Loss: 0.007116687949746847 -> Predictions: [[0.00576036]\n",
            " [0.9936346 ]\n",
            " [0.99361163]\n",
            " [0.00984629]]\n",
            "Step: 2467 -> Loss: 0.007111405022442341 -> Predictions: [[0.00575634]\n",
            " [0.9936393 ]\n",
            " [0.99361634]\n",
            " [0.00983876]]\n",
            "Step: 2468 -> Loss: 0.007106130011379719 -> Predictions: [[0.00575232]\n",
            " [0.993644  ]\n",
            " [0.99362105]\n",
            " [0.00983125]]\n",
            "Step: 2469 -> Loss: 0.007100860588252544 -> Predictions: [[0.00574831]\n",
            " [0.9936487 ]\n",
            " [0.99362576]\n",
            " [0.00982375]]\n",
            "Step: 2470 -> Loss: 0.0070955995470285416 -> Predictions: [[0.00574431]\n",
            " [0.9936533 ]\n",
            " [0.99363047]\n",
            " [0.00981625]]\n",
            "Step: 2471 -> Loss: 0.007090351544320583 -> Predictions: [[0.00574032]\n",
            " [0.993658  ]\n",
            " [0.9936352 ]\n",
            " [0.00980878]]\n",
            "Step: 2472 -> Loss: 0.007085105404257774 -> Predictions: [[0.00573631]\n",
            " [0.9936627 ]\n",
            " [0.9936399 ]\n",
            " [0.00980132]]\n",
            "Step: 2473 -> Loss: 0.007079867646098137 -> Predictions: [[0.00573233]\n",
            " [0.9936673 ]\n",
            " [0.9936446 ]\n",
            " [0.00979384]]\n",
            "Step: 2474 -> Loss: 0.007074639666825533 -> Predictions: [[0.00572835]\n",
            " [0.993672  ]\n",
            " [0.9936492 ]\n",
            " [0.0097864 ]]\n",
            "Step: 2475 -> Loss: 0.007069417275488377 -> Predictions: [[0.00572437]\n",
            " [0.9936766 ]\n",
            " [0.9936539 ]\n",
            " [0.00977896]]\n",
            "Step: 2476 -> Loss: 0.007064208388328552 -> Predictions: [[0.0057204 ]\n",
            " [0.9936813 ]\n",
            " [0.9936586 ]\n",
            " [0.00977154]]\n",
            "Step: 2477 -> Loss: 0.007059001363813877 -> Predictions: [[0.00571644]\n",
            " [0.9936859 ]\n",
            " [0.9936632 ]\n",
            " [0.00976413]]\n",
            "Step: 2478 -> Loss: 0.0070538027212023735 -> Predictions: [[0.00571247]\n",
            " [0.9936905 ]\n",
            " [0.9936679 ]\n",
            " [0.00975672]]\n",
            "Step: 2479 -> Loss: 0.007048608735203743 -> Predictions: [[0.00570853]\n",
            " [0.9936952 ]\n",
            " [0.9936725 ]\n",
            " [0.00974932]]\n",
            "Step: 2480 -> Loss: 0.007043429650366306 -> Predictions: [[0.00570459]\n",
            " [0.9936998 ]\n",
            " [0.9936772 ]\n",
            " [0.00974195]]\n",
            "Step: 2481 -> Loss: 0.007038254290819168 -> Predictions: [[0.00570064]\n",
            " [0.9937044 ]\n",
            " [0.9936818 ]\n",
            " [0.00973459]]\n",
            "Step: 2482 -> Loss: 0.00703307893127203 -> Predictions: [[0.00569669]\n",
            " [0.99370897]\n",
            " [0.9936864 ]\n",
            " [0.00972721]]\n",
            "Step: 2483 -> Loss: 0.007027921732515097 -> Predictions: [[0.00569277]\n",
            " [0.99371356]\n",
            " [0.99369097]\n",
            " [0.00971988]]\n",
            "Step: 2484 -> Loss: 0.007022765465080738 -> Predictions: [[0.00568884]\n",
            " [0.99371815]\n",
            " [0.9936957 ]\n",
            " [0.00971254]]\n",
            "Step: 2485 -> Loss: 0.007017622701823711 -> Predictions: [[0.00568493]\n",
            " [0.99372274]\n",
            " [0.99370027]\n",
            " [0.00970521]]\n",
            "Step: 2486 -> Loss: 0.007012483663856983 -> Predictions: [[0.005681  ]\n",
            " [0.9937273 ]\n",
            " [0.99370486]\n",
            " [0.0096979 ]]\n",
            "Step: 2487 -> Loss: 0.0070073483511805534 -> Predictions: [[0.00567709]\n",
            " [0.9937319 ]\n",
            " [0.99370944]\n",
            " [0.00969059]]\n",
            "Step: 2488 -> Loss: 0.007002227008342743 -> Predictions: [[0.00567319]\n",
            " [0.9937364 ]\n",
            " [0.99371403]\n",
            " [0.00968329]]\n",
            "Step: 2489 -> Loss: 0.006997106596827507 -> Predictions: [[0.00566928]\n",
            " [0.993741  ]\n",
            " [0.9937186 ]\n",
            " [0.00967601]]\n",
            "Step: 2490 -> Loss: 0.00699200015515089 -> Predictions: [[0.00566539]\n",
            " [0.99374557]\n",
            " [0.9937231 ]\n",
            " [0.00966874]]\n",
            "Step: 2491 -> Loss: 0.006986894644796848 -> Predictions: [[0.0056615 ]\n",
            " [0.99375004]\n",
            " [0.9937277 ]\n",
            " [0.00966148]]\n",
            "Step: 2492 -> Loss: 0.006981805898249149 -> Predictions: [[0.00565763]\n",
            " [0.9937546 ]\n",
            " [0.9937323 ]\n",
            " [0.00965423]]\n",
            "Step: 2493 -> Loss: 0.0069767143577337265 -> Predictions: [[0.00565375]\n",
            " [0.99375916]\n",
            " [0.99373686]\n",
            " [0.00964699]]\n",
            "Step: 2494 -> Loss: 0.0069716377183794975 -> Predictions: [[0.00564988]\n",
            " [0.99376374]\n",
            " [0.99374133]\n",
            " [0.00963976]]\n",
            "Step: 2495 -> Loss: 0.0069665610790252686 -> Predictions: [[0.005646  ]\n",
            " [0.9937682 ]\n",
            " [0.9937459 ]\n",
            " [0.00963254]]\n",
            "Step: 2496 -> Loss: 0.0069614918902516365 -> Predictions: [[0.00564213]\n",
            " [0.9937728 ]\n",
            " [0.9937504 ]\n",
            " [0.00962533]]\n",
            "Step: 2497 -> Loss: 0.006956436671316624 -> Predictions: [[0.00563828]\n",
            " [0.9937773 ]\n",
            " [0.993755  ]\n",
            " [0.00961814]]\n",
            "Step: 2498 -> Loss: 0.006951385177671909 -> Predictions: [[0.00563443]\n",
            " [0.99378175]\n",
            " [0.99375945]\n",
            " [0.00961095]]\n",
            "Step: 2499 -> Loss: 0.006946339271962643 -> Predictions: [[0.00563057]\n",
            " [0.9937862 ]\n",
            " [0.993764  ]\n",
            " [0.00960378]]\n",
            "Step: 2501 -> Loss: 0.006936280522495508 -> Predictions: [[0.00562291]\n",
            " [0.99379516]\n",
            " [0.99377304]\n",
            " [0.00958946]]\n",
            "Step: 2502 -> Loss: 0.006931256502866745 -> Predictions: [[0.00561907]\n",
            " [0.9937996 ]\n",
            " [0.9937775 ]\n",
            " [0.00958231]]\n",
            "Step: 2503 -> Loss: 0.006926239468157291 -> Predictions: [[0.00561524]\n",
            " [0.9938041 ]\n",
            " [0.993782  ]\n",
            " [0.00957517]]\n",
            "Step: 2504 -> Loss: 0.006921233609318733 -> Predictions: [[0.00561142]\n",
            " [0.99380857]\n",
            " [0.99378645]\n",
            " [0.00956804]]\n",
            "Step: 2505 -> Loss: 0.0069162314757704735 -> Predictions: [[0.00560759]\n",
            " [0.99381304]\n",
            " [0.9937909 ]\n",
            " [0.00956093]]\n",
            "Step: 2506 -> Loss: 0.00691123865544796 -> Predictions: [[0.00560378]\n",
            " [0.9938174 ]\n",
            " [0.9937954 ]\n",
            " [0.00955383]]\n",
            "Step: 2507 -> Loss: 0.006906250957399607 -> Predictions: [[0.00559997]\n",
            " [0.99382186]\n",
            " [0.99379987]\n",
            " [0.00954673]]\n",
            "Step: 2508 -> Loss: 0.006901268847286701 -> Predictions: [[0.00559617]\n",
            " [0.9938263 ]\n",
            " [0.99380434]\n",
            " [0.00953965]]\n",
            "Step: 2509 -> Loss: 0.006896302103996277 -> Predictions: [[0.00559238]\n",
            " [0.99383074]\n",
            " [0.9938088 ]\n",
            " [0.00953258]]\n",
            "Step: 2510 -> Loss: 0.006891333963721991 -> Predictions: [[0.00558859]\n",
            " [0.9938352 ]\n",
            " [0.99381316]\n",
            " [0.00952551]]\n",
            "Step: 2511 -> Loss: 0.0068863751366734505 -> Predictions: [[0.0055848 ]\n",
            " [0.9938397 ]\n",
            " [0.9938176 ]\n",
            " [0.00951847]]\n",
            "Step: 2512 -> Loss: 0.006881426088511944 -> Predictions: [[0.00558102]\n",
            " [0.99384403]\n",
            " [0.9938221 ]\n",
            " [0.00951143]]\n",
            "Step: 2513 -> Loss: 0.006876483093947172 -> Predictions: [[0.00557724]\n",
            " [0.9938484 ]\n",
            " [0.99382645]\n",
            " [0.0095044 ]]\n",
            "Step: 2514 -> Loss: 0.00687154196202755 -> Predictions: [[0.00557347]\n",
            " [0.99385285]\n",
            " [0.9938309 ]\n",
            " [0.00949738]]\n",
            "Step: 2515 -> Loss: 0.006866611540317535 -> Predictions: [[0.00556971]\n",
            " [0.9938572 ]\n",
            " [0.99383533]\n",
            " [0.00949037]]\n",
            "Step: 2516 -> Loss: 0.006861689500510693 -> Predictions: [[0.00556596]\n",
            " [0.99386156]\n",
            " [0.9938398 ]\n",
            " [0.00948336]]\n",
            "Step: 2517 -> Loss: 0.006856771185994148 -> Predictions: [[0.0055622 ]\n",
            " [0.9938659 ]\n",
            " [0.99384415]\n",
            " [0.00947638]]\n",
            "Step: 2518 -> Loss: 0.006851860322058201 -> Predictions: [[0.00555845]\n",
            " [0.9938704 ]\n",
            " [0.9938485 ]\n",
            " [0.0094694 ]]\n",
            "Step: 2519 -> Loss: 0.006846959702670574 -> Predictions: [[0.00555471]\n",
            " [0.9938747 ]\n",
            " [0.993853  ]\n",
            " [0.00946243]]\n",
            "Step: 2520 -> Loss: 0.006842062808573246 -> Predictions: [[0.00555097]\n",
            " [0.9938791 ]\n",
            " [0.9938573 ]\n",
            " [0.00945547]]\n",
            "Step: 2521 -> Loss: 0.006837174296379089 -> Predictions: [[0.00554724]\n",
            " [0.9938835 ]\n",
            " [0.9938617 ]\n",
            " [0.00944851]]\n",
            "Step: 2522 -> Loss: 0.00683229137212038 -> Predictions: [[0.00554351]\n",
            " [0.99388784]\n",
            " [0.993866  ]\n",
            " [0.00944158]]\n",
            "Step: 2523 -> Loss: 0.006827417761087418 -> Predictions: [[0.00553979]\n",
            " [0.9938922 ]\n",
            " [0.9938704 ]\n",
            " [0.00943465]]\n",
            "Step: 2524 -> Loss: 0.006822550669312477 -> Predictions: [[0.00553606]\n",
            " [0.9938964 ]\n",
            " [0.9938747 ]\n",
            " [0.00942773]]\n",
            "Step: 2525 -> Loss: 0.006817681714892387 -> Predictions: [[0.00553234]\n",
            " [0.9939008 ]\n",
            " [0.9938791 ]\n",
            " [0.00942081]]\n",
            "Step: 2526 -> Loss: 0.006812829524278641 -> Predictions: [[0.00552864]\n",
            " [0.9939051 ]\n",
            " [0.9938835 ]\n",
            " [0.00941391]]\n",
            "Step: 2527 -> Loss: 0.006807981990277767 -> Predictions: [[0.00552493]\n",
            " [0.9939095 ]\n",
            " [0.99388784]\n",
            " [0.00940702]]\n",
            "Step: 2528 -> Loss: 0.0068031419068574905 -> Predictions: [[0.00552123]\n",
            " [0.9939137 ]\n",
            " [0.9938922 ]\n",
            " [0.00940014]]\n",
            "Step: 2529 -> Loss: 0.006798308342695236 -> Predictions: [[0.00551753]\n",
            " [0.99391806]\n",
            " [0.9938964 ]\n",
            " [0.00939326]]\n",
            "Step: 2530 -> Loss: 0.006793479435145855 -> Predictions: [[0.00551384]\n",
            " [0.99392235]\n",
            " [0.9939008 ]\n",
            " [0.00938641]]\n",
            "Step: 2531 -> Loss: 0.006788658909499645 -> Predictions: [[0.00551016]\n",
            " [0.9939267 ]\n",
            " [0.9939051 ]\n",
            " [0.00937955]]\n",
            "Step: 2532 -> Loss: 0.0067838444374501705 -> Predictions: [[0.00550647]\n",
            " [0.99393094]\n",
            " [0.99390936]\n",
            " [0.00937271]]\n",
            "Step: 2533 -> Loss: 0.006779039744287729 -> Predictions: [[0.00550279]\n",
            " [0.99393517]\n",
            " [0.9939137 ]\n",
            " [0.00936588]]\n",
            "Step: 2534 -> Loss: 0.006774234585464001 -> Predictions: [[0.00549911]\n",
            " [0.9939395 ]\n",
            " [0.99391794]\n",
            " [0.00935905]]\n",
            "Step: 2535 -> Loss: 0.006769439671188593 -> Predictions: [[0.00549546]\n",
            " [0.99394375]\n",
            " [0.99392235]\n",
            " [0.00935223]]\n",
            "Step: 2536 -> Loss: 0.006764655001461506 -> Predictions: [[0.0054918 ]\n",
            " [0.993948  ]\n",
            " [0.9939266 ]\n",
            " [0.00934543]]\n",
            "Step: 2537 -> Loss: 0.006759872660040855 -> Predictions: [[0.00548813]\n",
            " [0.9939522 ]\n",
            " [0.9939308 ]\n",
            " [0.00933864]]\n",
            "Step: 2538 -> Loss: 0.006755099631845951 -> Predictions: [[0.00548448]\n",
            " [0.99395645]\n",
            " [0.99393517]\n",
            " [0.00933186]]\n",
            "Step: 2539 -> Loss: 0.006750331725925207 -> Predictions: [[0.00548084]\n",
            " [0.99396074]\n",
            " [0.9939394 ]\n",
            " [0.00932508]]\n",
            "Step: 2540 -> Loss: 0.006745573133230209 -> Predictions: [[0.0054772 ]\n",
            " [0.99396497]\n",
            " [0.99394363]\n",
            " [0.00931832]]\n",
            "Step: 2541 -> Loss: 0.006740816868841648 -> Predictions: [[0.00547355]\n",
            " [0.9939692 ]\n",
            " [0.99394786]\n",
            " [0.00931156]]\n",
            "Step: 2542 -> Loss: 0.006736068986356258 -> Predictions: [[0.00546992]\n",
            " [0.99397343]\n",
            " [0.9939521 ]\n",
            " [0.00930482]]\n",
            "Step: 2543 -> Loss: 0.0067313299514353275 -> Predictions: [[0.0054663 ]\n",
            " [0.99397767]\n",
            " [0.9939564 ]\n",
            " [0.00929808]]\n",
            "Step: 2544 -> Loss: 0.006726596970111132 -> Predictions: [[0.00546267]\n",
            " [0.9939819 ]\n",
            " [0.9939606 ]\n",
            " [0.00929136]]\n",
            "Step: 2545 -> Loss: 0.006721862591803074 -> Predictions: [[0.00545905]\n",
            " [0.9939861 ]\n",
            " [0.99396485]\n",
            " [0.00928463]]\n",
            "Step: 2546 -> Loss: 0.006717141717672348 -> Predictions: [[0.00545542]\n",
            " [0.9939903 ]\n",
            " [0.9939691 ]\n",
            " [0.00927793]]\n",
            "Step: 2547 -> Loss: 0.0067124273627996445 -> Predictions: [[0.00545182]\n",
            " [0.99399453]\n",
            " [0.9939733 ]\n",
            " [0.00927123]]\n",
            "Step: 2548 -> Loss: 0.006707722321152687 -> Predictions: [[0.00544822]\n",
            " [0.99399877]\n",
            " [0.99397755]\n",
            " [0.00926454]]\n",
            "Step: 2549 -> Loss: 0.006703022867441177 -> Predictions: [[0.00544462]\n",
            " [0.9940029 ]\n",
            " [0.99398166]\n",
            " [0.00925787]]\n",
            "Step: 2550 -> Loss: 0.006698326673358679 -> Predictions: [[0.00544103]\n",
            " [0.9940071 ]\n",
            " [0.9939859 ]\n",
            " [0.00925119]]\n",
            "Step: 2551 -> Loss: 0.0066936383955180645 -> Predictions: [[0.00543744]\n",
            " [0.9940112 ]\n",
            " [0.9939902 ]\n",
            " [0.00924454]]\n",
            "Step: 2552 -> Loss: 0.0066889552399516106 -> Predictions: [[0.00543385]\n",
            " [0.99401546]\n",
            " [0.9939943 ]\n",
            " [0.00923789]]\n",
            "Step: 2553 -> Loss: 0.006684279069304466 -> Predictions: [[0.00543027]\n",
            " [0.9940196 ]\n",
            " [0.9939985 ]\n",
            " [0.00923125]]\n",
            "Step: 2554 -> Loss: 0.00667960848659277 -> Predictions: [[0.00542669]\n",
            " [0.99402374]\n",
            " [0.99400264]\n",
            " [0.00922462]]\n",
            "Step: 2555 -> Loss: 0.00667494535446167 -> Predictions: [[0.00542313]\n",
            " [0.994028  ]\n",
            " [0.9940069 ]\n",
            " [0.009218  ]]\n",
            "Step: 2556 -> Loss: 0.006670292001217604 -> Predictions: [[0.00541956]\n",
            " [0.9940321 ]\n",
            " [0.994011  ]\n",
            " [0.00921139]]\n",
            "Step: 2557 -> Loss: 0.006665639579296112 -> Predictions: [[0.00541599]\n",
            " [0.9940362 ]\n",
            " [0.9940153 ]\n",
            " [0.00920478]]\n",
            "Step: 2558 -> Loss: 0.0066609932109713554 -> Predictions: [[0.00541243]\n",
            " [0.9940403 ]\n",
            " [0.9940194 ]\n",
            " [0.00919819]]\n",
            "Step: 2559 -> Loss: 0.00665635708719492 -> Predictions: [[0.00540887]\n",
            " [0.9940445 ]\n",
            " [0.9940235 ]\n",
            " [0.0091916 ]]\n",
            "Step: 2560 -> Loss: 0.006651726085692644 -> Predictions: [[0.00540533]\n",
            " [0.9940486 ]\n",
            " [0.9940276 ]\n",
            " [0.00918502]]\n",
            "Step: 2561 -> Loss: 0.006647102534770966 -> Predictions: [[0.00540179]\n",
            " [0.9940527 ]\n",
            " [0.9940317 ]\n",
            " [0.00917846]]\n",
            "Step: 2562 -> Loss: 0.006642483174800873 -> Predictions: [[0.00539826]\n",
            " [0.9940568 ]\n",
            " [0.99403596]\n",
            " [0.0091719 ]]\n",
            "Step: 2563 -> Loss: 0.006637871731072664 -> Predictions: [[0.00539472]\n",
            " [0.99406093]\n",
            " [0.99404013]\n",
            " [0.00916535]]\n",
            "Step: 2564 -> Loss: 0.0066332630813121796 -> Predictions: [[0.00539119]\n",
            " [0.99406505]\n",
            " [0.99404424]\n",
            " [0.00915882]]\n",
            "Step: 2565 -> Loss: 0.006628665141761303 -> Predictions: [[0.00538766]\n",
            " [0.9940692 ]\n",
            " [0.99404836]\n",
            " [0.0091523 ]]\n",
            "Step: 2566 -> Loss: 0.006624071858823299 -> Predictions: [[0.00538414]\n",
            " [0.9940732 ]\n",
            " [0.99405235]\n",
            " [0.00914577]]\n",
            "Step: 2567 -> Loss: 0.006619484629482031 -> Predictions: [[0.00538063]\n",
            " [0.9940773 ]\n",
            " [0.99405646]\n",
            " [0.00913926]]\n",
            "Step: 2568 -> Loss: 0.006614909507334232 -> Predictions: [[0.00537712]\n",
            " [0.99408144]\n",
            " [0.9940606 ]\n",
            " [0.00913277]]\n",
            "Step: 2569 -> Loss: 0.006610332988202572 -> Predictions: [[0.00537361]\n",
            " [0.99408543]\n",
            " [0.99406475]\n",
            " [0.00912628]]\n",
            "Step: 2570 -> Loss: 0.006605759263038635 -> Predictions: [[0.0053701 ]\n",
            " [0.9940896 ]\n",
            " [0.99406886]\n",
            " [0.00911978]]\n",
            "Step: 2571 -> Loss: 0.0066012004390358925 -> Predictions: [[0.00536661]\n",
            " [0.9940936 ]\n",
            " [0.99407285]\n",
            " [0.00911331]]\n",
            "Step: 2572 -> Loss: 0.006596643943339586 -> Predictions: [[0.00536312]\n",
            " [0.9940977 ]\n",
            " [0.99407697]\n",
            " [0.00910685]]\n",
            "Step: 2573 -> Loss: 0.006592093035578728 -> Predictions: [[0.00535963]\n",
            " [0.9941017 ]\n",
            " [0.9940811 ]\n",
            " [0.00910039]]\n",
            "Step: 2574 -> Loss: 0.006587550509721041 -> Predictions: [[0.00535615]\n",
            " [0.9941058 ]\n",
            " [0.9940851 ]\n",
            " [0.00909394]]\n",
            "Step: 2575 -> Loss: 0.006583012640476227 -> Predictions: [[0.00535266]\n",
            " [0.99410987]\n",
            " [0.9940891 ]\n",
            " [0.0090875 ]]\n",
            "Step: 2576 -> Loss: 0.0065784817561507225 -> Predictions: [[0.00534918]\n",
            " [0.99411386]\n",
            " [0.99409324]\n",
            " [0.00908108]]\n",
            "Step: 2577 -> Loss: 0.006573958322405815 -> Predictions: [[0.00534571]\n",
            " [0.99411786]\n",
            " [0.99409723]\n",
            " [0.00907465]]\n",
            "Step: 2578 -> Loss: 0.0065694404765963554 -> Predictions: [[0.00534225]\n",
            " [0.99412185]\n",
            " [0.99410135]\n",
            " [0.00906824]]\n",
            "Step: 2579 -> Loss: 0.006564929615706205 -> Predictions: [[0.00533879]\n",
            " [0.99412596]\n",
            " [0.99410534]\n",
            " [0.00906184]]\n",
            "Step: 2580 -> Loss: 0.006560418289154768 -> Predictions: [[0.00533533]\n",
            " [0.99413   ]\n",
            " [0.9941094 ]\n",
            " [0.00905544]]\n",
            "Step: 2581 -> Loss: 0.0065559158101677895 -> Predictions: [[0.00533187]\n",
            " [0.994134  ]\n",
            " [0.9941134 ]\n",
            " [0.00904905]]\n",
            "Step: 2582 -> Loss: 0.006551424041390419 -> Predictions: [[0.00532843]\n",
            " [0.994138  ]\n",
            " [0.9941175 ]\n",
            " [0.00904268]]\n",
            "Step: 2583 -> Loss: 0.006546933203935623 -> Predictions: [[0.00532498]\n",
            " [0.994142  ]\n",
            " [0.9941215 ]\n",
            " [0.0090363 ]]\n",
            "Step: 2584 -> Loss: 0.006542452611029148 -> Predictions: [[0.00532154]\n",
            " [0.994146  ]\n",
            " [0.9941255 ]\n",
            " [0.00902994]]\n",
            "Step: 2585 -> Loss: 0.006537974812090397 -> Predictions: [[0.0053181 ]\n",
            " [0.9941499 ]\n",
            " [0.99412954]\n",
            " [0.0090236 ]]\n",
            "Step: 2586 -> Loss: 0.00653350492939353 -> Predictions: [[0.00531467]\n",
            " [0.9941539 ]\n",
            " [0.99413353]\n",
            " [0.00901725]]\n",
            "Step: 2587 -> Loss: 0.006529042962938547 -> Predictions: [[0.00531124]\n",
            " [0.9941579 ]\n",
            " [0.9941375 ]\n",
            " [0.00901092]]\n",
            "Step: 2588 -> Loss: 0.006524586118757725 -> Predictions: [[0.00530783]\n",
            " [0.9941619 ]\n",
            " [0.9941414 ]\n",
            " [0.0090046 ]]\n",
            "Step: 2589 -> Loss: 0.006520132068544626 -> Predictions: [[0.0053044 ]\n",
            " [0.9941658 ]\n",
            " [0.9941454 ]\n",
            " [0.00899829]]\n",
            "Step: 2590 -> Loss: 0.006515687797218561 -> Predictions: [[0.00530099]\n",
            " [0.99416983]\n",
            " [0.99414945]\n",
            " [0.00899199]]\n",
            "Step: 2591 -> Loss: 0.006511244457215071 -> Predictions: [[0.00529758]\n",
            " [0.9941738 ]\n",
            " [0.99415344]\n",
            " [0.00898568]]\n",
            "Step: 2592 -> Loss: 0.006506810896098614 -> Predictions: [[0.00529417]\n",
            " [0.9941777 ]\n",
            " [0.99415743]\n",
            " [0.0089794 ]]\n",
            "Step: 2593 -> Loss: 0.006502380128949881 -> Predictions: [[0.00529077]\n",
            " [0.9941817 ]\n",
            " [0.9941613 ]\n",
            " [0.00897312]]\n",
            "Step: 2594 -> Loss: 0.006497963331639767 -> Predictions: [[0.00528738]\n",
            " [0.9941856 ]\n",
            " [0.99416536]\n",
            " [0.00896685]]\n",
            "Step: 2595 -> Loss: 0.006493539083749056 -> Predictions: [[0.00528398]\n",
            " [0.9941895 ]\n",
            " [0.99416924]\n",
            " [0.00896057]]\n",
            "Step: 2596 -> Loss: 0.006489132530987263 -> Predictions: [[0.00528059]\n",
            " [0.9941935 ]\n",
            " [0.9941732 ]\n",
            " [0.00895432]]\n",
            "Step: 2597 -> Loss: 0.006484727840870619 -> Predictions: [[0.00527721]\n",
            " [0.99419737]\n",
            " [0.9941771 ]\n",
            " [0.00894807]]\n",
            "Step: 2598 -> Loss: 0.006480327807366848 -> Predictions: [[0.00527383]\n",
            " [0.99420124]\n",
            " [0.9941811 ]\n",
            " [0.00894183]]\n",
            "Step: 2599 -> Loss: 0.006475936621427536 -> Predictions: [[0.00527046]\n",
            " [0.9942053 ]\n",
            " [0.99418503]\n",
            " [0.0089356 ]]\n",
            "Step: 2600 -> Loss: 0.006471548229455948 -> Predictions: [[0.00526709]\n",
            " [0.9942092 ]\n",
            " [0.9941889 ]\n",
            " [0.00892938]]\n",
            "Step: 2601 -> Loss: 0.0064671714790165424 -> Predictions: [[0.00526372]\n",
            " [0.99421304]\n",
            " [0.9941929 ]\n",
            " [0.00892317]]\n",
            "Step: 2602 -> Loss: 0.006462791934609413 -> Predictions: [[0.00526036]\n",
            " [0.9942169 ]\n",
            " [0.9941968 ]\n",
            " [0.00891696]]\n",
            "Step: 2603 -> Loss: 0.0064584254287183285 -> Predictions: [[0.005257  ]\n",
            " [0.99422085]\n",
            " [0.9942007 ]\n",
            " [0.00891078]]\n",
            "Step: 2604 -> Loss: 0.006454054266214371 -> Predictions: [[0.00525364]\n",
            " [0.9942247 ]\n",
            " [0.9942046 ]\n",
            " [0.00890458]]\n",
            "Step: 2605 -> Loss: 0.006449700798839331 -> Predictions: [[0.0052503]\n",
            " [0.9942286]\n",
            " [0.9942086]\n",
            " [0.0088984]]\n",
            "Step: 2606 -> Loss: 0.006445349659770727 -> Predictions: [[0.00524695]\n",
            " [0.9942325 ]\n",
            " [0.99421245]\n",
            " [0.00889223]]\n",
            "Step: 2607 -> Loss: 0.006441001780331135 -> Predictions: [[0.00524361]\n",
            " [0.9942364 ]\n",
            " [0.9942163 ]\n",
            " [0.00888607]]\n",
            "Step: 2608 -> Loss: 0.0064366599544882774 -> Predictions: [[0.00524026]\n",
            " [0.99424016]\n",
            " [0.99422026]\n",
            " [0.00887991]]\n",
            "Step: 2609 -> Loss: 0.006432326510548592 -> Predictions: [[0.00523693]\n",
            " [0.99424404]\n",
            " [0.994224  ]\n",
            " [0.00887376]]\n",
            "Step: 2610 -> Loss: 0.006428000517189503 -> Predictions: [[0.00523361]\n",
            " [0.9942479 ]\n",
            " [0.9942279 ]\n",
            " [0.00886763]]\n",
            "Step: 2611 -> Loss: 0.006423676386475563 -> Predictions: [[0.00523028]\n",
            " [0.99425185]\n",
            " [0.99423176]\n",
            " [0.00886151]]\n",
            "Step: 2612 -> Loss: 0.006419355981051922 -> Predictions: [[0.00522696]\n",
            " [0.9942556 ]\n",
            " [0.9942357 ]\n",
            " [0.00885538]]\n",
            "Step: 2613 -> Loss: 0.006415046751499176 -> Predictions: [[0.00522365]\n",
            " [0.9942595 ]\n",
            " [0.99423957]\n",
            " [0.00884928]]\n",
            "Step: 2614 -> Loss: 0.0064107393845915794 -> Predictions: [[0.00522034]\n",
            " [0.99426335]\n",
            " [0.99424344]\n",
            " [0.00884318]]\n",
            "Step: 2615 -> Loss: 0.006406440399587154 -> Predictions: [[0.00521702]\n",
            " [0.99426717]\n",
            " [0.9942472 ]\n",
            " [0.00883708]]\n",
            "Step: 2616 -> Loss: 0.006402144208550453 -> Predictions: [[0.00521372]\n",
            " [0.9942709 ]\n",
            " [0.99425113]\n",
            " [0.00883099]]\n",
            "Step: 2617 -> Loss: 0.006397857330739498 -> Predictions: [[0.00521043]\n",
            " [0.9942748 ]\n",
            " [0.9942549 ]\n",
            " [0.00882491]]\n",
            "Step: 2618 -> Loss: 0.006393571849912405 -> Predictions: [[0.00520713]\n",
            " [0.99427855]\n",
            " [0.99425876]\n",
            " [0.00881884]]\n",
            "Step: 2619 -> Loss: 0.006389293819665909 -> Predictions: [[0.00520384]\n",
            " [0.9942825 ]\n",
            " [0.9942625 ]\n",
            " [0.00881278]]\n",
            "Step: 2620 -> Loss: 0.006385019980370998 -> Predictions: [[0.00520055]\n",
            " [0.99428624]\n",
            " [0.99426645]\n",
            " [0.00880673]]\n",
            "Step: 2621 -> Loss: 0.006380753591656685 -> Predictions: [[0.00519726]\n",
            " [0.99429   ]\n",
            " [0.9942702 ]\n",
            " [0.00880068]]\n",
            "Step: 2622 -> Loss: 0.006376493722200394 -> Predictions: [[0.00519399]\n",
            " [0.99429387]\n",
            " [0.9942741 ]\n",
            " [0.00879465]]\n",
            "Step: 2623 -> Loss: 0.0063722385093569756 -> Predictions: [[0.00519072]\n",
            " [0.9942977 ]\n",
            " [0.99427783]\n",
            " [0.00878862]]\n",
            "Step: 2624 -> Loss: 0.006367993541061878 -> Predictions: [[0.00518745]\n",
            " [0.99430144]\n",
            " [0.99428165]\n",
            " [0.00878261]]\n",
            "Step: 2625 -> Loss: 0.006363746710121632 -> Predictions: [[0.00518418]\n",
            " [0.9943052 ]\n",
            " [0.9942855 ]\n",
            " [0.00877659]]\n",
            "Step: 2626 -> Loss: 0.006359506398439407 -> Predictions: [[0.00518091]\n",
            " [0.99430895]\n",
            " [0.9942893 ]\n",
            " [0.00877058]]\n",
            "Step: 2627 -> Loss: 0.0063552698120474815 -> Predictions: [[0.00517765]\n",
            " [0.99431276]\n",
            " [0.9942931 ]\n",
            " [0.00876458]]\n",
            "Step: 2628 -> Loss: 0.00635104812681675 -> Predictions: [[0.0051744 ]\n",
            " [0.9943165 ]\n",
            " [0.99429685]\n",
            " [0.0087586 ]]\n",
            "Step: 2629 -> Loss: 0.0063468217849731445 -> Predictions: [[0.00517114]\n",
            " [0.9943203 ]\n",
            " [0.9943006 ]\n",
            " [0.00875261]]\n",
            "Step: 2630 -> Loss: 0.006342603825032711 -> Predictions: [[0.00516791]\n",
            " [0.9943241 ]\n",
            " [0.99430436]\n",
            " [0.00874664]]\n",
            "Step: 2631 -> Loss: 0.006338398903608322 -> Predictions: [[0.00516466]\n",
            " [0.99432784]\n",
            " [0.9943082 ]\n",
            " [0.00874069]]\n",
            "Step: 2632 -> Loss: 0.006334192119538784 -> Predictions: [[0.00516143]\n",
            " [0.9943315 ]\n",
            " [0.9943119 ]\n",
            " [0.00873473]]\n",
            "Step: 2633 -> Loss: 0.0063299923203885555 -> Predictions: [[0.00515819]\n",
            " [0.99433523]\n",
            " [0.9943157 ]\n",
            " [0.00872877]]\n",
            "Step: 2634 -> Loss: 0.006325795780867338 -> Predictions: [[0.00515495]\n",
            " [0.99433905]\n",
            " [0.99431944]\n",
            " [0.00872284]]\n",
            "Step: 2635 -> Loss: 0.00632160808891058 -> Predictions: [[0.00515174]\n",
            " [0.9943428 ]\n",
            " [0.99432325]\n",
            " [0.00871689]]\n",
            "Step: 2636 -> Loss: 0.00631742225959897 -> Predictions: [[0.0051485 ]\n",
            " [0.99434644]\n",
            " [0.994327  ]\n",
            " [0.00871097]]\n",
            "Step: 2637 -> Loss: 0.006313243880867958 -> Predictions: [[0.00514528]\n",
            " [0.99435025]\n",
            " [0.99433064]\n",
            " [0.00870505]]\n",
            "Step: 2638 -> Loss: 0.00630907341837883 -> Predictions: [[0.00514206]\n",
            " [0.9943539 ]\n",
            " [0.99433446]\n",
            " [0.00869915]]\n",
            "Step: 2639 -> Loss: 0.0063049038872122765 -> Predictions: [[0.00513886]\n",
            " [0.99435765]\n",
            " [0.9943382 ]\n",
            " [0.00869325]]\n",
            "Step: 2640 -> Loss: 0.006300743669271469 -> Predictions: [[0.00513565]\n",
            " [0.9943613 ]\n",
            " [0.99434185]\n",
            " [0.00868735]]\n",
            "Step: 2641 -> Loss: 0.006296589504927397 -> Predictions: [[0.00513245]\n",
            " [0.9943651 ]\n",
            " [0.9943456 ]\n",
            " [0.00868148]]\n",
            "Step: 2642 -> Loss: 0.006292434874922037 -> Predictions: [[0.00512925]\n",
            " [0.99436873]\n",
            " [0.9943493 ]\n",
            " [0.00867559]]\n",
            "Step: 2643 -> Loss: 0.006288293749094009 -> Predictions: [[0.00512606]\n",
            " [0.99437237]\n",
            " [0.99435306]\n",
            " [0.00866972]]\n",
            "Step: 2644 -> Loss: 0.006284154020249844 -> Predictions: [[0.00512286]\n",
            " [0.9943762 ]\n",
            " [0.9943567 ]\n",
            " [0.00866386]]\n",
            "Step: 2645 -> Loss: 0.006280021741986275 -> Predictions: [[0.00511968]\n",
            " [0.9943798 ]\n",
            " [0.9943605 ]\n",
            " [0.00865801]]\n",
            "Step: 2646 -> Loss: 0.006275887601077557 -> Predictions: [[0.00511649]\n",
            " [0.99438345]\n",
            " [0.99436414]\n",
            " [0.00865216]]\n",
            "Step: 2647 -> Loss: 0.006271765101701021 -> Predictions: [[0.00511332]\n",
            " [0.99438727]\n",
            " [0.9943678 ]\n",
            " [0.00864632]]\n",
            "Step: 2648 -> Loss: 0.006267646327614784 -> Predictions: [[0.00511015]\n",
            " [0.9943909 ]\n",
            " [0.99437153]\n",
            " [0.00864049]]\n",
            "Step: 2649 -> Loss: 0.006263533607125282 -> Predictions: [[0.00510697]\n",
            " [0.99439454]\n",
            " [0.9943752 ]\n",
            " [0.00863467]]\n",
            "Step: 2650 -> Loss: 0.006259421817958355 -> Predictions: [[0.0051038 ]\n",
            " [0.9943982 ]\n",
            " [0.99437886]\n",
            " [0.00862884]]\n",
            "Step: 2651 -> Loss: 0.006255322135984898 -> Predictions: [[0.00510064]\n",
            " [0.9944019 ]\n",
            " [0.9943825 ]\n",
            " [0.00862304]]\n",
            "Step: 2652 -> Loss: 0.00625122245401144 -> Predictions: [[0.00509748]\n",
            " [0.9944055 ]\n",
            " [0.9943862 ]\n",
            " [0.00861723]]\n",
            "Step: 2653 -> Loss: 0.006247133482247591 -> Predictions: [[0.00509432]\n",
            " [0.99440914]\n",
            " [0.99438995]\n",
            " [0.00861144]]\n",
            "Step: 2654 -> Loss: 0.0062430426478385925 -> Predictions: [[0.00509117]\n",
            " [0.99441284]\n",
            " [0.9943936 ]\n",
            " [0.00860565]]\n",
            "Step: 2655 -> Loss: 0.006238959264010191 -> Predictions: [[0.00508802]\n",
            " [0.99441636]\n",
            " [0.9943973 ]\n",
            " [0.00859987]]\n",
            "Step: 2656 -> Loss: 0.006234883330762386 -> Predictions: [[0.00508487]\n",
            " [0.99442   ]\n",
            " [0.9944009 ]\n",
            " [0.00859411]]\n",
            "Step: 2657 -> Loss: 0.006230813451111317 -> Predictions: [[0.00508173]\n",
            " [0.9944237 ]\n",
            " [0.99440455]\n",
            " [0.00858834]]\n",
            "Step: 2658 -> Loss: 0.00622674822807312 -> Predictions: [[0.0050786 ]\n",
            " [0.9944273 ]\n",
            " [0.99440813]\n",
            " [0.00858258]]\n",
            "Step: 2659 -> Loss: 0.006222688592970371 -> Predictions: [[0.00507546]\n",
            " [0.99443096]\n",
            " [0.99441177]\n",
            " [0.00857684]]\n",
            "Step: 2660 -> Loss: 0.006218631751835346 -> Predictions: [[0.00507234]\n",
            " [0.99443454]\n",
            " [0.9944154 ]\n",
            " [0.0085711 ]]\n",
            "Step: 2661 -> Loss: 0.006214580498635769 -> Predictions: [[0.00506921]\n",
            " [0.9944382 ]\n",
            " [0.99441904]\n",
            " [0.00856536]]\n",
            "Step: 2662 -> Loss: 0.0062105366960167885 -> Predictions: [[0.00506609]\n",
            " [0.9944417 ]\n",
            " [0.99442273]\n",
            " [0.00855965]]\n",
            "Step: 2663 -> Loss: 0.006206498481333256 -> Predictions: [[0.00506297]\n",
            " [0.9944454 ]\n",
            " [0.99442625]\n",
            " [0.00855393]]\n",
            "Step: 2664 -> Loss: 0.006202466785907745 -> Predictions: [[0.00505986]\n",
            " [0.9944489 ]\n",
            " [0.9944299 ]\n",
            " [0.00854823]]\n",
            "Step: 2665 -> Loss: 0.00619843415915966 -> Predictions: [[0.00505675]\n",
            " [0.99445254]\n",
            " [0.9944336 ]\n",
            " [0.00854252]]\n",
            "Step: 2666 -> Loss: 0.006194409914314747 -> Predictions: [[0.00505364]\n",
            " [0.9944561 ]\n",
            " [0.9944371 ]\n",
            " [0.00853682]]\n",
            "Step: 2667 -> Loss: 0.006190388463437557 -> Predictions: [[0.00505054]\n",
            " [0.99445975]\n",
            " [0.99444073]\n",
            " [0.00853114]]\n",
            "Step: 2668 -> Loss: 0.006186375394463539 -> Predictions: [[0.00504744]\n",
            " [0.99446326]\n",
            " [0.9944443 ]\n",
            " [0.00852546]]\n",
            "Step: 2669 -> Loss: 0.006182366982102394 -> Predictions: [[0.00504434]\n",
            " [0.99446684]\n",
            " [0.99444795]\n",
            " [0.00851979]]\n",
            "Step: 2670 -> Loss: 0.006178363226354122 -> Predictions: [[0.00504126]\n",
            " [0.9944705 ]\n",
            " [0.99445146]\n",
            " [0.00851412]]\n",
            "Step: 2671 -> Loss: 0.006174362264573574 -> Predictions: [[0.00503816]\n",
            " [0.994474  ]\n",
            " [0.99445504]\n",
            " [0.00850846]]\n",
            "Step: 2672 -> Loss: 0.006170367822051048 -> Predictions: [[0.00503508]\n",
            " [0.99447757]\n",
            " [0.9944587 ]\n",
            " [0.0085028 ]]\n",
            "Step: 2673 -> Loss: 0.006166383624076843 -> Predictions: [[0.005032  ]\n",
            " [0.9944811 ]\n",
            " [0.9944622 ]\n",
            " [0.00849717]]\n",
            "Step: 2674 -> Loss: 0.0061624012887477875 -> Predictions: [[0.00502893]\n",
            " [0.9944846 ]\n",
            " [0.99446577]\n",
            " [0.00849154]]\n",
            "Step: 2675 -> Loss: 0.006158420350402594 -> Predictions: [[0.00502585]\n",
            " [0.9944883 ]\n",
            " [0.9944693 ]\n",
            " [0.0084859 ]]\n",
            "Step: 2676 -> Loss: 0.006154447793960571 -> Predictions: [[0.00502278]\n",
            " [0.9944918 ]\n",
            " [0.9944729 ]\n",
            " [0.00848028]]\n",
            "Step: 2677 -> Loss: 0.006150480359792709 -> Predictions: [[0.00501972]\n",
            " [0.9944952 ]\n",
            " [0.9944765 ]\n",
            " [0.00847468]]\n",
            "Step: 2678 -> Loss: 0.006146514788269997 -> Predictions: [[0.00501666]\n",
            " [0.9944989 ]\n",
            " [0.99448   ]\n",
            " [0.00846906]]\n",
            "Step: 2679 -> Loss: 0.006142554804682732 -> Predictions: [[0.0050136 ]\n",
            " [0.9945023 ]\n",
            " [0.99448353]\n",
            " [0.00846346]]\n",
            "Step: 2680 -> Loss: 0.006138605065643787 -> Predictions: [[0.00501055]\n",
            " [0.9945058 ]\n",
            " [0.9944871 ]\n",
            " [0.00845788]]\n",
            "Step: 2681 -> Loss: 0.006134652998298407 -> Predictions: [[0.00500749]\n",
            " [0.9945094 ]\n",
            " [0.9944906 ]\n",
            " [0.00845229]]\n",
            "Step: 2682 -> Loss: 0.006130715366452932 -> Predictions: [[0.00500445]\n",
            " [0.9945129 ]\n",
            " [0.99449414]\n",
            " [0.00844672]]\n",
            "Step: 2683 -> Loss: 0.00612677400931716 -> Predictions: [[0.00500141]\n",
            " [0.99451643]\n",
            " [0.9944977 ]\n",
            " [0.00844115]]\n",
            "Step: 2684 -> Loss: 0.006122840568423271 -> Predictions: [[0.00499837]\n",
            " [0.99452   ]\n",
            " [0.99450123]\n",
            " [0.00843559]]\n",
            "Step: 2685 -> Loss: 0.00611891457810998 -> Predictions: [[0.00499534]\n",
            " [0.9945234 ]\n",
            " [0.99450475]\n",
            " [0.00843003]]\n",
            "Step: 2686 -> Loss: 0.0061149862594902515 -> Predictions: [[0.0049923 ]\n",
            " [0.9945269 ]\n",
            " [0.9945082 ]\n",
            " [0.00842448]]\n",
            "Step: 2687 -> Loss: 0.00611107237637043 -> Predictions: [[0.00498927]\n",
            " [0.9945305 ]\n",
            " [0.9945117 ]\n",
            " [0.00841894]]\n",
            "Step: 2688 -> Loss: 0.006107160821557045 -> Predictions: [[0.00498625]\n",
            " [0.9945339 ]\n",
            " [0.99451524]\n",
            " [0.00841341]]\n",
            "Step: 2689 -> Loss: 0.006103248335421085 -> Predictions: [[0.00498322]\n",
            " [0.9945374 ]\n",
            " [0.9945188 ]\n",
            " [0.00840788]]\n",
            "Step: 2690 -> Loss: 0.006099347025156021 -> Predictions: [[0.00498021]\n",
            " [0.99454087]\n",
            " [0.9945222 ]\n",
            " [0.00840236]]\n",
            "Step: 2691 -> Loss: 0.006095448974519968 -> Predictions: [[0.00497719]\n",
            " [0.9945444 ]\n",
            " [0.9945258 ]\n",
            " [0.00839685]]\n",
            "Step: 2692 -> Loss: 0.006091558374464512 -> Predictions: [[0.00497419]\n",
            " [0.9945478 ]\n",
            " [0.9945292 ]\n",
            " [0.00839135]]\n",
            "Step: 2693 -> Loss: 0.0060876659117639065 -> Predictions: [[0.00497118]\n",
            " [0.99455136]\n",
            " [0.9945327 ]\n",
            " [0.00838584]]\n",
            "Step: 2694 -> Loss: 0.006083782762289047 -> Predictions: [[0.00496817]\n",
            " [0.99455476]\n",
            " [0.9945363 ]\n",
            " [0.00838035]]\n",
            "Step: 2695 -> Loss: 0.006079903803765774 -> Predictions: [[0.00496517]\n",
            " [0.9945582 ]\n",
            " [0.9945397 ]\n",
            " [0.00837487]]\n",
            "Step: 2696 -> Loss: 0.006076029501855373 -> Predictions: [[0.00496218]\n",
            " [0.9945616 ]\n",
            " [0.9945431 ]\n",
            " [0.0083694 ]]\n",
            "Step: 2697 -> Loss: 0.006072157993912697 -> Predictions: [[0.00495918]\n",
            " [0.9945651 ]\n",
            " [0.99454665]\n",
            " [0.00836392]]\n",
            "Step: 2698 -> Loss: 0.006068293936550617 -> Predictions: [[0.0049562 ]\n",
            " [0.9945686 ]\n",
            " [0.99455005]\n",
            " [0.00835845]]\n",
            "Step: 2699 -> Loss: 0.006064435467123985 -> Predictions: [[0.00495321]\n",
            " [0.994572  ]\n",
            " [0.99455345]\n",
            " [0.008353  ]]\n",
            "Step: 2700 -> Loss: 0.006060581188648939 -> Predictions: [[0.00495023]\n",
            " [0.9945754 ]\n",
            " [0.994557  ]\n",
            " [0.00834755]]\n",
            "Step: 2701 -> Loss: 0.006056732498109341 -> Predictions: [[0.00494726]\n",
            " [0.99457884]\n",
            " [0.9945604 ]\n",
            " [0.00834211]]\n",
            "Step: 2702 -> Loss: 0.006052885204553604 -> Predictions: [[0.00494428]\n",
            " [0.99458224]\n",
            " [0.9945639 ]\n",
            " [0.00833667]]\n",
            "Step: 2703 -> Loss: 0.006049044895917177 -> Predictions: [[0.00494131]\n",
            " [0.99458575]\n",
            " [0.9945673 ]\n",
            " [0.00833124]]\n",
            "Step: 2704 -> Loss: 0.006045210640877485 -> Predictions: [[0.00493834]\n",
            " [0.9945892 ]\n",
            " [0.9945708 ]\n",
            " [0.00832582]]\n",
            "Step: 2705 -> Loss: 0.006041380576789379 -> Predictions: [[0.00493538]\n",
            " [0.9945925 ]\n",
            " [0.99457425]\n",
            " [0.00832041]]\n",
            "Step: 2706 -> Loss: 0.006037554703652859 -> Predictions: [[0.00493241]\n",
            " [0.99459594]\n",
            " [0.99457765]\n",
            " [0.008315  ]]\n",
            "Step: 2707 -> Loss: 0.006033733952790499 -> Predictions: [[0.00492946]\n",
            " [0.99459934]\n",
            " [0.99458104]\n",
            " [0.0083096 ]]\n",
            "Step: 2708 -> Loss: 0.006029915995895863 -> Predictions: [[0.00492651]\n",
            " [0.99460274]\n",
            " [0.9945845 ]\n",
            " [0.00830421]]\n",
            "Step: 2709 -> Loss: 0.006026104092597961 -> Predictions: [[0.00492356]\n",
            " [0.9946062 ]\n",
            " [0.9945879 ]\n",
            " [0.00829882]]\n",
            "Step: 2710 -> Loss: 0.006022298708558083 -> Predictions: [[0.00492062]\n",
            " [0.9946096 ]\n",
            " [0.9945913 ]\n",
            " [0.00829344]]\n",
            "Step: 2711 -> Loss: 0.006018496118485928 -> Predictions: [[0.00491767]\n",
            " [0.99461293]\n",
            " [0.99459463]\n",
            " [0.00828806]]\n",
            "Step: 2712 -> Loss: 0.006014696322381496 -> Predictions: [[0.00491473]\n",
            " [0.9946163 ]\n",
            " [0.99459803]\n",
            " [0.00828269]]\n",
            "Step: 2713 -> Loss: 0.006010903976857662 -> Predictions: [[0.00491179]\n",
            " [0.9946197 ]\n",
            " [0.9946015 ]\n",
            " [0.00827734]]\n",
            "Step: 2714 -> Loss: 0.006007120944559574 -> Predictions: [[0.00490887]\n",
            " [0.9946232 ]\n",
            " [0.9946049 ]\n",
            " [0.008272  ]]\n",
            "Step: 2715 -> Loss: 0.006003338843584061 -> Predictions: [[0.00490594]\n",
            " [0.99462646]\n",
            " [0.9946083 ]\n",
            " [0.00826664]]\n",
            "Step: 2716 -> Loss: 0.005999553948640823 -> Predictions: [[0.004903  ]\n",
            " [0.99462986]\n",
            " [0.9946116 ]\n",
            " [0.0082613 ]]\n",
            "Step: 2717 -> Loss: 0.0059957802295684814 -> Predictions: [[0.0049001 ]\n",
            " [0.9946332 ]\n",
            " [0.994615  ]\n",
            " [0.00825597]]\n",
            "Step: 2718 -> Loss: 0.0059920139610767365 -> Predictions: [[0.00489717]\n",
            " [0.9946366 ]\n",
            " [0.9946185 ]\n",
            " [0.00825064]]\n",
            "Step: 2719 -> Loss: 0.0059882476925849915 -> Predictions: [[0.00489425]\n",
            " [0.99463993]\n",
            " [0.99462175]\n",
            " [0.00824532]]\n",
            "Step: 2720 -> Loss: 0.0059844874776899815 -> Predictions: [[0.00489134]\n",
            " [0.99464333]\n",
            " [0.99462515]\n",
            " [0.00824001]]\n",
            "Step: 2721 -> Loss: 0.0059807319194078445 -> Predictions: [[0.00488843]\n",
            " [0.9946466 ]\n",
            " [0.9946285 ]\n",
            " [0.00823471]]\n",
            "Step: 2722 -> Loss: 0.005976987071335316 -> Predictions: [[0.00488553]\n",
            " [0.99464995]\n",
            " [0.9946319 ]\n",
            " [0.00822942]]\n",
            "Step: 2723 -> Loss: 0.005973237566649914 -> Predictions: [[0.00488263]\n",
            " [0.99465334]\n",
            " [0.99463516]\n",
            " [0.00822411]]\n",
            "Step: 2724 -> Loss: 0.005969499237835407 -> Predictions: [[0.00487973]\n",
            " [0.9946567 ]\n",
            " [0.9946386 ]\n",
            " [0.00821884]]\n",
            "Step: 2725 -> Loss: 0.005965758115053177 -> Predictions: [[0.00487684]\n",
            " [0.99465996]\n",
            " [0.9946419 ]\n",
            " [0.00821355]]\n",
            "Step: 2726 -> Loss: 0.005962026305496693 -> Predictions: [[0.00487394]\n",
            " [0.99466324]\n",
            " [0.99464524]\n",
            " [0.00820828]]\n",
            "Step: 2727 -> Loss: 0.0059583005495369434 -> Predictions: [[0.00487106]\n",
            " [0.9946667 ]\n",
            " [0.99464864]\n",
            " [0.00820301]]\n",
            "Step: 2728 -> Loss: 0.005954578053206205 -> Predictions: [[0.00486817]\n",
            " [0.99467   ]\n",
            " [0.9946519 ]\n",
            " [0.00819776]]\n",
            "Step: 2729 -> Loss: 0.005950859747827053 -> Predictions: [[0.00486529]\n",
            " [0.9946733 ]\n",
            " [0.99465525]\n",
            " [0.0081925 ]]\n",
            "Step: 2730 -> Loss: 0.005947146564722061 -> Predictions: [[0.00486241]\n",
            " [0.9946766 ]\n",
            " [0.9946585 ]\n",
            " [0.00818726]]\n",
            "Step: 2731 -> Loss: 0.005943436175584793 -> Predictions: [[0.00485954]\n",
            " [0.99467987]\n",
            " [0.994662  ]\n",
            " [0.00818202]]\n",
            "Step: 2732 -> Loss: 0.005939733702689409 -> Predictions: [[0.00485667]\n",
            " [0.9946832 ]\n",
            " [0.99466527]\n",
            " [0.00817679]]\n",
            "Step: 2733 -> Loss: 0.005936030764132738 -> Predictions: [[0.0048538 ]\n",
            " [0.9946865 ]\n",
            " [0.99466854]\n",
            " [0.00817156]]\n",
            "Step: 2734 -> Loss: 0.005932335741817951 -> Predictions: [[0.00485093]\n",
            " [0.9946898 ]\n",
            " [0.9946719 ]\n",
            " [0.00816634]]\n",
            "Step: 2735 -> Loss: 0.005928648170083761 -> Predictions: [[0.00484808]\n",
            " [0.9946931 ]\n",
            " [0.99467516]\n",
            " [0.00816113]]\n",
            "Step: 2736 -> Loss: 0.005924961529672146 -> Predictions: [[0.00484522]\n",
            " [0.9946964 ]\n",
            " [0.9946785 ]\n",
            " [0.00815593]]\n",
            "Step: 2737 -> Loss: 0.005921278148889542 -> Predictions: [[0.00484236]\n",
            " [0.9946997 ]\n",
            " [0.9946818 ]\n",
            " [0.00815073]]\n",
            "Step: 2738 -> Loss: 0.005917602218687534 -> Predictions: [[0.00483951]\n",
            " [0.9947029 ]\n",
            " [0.99468505]\n",
            " [0.00814552]]\n",
            "Step: 2739 -> Loss: 0.0059139309450984 -> Predictions: [[0.00483666]\n",
            " [0.9947062 ]\n",
            " [0.9946884 ]\n",
            " [0.00814035]]\n",
            "Step: 2740 -> Loss: 0.005910257808864117 -> Predictions: [[0.00483382]\n",
            " [0.9947095 ]\n",
            " [0.99469167]\n",
            " [0.00813516]]\n",
            "Step: 2741 -> Loss: 0.005906593985855579 -> Predictions: [[0.00483097]\n",
            " [0.99471277]\n",
            " [0.9946949 ]\n",
            " [0.00812999]]\n",
            "Step: 2742 -> Loss: 0.005902936682105064 -> Predictions: [[0.00482814]\n",
            " [0.994716  ]\n",
            " [0.99469817]\n",
            " [0.00812482]]\n",
            "Step: 2743 -> Loss: 0.005899281706660986 -> Predictions: [[0.00482531]\n",
            " [0.99471927]\n",
            " [0.9947015 ]\n",
            " [0.00811967]]\n",
            "Step: 2744 -> Loss: 0.00589563325047493 -> Predictions: [[0.00482248]\n",
            " [0.9947225 ]\n",
            " [0.9947048 ]\n",
            " [0.00811452]]\n",
            "Step: 2745 -> Loss: 0.0058919889852404594 -> Predictions: [[0.00481965]\n",
            " [0.99472576]\n",
            " [0.99470794]\n",
            " [0.00810937]]\n",
            "Step: 2746 -> Loss: 0.005888345651328564 -> Predictions: [[0.00481682]\n",
            " [0.994729  ]\n",
            " [0.9947113 ]\n",
            " [0.00810421]]\n",
            "Step: 2747 -> Loss: 0.005884706042706966 -> Predictions: [[0.00481399]\n",
            " [0.99473226]\n",
            " [0.99471456]\n",
            " [0.00809909]]\n",
            "Step: 2748 -> Loss: 0.005881072953343391 -> Predictions: [[0.00481117]\n",
            " [0.9947354 ]\n",
            " [0.9947178 ]\n",
            " [0.00809396]]\n",
            "Step: 2749 -> Loss: 0.005877446383237839 -> Predictions: [[0.00480837]\n",
            " [0.99473876]\n",
            " [0.99472106]\n",
            " [0.00808884]]\n",
            "Step: 2750 -> Loss: 0.005873821675777435 -> Predictions: [[0.00480556]\n",
            " [0.9947419 ]\n",
            " [0.9947242 ]\n",
            " [0.00808372]]\n",
            "Step: 2751 -> Loss: 0.005870201624929905 -> Predictions: [[0.00480275]\n",
            " [0.99474525]\n",
            " [0.99472755]\n",
            " [0.00807861]]\n",
            "Step: 2752 -> Loss: 0.005866584833711386 -> Predictions: [[0.00479994]\n",
            " [0.9947484 ]\n",
            " [0.9947307 ]\n",
            " [0.00807351]]\n",
            "Step: 2753 -> Loss: 0.005862974561750889 -> Predictions: [[0.00479714]\n",
            " [0.99475163]\n",
            " [0.99473405]\n",
            " [0.00806841]]\n",
            "Step: 2754 -> Loss: 0.005859370343387127 -> Predictions: [[0.00479434]\n",
            " [0.9947549 ]\n",
            " [0.9947372 ]\n",
            " [0.00806333]]\n",
            "Step: 2755 -> Loss: 0.00585576519370079 -> Predictions: [[0.00479154]\n",
            " [0.99475807]\n",
            " [0.99474055]\n",
            " [0.00805824]]\n",
            "Step: 2756 -> Loss: 0.005852170288562775 -> Predictions: [[0.00478875]\n",
            " [0.9947613 ]\n",
            " [0.9947437 ]\n",
            " [0.00805316]]\n",
            "Step: 2757 -> Loss: 0.005848578177392483 -> Predictions: [[0.00478596]\n",
            " [0.99476445]\n",
            " [0.99474686]\n",
            " [0.0080481 ]]\n",
            "Step: 2758 -> Loss: 0.0058449916541576385 -> Predictions: [[0.00478318]\n",
            " [0.99476767]\n",
            " [0.9947501 ]\n",
            " [0.00804303]]\n",
            "Step: 2759 -> Loss: 0.005841403268277645 -> Predictions: [[0.00478039]\n",
            " [0.9947708 ]\n",
            " [0.99475336]\n",
            " [0.00803797]]\n",
            "Step: 2760 -> Loss: 0.0058378251269459724 -> Predictions: [[0.00477762]\n",
            " [0.99477416]\n",
            " [0.9947566 ]\n",
            " [0.00803292]]\n",
            "Step: 2761 -> Loss: 0.005834248382598162 -> Predictions: [[0.00477484]\n",
            " [0.9947772 ]\n",
            " [0.99475974]\n",
            " [0.00802787]]\n",
            "Step: 2762 -> Loss: 0.005830679088830948 -> Predictions: [[0.00477206]\n",
            " [0.99478036]\n",
            " [0.99476296]\n",
            " [0.00802282]]\n",
            "Step: 2763 -> Loss: 0.005827109329402447 -> Predictions: [[0.0047693]\n",
            " [0.9947837]\n",
            " [0.9947661]\n",
            " [0.0080178]]\n",
            "Step: 2764 -> Loss: 0.005823548883199692 -> Predictions: [[0.00476654]\n",
            " [0.99478674]\n",
            " [0.9947693 ]\n",
            " [0.00801277]]\n",
            "Step: 2765 -> Loss: 0.005819988436996937 -> Predictions: [[0.00476376]\n",
            " [0.99478996]\n",
            " [0.9947725 ]\n",
            " [0.00800775]]\n",
            "Step: 2766 -> Loss: 0.005816434510052204 -> Predictions: [[0.00476101]\n",
            " [0.9947931 ]\n",
            " [0.99477565]\n",
            " [0.00800273]]\n",
            "Step: 2767 -> Loss: 0.005812881980091333 -> Predictions: [[0.00475825]\n",
            " [0.99479634]\n",
            " [0.9947789 ]\n",
            " [0.00799772]]\n",
            "Step: 2768 -> Loss: 0.005809337832033634 -> Predictions: [[0.0047555 ]\n",
            " [0.9947995 ]\n",
            " [0.99478203]\n",
            " [0.00799273]]\n",
            "Step: 2769 -> Loss: 0.005805797874927521 -> Predictions: [[0.00475275]\n",
            " [0.9948027 ]\n",
            " [0.99478525]\n",
            " [0.00798773]]\n",
            "Step: 2770 -> Loss: 0.005802260711789131 -> Predictions: [[0.00475   ]\n",
            " [0.99480575]\n",
            " [0.9947884 ]\n",
            " [0.00798273]]\n",
            "Step: 2771 -> Loss: 0.005798725411295891 -> Predictions: [[0.00474726]\n",
            " [0.9948089 ]\n",
            " [0.9947916 ]\n",
            " [0.00797775]]\n",
            "Step: 2772 -> Loss: 0.005795196630060673 -> Predictions: [[0.00474451]\n",
            " [0.99481213]\n",
            " [0.9947948 ]\n",
            " [0.00797277]]\n",
            "Step: 2773 -> Loss: 0.005791673436760902 -> Predictions: [[0.00474178]\n",
            " [0.9948152 ]\n",
            " [0.9947978 ]\n",
            " [0.0079678 ]]\n",
            "Step: 2774 -> Loss: 0.005788151174783707 -> Predictions: [[0.00473904]\n",
            " [0.9948184 ]\n",
            " [0.99480104]\n",
            " [0.00796284]]\n",
            "Step: 2775 -> Loss: 0.005784639623016119 -> Predictions: [[0.00473631]\n",
            " [0.99482155]\n",
            " [0.9948042 ]\n",
            " [0.00795788]]\n",
            "Step: 2776 -> Loss: 0.005781124345958233 -> Predictions: [[0.00473358]\n",
            " [0.99482465]\n",
            " [0.9948074 ]\n",
            " [0.00795292]]\n",
            "Step: 2777 -> Loss: 0.00577761884778738 -> Predictions: [[0.00473086]\n",
            " [0.9948278 ]\n",
            " [0.99481046]\n",
            " [0.00794797]]\n",
            "Step: 2778 -> Loss: 0.0057741133496165276 -> Predictions: [[0.00472814]\n",
            " [0.9948309 ]\n",
            " [0.9948137 ]\n",
            " [0.00794303]]\n",
            "Step: 2779 -> Loss: 0.005770617630332708 -> Predictions: [[0.00472541]\n",
            " [0.99483407]\n",
            " [0.9948167 ]\n",
            " [0.0079381 ]]\n",
            "Step: 2780 -> Loss: 0.005767119582742453 -> Predictions: [[0.0047227 ]\n",
            " [0.99483716]\n",
            " [0.99481994]\n",
            " [0.00793317]]\n",
            "Step: 2781 -> Loss: 0.00576363131403923 -> Predictions: [[0.00471999]\n",
            " [0.9948402 ]\n",
            " [0.994823  ]\n",
            " [0.00792824]]\n",
            "Step: 2782 -> Loss: 0.005760142579674721 -> Predictions: [[0.00471727]\n",
            " [0.99484336]\n",
            " [0.99482614]\n",
            " [0.00792332]]\n",
            "Step: 2783 -> Loss: 0.005756659898906946 -> Predictions: [[0.00471457]\n",
            " [0.99484646]\n",
            " [0.99482924]\n",
            " [0.00791841]]\n",
            "Step: 2784 -> Loss: 0.00575318094342947 -> Predictions: [[0.00471187]\n",
            " [0.9948495 ]\n",
            " [0.9948324 ]\n",
            " [0.00791351]]\n",
            "Step: 2785 -> Loss: 0.005749707110226154 -> Predictions: [[0.00470916]\n",
            " [0.9948527 ]\n",
            " [0.9948355 ]\n",
            " [0.0079086 ]]\n",
            "Step: 2786 -> Loss: 0.005746238864958286 -> Predictions: [[0.00470647]\n",
            " [0.99485576]\n",
            " [0.99483865]\n",
            " [0.00790372]]\n",
            "Step: 2787 -> Loss: 0.005742773413658142 -> Predictions: [[0.00470377]\n",
            " [0.99485886]\n",
            " [0.99484175]\n",
            " [0.00789882]]\n",
            "Step: 2788 -> Loss: 0.005739307962357998 -> Predictions: [[0.00470107]\n",
            " [0.9948619 ]\n",
            " [0.9948448 ]\n",
            " [0.00789394]]\n",
            "Step: 2789 -> Loss: 0.005735849961638451 -> Predictions: [[0.00469838]\n",
            " [0.994865  ]\n",
            " [0.9948479 ]\n",
            " [0.00788907]]\n",
            "Step: 2790 -> Loss: 0.005732396617531776 -> Predictions: [[0.0046957 ]\n",
            " [0.99486816]\n",
            " [0.99485105]\n",
            " [0.0078842 ]]\n",
            "Step: 2791 -> Loss: 0.005728950258344412 -> Predictions: [[0.00469302]\n",
            " [0.99487126]\n",
            " [0.99485415]\n",
            " [0.00787933]]\n",
            "Step: 2792 -> Loss: 0.005725504830479622 -> Predictions: [[0.00469034]\n",
            " [0.9948743 ]\n",
            " [0.9948572 ]\n",
            " [0.00787447]]\n",
            "Step: 2793 -> Loss: 0.005722058936953545 -> Predictions: [[0.00468766]\n",
            " [0.9948774 ]\n",
            " [0.99486023]\n",
            " [0.00786962]]\n",
            "Step: 2794 -> Loss: 0.005718625150620937 -> Predictions: [[0.00468499]\n",
            " [0.99488044]\n",
            " [0.99486333]\n",
            " [0.00786477]]\n",
            "Step: 2795 -> Loss: 0.0057151950895786285 -> Predictions: [[0.00468233]\n",
            " [0.9948835 ]\n",
            " [0.9948664 ]\n",
            " [0.00785994]]\n",
            "Step: 2796 -> Loss: 0.005711762700229883 -> Predictions: [[0.00467965]\n",
            " [0.9948866 ]\n",
            " [0.9948695 ]\n",
            " [0.0078551 ]]\n",
            "Step: 2797 -> Loss: 0.00570833683013916 -> Predictions: [[0.00467699]\n",
            " [0.9948895 ]\n",
            " [0.9948725 ]\n",
            " [0.00785028]]\n",
            "Step: 2798 -> Loss: 0.005704913288354874 -> Predictions: [[0.00467433]\n",
            " [0.9948926 ]\n",
            " [0.9948756 ]\n",
            " [0.00784545]]\n",
            "Step: 2799 -> Loss: 0.005701496731489897 -> Predictions: [[0.00467166]\n",
            " [0.99489564]\n",
            " [0.99487865]\n",
            " [0.00784063]]\n",
            "Step: 2800 -> Loss: 0.005698083899915218 -> Predictions: [[0.00466901]\n",
            " [0.99489874]\n",
            " [0.99488175]\n",
            " [0.00783582]]\n",
            "Step: 2801 -> Loss: 0.005694677121937275 -> Predictions: [[0.00466636]\n",
            " [0.9949018 ]\n",
            " [0.9948848 ]\n",
            " [0.00783101]]\n",
            "Step: 2802 -> Loss: 0.005691271275281906 -> Predictions: [[0.00466371]\n",
            " [0.99490476]\n",
            " [0.9948879 ]\n",
            " [0.00782621]]\n",
            "Step: 2803 -> Loss: 0.005687872413545847 -> Predictions: [[0.00466107]\n",
            " [0.9949078 ]\n",
            " [0.9948909 ]\n",
            " [0.00782142]]\n",
            "Step: 2804 -> Loss: 0.005684472620487213 -> Predictions: [[0.00465842]\n",
            " [0.9949109 ]\n",
            " [0.994894  ]\n",
            " [0.00781663]]\n",
            "Step: 2805 -> Loss: 0.0056810807436704636 -> Predictions: [[0.00465579]\n",
            " [0.99491394]\n",
            " [0.99489695]\n",
            " [0.00781185]]\n",
            "Step: 2806 -> Loss: 0.0056776925921440125 -> Predictions: [[0.00465314]\n",
            " [0.9949169 ]\n",
            " [0.99490005]\n",
            " [0.00780708]]\n",
            "Step: 2807 -> Loss: 0.005674304440617561 -> Predictions: [[0.0046505 ]\n",
            " [0.99491996]\n",
            " [0.9949031 ]\n",
            " [0.0078023 ]]\n",
            "Step: 2808 -> Loss: 0.0056709242053329945 -> Predictions: [[0.00464788]\n",
            " [0.99492294]\n",
            " [0.9949062 ]\n",
            " [0.00779754]]\n",
            "Step: 2809 -> Loss: 0.005667547695338726 -> Predictions: [[0.00464525]\n",
            " [0.994926  ]\n",
            " [0.9949091 ]\n",
            " [0.00779278]]\n",
            "Step: 2810 -> Loss: 0.005664176307618618 -> Predictions: [[0.00464263]\n",
            " [0.99492896]\n",
            " [0.9949122 ]\n",
            " [0.00778803]]\n",
            "Step: 2811 -> Loss: 0.005660806782543659 -> Predictions: [[0.00464001]\n",
            " [0.994932  ]\n",
            " [0.9949151 ]\n",
            " [0.00778328]]\n",
            "Step: 2812 -> Loss: 0.0056574405170977116 -> Predictions: [[0.00463738]\n",
            " [0.994935  ]\n",
            " [0.99491817]\n",
            " [0.00777854]]\n",
            "Step: 2813 -> Loss: 0.005654079839587212 -> Predictions: [[0.00463477]\n",
            " [0.994938  ]\n",
            " [0.99492115]\n",
            " [0.0077738 ]]\n",
            "Step: 2814 -> Loss: 0.005650719627737999 -> Predictions: [[0.00463215]\n",
            " [0.994941  ]\n",
            " [0.9949242 ]\n",
            " [0.00776907]]\n",
            "Step: 2815 -> Loss: 0.005647372454404831 -> Predictions: [[0.00462954]\n",
            " [0.9949439 ]\n",
            " [0.99492717]\n",
            " [0.00776435]]\n",
            "Step: 2816 -> Loss: 0.005644018761813641 -> Predictions: [[0.00462694]\n",
            " [0.994947  ]\n",
            " [0.9949302 ]\n",
            " [0.00775962]]\n",
            "Step: 2817 -> Loss: 0.005640675779432058 -> Predictions: [[0.00462434]\n",
            " [0.99494994]\n",
            " [0.9949332 ]\n",
            " [0.00775491]]\n",
            "Step: 2818 -> Loss: 0.005637334194034338 -> Predictions: [[0.00462173]\n",
            " [0.9949529 ]\n",
            " [0.9949362 ]\n",
            " [0.0077502 ]]\n",
            "Step: 2819 -> Loss: 0.005633994936943054 -> Predictions: [[0.00461913]\n",
            " [0.99495596]\n",
            " [0.9949392 ]\n",
            " [0.0077455 ]]\n",
            "Step: 2820 -> Loss: 0.00563066266477108 -> Predictions: [[0.00461654]\n",
            " [0.99495894]\n",
            " [0.9949421 ]\n",
            " [0.0077408 ]]\n",
            "Step: 2821 -> Loss: 0.005627332255244255 -> Predictions: [[0.00461394]\n",
            " [0.99496186]\n",
            " [0.9949452 ]\n",
            " [0.00773611]]\n",
            "Step: 2822 -> Loss: 0.005624004639685154 -> Predictions: [[0.00461134]\n",
            " [0.99496484]\n",
            " [0.99494815]\n",
            " [0.00773143]]\n",
            "Step: 2823 -> Loss: 0.00562068447470665 -> Predictions: [[0.00460876]\n",
            " [0.99496776]\n",
            " [0.9949511 ]\n",
            " [0.00772675]]\n",
            "Step: 2824 -> Loss: 0.005617366172373295 -> Predictions: [[0.00460618]\n",
            " [0.99497074]\n",
            " [0.99495405]\n",
            " [0.00772206]]\n",
            "Step: 2825 -> Loss: 0.005614049732685089 -> Predictions: [[0.0046036 ]\n",
            " [0.99497366]\n",
            " [0.99495715]\n",
            " [0.00771739]]\n",
            "Step: 2826 -> Loss: 0.0056107379496097565 -> Predictions: [[0.00460101]\n",
            " [0.99497664]\n",
            " [0.99496007]\n",
            " [0.00771273]]\n",
            "Step: 2827 -> Loss: 0.005607434548437595 -> Predictions: [[0.00459843]\n",
            " [0.99497956]\n",
            " [0.99496305]\n",
            " [0.00770808]]\n",
            "Step: 2828 -> Loss: 0.005604134406894445 -> Predictions: [[0.00459587]\n",
            " [0.9949825 ]\n",
            " [0.994966  ]\n",
            " [0.00770343]]\n",
            "Step: 2829 -> Loss: 0.005600830540060997 -> Predictions: [[0.00459329]\n",
            " [0.99498546]\n",
            " [0.99496895]\n",
            " [0.00769877]]\n",
            "Step: 2830 -> Loss: 0.005597541108727455 -> Predictions: [[0.00459073]\n",
            " [0.9949884 ]\n",
            " [0.9949719 ]\n",
            " [0.00769414]]\n",
            "Step: 2831 -> Loss: 0.005594245158135891 -> Predictions: [[0.00458816]\n",
            " [0.99499136]\n",
            " [0.99497485]\n",
            " [0.0076895 ]]\n",
            "Step: 2832 -> Loss: 0.005590958520770073 -> Predictions: [[0.00458559]\n",
            " [0.99499434]\n",
            " [0.9949778 ]\n",
            " [0.00768487]]\n",
            "Step: 2833 -> Loss: 0.005587673280388117 -> Predictions: [[0.00458303]\n",
            " [0.99499726]\n",
            " [0.99498075]\n",
            " [0.00768025]]\n",
            "Step: 2834 -> Loss: 0.0055843922309577465 -> Predictions: [[0.00458048]\n",
            " [0.99500024]\n",
            " [0.9949837 ]\n",
            " [0.00767562]]\n",
            "Step: 2835 -> Loss: 0.0055811177007853985 -> Predictions: [[0.00457792]\n",
            " [0.99500304]\n",
            " [0.99498665]\n",
            " [0.00767101]]\n",
            "Step: 2836 -> Loss: 0.0055778478272259235 -> Predictions: [[0.00457538]\n",
            " [0.995006  ]\n",
            " [0.9949896 ]\n",
            " [0.0076664 ]]\n",
            "Step: 2837 -> Loss: 0.0055745793506503105 -> Predictions: [[0.00457283]\n",
            " [0.99500895]\n",
            " [0.99499243]\n",
            " [0.00766181]]\n",
            "Step: 2838 -> Loss: 0.005571311805397272 -> Predictions: [[0.00457028]\n",
            " [0.9950118 ]\n",
            " [0.99499536]\n",
            " [0.0076572 ]]\n",
            "Step: 2839 -> Loss: 0.005568050313740969 -> Predictions: [[0.00456774]\n",
            " [0.9950147 ]\n",
            " [0.99499834]\n",
            " [0.00765261]]\n",
            "Step: 2840 -> Loss: 0.005564793944358826 -> Predictions: [[0.00456521]\n",
            " [0.9950177 ]\n",
            " [0.99500126]\n",
            " [0.00764802]]\n",
            "Step: 2841 -> Loss: 0.005561542231589556 -> Predictions: [[0.00456266]\n",
            " [0.9950205 ]\n",
            " [0.9950041 ]\n",
            " [0.00764345]]\n",
            "Step: 2842 -> Loss: 0.005558291915804148 -> Predictions: [[0.00456013]\n",
            " [0.9950235 ]\n",
            " [0.99500704]\n",
            " [0.00763887]]\n",
            "Step: 2843 -> Loss: 0.0055550443939864635 -> Predictions: [[0.0045576 ]\n",
            " [0.9950263 ]\n",
            " [0.99501   ]\n",
            " [0.00763429]]\n",
            "Step: 2844 -> Loss: 0.005551801063120365 -> Predictions: [[0.00455506]\n",
            " [0.9950293 ]\n",
            " [0.9950128 ]\n",
            " [0.00762973]]\n",
            "Step: 2845 -> Loss: 0.00554856238886714 -> Predictions: [[0.00455254]\n",
            " [0.9950321 ]\n",
            " [0.9950158 ]\n",
            " [0.00762517]]\n",
            "Step: 2846 -> Loss: 0.005545330233871937 -> Predictions: [[0.00455002]\n",
            " [0.99503505]\n",
            " [0.9950186 ]\n",
            " [0.00762061]]\n",
            "Step: 2847 -> Loss: 0.0055420976132154465 -> Predictions: [[0.0045475 ]\n",
            " [0.99503785]\n",
            " [0.9950216 ]\n",
            " [0.00761607]]\n",
            "Step: 2848 -> Loss: 0.00553887290880084 -> Predictions: [[0.00454499]\n",
            " [0.99504083]\n",
            " [0.9950245 ]\n",
            " [0.00761152]]\n",
            "Step: 2849 -> Loss: 0.005535648670047522 -> Predictions: [[0.00454247]\n",
            " [0.99504364]\n",
            " [0.99502736]\n",
            " [0.00760697]]\n",
            "Step: 2850 -> Loss: 0.005532426293939352 -> Predictions: [[0.00453995]\n",
            " [0.9950465 ]\n",
            " [0.99503016]\n",
            " [0.00760245]]\n",
            "Step: 2851 -> Loss: 0.005529210902750492 -> Predictions: [[0.00453744]\n",
            " [0.9950494 ]\n",
            " [0.99503314]\n",
            " [0.00759792]]\n",
            "Step: 2852 -> Loss: 0.0055259959772229195 -> Predictions: [[0.00453493]\n",
            " [0.9950523 ]\n",
            " [0.99503595]\n",
            " [0.00759339]]\n",
            "Step: 2853 -> Loss: 0.005522788502275944 -> Predictions: [[0.00453243]\n",
            " [0.9950551 ]\n",
            " [0.9950389 ]\n",
            " [0.00758888]]\n",
            "Step: 2854 -> Loss: 0.005519581027328968 -> Predictions: [[0.00452993]\n",
            " [0.99505806]\n",
            " [0.9950418 ]\n",
            " [0.00758437]]\n",
            "Step: 2855 -> Loss: 0.005516382399946451 -> Predictions: [[0.00452743]\n",
            " [0.99506086]\n",
            " [0.9950446 ]\n",
            " [0.00757986]]\n",
            "Step: 2856 -> Loss: 0.005513187497854233 -> Predictions: [[0.00452494]\n",
            " [0.9950637 ]\n",
            " [0.99504757]\n",
            " [0.00757536]]\n",
            "Step: 2857 -> Loss: 0.005509992130100727 -> Predictions: [[0.00452245]\n",
            " [0.9950665 ]\n",
            " [0.9950504 ]\n",
            " [0.00757086]]\n",
            "Step: 2858 -> Loss: 0.005506797693669796 -> Predictions: [[0.00451995]\n",
            " [0.9950694 ]\n",
            " [0.99505323]\n",
            " [0.00756637]]\n",
            "Step: 2859 -> Loss: 0.00550361443310976 -> Predictions: [[0.00451748]\n",
            " [0.9950722 ]\n",
            " [0.99505603]\n",
            " [0.00756188]]\n",
            "Step: 2860 -> Loss: 0.00550043024122715 -> Predictions: [[0.00451498]\n",
            " [0.99507505]\n",
            " [0.9950589 ]\n",
            " [0.00755741]]\n",
            "Step: 2861 -> Loss: 0.005497249774634838 -> Predictions: [[0.00451251]\n",
            " [0.99507785]\n",
            " [0.9950618 ]\n",
            " [0.00755293]]\n",
            "Step: 2862 -> Loss: 0.005494074430316687 -> Predictions: [[0.00451003]\n",
            " [0.9950807 ]\n",
            " [0.9950647 ]\n",
            " [0.00754846]]\n",
            "Step: 2863 -> Loss: 0.00549090001732111 -> Predictions: [[0.00450755]\n",
            " [0.9950836 ]\n",
            " [0.9950675 ]\n",
            " [0.007544  ]]\n",
            "Step: 2864 -> Loss: 0.005487731192260981 -> Predictions: [[0.00450507]\n",
            " [0.9950864 ]\n",
            " [0.99507034]\n",
            " [0.00753953]]\n",
            "Step: 2865 -> Loss: 0.005484569817781448 -> Predictions: [[0.0045026 ]\n",
            " [0.99508923]\n",
            " [0.99507314]\n",
            " [0.00753508]]\n",
            "Step: 2866 -> Loss: 0.005481408908963203 -> Predictions: [[0.00450014]\n",
            " [0.99509203]\n",
            " [0.995076  ]\n",
            " [0.00753064]]\n",
            "Step: 2867 -> Loss: 0.005478250794112682 -> Predictions: [[0.00449767]\n",
            " [0.9950949 ]\n",
            " [0.9950788 ]\n",
            " [0.00752619]]\n",
            "Step: 2868 -> Loss: 0.005475097335875034 -> Predictions: [[0.00449521]\n",
            " [0.9950977 ]\n",
            " [0.99508166]\n",
            " [0.00752175]]\n",
            "Step: 2869 -> Loss: 0.005471939221024513 -> Predictions: [[0.00449274]\n",
            " [0.99510056]\n",
            " [0.99508446]\n",
            " [0.00751731]]\n",
            "Step: 2870 -> Loss: 0.005468792747706175 -> Predictions: [[0.00449028]\n",
            " [0.99510336]\n",
            " [0.9950873 ]\n",
            " [0.00751288]]\n",
            "Step: 2871 -> Loss: 0.005465655121952295 -> Predictions: [[0.00448783]\n",
            " [0.9951061 ]\n",
            " [0.9950901 ]\n",
            " [0.00750847]]\n",
            "Step: 2872 -> Loss: 0.00546251330524683 -> Predictions: [[0.00448538]\n",
            " [0.9951089 ]\n",
            " [0.99509287]\n",
            " [0.00750405]]\n",
            "Step: 2873 -> Loss: 0.005459373816847801 -> Predictions: [[0.00448292]\n",
            " [0.99511176]\n",
            " [0.99509573]\n",
            " [0.00749963]]\n",
            "Step: 2874 -> Loss: 0.005456242244690657 -> Predictions: [[0.00448048]\n",
            " [0.99511445]\n",
            " [0.99509853]\n",
            " [0.00749522]]\n",
            "Step: 2875 -> Loss: 0.005453113466501236 -> Predictions: [[0.00447804]\n",
            " [0.9951173 ]\n",
            " [0.9951014 ]\n",
            " [0.00749082]]\n",
            "Step: 2876 -> Loss: 0.005449987016618252 -> Predictions: [[0.00447559]\n",
            " [0.9951201 ]\n",
            " [0.9951041 ]\n",
            " [0.00748641]]\n",
            "Step: 2877 -> Loss: 0.005446863826364279 -> Predictions: [[0.00447315]\n",
            " [0.99512285]\n",
            " [0.99510694]\n",
            " [0.00748201]]\n",
            "Step: 2878 -> Loss: 0.005443748086690903 -> Predictions: [[0.00447071]\n",
            " [0.9951257 ]\n",
            " [0.99510974]\n",
            " [0.00747764]]\n",
            "Step: 2879 -> Loss: 0.005440631881356239 -> Predictions: [[0.00446828]\n",
            " [0.9951284 ]\n",
            " [0.9951126 ]\n",
            " [0.00747325]]\n",
            "Step: 2880 -> Loss: 0.005437520332634449 -> Predictions: [[0.00446585]\n",
            " [0.99513125]\n",
            " [0.9951153 ]\n",
            " [0.00746888]]\n",
            "Step: 2881 -> Loss: 0.005434410646557808 -> Predictions: [[0.00446342]\n",
            " [0.99513394]\n",
            " [0.99511814]\n",
            " [0.00746449]]\n",
            "Step: 2882 -> Loss: 0.00543130561709404 -> Predictions: [[0.00446099]\n",
            " [0.9951368 ]\n",
            " [0.9951208 ]\n",
            " [0.00746013]]\n",
            "Step: 2883 -> Loss: 0.005428203381597996 -> Predictions: [[0.00445857]\n",
            " [0.9951395 ]\n",
            " [0.9951237 ]\n",
            " [0.00745577]]\n",
            "Step: 2884 -> Loss: 0.005425109528005123 -> Predictions: [[0.00445615]\n",
            " [0.99514234]\n",
            " [0.99512637]\n",
            " [0.00745142]]\n",
            "Step: 2885 -> Loss: 0.005422013346105814 -> Predictions: [[0.00445373]\n",
            " [0.995145  ]\n",
            " [0.9951292 ]\n",
            " [0.00744706]]\n",
            "Step: 2886 -> Loss: 0.005418920889496803 -> Predictions: [[0.00445131]\n",
            " [0.9951479 ]\n",
            " [0.99513197]\n",
            " [0.00744271]]\n",
            "Step: 2887 -> Loss: 0.005415836814790964 -> Predictions: [[0.00444891]\n",
            " [0.99515057]\n",
            " [0.9951348 ]\n",
            " [0.00743837]]\n",
            "Step: 2888 -> Loss: 0.005412750877439976 -> Predictions: [[0.00444649]\n",
            " [0.9951533 ]\n",
            " [0.9951375 ]\n",
            " [0.00743403]]\n",
            "Step: 2889 -> Loss: 0.005409670993685722 -> Predictions: [[0.00444408]\n",
            " [0.99515605]\n",
            " [0.9951403 ]\n",
            " [0.00742969]]\n",
            "Step: 2890 -> Loss: 0.005406591575592756 -> Predictions: [[0.00444168]\n",
            " [0.99515885]\n",
            " [0.99514306]\n",
            " [0.00742536]]\n",
            "Step: 2891 -> Loss: 0.005403519608080387 -> Predictions: [[0.00443928]\n",
            " [0.9951616 ]\n",
            " [0.99514574]\n",
            " [0.00742104]]\n",
            "Step: 2892 -> Loss: 0.005400449503213167 -> Predictions: [[0.00443688]\n",
            " [0.9951643 ]\n",
            " [0.9951486 ]\n",
            " [0.00741673]]\n",
            "Step: 2893 -> Loss: 0.00539738405495882 -> Predictions: [[0.00443448]\n",
            " [0.995167  ]\n",
            " [0.9951513 ]\n",
            " [0.00741241]]\n",
            "Step: 2894 -> Loss: 0.005394320469349623 -> Predictions: [[0.00443209]\n",
            " [0.9951697 ]\n",
            " [0.995154  ]\n",
            " [0.00740811]]\n",
            "Step: 2895 -> Loss: 0.005391261074692011 -> Predictions: [[0.00442969]\n",
            " [0.99517256]\n",
            " [0.9951567 ]\n",
            " [0.0074038 ]]\n",
            "Step: 2896 -> Loss: 0.005388202611356974 -> Predictions: [[0.0044273 ]\n",
            " [0.99517524]\n",
            " [0.99515957]\n",
            " [0.0073995 ]]\n",
            "Step: 2897 -> Loss: 0.005385151132941246 -> Predictions: [[0.00442492]\n",
            " [0.995178  ]\n",
            " [0.9951623 ]\n",
            " [0.00739521]]\n",
            "Step: 2898 -> Loss: 0.005382102448493242 -> Predictions: [[0.00442253]\n",
            " [0.9951807 ]\n",
            " [0.995165  ]\n",
            " [0.00739093]]\n",
            "Step: 2899 -> Loss: 0.005379054229706526 -> Predictions: [[0.00442014]\n",
            " [0.9951834 ]\n",
            " [0.99516773]\n",
            " [0.00738664]]\n",
            "Step: 2900 -> Loss: 0.005376013461500406 -> Predictions: [[0.00441778]\n",
            " [0.99518615]\n",
            " [0.9951704 ]\n",
            " [0.00738236]]\n",
            "Step: 2901 -> Loss: 0.005372975952923298 -> Predictions: [[0.00441539]\n",
            " [0.99518883]\n",
            " [0.99517316]\n",
            " [0.00737809]]\n",
            "Step: 2902 -> Loss: 0.005369937047362328 -> Predictions: [[0.00441302]\n",
            " [0.9951916 ]\n",
            " [0.99517584]\n",
            " [0.00737382]]\n",
            "Step: 2903 -> Loss: 0.0053669060580432415 -> Predictions: [[0.00441065]\n",
            " [0.99519426]\n",
            " [0.9951786 ]\n",
            " [0.00736955]]\n",
            "Step: 2904 -> Loss: 0.005363875068724155 -> Predictions: [[0.00440827]\n",
            " [0.995197  ]\n",
            " [0.99518126]\n",
            " [0.0073653 ]]\n",
            "Step: 2905 -> Loss: 0.0053608473390340805 -> Predictions: [[0.0044059 ]\n",
            " [0.9951997 ]\n",
            " [0.995184  ]\n",
            " [0.00736104]]\n",
            "Step: 2906 -> Loss: 0.005357828456908464 -> Predictions: [[0.00440355]\n",
            " [0.9952023 ]\n",
            " [0.99518675]\n",
            " [0.0073568 ]]\n",
            "Step: 2907 -> Loss: 0.005354808643460274 -> Predictions: [[0.00440118]\n",
            " [0.99520504]\n",
            " [0.9951894 ]\n",
            " [0.00735255]]\n",
            "Step: 2908 -> Loss: 0.005351794883608818 -> Predictions: [[0.00439883]\n",
            " [0.9952077 ]\n",
            " [0.99519217]\n",
            " [0.00734831]]\n",
            "Step: 2909 -> Loss: 0.005348782055079937 -> Predictions: [[0.00439647]\n",
            " [0.99521047]\n",
            " [0.99519485]\n",
            " [0.00734407]]\n",
            "Step: 2910 -> Loss: 0.0053457701578736305 -> Predictions: [[0.00439411]\n",
            " [0.99521315]\n",
            " [0.9951976 ]\n",
            " [0.00733983]]\n",
            "Step: 2911 -> Loss: 0.005342768505215645 -> Predictions: [[0.00439176]\n",
            " [0.9952158 ]\n",
            " [0.9952003 ]\n",
            " [0.00733562]]\n",
            "Step: 2912 -> Loss: 0.005339764524251223 -> Predictions: [[0.00438941]\n",
            " [0.99521846]\n",
            " [0.995203  ]\n",
            " [0.00733139]]\n",
            "Step: 2913 -> Loss: 0.0053367651998996735 -> Predictions: [[0.00438706]\n",
            " [0.9952212 ]\n",
            " [0.99520564]\n",
            " [0.00732719]]\n",
            "Step: 2914 -> Loss: 0.005333768669515848 -> Predictions: [[0.00438472]\n",
            " [0.9952238 ]\n",
            " [0.9952083 ]\n",
            " [0.00732297]]\n",
            "Step: 2915 -> Loss: 0.005330778658390045 -> Predictions: [[0.00438237]\n",
            " [0.9952265 ]\n",
            " [0.99521106]\n",
            " [0.00731876]]\n",
            "Step: 2916 -> Loss: 0.005327790044248104 -> Predictions: [[0.00438004]\n",
            " [0.9952291 ]\n",
            " [0.9952136 ]\n",
            " [0.00731455]]\n",
            "Step: 2917 -> Loss: 0.005324805621057749 -> Predictions: [[0.00437771]\n",
            " [0.9952318 ]\n",
            " [0.99521637]\n",
            " [0.00731036]]\n",
            "Step: 2918 -> Loss: 0.005321822129189968 -> Predictions: [[0.00437536]\n",
            " [0.99523455]\n",
            " [0.99521905]\n",
            " [0.00730617]]\n",
            "Step: 2919 -> Loss: 0.005318841896951199 -> Predictions: [[0.00437303]\n",
            " [0.9952371 ]\n",
            " [0.9952217 ]\n",
            " [0.00730198]]\n",
            "Step: 2920 -> Loss: 0.0053158653900027275 -> Predictions: [[0.0043707 ]\n",
            " [0.99523985]\n",
            " [0.99522436]\n",
            " [0.0072978 ]]\n",
            "Step: 2921 -> Loss: 0.005312894005328417 -> Predictions: [[0.00436838]\n",
            " [0.9952425 ]\n",
            " [0.9952271 ]\n",
            " [0.00729362]]\n",
            "Step: 2922 -> Loss: 0.005309923551976681 -> Predictions: [[0.00436605]\n",
            " [0.99524516]\n",
            " [0.9952297 ]\n",
            " [0.00728945]]\n",
            "Step: 2923 -> Loss: 0.0053069558925926685 -> Predictions: [[0.00436372]\n",
            " [0.9952478 ]\n",
            " [0.9952324 ]\n",
            " [0.00728528]]\n",
            "Step: 2924 -> Loss: 0.005303992424160242 -> Predictions: [[0.00436141]\n",
            " [0.99525034]\n",
            " [0.995235  ]\n",
            " [0.00728111]]\n",
            "Step: 2925 -> Loss: 0.005301033146679401 -> Predictions: [[0.00435909]\n",
            " [0.9952531 ]\n",
            " [0.9952377 ]\n",
            " [0.00727695]]\n",
            "Step: 2926 -> Loss: 0.005298077594488859 -> Predictions: [[0.00435677]\n",
            " [0.99525565]\n",
            " [0.99524033]\n",
            " [0.0072728 ]]\n",
            "Step: 2927 -> Loss: 0.005295129492878914 -> Predictions: [[0.00435447]\n",
            " [0.9952583 ]\n",
            " [0.9952429 ]\n",
            " [0.00726865]]\n",
            "Step: 2928 -> Loss: 0.005292176268994808 -> Predictions: [[0.00435215]\n",
            " [0.995261  ]\n",
            " [0.99524564]\n",
            " [0.0072645 ]]\n",
            "Step: 2929 -> Loss: 0.005289227701723576 -> Predictions: [[0.00434984]\n",
            " [0.9952636 ]\n",
            " [0.99524826]\n",
            " [0.00726037]]\n",
            "Step: 2930 -> Loss: 0.005286285653710365 -> Predictions: [[0.00434754]\n",
            " [0.9952662 ]\n",
            " [0.99525094]\n",
            " [0.00725623]]\n",
            "Step: 2931 -> Loss: 0.005283348727971315 -> Predictions: [[0.00434524]\n",
            " [0.99526876]\n",
            " [0.99525356]\n",
            " [0.0072521 ]]\n",
            "Step: 2932 -> Loss: 0.005280411336570978 -> Predictions: [[0.00434294]\n",
            " [0.9952715 ]\n",
            " [0.9952561 ]\n",
            " [0.00724797]]\n",
            "Step: 2933 -> Loss: 0.0052774762734770775 -> Predictions: [[0.00434063]\n",
            " [0.99527407]\n",
            " [0.99525875]\n",
            " [0.00724385]]\n",
            "Step: 2934 -> Loss: 0.005274544470012188 -> Predictions: [[0.00433834]\n",
            " [0.9952767 ]\n",
            " [0.9952615 ]\n",
            " [0.00723973]]\n",
            "Step: 2935 -> Loss: 0.005271618720144033 -> Predictions: [[0.00433605]\n",
            " [0.9952793 ]\n",
            " [0.99526405]\n",
            " [0.00723562]]\n",
            "Step: 2936 -> Loss: 0.005268692970275879 -> Predictions: [[0.00433376]\n",
            " [0.9952819 ]\n",
            " [0.9952667 ]\n",
            " [0.00723151]]\n",
            "Step: 2937 -> Loss: 0.005265773739665747 -> Predictions: [[0.00433148]\n",
            " [0.9952845 ]\n",
            " [0.99526924]\n",
            " [0.00722741]]\n",
            "Step: 2938 -> Loss: 0.005262857768684626 -> Predictions: [[0.00432919]\n",
            " [0.99528706]\n",
            " [0.995272  ]\n",
            " [0.00722332]]\n",
            "Step: 2939 -> Loss: 0.005259939469397068 -> Predictions: [[0.0043269 ]\n",
            " [0.9952897 ]\n",
            " [0.99527454]\n",
            " [0.00721922]]\n",
            "Step: 2940 -> Loss: 0.005257030948996544 -> Predictions: [[0.00432462]\n",
            " [0.9952923 ]\n",
            " [0.99527717]\n",
            " [0.00721513]]\n",
            "Step: 2941 -> Loss: 0.00525412242859602 -> Predictions: [[0.00432234]\n",
            " [0.99529487]\n",
            " [0.9952798 ]\n",
            " [0.00721105]]\n",
            "Step: 2942 -> Loss: 0.005251220893114805 -> Predictions: [[0.00432006]\n",
            " [0.9952975 ]\n",
            " [0.99528235]\n",
            " [0.00720697]]\n",
            "Step: 2943 -> Loss: 0.005248314701020718 -> Predictions: [[0.00431779]\n",
            " [0.99530005]\n",
            " [0.995285  ]\n",
            " [0.00720289]]\n",
            "Step: 2944 -> Loss: 0.005245416425168514 -> Predictions: [[0.00431553]\n",
            " [0.9953027 ]\n",
            " [0.99528754]\n",
            " [0.00719882]]\n",
            "Step: 2945 -> Loss: 0.005242522805929184 -> Predictions: [[0.00431325]\n",
            " [0.9953053 ]\n",
            " [0.99529016]\n",
            " [0.00719476]]\n",
            "Step: 2946 -> Loss: 0.0052396273240447044 -> Predictions: [[0.00431098]\n",
            " [0.99530786]\n",
            " [0.9952928 ]\n",
            " [0.00719069]]\n",
            "Step: 2947 -> Loss: 0.005236741155385971 -> Predictions: [[0.00430872]\n",
            " [0.9953105 ]\n",
            " [0.99529535]\n",
            " [0.00718663]]\n",
            "Step: 2948 -> Loss: 0.0052338531240820885 -> Predictions: [[0.00430645]\n",
            " [0.99531305]\n",
            " [0.99529797]\n",
            " [0.00718258]]\n",
            "Step: 2949 -> Loss: 0.005230972543358803 -> Predictions: [[0.00430419]\n",
            " [0.99531555]\n",
            " [0.99530053]\n",
            " [0.00717853]]\n",
            "Step: 2950 -> Loss: 0.005228094756603241 -> Predictions: [[0.00430194]\n",
            " [0.9953181 ]\n",
            " [0.99530315]\n",
            " [0.00717449]]\n",
            "Step: 2951 -> Loss: 0.0052252160385251045 -> Predictions: [[0.00429968]\n",
            " [0.99532074]\n",
            " [0.9953056 ]\n",
            " [0.00717045]]\n",
            "Step: 2952 -> Loss: 0.005222341977059841 -> Predictions: [[0.00429743]\n",
            " [0.99532336]\n",
            " [0.9953082 ]\n",
            " [0.00716641]]\n",
            "Step: 2953 -> Loss: 0.00521946931257844 -> Predictions: [[0.00429517]\n",
            " [0.9953258 ]\n",
            " [0.99531084]\n",
            " [0.00716238]]\n",
            "Step: 2954 -> Loss: 0.005216605961322784 -> Predictions: [[0.00429293]\n",
            " [0.9953284 ]\n",
            " [0.9953134 ]\n",
            " [0.00715835]]\n",
            "Step: 2955 -> Loss: 0.005213739350438118 -> Predictions: [[0.00429068]\n",
            " [0.995331  ]\n",
            " [0.9953159 ]\n",
            " [0.00715432]]\n",
            "Step: 2956 -> Loss: 0.005210881121456623 -> Predictions: [[0.00428844]\n",
            " [0.9953335 ]\n",
            " [0.9953185 ]\n",
            " [0.00715031]]\n",
            "Step: 2957 -> Loss: 0.005208022892475128 -> Predictions: [[0.0042862]\n",
            " [0.9953361]\n",
            " [0.9953211]\n",
            " [0.0071463]]\n",
            "Step: 2958 -> Loss: 0.00520516699180007 -> Predictions: [[0.00428396]\n",
            " [0.99533856]\n",
            " [0.9953237 ]\n",
            " [0.00714229]]\n",
            "Step: 2959 -> Loss: 0.005202312953770161 -> Predictions: [[0.00428172]\n",
            " [0.9953412 ]\n",
            " [0.99532616]\n",
            " [0.00713829]]\n",
            "Step: 2960 -> Loss: 0.005199466831982136 -> Predictions: [[0.00427949]\n",
            " [0.99534374]\n",
            " [0.9953288 ]\n",
            " [0.00713429]]\n",
            "Step: 2961 -> Loss: 0.005196616984903812 -> Predictions: [[0.00427725]\n",
            " [0.99534625]\n",
            " [0.99533135]\n",
            " [0.00713029]]\n",
            "Step: 2962 -> Loss: 0.005193779245018959 -> Predictions: [[0.00427503]\n",
            " [0.9953489 ]\n",
            " [0.99533385]\n",
            " [0.0071263 ]]\n",
            "Step: 2963 -> Loss: 0.005190940573811531 -> Predictions: [[0.0042728 ]\n",
            " [0.9953513 ]\n",
            " [0.9953365 ]\n",
            " [0.00712232]]\n",
            "Step: 2964 -> Loss: 0.005188103299587965 -> Predictions: [[0.00427058]\n",
            " [0.99535394]\n",
            " [0.9953389 ]\n",
            " [0.00711832]]\n",
            "Step: 2965 -> Loss: 0.005185269750654697 -> Predictions: [[0.00426836]\n",
            " [0.9953564 ]\n",
            " [0.99534154]\n",
            " [0.00711436]]\n",
            "Step: 2966 -> Loss: 0.005182442255318165 -> Predictions: [[0.00426614]\n",
            " [0.9953589 ]\n",
            " [0.995344  ]\n",
            " [0.00711038]]\n",
            "Step: 2967 -> Loss: 0.00517961336299777 -> Predictions: [[0.00426392]\n",
            " [0.9953615 ]\n",
            " [0.9953466 ]\n",
            " [0.00710641]]\n",
            "Step: 2968 -> Loss: 0.005176784470677376 -> Predictions: [[0.0042617 ]\n",
            " [0.99536395]\n",
            " [0.9953491 ]\n",
            " [0.00710243]]\n",
            "Step: 2969 -> Loss: 0.005173968616873026 -> Predictions: [[0.00425949]\n",
            " [0.99536645]\n",
            " [0.99535155]\n",
            " [0.00709848]]\n",
            "Step: 2970 -> Loss: 0.005171150900423527 -> Predictions: [[0.00425727]\n",
            " [0.995369  ]\n",
            " [0.9953542 ]\n",
            " [0.00709453]]\n",
            "Step: 2971 -> Loss: 0.005168335512280464 -> Predictions: [[0.00425507]\n",
            " [0.9953715 ]\n",
            " [0.9953566 ]\n",
            " [0.00709058]]\n",
            "Step: 2972 -> Loss: 0.005165526177734137 -> Predictions: [[0.00425286]\n",
            " [0.995374  ]\n",
            " [0.99535924]\n",
            " [0.00708663]]\n",
            "Step: 2973 -> Loss: 0.005162717774510384 -> Predictions: [[0.00425066]\n",
            " [0.99537647]\n",
            " [0.99536175]\n",
            " [0.00708268]]\n",
            "Step: 2974 -> Loss: 0.005159906577318907 -> Predictions: [[0.00424845]\n",
            " [0.9953791 ]\n",
            " [0.9953642 ]\n",
            " [0.00707874]]\n",
            "Step: 2975 -> Loss: 0.00515710050240159 -> Predictions: [[0.00424625]\n",
            " [0.9953816 ]\n",
            " [0.9953668 ]\n",
            " [0.0070748 ]]\n",
            "Step: 2976 -> Loss: 0.005154304206371307 -> Predictions: [[0.00424406]\n",
            " [0.99538404]\n",
            " [0.99536926]\n",
            " [0.00707087]]\n",
            "Step: 2977 -> Loss: 0.005151506047695875 -> Predictions: [[0.00424186]\n",
            " [0.99538654]\n",
            " [0.99537176]\n",
            " [0.00706694]]\n",
            "Step: 2978 -> Loss: 0.005148713476955891 -> Predictions: [[0.00423966]\n",
            " [0.995389  ]\n",
            " [0.99537426]\n",
            " [0.00706302]]\n",
            "Step: 2979 -> Loss: 0.005145926959812641 -> Predictions: [[0.00423748]\n",
            " [0.9953915 ]\n",
            " [0.9953767 ]\n",
            " [0.0070591 ]]\n",
            "Step: 2980 -> Loss: 0.005143136717379093 -> Predictions: [[0.00423528]\n",
            " [0.995394  ]\n",
            " [0.9953793 ]\n",
            " [0.00705519]]\n",
            "Step: 2981 -> Loss: 0.00514034740626812 -> Predictions: [[0.00423309]\n",
            " [0.99539644]\n",
            " [0.9953818 ]\n",
            " [0.00705128]]\n",
            "Step: 2982 -> Loss: 0.00513756787404418 -> Predictions: [[0.0042309 ]\n",
            " [0.99539894]\n",
            " [0.9953843 ]\n",
            " [0.00704738]]\n",
            "Step: 2983 -> Loss: 0.005134787410497665 -> Predictions: [[0.00422873]\n",
            " [0.9954014 ]\n",
            " [0.9953868 ]\n",
            " [0.00704347]]\n",
            "Step: 2984 -> Loss: 0.005132009275257587 -> Predictions: [[0.00422654]\n",
            " [0.9954039 ]\n",
            " [0.9953892 ]\n",
            " [0.00703958]]\n",
            "Step: 2985 -> Loss: 0.0051292418502271175 -> Predictions: [[0.00422437]\n",
            " [0.9954064 ]\n",
            " [0.9953917 ]\n",
            " [0.00703569]]\n",
            "Step: 2986 -> Loss: 0.005126469768583775 -> Predictions: [[0.0042222 ]\n",
            " [0.99540883]\n",
            " [0.99539423]\n",
            " [0.0070318 ]]\n",
            "Step: 2987 -> Loss: 0.005123700015246868 -> Predictions: [[0.00422002]\n",
            " [0.99541134]\n",
            " [0.9953967 ]\n",
            " [0.00702791]]\n",
            "Step: 2988 -> Loss: 0.005120942369103432 -> Predictions: [[0.00421785]\n",
            " [0.99541384]\n",
            " [0.9953992 ]\n",
            " [0.00702404]]\n",
            "Step: 2989 -> Loss: 0.0051181744784116745 -> Predictions: [[0.00421568]\n",
            " [0.9954163 ]\n",
            " [0.9954016 ]\n",
            " [0.00702015]]\n",
            "Step: 2990 -> Loss: 0.0051154182292521 -> Predictions: [[0.00421351]\n",
            " [0.9954188 ]\n",
            " [0.9954041 ]\n",
            " [0.00701629]]\n",
            "Step: 2991 -> Loss: 0.005112662445753813 -> Predictions: [[0.00421135]\n",
            " [0.99542123]\n",
            " [0.9954066 ]\n",
            " [0.00701242]]\n",
            "Step: 2992 -> Loss: 0.005109913647174835 -> Predictions: [[0.00420919]\n",
            " [0.9954236 ]\n",
            " [0.9954091 ]\n",
            " [0.00700857]]\n",
            "Step: 2993 -> Loss: 0.005107158794999123 -> Predictions: [[0.00420702]\n",
            " [0.9954261 ]\n",
            " [0.9954116 ]\n",
            " [0.0070047 ]]\n",
            "Step: 2994 -> Loss: 0.005104415584355593 -> Predictions: [[0.00420487]\n",
            " [0.99542856]\n",
            " [0.995414  ]\n",
            " [0.00700085]]\n",
            "Step: 2995 -> Loss: 0.0051016733050346375 -> Predictions: [[0.00420271]\n",
            " [0.99543107]\n",
            " [0.9954164 ]\n",
            " [0.00699701]]\n",
            "Step: 2996 -> Loss: 0.0050989314913749695 -> Predictions: [[0.00420056]\n",
            " [0.9954335 ]\n",
            " [0.9954189 ]\n",
            " [0.00699315]]\n",
            "Step: 2997 -> Loss: 0.005096192471683025 -> Predictions: [[0.00419841]\n",
            " [0.9954359 ]\n",
            " [0.99542135]\n",
            " [0.00698931]]\n",
            "Step: 2998 -> Loss: 0.005093459039926529 -> Predictions: [[0.00419627]\n",
            " [0.9954384 ]\n",
            " [0.99542385]\n",
            " [0.00698547]]\n",
            "Step: 2999 -> Loss: 0.005090727470815182 -> Predictions: [[0.00419412]\n",
            " [0.99544084]\n",
            " [0.99542624]\n",
            " [0.00698164]]\n",
            "Step: 3001 -> Loss: 0.005087723024189472 -> Predictions: [[0.00419176]\n",
            " [0.99544346]\n",
            " [0.9954289 ]\n",
            " [0.00697743]]\n",
            "Step: 3002 -> Loss: 0.00508745014667511 -> Predictions: [[0.00419155]\n",
            " [0.9954437 ]\n",
            " [0.99542916]\n",
            " [0.00697705]]\n",
            "Step: 3003 -> Loss: 0.0050871786661446095 -> Predictions: [[0.00419134]\n",
            " [0.99544394]\n",
            " [0.9954294 ]\n",
            " [0.00697666]]\n",
            "Step: 3004 -> Loss: 0.005086905788630247 -> Predictions: [[0.00419113]\n",
            " [0.9954443 ]\n",
            " [0.99542975]\n",
            " [0.00697629]]\n",
            "Step: 3005 -> Loss: 0.005086635239422321 -> Predictions: [[0.00419092]\n",
            " [0.99544454]\n",
            " [0.99543   ]\n",
            " [0.00697591]]\n",
            "Step: 3006 -> Loss: 0.005086362361907959 -> Predictions: [[0.0041907 ]\n",
            " [0.9954448 ]\n",
            " [0.99543023]\n",
            " [0.00697553]]\n",
            "Step: 3007 -> Loss: 0.005086089484393597 -> Predictions: [[0.0041905 ]\n",
            " [0.995445  ]\n",
            " [0.99543047]\n",
            " [0.00697515]]\n",
            "Step: 3008 -> Loss: 0.005085817072540522 -> Predictions: [[0.00419028]\n",
            " [0.99544525]\n",
            " [0.9954307 ]\n",
            " [0.00697477]]\n",
            "Step: 3009 -> Loss: 0.005085544660687447 -> Predictions: [[0.00419007]\n",
            " [0.9954455 ]\n",
            " [0.99543095]\n",
            " [0.00697439]]\n",
            "Step: 3010 -> Loss: 0.005085272714495659 -> Predictions: [[0.00418985]\n",
            " [0.9954457 ]\n",
            " [0.9954312 ]\n",
            " [0.006974  ]]\n",
            "Step: 3011 -> Loss: 0.005085000768303871 -> Predictions: [[0.00418963]\n",
            " [0.99544597]\n",
            " [0.9954314 ]\n",
            " [0.00697362]]\n",
            "Step: 3012 -> Loss: 0.005084727890789509 -> Predictions: [[0.00418942]\n",
            " [0.9954462 ]\n",
            " [0.99543166]\n",
            " [0.00697324]]\n",
            "Step: 3013 -> Loss: 0.005084458272904158 -> Predictions: [[0.0041892 ]\n",
            " [0.9954464 ]\n",
            " [0.9954319 ]\n",
            " [0.00697286]]\n",
            "Step: 3014 -> Loss: 0.005084183532744646 -> Predictions: [[0.00418898]\n",
            " [0.9954466 ]\n",
            " [0.99543214]\n",
            " [0.00697248]]\n",
            "Step: 3015 -> Loss: 0.005083911120891571 -> Predictions: [[0.00418877]\n",
            " [0.99544686]\n",
            " [0.9954324 ]\n",
            " [0.0069721 ]]\n",
            "Step: 3016 -> Loss: 0.005083638243377209 -> Predictions: [[0.00418856]\n",
            " [0.9954471 ]\n",
            " [0.9954326 ]\n",
            " [0.00697171]]\n",
            "Step: 3017 -> Loss: 0.005083370953798294 -> Predictions: [[0.00418834]\n",
            " [0.99544734]\n",
            " [0.99543285]\n",
            " [0.00697134]]\n",
            "Step: 3018 -> Loss: 0.005083097144961357 -> Predictions: [[0.00418813]\n",
            " [0.9954476 ]\n",
            " [0.9954331 ]\n",
            " [0.00697095]]\n",
            "Step: 3019 -> Loss: 0.0050828238017857075 -> Predictions: [[0.00418791]\n",
            " [0.9954478 ]\n",
            " [0.9954333 ]\n",
            " [0.00697057]]\n",
            "Step: 3020 -> Loss: 0.005082552321255207 -> Predictions: [[0.00418769]\n",
            " [0.9954482 ]\n",
            " [0.9954336 ]\n",
            " [0.00697019]]\n",
            "Step: 3021 -> Loss: 0.005082282237708569 -> Predictions: [[0.00418748]\n",
            " [0.9954484 ]\n",
            " [0.99543387]\n",
            " [0.00696982]]\n",
            "Step: 3022 -> Loss: 0.00508201215416193 -> Predictions: [[0.00418726]\n",
            " [0.99544865]\n",
            " [0.9954341 ]\n",
            " [0.00696944]]\n",
            "Step: 3023 -> Loss: 0.005081737879663706 -> Predictions: [[0.00418705]\n",
            " [0.9954489 ]\n",
            " [0.99543434]\n",
            " [0.00696904]]\n",
            "Step: 3024 -> Loss: 0.005081466864794493 -> Predictions: [[0.00418684]\n",
            " [0.9954491 ]\n",
            " [0.9954346 ]\n",
            " [0.00696867]]\n",
            "Step: 3025 -> Loss: 0.005081196315586567 -> Predictions: [[0.00418662]\n",
            " [0.99544936]\n",
            " [0.9954348 ]\n",
            " [0.00696829]]\n",
            "Step: 3026 -> Loss: 0.00508092250674963 -> Predictions: [[0.0041864 ]\n",
            " [0.9954496 ]\n",
            " [0.99543506]\n",
            " [0.00696791]]\n",
            "Step: 3027 -> Loss: 0.005080648697912693 -> Predictions: [[0.00418618]\n",
            " [0.99544984]\n",
            " [0.9954353 ]\n",
            " [0.00696753]]\n",
            "Step: 3028 -> Loss: 0.005080381873995066 -> Predictions: [[0.00418598]\n",
            " [0.9954501 ]\n",
            " [0.99543554]\n",
            " [0.00696715]]\n",
            "Step: 3029 -> Loss: 0.005080110859125853 -> Predictions: [[0.00418576]\n",
            " [0.9954503 ]\n",
            " [0.9954358 ]\n",
            " [0.00696677]]\n",
            "Step: 3030 -> Loss: 0.005079836584627628 -> Predictions: [[0.00418554]\n",
            " [0.99545056]\n",
            " [0.995436  ]\n",
            " [0.00696639]]\n",
            "Step: 3031 -> Loss: 0.005079562310129404 -> Predictions: [[0.00418533]\n",
            " [0.9954508 ]\n",
            " [0.99543625]\n",
            " [0.00696601]]\n",
            "Step: 3032 -> Loss: 0.005079294089227915 -> Predictions: [[0.00418511]\n",
            " [0.99545103]\n",
            " [0.9954365 ]\n",
            " [0.00696563]]\n",
            "Step: 3033 -> Loss: 0.0050790212117135525 -> Predictions: [[0.0041849 ]\n",
            " [0.9954513 ]\n",
            " [0.9954367 ]\n",
            " [0.00696525]]\n",
            "Step: 3034 -> Loss: 0.005078752990812063 -> Predictions: [[0.00418469]\n",
            " [0.9954515 ]\n",
            " [0.99543697]\n",
            " [0.00696487]]\n",
            "Step: 3035 -> Loss: 0.005078477784991264 -> Predictions: [[0.00418447]\n",
            " [0.99545175]\n",
            " [0.9954372 ]\n",
            " [0.00696448]]\n",
            "Step: 3036 -> Loss: 0.005078207701444626 -> Predictions: [[0.00418425]\n",
            " [0.995452  ]\n",
            " [0.99543744]\n",
            " [0.00696411]]\n",
            "Step: 3037 -> Loss: 0.005077935755252838 -> Predictions: [[0.00418404]\n",
            " [0.9954522 ]\n",
            " [0.9954377 ]\n",
            " [0.00696373]]\n",
            "Step: 3038 -> Loss: 0.005077664740383625 -> Predictions: [[0.00418383]\n",
            " [0.9954526 ]\n",
            " [0.9954379 ]\n",
            " [0.00696335]]\n",
            "Step: 3039 -> Loss: 0.005077396519482136 -> Predictions: [[0.00418361]\n",
            " [0.99545276]\n",
            " [0.99543816]\n",
            " [0.00696296]]\n",
            "Step: 3040 -> Loss: 0.005077121313661337 -> Predictions: [[0.00418339]\n",
            " [0.995453  ]\n",
            " [0.9954384 ]\n",
            " [0.00696258]]\n",
            "Step: 3041 -> Loss: 0.0050768498331308365 -> Predictions: [[0.00418318]\n",
            " [0.99545324]\n",
            " [0.99543875]\n",
            " [0.0069622 ]]\n",
            "Step: 3042 -> Loss: 0.005076578352600336 -> Predictions: [[0.00418296]\n",
            " [0.9954535 ]\n",
            " [0.995439  ]\n",
            " [0.00696183]]\n",
            "Step: 3043 -> Loss: 0.005076305475085974 -> Predictions: [[0.00418275]\n",
            " [0.9954537 ]\n",
            " [0.99543923]\n",
            " [0.00696144]]\n",
            "Step: 3044 -> Loss: 0.005076037719845772 -> Predictions: [[0.00418253]\n",
            " [0.99545395]\n",
            " [0.99543947]\n",
            " [0.00696107]]\n",
            "Step: 3045 -> Loss: 0.0050757648423314095 -> Predictions: [[0.00418232]\n",
            " [0.9954542 ]\n",
            " [0.9954397 ]\n",
            " [0.00696069]]\n",
            "Step: 3046 -> Loss: 0.005075494293123484 -> Predictions: [[0.0041821 ]\n",
            " [0.99545443]\n",
            " [0.9954399 ]\n",
            " [0.00696031]]\n",
            "Step: 3047 -> Loss: 0.005075223743915558 -> Predictions: [[0.00418189]\n",
            " [0.99545467]\n",
            " [0.9954401 ]\n",
            " [0.00695993]]\n",
            "Step: 3048 -> Loss: 0.005074950400739908 -> Predictions: [[0.00418167]\n",
            " [0.9954549 ]\n",
            " [0.99544036]\n",
            " [0.00695955]]\n",
            "Step: 3049 -> Loss: 0.005074680782854557 -> Predictions: [[0.00418146]\n",
            " [0.99545515]\n",
            " [0.9954406 ]\n",
            " [0.00695917]]\n",
            "Step: 3050 -> Loss: 0.005074409302324057 -> Predictions: [[0.00418124]\n",
            " [0.9954554 ]\n",
            " [0.99544084]\n",
            " [0.0069588 ]]\n",
            "Step: 3051 -> Loss: 0.005074137821793556 -> Predictions: [[0.00418103]\n",
            " [0.9954556 ]\n",
            " [0.9954411 ]\n",
            " [0.00695842]]\n",
            "Step: 3052 -> Loss: 0.005073866806924343 -> Predictions: [[0.00418081]\n",
            " [0.99545586]\n",
            " [0.9954413 ]\n",
            " [0.00695804]]\n",
            "Step: 3053 -> Loss: 0.005073596257716417 -> Predictions: [[0.0041806 ]\n",
            " [0.9954561 ]\n",
            " [0.99544156]\n",
            " [0.00695766]]\n",
            "Step: 3054 -> Loss: 0.00507332431152463 -> Predictions: [[0.00418038]\n",
            " [0.99545634]\n",
            " [0.9954418 ]\n",
            " [0.00695729]]\n",
            "Step: 3055 -> Loss: 0.005073056556284428 -> Predictions: [[0.00418018]\n",
            " [0.9954566 ]\n",
            " [0.99544203]\n",
            " [0.00695691]]\n",
            "Step: 3056 -> Loss: 0.005072782747447491 -> Predictions: [[0.00417996]\n",
            " [0.9954568 ]\n",
            " [0.9954423 ]\n",
            " [0.00695652]]\n",
            "Step: 3057 -> Loss: 0.005072509869933128 -> Predictions: [[0.00417974]\n",
            " [0.9954572 ]\n",
            " [0.9954425 ]\n",
            " [0.00695615]]\n",
            "Step: 3058 -> Loss: 0.005072243511676788 -> Predictions: [[0.00417953]\n",
            " [0.9954574 ]\n",
            " [0.99544287]\n",
            " [0.00695578]]\n",
            "Step: 3059 -> Loss: 0.005071969702839851 -> Predictions: [[0.00417932]\n",
            " [0.99545765]\n",
            " [0.9954431 ]\n",
            " [0.00695539]]\n",
            "Step: 3060 -> Loss: 0.005071697756648064 -> Predictions: [[0.0041791 ]\n",
            " [0.9954579 ]\n",
            " [0.99544334]\n",
            " [0.00695502]]\n",
            "Step: 3061 -> Loss: 0.005071427673101425 -> Predictions: [[0.00417888]\n",
            " [0.9954581 ]\n",
            " [0.9954436 ]\n",
            " [0.00695464]]\n",
            "Step: 3062 -> Loss: 0.005071158520877361 -> Predictions: [[0.00417867]\n",
            " [0.99545836]\n",
            " [0.9954438 ]\n",
            " [0.00695427]]\n",
            "Step: 3063 -> Loss: 0.005070885177701712 -> Predictions: [[0.00417845]\n",
            " [0.9954586 ]\n",
            " [0.99544406]\n",
            " [0.00695388]]\n",
            "Step: 3064 -> Loss: 0.005070612765848637 -> Predictions: [[0.00417823]\n",
            " [0.99545884]\n",
            " [0.9954443 ]\n",
            " [0.00695351]]\n",
            "Step: 3065 -> Loss: 0.0050703417509794235 -> Predictions: [[0.00417802]\n",
            " [0.9954591 ]\n",
            " [0.99544454]\n",
            " [0.00695312]]\n",
            "Step: 3066 -> Loss: 0.005070071667432785 -> Predictions: [[0.0041778 ]\n",
            " [0.99545926]\n",
            " [0.9954448 ]\n",
            " [0.00695275]]\n",
            "Step: 3067 -> Loss: 0.0050698015838861465 -> Predictions: [[0.0041776 ]\n",
            " [0.9954595 ]\n",
            " [0.995445  ]\n",
            " [0.00695236]]\n",
            "Step: 3068 -> Loss: 0.0050695305690169334 -> Predictions: [[0.00417738]\n",
            " [0.99545974]\n",
            " [0.99544525]\n",
            " [0.00695199]]\n",
            "Step: 3069 -> Loss: 0.005069258157163858 -> Predictions: [[0.00417715]\n",
            " [0.99546   ]\n",
            " [0.9954455 ]\n",
            " [0.0069516 ]]\n",
            "Step: 3070 -> Loss: 0.005068992264568806 -> Predictions: [[0.00417695]\n",
            " [0.9954602 ]\n",
            " [0.9954457 ]\n",
            " [0.00695123]]\n",
            "Step: 3071 -> Loss: 0.005068720318377018 -> Predictions: [[0.00417673]\n",
            " [0.99546045]\n",
            " [0.99544597]\n",
            " [0.00695084]]\n",
            "Step: 3072 -> Loss: 0.005068451631814241 -> Predictions: [[0.00417652]\n",
            " [0.9954607 ]\n",
            " [0.9954462 ]\n",
            " [0.00695047]]\n",
            "Step: 3073 -> Loss: 0.005068178754299879 -> Predictions: [[0.0041763 ]\n",
            " [0.9954609 ]\n",
            " [0.9954464 ]\n",
            " [0.00695008]]\n",
            "Step: 3074 -> Loss: 0.005067909136414528 -> Predictions: [[0.00417609]\n",
            " [0.99546117]\n",
            " [0.9954466 ]\n",
            " [0.0069497 ]]\n",
            "Step: 3075 -> Loss: 0.005067639052867889 -> Predictions: [[0.00417588]\n",
            " [0.9954614 ]\n",
            " [0.99544686]\n",
            " [0.00694931]]\n",
            "Step: 3076 -> Loss: 0.005067366175353527 -> Predictions: [[0.00417566]\n",
            " [0.99546164]\n",
            " [0.9954471 ]\n",
            " [0.00694893]]\n",
            "Step: 3077 -> Loss: 0.005067097954452038 -> Predictions: [[0.00417545]\n",
            " [0.9954619 ]\n",
            " [0.99544734]\n",
            " [0.00694855]]\n",
            "Step: 3078 -> Loss: 0.005066828802227974 -> Predictions: [[0.00417523]\n",
            " [0.9954621 ]\n",
            " [0.9954476 ]\n",
            " [0.00694818]]\n",
            "Step: 3079 -> Loss: 0.005066555924713612 -> Predictions: [[0.00417502]\n",
            " [0.99546236]\n",
            " [0.99544793]\n",
            " [0.00694778]]\n",
            "Step: 3080 -> Loss: 0.005066287238150835 -> Predictions: [[0.0041748 ]\n",
            " [0.9954626 ]\n",
            " [0.9954482 ]\n",
            " [0.00694741]]\n",
            "Step: 3081 -> Loss: 0.0050660171546041965 -> Predictions: [[0.0041746 ]\n",
            " [0.99546283]\n",
            " [0.9954484 ]\n",
            " [0.00694702]]\n",
            "Step: 3082 -> Loss: 0.005065747536718845 -> Predictions: [[0.00417438]\n",
            " [0.9954631 ]\n",
            " [0.99544865]\n",
            " [0.00694665]]\n",
            "Step: 3083 -> Loss: 0.005065474659204483 -> Predictions: [[0.00417416]\n",
            " [0.9954633 ]\n",
            " [0.9954489 ]\n",
            " [0.00694625]]\n",
            "Step: 3084 -> Loss: 0.005065208300948143 -> Predictions: [[0.00417395]\n",
            " [0.99546355]\n",
            " [0.9954491 ]\n",
            " [0.00694588]]\n",
            "Step: 3085 -> Loss: 0.005064935423433781 -> Predictions: [[0.00417373]\n",
            " [0.9954638 ]\n",
            " [0.99544936]\n",
            " [0.0069455 ]]\n",
            "Step: 3086 -> Loss: 0.005064666736871004 -> Predictions: [[0.00417352]\n",
            " [0.995464  ]\n",
            " [0.9954496 ]\n",
            " [0.00694512]]\n",
            "Step: 3087 -> Loss: 0.005064394325017929 -> Predictions: [[0.0041733 ]\n",
            " [0.99546427]\n",
            " [0.99544984]\n",
            " [0.00694473]]\n",
            "Step: 3088 -> Loss: 0.0050641256384551525 -> Predictions: [[0.00417309]\n",
            " [0.9954646 ]\n",
            " [0.9954501 ]\n",
            " [0.00694436]]\n",
            "Step: 3089 -> Loss: 0.005063854157924652 -> Predictions: [[0.00417288]\n",
            " [0.99546486]\n",
            " [0.9954503 ]\n",
            " [0.00694397]]\n",
            "Step: 3090 -> Loss: 0.00506358640268445 -> Predictions: [[0.00417267]\n",
            " [0.9954651 ]\n",
            " [0.99545056]\n",
            " [0.00694359]]\n",
            "Step: 3091 -> Loss: 0.005063315853476524 -> Predictions: [[0.00417246]\n",
            " [0.99546534]\n",
            " [0.9954508 ]\n",
            " [0.00694321]]\n",
            "Step: 3092 -> Loss: 0.005063047166913748 -> Predictions: [[0.00417224]\n",
            " [0.9954656 ]\n",
            " [0.99545103]\n",
            " [0.00694283]]\n",
            "Step: 3093 -> Loss: 0.0050627728924155235 -> Predictions: [[0.00417202]\n",
            " [0.99546576]\n",
            " [0.9954513 ]\n",
            " [0.00694244]]\n",
            "Step: 3094 -> Loss: 0.0050625065341591835 -> Predictions: [[0.00417181]\n",
            " [0.995466  ]\n",
            " [0.9954515 ]\n",
            " [0.00694207]]\n",
            "Step: 3095 -> Loss: 0.00506223738193512 -> Predictions: [[0.0041716 ]\n",
            " [0.99546623]\n",
            " [0.99545175]\n",
            " [0.00694168]]\n",
            "Step: 3096 -> Loss: 0.005061966832727194 -> Predictions: [[0.00417139]\n",
            " [0.9954665 ]\n",
            " [0.995452  ]\n",
            " [0.0069413 ]]\n",
            "Step: 3097 -> Loss: 0.005061696283519268 -> Predictions: [[0.00417117]\n",
            " [0.9954667 ]\n",
            " [0.9954522 ]\n",
            " [0.00694093]]\n",
            "Step: 3098 -> Loss: 0.005061428062617779 -> Predictions: [[0.00417096]\n",
            " [0.99546695]\n",
            " [0.99545246]\n",
            " [0.00694056]]\n",
            "Step: 3099 -> Loss: 0.005061156116425991 -> Predictions: [[0.00417075]\n",
            " [0.9954672 ]\n",
            " [0.9954527 ]\n",
            " [0.00694017]]\n",
            "Step: 3100 -> Loss: 0.005060888826847076 -> Predictions: [[0.00417054]\n",
            " [0.9954674 ]\n",
            " [0.9954529 ]\n",
            " [0.00693979]]\n",
            "Step: 3101 -> Loss: 0.005060615483671427 -> Predictions: [[0.00417032]\n",
            " [0.99546766]\n",
            " [0.9954531 ]\n",
            " [0.00693941]]\n",
            "Step: 3102 -> Loss: 0.005060345865786076 -> Predictions: [[0.00417011]\n",
            " [0.9954679 ]\n",
            " [0.99545336]\n",
            " [0.00693904]]\n",
            "Step: 3103 -> Loss: 0.0050600795075297356 -> Predictions: [[0.0041699 ]\n",
            " [0.99546814]\n",
            " [0.9954536 ]\n",
            " [0.00693866]]\n",
            "Step: 3104 -> Loss: 0.00505980895832181 -> Predictions: [[0.00416969]\n",
            " [0.9954684 ]\n",
            " [0.99545383]\n",
            " [0.00693828]]\n",
            "Step: 3105 -> Loss: 0.005059537943452597 -> Predictions: [[0.00416948]\n",
            " [0.9954686 ]\n",
            " [0.9954541 ]\n",
            " [0.0069379 ]]\n",
            "Step: 3106 -> Loss: 0.005059267394244671 -> Predictions: [[0.00416927]\n",
            " [0.99546885]\n",
            " [0.99545443]\n",
            " [0.00693753]]\n",
            "Step: 3107 -> Loss: 0.005058998707681894 -> Predictions: [[0.00416905]\n",
            " [0.9954691 ]\n",
            " [0.99545467]\n",
            " [0.00693715]]\n",
            "Step: 3108 -> Loss: 0.005058730021119118 -> Predictions: [[0.00416884]\n",
            " [0.99546933]\n",
            " [0.9954549 ]\n",
            " [0.00693677]]\n",
            "Step: 3109 -> Loss: 0.00505845807492733 -> Predictions: [[0.00416863]\n",
            " [0.99546957]\n",
            " [0.99545515]\n",
            " [0.00693638]]\n",
            "Step: 3110 -> Loss: 0.0050581893883645535 -> Predictions: [[0.00416841]\n",
            " [0.9954698 ]\n",
            " [0.9954554 ]\n",
            " [0.00693601]]\n",
            "Step: 3111 -> Loss: 0.005057919770479202 -> Predictions: [[0.00416821]\n",
            " [0.99547005]\n",
            " [0.9954556 ]\n",
            " [0.00693564]]\n",
            "Step: 3112 -> Loss: 0.005057652015239 -> Predictions: [[0.00416799]\n",
            " [0.9954703 ]\n",
            " [0.99545586]\n",
            " [0.00693527]]\n",
            "Step: 3113 -> Loss: 0.005057382397353649 -> Predictions: [[0.00416778]\n",
            " [0.9954705 ]\n",
            " [0.9954561 ]\n",
            " [0.00693488]]\n",
            "Step: 3114 -> Loss: 0.005057113245129585 -> Predictions: [[0.00416757]\n",
            " [0.99547076]\n",
            " [0.99545634]\n",
            " [0.00693451]]\n",
            "Step: 3115 -> Loss: 0.0050568426959216595 -> Predictions: [[0.00416736]\n",
            " [0.9954711 ]\n",
            " [0.9954566 ]\n",
            " [0.00693413]]\n",
            "Step: 3116 -> Loss: 0.005056572612375021 -> Predictions: [[0.00416714]\n",
            " [0.99547136]\n",
            " [0.9954568 ]\n",
            " [0.00693375]]\n",
            "Step: 3117 -> Loss: 0.00505630299448967 -> Predictions: [[0.00416694]\n",
            " [0.9954716 ]\n",
            " [0.99545705]\n",
            " [0.00693337]]\n",
            "Step: 3118 -> Loss: 0.005056033842265606 -> Predictions: [[0.00416672]\n",
            " [0.99547184]\n",
            " [0.9954573 ]\n",
            " [0.00693299]]\n",
            "Step: 3119 -> Loss: 0.005055764690041542 -> Predictions: [[0.00416652]\n",
            " [0.9954721 ]\n",
            " [0.99545753]\n",
            " [0.00693261]]\n",
            "Step: 3120 -> Loss: 0.005055495537817478 -> Predictions: [[0.0041663 ]\n",
            " [0.9954723 ]\n",
            " [0.99545777]\n",
            " [0.00693224]]\n",
            "Step: 3121 -> Loss: 0.005055227782577276 -> Predictions: [[0.00416609]\n",
            " [0.9954725 ]\n",
            " [0.995458  ]\n",
            " [0.00693186]]\n",
            "Step: 3122 -> Loss: 0.005054958630353212 -> Predictions: [[0.00416588]\n",
            " [0.9954727 ]\n",
            " [0.99545825]\n",
            " [0.00693149]]\n",
            "Step: 3123 -> Loss: 0.005054687149822712 -> Predictions: [[0.00416566]\n",
            " [0.99547297]\n",
            " [0.9954585 ]\n",
            " [0.00693111]]\n",
            "Step: 3124 -> Loss: 0.005054420325905085 -> Predictions: [[0.00416546]\n",
            " [0.9954732 ]\n",
            " [0.9954587 ]\n",
            " [0.00693073]]\n",
            "Step: 3125 -> Loss: 0.005054149776697159 -> Predictions: [[0.00416524]\n",
            " [0.99547344]\n",
            " [0.99545896]\n",
            " [0.00693035]]\n",
            "Step: 3126 -> Loss: 0.005053877830505371 -> Predictions: [[0.00416503]\n",
            " [0.9954737 ]\n",
            " [0.99545926]\n",
            " [0.00692997]]\n",
            "Step: 3127 -> Loss: 0.005053609609603882 -> Predictions: [[0.00416482]\n",
            " [0.9954739 ]\n",
            " [0.9954595 ]\n",
            " [0.00692959]]\n",
            "Step: 3128 -> Loss: 0.0050533427856862545 -> Predictions: [[0.00416461]\n",
            " [0.99547416]\n",
            " [0.99545974]\n",
            " [0.00692923]]\n",
            "Step: 3129 -> Loss: 0.005053069442510605 -> Predictions: [[0.00416439]\n",
            " [0.9954744 ]\n",
            " [0.99546   ]\n",
            " [0.00692884]]\n",
            "Step: 3130 -> Loss: 0.005052805412560701 -> Predictions: [[0.00416419]\n",
            " [0.99547464]\n",
            " [0.9954602 ]\n",
            " [0.00692848]]\n",
            "Step: 3131 -> Loss: 0.005052536725997925 -> Predictions: [[0.00416397]\n",
            " [0.9954749 ]\n",
            " [0.99546045]\n",
            " [0.0069281 ]]\n",
            "Step: 3132 -> Loss: 0.005052264779806137 -> Predictions: [[0.00416376]\n",
            " [0.9954751 ]\n",
            " [0.9954607 ]\n",
            " [0.00692772]]\n",
            "Step: 3133 -> Loss: 0.005051995627582073 -> Predictions: [[0.00416355]\n",
            " [0.99547535]\n",
            " [0.9954609 ]\n",
            " [0.00692733]]\n",
            "Step: 3134 -> Loss: 0.005051728338003159 -> Predictions: [[0.00416334]\n",
            " [0.9954756 ]\n",
            " [0.99546117]\n",
            " [0.00692696]]\n",
            "Step: 3135 -> Loss: 0.005051456391811371 -> Predictions: [[0.00416313]\n",
            " [0.9954758 ]\n",
            " [0.9954614 ]\n",
            " [0.00692657]]\n",
            "Step: 3136 -> Loss: 0.005051190033555031 -> Predictions: [[0.00416292]\n",
            " [0.99547607]\n",
            " [0.99546164]\n",
            " [0.00692621]]\n",
            "Step: 3137 -> Loss: 0.005050918087363243 -> Predictions: [[0.0041627 ]\n",
            " [0.9954763 ]\n",
            " [0.9954619 ]\n",
            " [0.00692583]]\n",
            "Step: 3138 -> Loss: 0.00505065219476819 -> Predictions: [[0.0041625 ]\n",
            " [0.99547654]\n",
            " [0.9954621 ]\n",
            " [0.00692545]]\n",
            "Step: 3139 -> Loss: 0.005050382576882839 -> Predictions: [[0.00416228]\n",
            " [0.9954768 ]\n",
            " [0.99546236]\n",
            " [0.00692507]]\n",
            "Step: 3140 -> Loss: 0.005050111096352339 -> Predictions: [[0.00416207]\n",
            " [0.995477  ]\n",
            " [0.9954626 ]\n",
            " [0.00692469]]\n",
            "Step: 3141 -> Loss: 0.005049843341112137 -> Predictions: [[0.00416186]\n",
            " [0.99547726]\n",
            " [0.99546283]\n",
            " [0.00692431]]\n",
            "Step: 3142 -> Loss: 0.005049572791904211 -> Predictions: [[0.00416165]\n",
            " [0.9954775 ]\n",
            " [0.9954631 ]\n",
            " [0.00692394]]\n",
            "Step: 3143 -> Loss: 0.0050493041053414345 -> Predictions: [[0.00416144]\n",
            " [0.99547786]\n",
            " [0.9954633 ]\n",
            " [0.00692356]]\n",
            "Step: 3144 -> Loss: 0.005049038678407669 -> Predictions: [[0.00416122]\n",
            " [0.995478  ]\n",
            " [0.99546355]\n",
            " [0.00692319]]\n",
            "Step: 3145 -> Loss: 0.005048769526183605 -> Predictions: [[0.00416102]\n",
            " [0.99547833]\n",
            " [0.9954638 ]\n",
            " [0.00692281]]\n",
            "Step: 3146 -> Loss: 0.005048500373959541 -> Predictions: [[0.00416081]\n",
            " [0.9954786 ]\n",
            " [0.995464  ]\n",
            " [0.00692244]]\n",
            "Step: 3147 -> Loss: 0.005048226565122604 -> Predictions: [[0.00416059]\n",
            " [0.9954788 ]\n",
            " [0.99546427]\n",
            " [0.00692205]]\n",
            "Step: 3148 -> Loss: 0.005047963000833988 -> Predictions: [[0.00416038]\n",
            " [0.995479  ]\n",
            " [0.9954646 ]\n",
            " [0.00692168]]\n",
            "Step: 3149 -> Loss: 0.005047691985964775 -> Predictions: [[0.00416017]\n",
            " [0.9954792 ]\n",
            " [0.99546486]\n",
            " [0.0069213 ]]\n",
            "Step: 3150 -> Loss: 0.005047424230724573 -> Predictions: [[0.00415995]\n",
            " [0.99547946]\n",
            " [0.9954651 ]\n",
            " [0.00692093]]\n",
            "Step: 3151 -> Loss: 0.005047155078500509 -> Predictions: [[0.00415975]\n",
            " [0.9954797 ]\n",
            " [0.99546534]\n",
            " [0.00692054]]\n",
            "Step: 3152 -> Loss: 0.005046887323260307 -> Predictions: [[0.00415954]\n",
            " [0.99547994]\n",
            " [0.9954656 ]\n",
            " [0.00692017]]\n",
            "Step: 3153 -> Loss: 0.00504661351442337 -> Predictions: [[0.00415932]\n",
            " [0.9954802 ]\n",
            " [0.99546576]\n",
            " [0.00691978]]\n",
            "Step: 3154 -> Loss: 0.0050463504157960415 -> Predictions: [[0.00415911]\n",
            " [0.9954804 ]\n",
            " [0.995466  ]\n",
            " [0.00691942]]\n",
            "Step: 3155 -> Loss: 0.005046078935265541 -> Predictions: [[0.0041589 ]\n",
            " [0.99548066]\n",
            " [0.99546623]\n",
            " [0.00691904]]\n",
            "Step: 3156 -> Loss: 0.005045811180025339 -> Predictions: [[0.0041587 ]\n",
            " [0.9954809 ]\n",
            " [0.9954665 ]\n",
            " [0.00691866]]\n",
            "Step: 3157 -> Loss: 0.005045544356107712 -> Predictions: [[0.00415849]\n",
            " [0.99548113]\n",
            " [0.9954667 ]\n",
            " [0.00691829]]\n",
            "Step: 3158 -> Loss: 0.005045277066528797 -> Predictions: [[0.00415828]\n",
            " [0.9954814 ]\n",
            " [0.99546695]\n",
            " [0.00691791]]\n",
            "Step: 3159 -> Loss: 0.005045007914304733 -> Predictions: [[0.00415808]\n",
            " [0.9954816 ]\n",
            " [0.9954672 ]\n",
            " [0.00691753]]\n",
            "Step: 3160 -> Loss: 0.005044740624725819 -> Predictions: [[0.00415786]\n",
            " [0.99548185]\n",
            " [0.9954674 ]\n",
            " [0.00691716]]\n",
            "Step: 3161 -> Loss: 0.005044475197792053 -> Predictions: [[0.00415766]\n",
            " [0.9954821 ]\n",
            " [0.99546766]\n",
            " [0.00691678]]\n",
            "Step: 3162 -> Loss: 0.00504420418292284 -> Predictions: [[0.00415745]\n",
            " [0.9954823 ]\n",
            " [0.9954679 ]\n",
            " [0.0069164 ]]\n",
            "Step: 3163 -> Loss: 0.005043934565037489 -> Predictions: [[0.00415724]\n",
            " [0.99548256]\n",
            " [0.99546814]\n",
            " [0.00691602]]\n",
            "Step: 3164 -> Loss: 0.005043669603765011 -> Predictions: [[0.00415703]\n",
            " [0.9954828 ]\n",
            " [0.9954684 ]\n",
            " [0.00691565]]\n",
            "Step: 3165 -> Loss: 0.005043401382863522 -> Predictions: [[0.00415683]\n",
            " [0.99548304]\n",
            " [0.9954686 ]\n",
            " [0.00691527]]\n",
            "Step: 3166 -> Loss: 0.005043133161962032 -> Predictions: [[0.00415662]\n",
            " [0.9954833 ]\n",
            " [0.99546885]\n",
            " [0.0069149 ]]\n",
            "Step: 3167 -> Loss: 0.0050428640097379684 -> Predictions: [[0.00415641]\n",
            " [0.9954835 ]\n",
            " [0.9954691 ]\n",
            " [0.00691452]]\n",
            "Step: 3168 -> Loss: 0.005042601842433214 -> Predictions: [[0.00415621]\n",
            " [0.99548376]\n",
            " [0.99546933]\n",
            " [0.00691414]]\n",
            "Step: 3169 -> Loss: 0.005042331758886576 -> Predictions: [[0.004156  ]\n",
            " [0.995484  ]\n",
            " [0.99546957]\n",
            " [0.00691377]]\n",
            "Step: 3170 -> Loss: 0.0050420621410012245 -> Predictions: [[0.00415578]\n",
            " [0.99548423]\n",
            " [0.9954699 ]\n",
            " [0.0069134 ]]\n",
            "Step: 3171 -> Loss: 0.005041794385761023 -> Predictions: [[0.00415558]\n",
            " [0.9954845 ]\n",
            " [0.99547017]\n",
            " [0.00691301]]\n",
            "Step: 3172 -> Loss: 0.005041525699198246 -> Predictions: [[0.00415538]\n",
            " [0.9954847 ]\n",
            " [0.9954704 ]\n",
            " [0.00691264]]\n",
            "Step: 3173 -> Loss: 0.005041256546974182 -> Predictions: [[0.00415517]\n",
            " [0.99548495]\n",
            " [0.99547064]\n",
            " [0.00691225]]\n",
            "Step: 3174 -> Loss: 0.005040992982685566 -> Predictions: [[0.00415496]\n",
            " [0.9954852 ]\n",
            " [0.9954709 ]\n",
            " [0.00691188]]\n",
            "Step: 3175 -> Loss: 0.005040723364800215 -> Predictions: [[0.00415475]\n",
            " [0.9954855 ]\n",
            " [0.9954711 ]\n",
            " [0.00691151]]\n",
            "Step: 3176 -> Loss: 0.005040459334850311 -> Predictions: [[0.00415455]\n",
            " [0.9954857 ]\n",
            " [0.99547136]\n",
            " [0.00691114]]\n",
            "Step: 3177 -> Loss: 0.005040188319981098 -> Predictions: [[0.00415434]\n",
            " [0.99548596]\n",
            " [0.9954716 ]\n",
            " [0.00691075]]\n",
            "Step: 3178 -> Loss: 0.0050399210304021835 -> Predictions: [[0.00415413]\n",
            " [0.9954862 ]\n",
            " [0.99547184]\n",
            " [0.00691038]]\n",
            "Step: 3179 -> Loss: 0.00503965187817812 -> Predictions: [[0.00415392]\n",
            " [0.99548644]\n",
            " [0.9954721 ]\n",
            " [0.00691   ]]\n",
            "Step: 3180 -> Loss: 0.005039386451244354 -> Predictions: [[0.00415372]\n",
            " [0.9954867 ]\n",
            " [0.9954723 ]\n",
            " [0.00690963]]\n",
            "Step: 3181 -> Loss: 0.005039118696004152 -> Predictions: [[0.00415351]\n",
            " [0.9954869 ]\n",
            " [0.9954725 ]\n",
            " [0.00690925]]\n",
            "Step: 3182 -> Loss: 0.005038850475102663 -> Predictions: [[0.0041533 ]\n",
            " [0.99548715]\n",
            " [0.9954727 ]\n",
            " [0.00690887]]\n",
            "Step: 3183 -> Loss: 0.005038583185523748 -> Predictions: [[0.0041531 ]\n",
            " [0.9954874 ]\n",
            " [0.99547297]\n",
            " [0.00690849]]\n",
            "Step: 3184 -> Loss: 0.005038312636315823 -> Predictions: [[0.00415288]\n",
            " [0.99548763]\n",
            " [0.9954732 ]\n",
            " [0.00690812]]\n",
            "Step: 3185 -> Loss: 0.005038048140704632 -> Predictions: [[0.00415268]\n",
            " [0.99548787]\n",
            " [0.99547344]\n",
            " [0.00690774]]\n",
            "Step: 3186 -> Loss: 0.005037782713770866 -> Predictions: [[0.00415248]\n",
            " [0.9954881 ]\n",
            " [0.9954737 ]\n",
            " [0.00690737]]\n",
            "Step: 3187 -> Loss: 0.0050375135615468025 -> Predictions: [[0.00415227]\n",
            " [0.99548835]\n",
            " [0.9954739 ]\n",
            " [0.00690699]]\n",
            "Step: 3188 -> Loss: 0.005037245806306601 -> Predictions: [[0.00415206]\n",
            " [0.9954886 ]\n",
            " [0.99547416]\n",
            " [0.00690662]]\n",
            "Step: 3189 -> Loss: 0.005036979913711548 -> Predictions: [[0.00415186]\n",
            " [0.9954888 ]\n",
            " [0.9954744 ]\n",
            " [0.00690624]]\n",
            "Step: 3190 -> Loss: 0.005036710761487484 -> Predictions: [[0.00415164]\n",
            " [0.99548906]\n",
            " [0.99547464]\n",
            " [0.00690586]]\n",
            "Step: 3191 -> Loss: 0.005036442540585995 -> Predictions: [[0.00415144]\n",
            " [0.9954893 ]\n",
            " [0.9954749 ]\n",
            " [0.00690548]]\n",
            "Step: 3192 -> Loss: 0.005036174785345793 -> Predictions: [[0.00415123]\n",
            " [0.99548954]\n",
            " [0.9954751 ]\n",
            " [0.00690511]]\n",
            "Step: 3193 -> Loss: 0.0050359065644443035 -> Predictions: [[0.00415102]\n",
            " [0.9954898 ]\n",
            " [0.99547535]\n",
            " [0.00690473]]\n",
            "Step: 3194 -> Loss: 0.005035643931478262 -> Predictions: [[0.00415082]\n",
            " [0.99549   ]\n",
            " [0.9954756 ]\n",
            " [0.00690436]]\n",
            "Step: 3195 -> Loss: 0.005035374313592911 -> Predictions: [[0.00415061]\n",
            " [0.99549025]\n",
            " [0.99547595]\n",
            " [0.00690398]]\n",
            "Step: 3196 -> Loss: 0.005035107024013996 -> Predictions: [[0.0041504 ]\n",
            " [0.9954905 ]\n",
            " [0.9954762 ]\n",
            " [0.00690361]]\n",
            "Step: 3197 -> Loss: 0.005034840665757656 -> Predictions: [[0.00415019]\n",
            " [0.99549073]\n",
            " [0.9954764 ]\n",
            " [0.00690323]]\n",
            "Step: 3198 -> Loss: 0.0050345733761787415 -> Predictions: [[0.00414998]\n",
            " [0.99549097]\n",
            " [0.99547666]\n",
            " [0.00690285]]\n",
            "Step: 3199 -> Loss: 0.005034307949244976 -> Predictions: [[0.00414977]\n",
            " [0.9954912 ]\n",
            " [0.9954769 ]\n",
            " [0.00690248]]\n",
            "Step: 3200 -> Loss: 0.005034042987972498 -> Predictions: [[0.00414956]\n",
            " [0.99549145]\n",
            " [0.99547714]\n",
            " [0.0069021 ]]\n",
            "Step: 3201 -> Loss: 0.005033777095377445 -> Predictions: [[0.00414934]\n",
            " [0.9954917 ]\n",
            " [0.9954774 ]\n",
            " [0.00690173]]\n",
            "Step: 3202 -> Loss: 0.005033510271459818 -> Predictions: [[0.00414914]\n",
            " [0.9954919 ]\n",
            " [0.9954776 ]\n",
            " [0.00690135]]\n",
            "Step: 3203 -> Loss: 0.0050332434475421906 -> Predictions: [[0.00414892]\n",
            " [0.9954921 ]\n",
            " [0.99547786]\n",
            " [0.00690097]]\n",
            "Step: 3204 -> Loss: 0.005032978951931 -> Predictions: [[0.00414871]\n",
            " [0.99549234]\n",
            " [0.9954781 ]\n",
            " [0.00690061]]\n",
            "Step: 3205 -> Loss: 0.005032708402723074 -> Predictions: [[0.0041485 ]\n",
            " [0.9954926 ]\n",
            " [0.99547833]\n",
            " [0.00690022]]\n",
            "Step: 3206 -> Loss: 0.005032446701079607 -> Predictions: [[0.00414829]\n",
            " [0.9954928 ]\n",
            " [0.9954786 ]\n",
            " [0.00689985]]\n",
            "Step: 3207 -> Loss: 0.005032178480178118 -> Predictions: [[0.00414808]\n",
            " [0.99549305]\n",
            " [0.9954788 ]\n",
            " [0.00689946]]\n",
            "Step: 3208 -> Loss: 0.005031912587583065 -> Predictions: [[0.00414787]\n",
            " [0.9954933 ]\n",
            " [0.995479  ]\n",
            " [0.00689909]]\n",
            "Step: 3209 -> Loss: 0.005031644832342863 -> Predictions: [[0.00414766]\n",
            " [0.99549353]\n",
            " [0.9954792 ]\n",
            " [0.00689871]]\n",
            "Step: 3210 -> Loss: 0.0050313821993768215 -> Predictions: [[0.00414745]\n",
            " [0.99549377]\n",
            " [0.99547946]\n",
            " [0.00689834]]\n",
            "Step: 3211 -> Loss: 0.005031113047152758 -> Predictions: [[0.00414723]\n",
            " [0.995494  ]\n",
            " [0.9954797 ]\n",
            " [0.00689797]]\n",
            "Step: 3212 -> Loss: 0.005030845291912556 -> Predictions: [[0.00414702]\n",
            " [0.99549425]\n",
            " [0.99547994]\n",
            " [0.00689759]]\n",
            "Step: 3213 -> Loss: 0.005030579399317503 -> Predictions: [[0.00414681]\n",
            " [0.9954945 ]\n",
            " [0.9954802 ]\n",
            " [0.00689721]]\n",
            "Step: 3214 -> Loss: 0.0050303139723837376 -> Predictions: [[0.0041466 ]\n",
            " [0.9954947 ]\n",
            " [0.9954804 ]\n",
            " [0.00689683]]\n",
            "Step: 3215 -> Loss: 0.005030050873756409 -> Predictions: [[0.00414639]\n",
            " [0.99549496]\n",
            " [0.99548066]\n",
            " [0.00689646]]\n",
            "Step: 3216 -> Loss: 0.005029786378145218 -> Predictions: [[0.00414618]\n",
            " [0.9954952 ]\n",
            " [0.9954809 ]\n",
            " [0.00689609]]\n",
            "Step: 3217 -> Loss: 0.005029515828937292 -> Predictions: [[0.00414597]\n",
            " [0.99549544]\n",
            " [0.99548113]\n",
            " [0.0068957 ]]\n",
            "Step: 3218 -> Loss: 0.0050292471423745155 -> Predictions: [[0.00414575]\n",
            " [0.9954957 ]\n",
            " [0.9954814 ]\n",
            " [0.00689533]]\n",
            "Step: 3219 -> Loss: 0.005028986372053623 -> Predictions: [[0.00414555]\n",
            " [0.9954959 ]\n",
            " [0.9954816 ]\n",
            " [0.00689495]]\n",
            "Step: 3220 -> Loss: 0.005028720013797283 -> Predictions: [[0.00414534]\n",
            " [0.99549615]\n",
            " [0.99548185]\n",
            " [0.00689458]]\n",
            "Step: 3221 -> Loss: 0.005028451327234507 -> Predictions: [[0.00414513]\n",
            " [0.9954964 ]\n",
            " [0.9954821 ]\n",
            " [0.0068942 ]]\n",
            "Step: 3222 -> Loss: 0.0050281863659620285 -> Predictions: [[0.00414491]\n",
            " [0.99549663]\n",
            " [0.9954823 ]\n",
            " [0.00689383]]\n",
            "Step: 3223 -> Loss: 0.005027919076383114 -> Predictions: [[0.00414471]\n",
            " [0.99549687]\n",
            " [0.99548256]\n",
            " [0.00689345]]\n",
            "Step: 3224 -> Loss: 0.005027655977755785 -> Predictions: [[0.0041445 ]\n",
            " [0.9954971 ]\n",
            " [0.9954828 ]\n",
            " [0.00689308]]\n",
            "Step: 3225 -> Loss: 0.005027390085160732 -> Predictions: [[0.00414428]\n",
            " [0.99549735]\n",
            " [0.99548304]\n",
            " [0.0068927 ]]\n",
            "Step: 3226 -> Loss: 0.005027121864259243 -> Predictions: [[0.00414407]\n",
            " [0.9954976 ]\n",
            " [0.9954833 ]\n",
            " [0.00689232]]\n",
            "Step: 3227 -> Loss: 0.005026857368648052 -> Predictions: [[0.00414386]\n",
            " [0.9954978 ]\n",
            " [0.9954835 ]\n",
            " [0.00689195]]\n",
            "Step: 3228 -> Loss: 0.005026588216423988 -> Predictions: [[0.00414365]\n",
            " [0.99549806]\n",
            " [0.99548376]\n",
            " [0.00689157]]\n",
            "Step: 3229 -> Loss: 0.005026324186474085 -> Predictions: [[0.00414345]\n",
            " [0.9954983 ]\n",
            " [0.995484  ]\n",
            " [0.00689119]]\n",
            "Step: 3230 -> Loss: 0.005026061087846756 -> Predictions: [[0.00414323]\n",
            " [0.99549854]\n",
            " [0.99548423]\n",
            " [0.00689083]]\n",
            "Step: 3231 -> Loss: 0.005025794263929129 -> Predictions: [[0.00414302]\n",
            " [0.9954987 ]\n",
            " [0.9954845 ]\n",
            " [0.00689044]]\n",
            "Step: 3232 -> Loss: 0.005025527440011501 -> Predictions: [[0.00414281]\n",
            " [0.99549896]\n",
            " [0.9954847 ]\n",
            " [0.00689007]]\n",
            "Step: 3233 -> Loss: 0.005025260616093874 -> Predictions: [[0.0041426 ]\n",
            " [0.9954992 ]\n",
            " [0.99548495]\n",
            " [0.00688969]]\n",
            "Step: 3234 -> Loss: 0.005024997051805258 -> Predictions: [[0.00414239]\n",
            " [0.99549943]\n",
            " [0.9954852 ]\n",
            " [0.00688932]]\n",
            "Step: 3235 -> Loss: 0.005024728365242481 -> Predictions: [[0.00414218]\n",
            " [0.9954997 ]\n",
            " [0.99548537]\n",
            " [0.00688894]]\n",
            "Step: 3236 -> Loss: 0.005024462938308716 -> Predictions: [[0.00414197]\n",
            " [0.9954999 ]\n",
            " [0.9954856 ]\n",
            " [0.00688857]]\n",
            "Step: 3237 -> Loss: 0.005024197045713663 -> Predictions: [[0.00414175]\n",
            " [0.99550015]\n",
            " [0.99548584]\n",
            " [0.0068882 ]]\n",
            "Step: 3238 -> Loss: 0.005023930687457323 -> Predictions: [[0.00414154]\n",
            " [0.9955004 ]\n",
            " [0.9954861 ]\n",
            " [0.00688782]]\n",
            "Step: 3239 -> Loss: 0.00502366479486227 -> Predictions: [[0.00414134]\n",
            " [0.9955006 ]\n",
            " [0.9954863 ]\n",
            " [0.00688744]]\n",
            "Step: 3240 -> Loss: 0.005023398902267218 -> Predictions: [[0.00414112]\n",
            " [0.99550086]\n",
            " [0.99548656]\n",
            " [0.00688707]]\n",
            "Step: 3241 -> Loss: 0.005023130215704441 -> Predictions: [[0.00414091]\n",
            " [0.9955011 ]\n",
            " [0.9954868 ]\n",
            " [0.00688668]]\n",
            "Step: 3242 -> Loss: 0.005022869445383549 -> Predictions: [[0.00414071]\n",
            " [0.99550134]\n",
            " [0.99548703]\n",
            " [0.00688632]]\n",
            "Step: 3243 -> Loss: 0.005022603087127209 -> Predictions: [[0.00414049]\n",
            " [0.9955016 ]\n",
            " [0.9954873 ]\n",
            " [0.00688594]]\n",
            "Step: 3244 -> Loss: 0.005022336728870869 -> Predictions: [[0.00414028]\n",
            " [0.9955018 ]\n",
            " [0.9954875 ]\n",
            " [0.00688556]]\n",
            "Step: 3245 -> Loss: 0.005022070370614529 -> Predictions: [[0.00414007]\n",
            " [0.99550205]\n",
            " [0.99548775]\n",
            " [0.00688518]]\n",
            "Step: 3246 -> Loss: 0.0050218072719872 -> Predictions: [[0.00413986]\n",
            " [0.9955023 ]\n",
            " [0.995488  ]\n",
            " [0.00688482]]\n",
            "Step: 3247 -> Loss: 0.0050215390510857105 -> Predictions: [[0.00413965]\n",
            " [0.99550253]\n",
            " [0.9954882 ]\n",
            " [0.00688444]]\n",
            "Step: 3248 -> Loss: 0.005021276418119669 -> Predictions: [[0.00413944]\n",
            " [0.99550277]\n",
            " [0.99548846]\n",
            " [0.00688407]]\n",
            "Step: 3249 -> Loss: 0.005021008662879467 -> Predictions: [[0.00413923]\n",
            " [0.995503  ]\n",
            " [0.9954887 ]\n",
            " [0.00688369]]\n",
            "Step: 3250 -> Loss: 0.0050207446329295635 -> Predictions: [[0.00413902]\n",
            " [0.99550325]\n",
            " [0.99548894]\n",
            " [0.00688332]]\n",
            "Step: 3251 -> Loss: 0.0050204782746732235 -> Predictions: [[0.00413881]\n",
            " [0.9955035 ]\n",
            " [0.9954892 ]\n",
            " [0.00688295]]\n",
            "Step: 3252 -> Loss: 0.005020213313400745 -> Predictions: [[0.0041386 ]\n",
            " [0.9955037 ]\n",
            " [0.9954894 ]\n",
            " [0.00688257]]\n",
            "Step: 3253 -> Loss: 0.00501994788646698 -> Predictions: [[0.00413839]\n",
            " [0.99550396]\n",
            " [0.99548966]\n",
            " [0.0068822 ]]\n",
            "Step: 3254 -> Loss: 0.005019680596888065 -> Predictions: [[0.00413818]\n",
            " [0.9955042 ]\n",
            " [0.9954899 ]\n",
            " [0.00688183]]\n",
            "Step: 3255 -> Loss: 0.005019414238631725 -> Predictions: [[0.00413797]\n",
            " [0.99550444]\n",
            " [0.99549013]\n",
            " [0.00688145]]\n",
            "Step: 3256 -> Loss: 0.0050191511400043964 -> Predictions: [[0.00413776]\n",
            " [0.9955047 ]\n",
            " [0.9954904 ]\n",
            " [0.00688109]]\n",
            "Step: 3257 -> Loss: 0.005018885713070631 -> Predictions: [[0.00413755]\n",
            " [0.9955049 ]\n",
            " [0.9954906 ]\n",
            " [0.00688071]]\n",
            "Step: 3258 -> Loss: 0.005018618423491716 -> Predictions: [[0.00413734]\n",
            " [0.9955051 ]\n",
            " [0.99549085]\n",
            " [0.00688034]]\n",
            "Step: 3259 -> Loss: 0.005018354393541813 -> Predictions: [[0.00413713]\n",
            " [0.99550533]\n",
            " [0.9954911 ]\n",
            " [0.00687996]]\n",
            "Step: 3260 -> Loss: 0.005018085706979036 -> Predictions: [[0.00413691]\n",
            " [0.9955056 ]\n",
            " [0.9954913 ]\n",
            " [0.00687958]]\n",
            "Step: 3261 -> Loss: 0.005017826799303293 -> Predictions: [[0.00413671]\n",
            " [0.9955058 ]\n",
            " [0.99549156]\n",
            " [0.00687922]]\n",
            "Step: 3262 -> Loss: 0.005017558112740517 -> Predictions: [[0.0041365 ]\n",
            " [0.99550605]\n",
            " [0.9954918 ]\n",
            " [0.00687884]]\n",
            "Step: 3263 -> Loss: 0.005017292685806751 -> Predictions: [[0.00413628]\n",
            " [0.9955063 ]\n",
            " [0.995492  ]\n",
            " [0.00687847]]\n",
            "Step: 3264 -> Loss: 0.0050170281901955605 -> Predictions: [[0.00413608]\n",
            " [0.9955065 ]\n",
            " [0.9954922 ]\n",
            " [0.00687809]]\n",
            "Step: 3265 -> Loss: 0.00501676183193922 -> Predictions: [[0.00413586]\n",
            " [0.99550676]\n",
            " [0.99549246]\n",
            " [0.00687773]]\n",
            "Step: 3266 -> Loss: 0.005016497801989317 -> Predictions: [[0.00413566]\n",
            " [0.995507  ]\n",
            " [0.9954927 ]\n",
            " [0.00687735]]\n",
            "Step: 3267 -> Loss: 0.005016233306378126 -> Predictions: [[0.00413545]\n",
            " [0.99550724]\n",
            " [0.99549294]\n",
            " [0.00687698]]\n",
            "Step: 3268 -> Loss: 0.005015966948121786 -> Predictions: [[0.00413523]\n",
            " [0.9955075 ]\n",
            " [0.9954932 ]\n",
            " [0.00687661]]\n",
            "Step: 3269 -> Loss: 0.00501570338383317 -> Predictions: [[0.00413503]\n",
            " [0.9955077 ]\n",
            " [0.9954934 ]\n",
            " [0.00687624]]\n",
            "Step: 3270 -> Loss: 0.005015436559915543 -> Predictions: [[0.00413481]\n",
            " [0.99550796]\n",
            " [0.99549365]\n",
            " [0.00687586]]\n",
            "Step: 3271 -> Loss: 0.005015171132981777 -> Predictions: [[0.0041346]\n",
            " [0.9955082]\n",
            " [0.9954939]\n",
            " [0.0068755]]\n",
            "Step: 3272 -> Loss: 0.005014907103031874 -> Predictions: [[0.00413439]\n",
            " [0.99550843]\n",
            " [0.9954941 ]\n",
            " [0.00687512]]\n",
            "Step: 3273 -> Loss: 0.005014640279114246 -> Predictions: [[0.00413419]\n",
            " [0.9955087 ]\n",
            " [0.99549437]\n",
            " [0.00687475]]\n",
            "Step: 3274 -> Loss: 0.005014378111809492 -> Predictions: [[0.00413399]\n",
            " [0.9955089 ]\n",
            " [0.9954946 ]\n",
            " [0.00687439]]\n",
            "Step: 3275 -> Loss: 0.005014111287891865 -> Predictions: [[0.00413377]\n",
            " [0.99550915]\n",
            " [0.99549484]\n",
            " [0.00687402]]\n",
            "Step: 3276 -> Loss: 0.0050138444639742374 -> Predictions: [[0.00413357]\n",
            " [0.9955094 ]\n",
            " [0.9954951 ]\n",
            " [0.00687364]]\n",
            "Step: 3277 -> Loss: 0.005013582296669483 -> Predictions: [[0.00413336]\n",
            " [0.9955096 ]\n",
            " [0.9954953 ]\n",
            " [0.00687327]]\n",
            "Step: 3278 -> Loss: 0.005013316869735718 -> Predictions: [[0.00413315]\n",
            " [0.99550986]\n",
            " [0.99549556]\n",
            " [0.0068729 ]]\n",
            "Step: 3279 -> Loss: 0.005013052839785814 -> Predictions: [[0.00413294]\n",
            " [0.9955101 ]\n",
            " [0.9954958 ]\n",
            " [0.00687254]]\n",
            "Step: 3280 -> Loss: 0.005012787878513336 -> Predictions: [[0.00413273]\n",
            " [0.99551034]\n",
            " [0.99549603]\n",
            " [0.00687217]]\n",
            "Step: 3281 -> Loss: 0.005012521520256996 -> Predictions: [[0.00413252]\n",
            " [0.9955106 ]\n",
            " [0.9954963 ]\n",
            " [0.0068718 ]]\n",
            "Step: 3282 -> Loss: 0.005012258421629667 -> Predictions: [[0.00413232]\n",
            " [0.9955108 ]\n",
            " [0.9954965 ]\n",
            " [0.00687143]]\n",
            "Step: 3283 -> Loss: 0.00501199159771204 -> Predictions: [[0.00413211]\n",
            " [0.99551105]\n",
            " [0.99549675]\n",
            " [0.00687106]]\n",
            "Step: 3284 -> Loss: 0.005011728964745998 -> Predictions: [[0.0041319 ]\n",
            " [0.9955113 ]\n",
            " [0.995497  ]\n",
            " [0.00687069]]\n",
            "Step: 3285 -> Loss: 0.00501146400347352 -> Predictions: [[0.00413169]\n",
            " [0.99551153]\n",
            " [0.9954972 ]\n",
            " [0.00687032]]\n",
            "Step: 3286 -> Loss: 0.005011203233152628 -> Predictions: [[0.00413149]\n",
            " [0.9955117 ]\n",
            " [0.99549747]\n",
            " [0.00686996]]\n",
            "Step: 3287 -> Loss: 0.005010932683944702 -> Predictions: [[0.00413127]\n",
            " [0.99551195]\n",
            " [0.9954977 ]\n",
            " [0.00686958]]\n",
            "Step: 3288 -> Loss: 0.005010666325688362 -> Predictions: [[0.00413107]\n",
            " [0.9955122 ]\n",
            " [0.99549794]\n",
            " [0.0068692 ]]\n",
            "Step: 3289 -> Loss: 0.005010403227061033 -> Predictions: [[0.00413086]\n",
            " [0.9955124 ]\n",
            " [0.9954982 ]\n",
            " [0.00686884]]\n",
            "Step: 3290 -> Loss: 0.005010140128433704 -> Predictions: [[0.00413065]\n",
            " [0.99551266]\n",
            " [0.9954984 ]\n",
            " [0.00686848]]\n",
            "Step: 3291 -> Loss: 0.005009875632822514 -> Predictions: [[0.00413044]\n",
            " [0.9955129 ]\n",
            " [0.9954986 ]\n",
            " [0.00686811]]\n",
            "Step: 3292 -> Loss: 0.005009608343243599 -> Predictions: [[0.00413023]\n",
            " [0.99551314]\n",
            " [0.99549884]\n",
            " [0.00686774]]\n",
            "Step: 3293 -> Loss: 0.0050093443132936954 -> Predictions: [[0.00413002]\n",
            " [0.9955134 ]\n",
            " [0.9954991 ]\n",
            " [0.00686737]]\n",
            "Step: 3294 -> Loss: 0.005009079817682505 -> Predictions: [[0.00412982]\n",
            " [0.9955136 ]\n",
            " [0.9954993 ]\n",
            " [0.006867  ]]\n",
            "Step: 3295 -> Loss: 0.005008815787732601 -> Predictions: [[0.00412961]\n",
            " [0.99551386]\n",
            " [0.99549955]\n",
            " [0.00686664]]\n",
            "Step: 3296 -> Loss: 0.005008552689105272 -> Predictions: [[0.0041294 ]\n",
            " [0.9955141 ]\n",
            " [0.9954998 ]\n",
            " [0.00686627]]\n",
            "Step: 3297 -> Loss: 0.005008287727832794 -> Predictions: [[0.00412919]\n",
            " [0.99551433]\n",
            " [0.9955    ]\n",
            " [0.00686591]]\n",
            "Step: 3298 -> Loss: 0.005008021369576454 -> Predictions: [[0.00412899]\n",
            " [0.9955146 ]\n",
            " [0.99550027]\n",
            " [0.00686553]]\n",
            "Step: 3299 -> Loss: 0.005007760599255562 -> Predictions: [[0.00412878]\n",
            " [0.9955148 ]\n",
            " [0.9955005 ]\n",
            " [0.00686517]]\n",
            "Step: 3300 -> Loss: 0.005007493309676647 -> Predictions: [[0.00412857]\n",
            " [0.99551505]\n",
            " [0.99550074]\n",
            " [0.0068648 ]]\n",
            "Step: 3301 -> Loss: 0.00500723160803318 -> Predictions: [[0.00412837]\n",
            " [0.9955153 ]\n",
            " [0.995501  ]\n",
            " [0.00686444]]\n",
            "Step: 3302 -> Loss: 0.005006964318454266 -> Predictions: [[0.00412816]\n",
            " [0.9955155 ]\n",
            " [0.9955012 ]\n",
            " [0.00686406]]\n",
            "Step: 3303 -> Loss: 0.005006700754165649 -> Predictions: [[0.00412794]\n",
            " [0.99551576]\n",
            " [0.99550146]\n",
            " [0.00686371]]\n",
            "Step: 3304 -> Loss: 0.005006438586860895 -> Predictions: [[0.00412774]\n",
            " [0.995516  ]\n",
            " [0.9955017 ]\n",
            " [0.00686334]]\n",
            "Step: 3305 -> Loss: 0.00500617315992713 -> Predictions: [[0.00412753]\n",
            " [0.99551624]\n",
            " [0.99550194]\n",
            " [0.00686297]]\n",
            "Step: 3306 -> Loss: 0.005005910526961088 -> Predictions: [[0.00412733]\n",
            " [0.9955165 ]\n",
            " [0.9955022 ]\n",
            " [0.0068626 ]]\n",
            "Step: 3307 -> Loss: 0.0050056446343660355 -> Predictions: [[0.00412712]\n",
            " [0.9955167 ]\n",
            " [0.9955024 ]\n",
            " [0.00686224]]\n",
            "Step: 3308 -> Loss: 0.00500537920743227 -> Predictions: [[0.0041269 ]\n",
            " [0.99551696]\n",
            " [0.99550265]\n",
            " [0.00686187]]\n",
            "Step: 3309 -> Loss: 0.005005117505788803 -> Predictions: [[0.0041267 ]\n",
            " [0.9955172 ]\n",
            " [0.995503  ]\n",
            " [0.00686151]]\n",
            "Step: 3310 -> Loss: 0.0050048502162098885 -> Predictions: [[0.00412649]\n",
            " [0.99551743]\n",
            " [0.99550325]\n",
            " [0.00686113]]\n",
            "Step: 3311 -> Loss: 0.00500458711758256 -> Predictions: [[0.00412628]\n",
            " [0.9955177 ]\n",
            " [0.9955035 ]\n",
            " [0.00686077]]\n",
            "Step: 3312 -> Loss: 0.005004323087632656 -> Predictions: [[0.00412608]\n",
            " [0.9955179 ]\n",
            " [0.9955037 ]\n",
            " [0.0068604 ]]\n",
            "Step: 3313 -> Loss: 0.005004057660698891 -> Predictions: [[0.00412587]\n",
            " [0.99551815]\n",
            " [0.99550396]\n",
            " [0.00686003]]\n",
            "Step: 3314 -> Loss: 0.0050037940964102745 -> Predictions: [[0.00412566]\n",
            " [0.9955183 ]\n",
            " [0.9955042 ]\n",
            " [0.00685967]]\n",
            "Step: 3315 -> Loss: 0.005003529600799084 -> Predictions: [[0.00412545]\n",
            " [0.99551857]\n",
            " [0.99550444]\n",
            " [0.0068593 ]]\n",
            "Step: 3316 -> Loss: 0.005003265105187893 -> Predictions: [[0.00412524]\n",
            " [0.9955188 ]\n",
            " [0.9955047 ]\n",
            " [0.00685894]]\n",
            "Step: 3317 -> Loss: 0.005003002006560564 -> Predictions: [[0.00412504]\n",
            " [0.99551904]\n",
            " [0.9955049 ]\n",
            " [0.00685858]]\n",
            "Step: 3318 -> Loss: 0.0050027393735945225 -> Predictions: [[0.00412483]\n",
            " [0.9955193 ]\n",
            " [0.9955051 ]\n",
            " [0.00685821]]\n",
            "Step: 3319 -> Loss: 0.0050024730153381824 -> Predictions: [[0.00412462]\n",
            " [0.9955195 ]\n",
            " [0.99550533]\n",
            " [0.00685784]]\n",
            "Step: 3320 -> Loss: 0.005002208985388279 -> Predictions: [[0.00412441]\n",
            " [0.99551976]\n",
            " [0.9955056 ]\n",
            " [0.00685747]]\n",
            "Step: 3321 -> Loss: 0.00500194588676095 -> Predictions: [[0.00412421]\n",
            " [0.99552   ]\n",
            " [0.9955058 ]\n",
            " [0.0068571 ]]\n",
            "Step: 3322 -> Loss: 0.005001684185117483 -> Predictions: [[0.004124  ]\n",
            " [0.99552023]\n",
            " [0.99550605]\n",
            " [0.00685674]]\n",
            "Step: 3323 -> Loss: 0.005001415964215994 -> Predictions: [[0.00412379]\n",
            " [0.9955205 ]\n",
            " [0.9955063 ]\n",
            " [0.00685637]]\n",
            "Step: 3324 -> Loss: 0.00500115193426609 -> Predictions: [[0.00412358]\n",
            " [0.9955207 ]\n",
            " [0.9955065 ]\n",
            " [0.006856  ]]\n",
            "Step: 3325 -> Loss: 0.005000886972993612 -> Predictions: [[0.00412337]\n",
            " [0.99552095]\n",
            " [0.99550676]\n",
            " [0.00685564]]\n",
            "Step: 3326 -> Loss: 0.005000624340027571 -> Predictions: [[0.00412317]\n",
            " [0.9955212 ]\n",
            " [0.995507  ]\n",
            " [0.00685527]]\n",
            "Step: 3327 -> Loss: 0.005000361707061529 -> Predictions: [[0.00412296]\n",
            " [0.9955214 ]\n",
            " [0.99550724]\n",
            " [0.00685491]]\n",
            "Step: 3328 -> Loss: 0.0050000958144664764 -> Predictions: [[0.00412275]\n",
            " [0.99552166]\n",
            " [0.9955075 ]\n",
            " [0.00685454]]\n",
            "Step: 3329 -> Loss: 0.00499983225017786 -> Predictions: [[0.00412254]\n",
            " [0.995522  ]\n",
            " [0.9955077 ]\n",
            " [0.00685417]]\n",
            "Step: 3330 -> Loss: 0.004999566823244095 -> Predictions: [[0.00412233]\n",
            " [0.99552226]\n",
            " [0.99550796]\n",
            " [0.0068538 ]]\n",
            "Step: 3331 -> Loss: 0.004999303258955479 -> Predictions: [[0.00412213]\n",
            " [0.9955225 ]\n",
            " [0.9955082 ]\n",
            " [0.00685344]]\n",
            "Step: 3332 -> Loss: 0.004999037366360426 -> Predictions: [[0.00412191]\n",
            " [0.99552274]\n",
            " [0.99550843]\n",
            " [0.00685307]]\n",
            "Step: 3333 -> Loss: 0.004998775199055672 -> Predictions: [[0.00412171]\n",
            " [0.995523  ]\n",
            " [0.9955087 ]\n",
            " [0.00685271]]\n",
            "Step: 3334 -> Loss: 0.004998510703444481 -> Predictions: [[0.0041215 ]\n",
            " [0.9955232 ]\n",
            " [0.9955089 ]\n",
            " [0.00685234]]\n",
            "Step: 3335 -> Loss: 0.004998249001801014 -> Predictions: [[0.0041213 ]\n",
            " [0.99552345]\n",
            " [0.99550915]\n",
            " [0.00685198]]\n",
            "Step: 3336 -> Loss: 0.0049979849718511105 -> Predictions: [[0.00412109]\n",
            " [0.9955237 ]\n",
            " [0.9955094 ]\n",
            " [0.00685161]]\n",
            "Step: 3337 -> Loss: 0.004997720941901207 -> Predictions: [[0.00412088]\n",
            " [0.9955239 ]\n",
            " [0.9955096 ]\n",
            " [0.00685125]]\n",
            "Step: 3338 -> Loss: 0.004997456446290016 -> Predictions: [[0.00412067]\n",
            " [0.99552417]\n",
            " [0.99550986]\n",
            " [0.00685088]]\n",
            "Step: 3339 -> Loss: 0.004997191950678825 -> Predictions: [[0.00412047]\n",
            " [0.9955244 ]\n",
            " [0.9955101 ]\n",
            " [0.00685051]]\n",
            "Step: 3340 -> Loss: 0.004996929317712784 -> Predictions: [[0.00412026]\n",
            " [0.99552464]\n",
            " [0.99551034]\n",
            " [0.00685015]]\n",
            "Step: 3341 -> Loss: 0.004996664822101593 -> Predictions: [[0.00412005]\n",
            " [0.9955249 ]\n",
            " [0.9955106 ]\n",
            " [0.00684978]]\n",
            "Step: 3342 -> Loss: 0.004996400326490402 -> Predictions: [[0.00411984]\n",
            " [0.99552506]\n",
            " [0.9955108 ]\n",
            " [0.00684941]]\n",
            "Step: 3343 -> Loss: 0.004996136762201786 -> Predictions: [[0.00411964]\n",
            " [0.9955253 ]\n",
            " [0.99551105]\n",
            " [0.00684905]]\n",
            "Step: 3344 -> Loss: 0.0049958727322518826 -> Predictions: [[0.00411942]\n",
            " [0.99552554]\n",
            " [0.9955113 ]\n",
            " [0.00684868]]\n",
            "Step: 3345 -> Loss: 0.004995610099285841 -> Predictions: [[0.00411922]\n",
            " [0.9955258 ]\n",
            " [0.99551153]\n",
            " [0.00684832]]\n",
            "Step: 3346 -> Loss: 0.00499534560367465 -> Predictions: [[0.00411901]\n",
            " [0.995526  ]\n",
            " [0.9955117 ]\n",
            " [0.00684795]]\n",
            "Step: 3347 -> Loss: 0.004995081573724747 -> Predictions: [[0.0041188 ]\n",
            " [0.99552625]\n",
            " [0.99551195]\n",
            " [0.00684758]]\n",
            "Step: 3348 -> Loss: 0.004994818940758705 -> Predictions: [[0.0041186 ]\n",
            " [0.9955265 ]\n",
            " [0.9955122 ]\n",
            " [0.00684722]]\n",
            "Step: 3349 -> Loss: 0.004994556307792664 -> Predictions: [[0.0041184 ]\n",
            " [0.99552673]\n",
            " [0.9955124 ]\n",
            " [0.00684685]]\n",
            "Step: 3350 -> Loss: 0.004994287621229887 -> Predictions: [[0.00411818]\n",
            " [0.99552697]\n",
            " [0.9955128 ]\n",
            " [0.00684648]]\n",
            "Step: 3351 -> Loss: 0.004994028247892857 -> Predictions: [[0.00411798]\n",
            " [0.9955272 ]\n",
            " [0.995513  ]\n",
            " [0.00684612]]\n",
            "Step: 3352 -> Loss: 0.004993762355297804 -> Predictions: [[0.00411777]\n",
            " [0.99552745]\n",
            " [0.99551326]\n",
            " [0.00684576]]\n",
            "Step: 3353 -> Loss: 0.004993499722331762 -> Predictions: [[0.00411756]\n",
            " [0.9955277 ]\n",
            " [0.9955135 ]\n",
            " [0.00684539]]\n",
            "Step: 3354 -> Loss: 0.004993237089365721 -> Predictions: [[0.00411736]\n",
            " [0.9955279 ]\n",
            " [0.99551374]\n",
            " [0.00684503]]\n",
            "Step: 3355 -> Loss: 0.00499297259375453 -> Predictions: [[0.00411715]\n",
            " [0.99552816]\n",
            " [0.995514  ]\n",
            " [0.00684466]]\n",
            "Step: 3356 -> Loss: 0.004992709495127201 -> Predictions: [[0.00411694]\n",
            " [0.9955284 ]\n",
            " [0.9955142 ]\n",
            " [0.00684429]]\n",
            "Step: 3357 -> Loss: 0.004992445930838585 -> Predictions: [[0.00411673]\n",
            " [0.99552864]\n",
            " [0.99551445]\n",
            " [0.00684393]]\n",
            "Step: 3358 -> Loss: 0.004992186091840267 -> Predictions: [[0.00411654]\n",
            " [0.9955289 ]\n",
            " [0.9955147 ]\n",
            " [0.00684356]]\n",
            "Step: 3359 -> Loss: 0.004991918336600065 -> Predictions: [[0.00411632]\n",
            " [0.9955291 ]\n",
            " [0.9955149 ]\n",
            " [0.00684319]]\n",
            "Step: 3360 -> Loss: 0.0049916538409888744 -> Predictions: [[0.00411612]\n",
            " [0.99552935]\n",
            " [0.99551517]\n",
            " [0.00684283]]\n",
            "Step: 3361 -> Loss: 0.004991396330296993 -> Predictions: [[0.00411592]\n",
            " [0.9955296 ]\n",
            " [0.9955154 ]\n",
            " [0.00684247]]\n",
            "Step: 3362 -> Loss: 0.004991132766008377 -> Predictions: [[0.00411572]\n",
            " [0.99552983]\n",
            " [0.99551564]\n",
            " [0.0068421 ]]\n",
            "Step: 3363 -> Loss: 0.004990866407752037 -> Predictions: [[0.00411551]\n",
            " [0.99553007]\n",
            " [0.9955159 ]\n",
            " [0.00684173]]\n",
            "Step: 3364 -> Loss: 0.004990607500076294 -> Predictions: [[0.00411531]\n",
            " [0.9955303 ]\n",
            " [0.9955161 ]\n",
            " [0.00684137]]\n",
            "Step: 3365 -> Loss: 0.00499034533277154 -> Predictions: [[0.0041151 ]\n",
            " [0.99553055]\n",
            " [0.99551636]\n",
            " [0.006841  ]]\n",
            "Step: 3366 -> Loss: 0.004990081302821636 -> Predictions: [[0.0041149 ]\n",
            " [0.9955308 ]\n",
            " [0.9955166 ]\n",
            " [0.00684063]]\n",
            "Step: 3367 -> Loss: 0.004989820998162031 -> Predictions: [[0.0041147 ]\n",
            " [0.995531  ]\n",
            " [0.99551684]\n",
            " [0.00684027]]\n",
            "Step: 3368 -> Loss: 0.00498955650255084 -> Predictions: [[0.00411449]\n",
            " [0.99553126]\n",
            " [0.9955171 ]\n",
            " [0.0068399 ]]\n",
            "Step: 3369 -> Loss: 0.004989294800907373 -> Predictions: [[0.00411429]\n",
            " [0.9955315 ]\n",
            " [0.9955173 ]\n",
            " [0.00683954]]\n",
            "Step: 3370 -> Loss: 0.004989034030586481 -> Predictions: [[0.00411409]\n",
            " [0.9955317 ]\n",
            " [0.99551755]\n",
            " [0.00683918]]\n",
            "Step: 3371 -> Loss: 0.004988770000636578 -> Predictions: [[0.00411389]\n",
            " [0.9955319 ]\n",
            " [0.9955178 ]\n",
            " [0.00683881]]\n",
            "Step: 3372 -> Loss: 0.004988507367670536 -> Predictions: [[0.00411368]\n",
            " [0.99553216]\n",
            " [0.995518  ]\n",
            " [0.00683844]]\n",
            "Step: 3373 -> Loss: 0.00498824380338192 -> Predictions: [[0.00411348]\n",
            " [0.9955324 ]\n",
            " [0.99551827]\n",
            " [0.00683807]]\n",
            "Step: 3374 -> Loss: 0.004987981170415878 -> Predictions: [[0.00411327]\n",
            " [0.99553263]\n",
            " [0.99551845]\n",
            " [0.00683771]]\n",
            "Step: 3375 -> Loss: 0.004987719003111124 -> Predictions: [[0.00411307]\n",
            " [0.9955329 ]\n",
            " [0.9955187 ]\n",
            " [0.00683735]]\n",
            "Step: 3376 -> Loss: 0.004987455904483795 -> Predictions: [[0.00411287]\n",
            " [0.9955331 ]\n",
            " [0.9955189 ]\n",
            " [0.00683698]]\n",
            "Step: 3377 -> Loss: 0.004987193737179041 -> Predictions: [[0.00411266]\n",
            " [0.99553335]\n",
            " [0.99551916]\n",
            " [0.00683662]]\n",
            "Step: 3378 -> Loss: 0.004986931569874287 -> Predictions: [[0.00411246]\n",
            " [0.9955336 ]\n",
            " [0.9955194 ]\n",
            " [0.00683626]]\n",
            "Step: 3379 -> Loss: 0.0049866680055856705 -> Predictions: [[0.00411226]\n",
            " [0.9955338 ]\n",
            " [0.99551964]\n",
            " [0.00683588]]\n",
            "Step: 3380 -> Loss: 0.004986403975635767 -> Predictions: [[0.00411205]\n",
            " [0.99553406]\n",
            " [0.9955199 ]\n",
            " [0.00683552]]\n",
            "Step: 3381 -> Loss: 0.004986145067960024 -> Predictions: [[0.00411185]\n",
            " [0.9955343 ]\n",
            " [0.9955201 ]\n",
            " [0.00683516]]\n",
            "Step: 3382 -> Loss: 0.004985883831977844 -> Predictions: [[0.00411165]\n",
            " [0.99553454]\n",
            " [0.99552035]\n",
            " [0.00683479]]\n",
            "Step: 3383 -> Loss: 0.004985620267689228 -> Predictions: [[0.00411144]\n",
            " [0.9955348 ]\n",
            " [0.9955206 ]\n",
            " [0.00683443]]\n",
            "Step: 3384 -> Loss: 0.004985353909432888 -> Predictions: [[0.00411124]\n",
            " [0.995535  ]\n",
            " [0.99552083]\n",
            " [0.00683406]]\n",
            "Step: 3385 -> Loss: 0.0049850973300635815 -> Predictions: [[0.00411104]\n",
            " [0.99553525]\n",
            " [0.99552107]\n",
            " [0.0068337 ]]\n",
            "Step: 3386 -> Loss: 0.004984832834452391 -> Predictions: [[0.00411083]\n",
            " [0.9955355 ]\n",
            " [0.9955213 ]\n",
            " [0.00683333]]\n",
            "Step: 3387 -> Loss: 0.004984570667147636 -> Predictions: [[0.00411062]\n",
            " [0.99553573]\n",
            " [0.99552155]\n",
            " [0.00683296]]\n",
            "Step: 3388 -> Loss: 0.004984309431165457 -> Predictions: [[0.00411042]\n",
            " [0.99553597]\n",
            " [0.9955218 ]\n",
            " [0.0068326 ]]\n",
            "Step: 3389 -> Loss: 0.0049840472638607025 -> Predictions: [[0.00411021]\n",
            " [0.9955362 ]\n",
            " [0.995522  ]\n",
            " [0.00683223]]\n",
            "Step: 3390 -> Loss: 0.0049837869592010975 -> Predictions: [[0.00411001]\n",
            " [0.99553645]\n",
            " [0.99552226]\n",
            " [0.00683187]]\n",
            "Step: 3391 -> Loss: 0.004983525723218918 -> Predictions: [[0.00410979]\n",
            " [0.9955367 ]\n",
            " [0.9955225 ]\n",
            " [0.0068315 ]]\n",
            "Step: 3392 -> Loss: 0.0049832649528980255 -> Predictions: [[0.0041096 ]\n",
            " [0.9955369 ]\n",
            " [0.99552274]\n",
            " [0.00683113]]\n",
            "Step: 3393 -> Loss: 0.004983002319931984 -> Predictions: [[0.00410938]\n",
            " [0.99553716]\n",
            " [0.995523  ]\n",
            " [0.00683077]]\n",
            "Step: 3394 -> Loss: 0.004982743877917528 -> Predictions: [[0.00410918]\n",
            " [0.9955374 ]\n",
            " [0.9955232 ]\n",
            " [0.0068304 ]]\n",
            "Step: 3395 -> Loss: 0.004982483573257923 -> Predictions: [[0.00410897]\n",
            " [0.99553764]\n",
            " [0.99552345]\n",
            " [0.00683004]]\n",
            "Step: 3396 -> Loss: 0.0049822209402918816 -> Predictions: [[0.00410876]\n",
            " [0.9955379 ]\n",
            " [0.9955237 ]\n",
            " [0.00682966]]\n",
            "Step: 3397 -> Loss: 0.004981961101293564 -> Predictions: [[0.00410856]\n",
            " [0.9955381 ]\n",
            " [0.9955239 ]\n",
            " [0.0068293 ]]\n",
            "Step: 3398 -> Loss: 0.004981697537004948 -> Predictions: [[0.00410835]\n",
            " [0.9955383 ]\n",
            " [0.99552417]\n",
            " [0.00682892]]\n",
            "Step: 3399 -> Loss: 0.004981438163667917 -> Predictions: [[0.00410814]\n",
            " [0.9955384 ]\n",
            " [0.9955244 ]\n",
            " [0.00682855]]\n",
            "Step: 3400 -> Loss: 0.004981178790330887 -> Predictions: [[0.00410794]\n",
            " [0.99553865]\n",
            " [0.99552464]\n",
            " [0.00682819]]\n",
            "Step: 3401 -> Loss: 0.00498091708868742 -> Predictions: [[0.00410773]\n",
            " [0.9955389 ]\n",
            " [0.9955249 ]\n",
            " [0.00682781]]\n",
            "Step: 3402 -> Loss: 0.004980654921382666 -> Predictions: [[0.00410752]\n",
            " [0.9955391 ]\n",
            " [0.99552506]\n",
            " [0.00682745]]\n",
            "Step: 3403 -> Loss: 0.00498039647936821 -> Predictions: [[0.00410732]\n",
            " [0.99553937]\n",
            " [0.9955253 ]\n",
            " [0.00682708]]\n",
            "Step: 3404 -> Loss: 0.004980134312063456 -> Predictions: [[0.00410711]\n",
            " [0.9955396 ]\n",
            " [0.99552554]\n",
            " [0.00682671]]\n",
            "Step: 3405 -> Loss: 0.004979873076081276 -> Predictions: [[0.0041069 ]\n",
            " [0.99553984]\n",
            " [0.9955258 ]\n",
            " [0.00682634]]\n",
            "Step: 3406 -> Loss: 0.004979614168405533 -> Predictions: [[0.0041067 ]\n",
            " [0.9955401 ]\n",
            " [0.995526  ]\n",
            " [0.00682597]]\n",
            "Step: 3407 -> Loss: 0.004979354329407215 -> Predictions: [[0.00410649]\n",
            " [0.9955403 ]\n",
            " [0.99552625]\n",
            " [0.0068256 ]]\n",
            "Step: 3408 -> Loss: 0.004979092162102461 -> Predictions: [[0.00410629]\n",
            " [0.99554056]\n",
            " [0.9955264 ]\n",
            " [0.00682523]]\n",
            "Step: 3409 -> Loss: 0.004978829063475132 -> Predictions: [[0.00410607]\n",
            " [0.9955408 ]\n",
            " [0.9955266 ]\n",
            " [0.00682486]]\n",
            "Step: 3410 -> Loss: 0.00497856829315424 -> Predictions: [[0.00410587]\n",
            " [0.99554104]\n",
            " [0.99552685]\n",
            " [0.00682449]]\n",
            "Step: 3411 -> Loss: 0.004978309851139784 -> Predictions: [[0.00410566]\n",
            " [0.9955413 ]\n",
            " [0.9955271 ]\n",
            " [0.00682412]]\n",
            "Step: 3412 -> Loss: 0.004978051874786615 -> Predictions: [[0.00410546]\n",
            " [0.9955415 ]\n",
            " [0.9955273 ]\n",
            " [0.00682376]]\n",
            "Step: 3413 -> Loss: 0.00497779157012701 -> Predictions: [[0.00410525]\n",
            " [0.99554175]\n",
            " [0.99552757]\n",
            " [0.00682338]]\n",
            "Step: 3414 -> Loss: 0.004977529868483543 -> Predictions: [[0.00410504]\n",
            " [0.995542  ]\n",
            " [0.9955278 ]\n",
            " [0.00682302]]\n",
            "Step: 3415 -> Loss: 0.0049772681668400764 -> Predictions: [[0.00410483]\n",
            " [0.9955422 ]\n",
            " [0.99552804]\n",
            " [0.00682264]]\n",
            "Step: 3416 -> Loss: 0.004977012053132057 -> Predictions: [[0.00410463]\n",
            " [0.99554235]\n",
            " [0.9955283 ]\n",
            " [0.00682228]]\n",
            "Step: 3417 -> Loss: 0.004976746626198292 -> Predictions: [[0.00410443]\n",
            " [0.9955426 ]\n",
            " [0.9955285 ]\n",
            " [0.0068219 ]]\n",
            "Step: 3418 -> Loss: 0.004976487718522549 -> Predictions: [[0.00410421]\n",
            " [0.9955428 ]\n",
            " [0.99552876]\n",
            " [0.00682154]]\n",
            "Step: 3419 -> Loss: 0.004976226482540369 -> Predictions: [[0.00410401]\n",
            " [0.99554306]\n",
            " [0.995529  ]\n",
            " [0.00682117]]\n",
            "Step: 3420 -> Loss: 0.004975966643542051 -> Predictions: [[0.00410381]\n",
            " [0.9955433 ]\n",
            " [0.99552923]\n",
            " [0.0068208 ]]\n",
            "Step: 3421 -> Loss: 0.004975705873221159 -> Predictions: [[0.0041036 ]\n",
            " [0.99554354]\n",
            " [0.9955295 ]\n",
            " [0.00682043]]\n",
            "Step: 3422 -> Loss: 0.0049754478968679905 -> Predictions: [[0.00410339]\n",
            " [0.9955438 ]\n",
            " [0.9955297 ]\n",
            " [0.00682006]]\n",
            "Step: 3423 -> Loss: 0.004975185263901949 -> Predictions: [[0.00410319]\n",
            " [0.995544  ]\n",
            " [0.99552995]\n",
            " [0.00681969]]\n",
            "Step: 3424 -> Loss: 0.0049749258905649185 -> Predictions: [[0.00410298]\n",
            " [0.99554425]\n",
            " [0.9955302 ]\n",
            " [0.00681933]]\n",
            "Step: 3425 -> Loss: 0.004974667448550463 -> Predictions: [[0.00410277]\n",
            " [0.9955445 ]\n",
            " [0.9955304 ]\n",
            " [0.00681895]]\n",
            "Step: 3426 -> Loss: 0.004974406212568283 -> Predictions: [[0.00410257]\n",
            " [0.99554473]\n",
            " [0.99553066]\n",
            " [0.00681858]]\n",
            "Step: 3427 -> Loss: 0.004974145442247391 -> Predictions: [[0.00410236]\n",
            " [0.9955449 ]\n",
            " [0.9955309 ]\n",
            " [0.00681822]]\n",
            "Step: 3428 -> Loss: 0.004973884671926498 -> Predictions: [[0.00410216]\n",
            " [0.99554515]\n",
            " [0.99553114]\n",
            " [0.00681785]]\n",
            "Step: 3429 -> Loss: 0.004973626229912043 -> Predictions: [[0.00410195]\n",
            " [0.9955454 ]\n",
            " [0.99553126]\n",
            " [0.00681748]]\n",
            "Step: 3430 -> Loss: 0.004973363131284714 -> Predictions: [[0.00410174]\n",
            " [0.9955456 ]\n",
            " [0.9955315 ]\n",
            " [0.00681711]]\n",
            "Step: 3431 -> Loss: 0.004973103757947683 -> Predictions: [[0.00410154]\n",
            " [0.99554586]\n",
            " [0.9955317 ]\n",
            " [0.00681674]]\n",
            "Step: 3432 -> Loss: 0.004972842056304216 -> Predictions: [[0.00410133]\n",
            " [0.9955461 ]\n",
            " [0.9955319 ]\n",
            " [0.00681636]]\n",
            "Step: 3433 -> Loss: 0.00497258547693491 -> Predictions: [[0.00410113]\n",
            " [0.99554634]\n",
            " [0.99553216]\n",
            " [0.00681601]]\n",
            "Step: 3434 -> Loss: 0.004972327034920454 -> Predictions: [[0.00410092]\n",
            " [0.99554646]\n",
            " [0.9955324 ]\n",
            " [0.00681564]]\n",
            "Step: 3435 -> Loss: 0.0049720630049705505 -> Predictions: [[0.00410071]\n",
            " [0.9955467 ]\n",
            " [0.99553263]\n",
            " [0.00681527]]\n",
            "Step: 3436 -> Loss: 0.004971803165972233 -> Predictions: [[0.0041005 ]\n",
            " [0.99554694]\n",
            " [0.9955329 ]\n",
            " [0.0068149 ]]\n",
            "Step: 3437 -> Loss: 0.004971545189619064 -> Predictions: [[0.00410031]\n",
            " [0.9955472 ]\n",
            " [0.9955331 ]\n",
            " [0.00681453]]\n",
            "Step: 3438 -> Loss: 0.004971283487975597 -> Predictions: [[0.00410009]\n",
            " [0.9955474 ]\n",
            " [0.99553335]\n",
            " [0.00681416]]\n",
            "Step: 3439 -> Loss: 0.004971023183315992 -> Predictions: [[0.00409988]\n",
            " [0.99554765]\n",
            " [0.9955336 ]\n",
            " [0.0068138 ]]\n",
            "Step: 3440 -> Loss: 0.0049707647413015366 -> Predictions: [[0.00409968]\n",
            " [0.9955479 ]\n",
            " [0.9955338 ]\n",
            " [0.00681343]]\n",
            "Step: 3441 -> Loss: 0.004970500711351633 -> Predictions: [[0.00409947]\n",
            " [0.9955481 ]\n",
            " [0.99553406]\n",
            " [0.00681305]]\n",
            "Step: 3442 -> Loss: 0.004970242269337177 -> Predictions: [[0.00409926]\n",
            " [0.99554837]\n",
            " [0.9955343 ]\n",
            " [0.00681268]]\n",
            "Step: 3443 -> Loss: 0.004969984758645296 -> Predictions: [[0.00409907]\n",
            " [0.9955486 ]\n",
            " [0.99553454]\n",
            " [0.00681232]]\n",
            "Step: 3444 -> Loss: 0.004969724919646978 -> Predictions: [[0.00409886]\n",
            " [0.99554884]\n",
            " [0.9955348 ]\n",
            " [0.00681195]]\n",
            "Step: 3445 -> Loss: 0.004969463218003511 -> Predictions: [[0.00409865]\n",
            " [0.9955491 ]\n",
            " [0.995535  ]\n",
            " [0.00681158]]\n",
            "Step: 3446 -> Loss: 0.004969204310327768 -> Predictions: [[0.00409844]\n",
            " [0.9955493 ]\n",
            " [0.99553525]\n",
            " [0.00681121]]\n",
            "Step: 3447 -> Loss: 0.004968943540006876 -> Predictions: [[0.00409824]\n",
            " [0.99554956]\n",
            " [0.9955355 ]\n",
            " [0.00681084]]\n",
            "Step: 3448 -> Loss: 0.004968682304024696 -> Predictions: [[0.00409804]\n",
            " [0.9955498 ]\n",
            " [0.99553573]\n",
            " [0.00681047]]\n",
            "Step: 3449 -> Loss: 0.004968421533703804 -> Predictions: [[0.00409782]\n",
            " [0.99555004]\n",
            " [0.99553585]\n",
            " [0.0068101 ]]\n",
            "Step: 3450 -> Loss: 0.004968163091689348 -> Predictions: [[0.00409762]\n",
            " [0.9955503 ]\n",
            " [0.9955361 ]\n",
            " [0.00680973]]\n",
            "Step: 3451 -> Loss: 0.004967903718352318 -> Predictions: [[0.00409741]\n",
            " [0.9955505 ]\n",
            " [0.9955363 ]\n",
            " [0.00680937]]\n",
            "Step: 3452 -> Loss: 0.004967643879354 -> Predictions: [[0.00409721]\n",
            " [0.99555063]\n",
            " [0.99553657]\n",
            " [0.006809  ]]\n",
            "Step: 3453 -> Loss: 0.004967381712049246 -> Predictions: [[0.004097  ]\n",
            " [0.9955509 ]\n",
            " [0.9955368 ]\n",
            " [0.00680863]]\n",
            "Step: 3454 -> Loss: 0.004967121407389641 -> Predictions: [[0.00409679]\n",
            " [0.9955511 ]\n",
            " [0.99553704]\n",
            " [0.00680826]]\n",
            "Step: 3455 -> Loss: 0.004966864362359047 -> Predictions: [[0.00409659]\n",
            " [0.99555135]\n",
            " [0.9955373 ]\n",
            " [0.00680789]]\n",
            "Step: 3456 -> Loss: 0.004966604057699442 -> Predictions: [[0.00409639]\n",
            " [0.9955515 ]\n",
            " [0.9955375 ]\n",
            " [0.00680753]]\n",
            "Step: 3457 -> Loss: 0.004966343753039837 -> Predictions: [[0.00409618]\n",
            " [0.99555176]\n",
            " [0.99553776]\n",
            " [0.00680716]]\n",
            "Step: 3458 -> Loss: 0.004966085311025381 -> Predictions: [[0.00409598]\n",
            " [0.995552  ]\n",
            " [0.995538  ]\n",
            " [0.0068068 ]]\n",
            "Step: 3459 -> Loss: 0.004965823609381914 -> Predictions: [[0.00409577]\n",
            " [0.99555224]\n",
            " [0.9955382 ]\n",
            " [0.00680643]]\n",
            "Step: 3460 -> Loss: 0.004965564701706171 -> Predictions: [[0.00409557]\n",
            " [0.9955525 ]\n",
            " [0.9955384 ]\n",
            " [0.00680607]]\n",
            "Step: 3461 -> Loss: 0.004965305328369141 -> Predictions: [[0.00409536]\n",
            " [0.9955527 ]\n",
            " [0.99553865]\n",
            " [0.0068057 ]]\n",
            "Step: 3462 -> Loss: 0.004965045489370823 -> Predictions: [[0.00409516]\n",
            " [0.99555296]\n",
            " [0.9955389 ]\n",
            " [0.00680534]]\n",
            "Step: 3463 -> Loss: 0.004964787047356367 -> Predictions: [[0.00409496]\n",
            " [0.9955532 ]\n",
            " [0.9955391 ]\n",
            " [0.00680497]]\n",
            "Step: 3464 -> Loss: 0.004964528139680624 -> Predictions: [[0.00409475]\n",
            " [0.99555343]\n",
            " [0.99553937]\n",
            " [0.00680461]]\n",
            "Step: 3465 -> Loss: 0.0049642701633274555 -> Predictions: [[0.00409455]\n",
            " [0.9955537 ]\n",
            " [0.9955396 ]\n",
            " [0.00680425]]\n",
            "Step: 3466 -> Loss: 0.0049640038050711155 -> Predictions: [[0.00409434]\n",
            " [0.9955539 ]\n",
            " [0.99553984]\n",
            " [0.00680387]]\n",
            "Step: 3467 -> Loss: 0.0049637481570243835 -> Predictions: [[0.00409414]\n",
            " [0.99555415]\n",
            " [0.9955401 ]\n",
            " [0.00680351]]\n",
            "Step: 3468 -> Loss: 0.004963490180671215 -> Predictions: [[0.00409394]\n",
            " [0.9955544 ]\n",
            " [0.9955403 ]\n",
            " [0.00680315]]\n",
            "Step: 3469 -> Loss: 0.004963228944689035 -> Predictions: [[0.00409373]\n",
            " [0.9955546 ]\n",
            " [0.99554056]\n",
            " [0.00680279]]\n",
            "Step: 3470 -> Loss: 0.004962970968335867 -> Predictions: [[0.00409353]\n",
            " [0.99555486]\n",
            " [0.9955408 ]\n",
            " [0.00680242]]\n",
            "Step: 3471 -> Loss: 0.0049627092666924 -> Predictions: [[0.00409332]\n",
            " [0.9955551 ]\n",
            " [0.99554104]\n",
            " [0.00680205]]\n",
            "Step: 3472 -> Loss: 0.00496244989335537 -> Predictions: [[0.00409312]\n",
            " [0.99555534]\n",
            " [0.9955413 ]\n",
            " [0.00680169]]\n",
            "Step: 3473 -> Loss: 0.004962191917002201 -> Predictions: [[0.00409291]\n",
            " [0.9955556 ]\n",
            " [0.9955415 ]\n",
            " [0.00680132]]\n",
            "Step: 3474 -> Loss: 0.004961933009326458 -> Predictions: [[0.00409271]\n",
            " [0.9955557 ]\n",
            " [0.99554175]\n",
            " [0.00680096]]\n",
            "Step: 3475 -> Loss: 0.0049616750329732895 -> Predictions: [[0.00409251]\n",
            " [0.99555594]\n",
            " [0.995542  ]\n",
            " [0.0068006 ]]\n",
            "Step: 3476 -> Loss: 0.004961410537362099 -> Predictions: [[0.0040923 ]\n",
            " [0.9955562 ]\n",
            " [0.9955422 ]\n",
            " [0.00680023]]\n",
            "Step: 3477 -> Loss: 0.004961155820637941 -> Predictions: [[0.0040921 ]\n",
            " [0.9955564 ]\n",
            " [0.99554235]\n",
            " [0.00679987]]\n",
            "Step: 3478 -> Loss: 0.004960894584655762 -> Predictions: [[0.0040919 ]\n",
            " [0.99555665]\n",
            " [0.9955426 ]\n",
            " [0.0067995 ]]\n",
            "Step: 3479 -> Loss: 0.004960635211318731 -> Predictions: [[0.0040917 ]\n",
            " [0.9955569 ]\n",
            " [0.9955428 ]\n",
            " [0.00679913]]\n",
            "Step: 3480 -> Loss: 0.004960375372320414 -> Predictions: [[0.00409149]\n",
            " [0.9955571 ]\n",
            " [0.99554306]\n",
            " [0.00679877]]\n",
            "Step: 3481 -> Loss: 0.004960119724273682 -> Predictions: [[0.00409129]\n",
            " [0.99555737]\n",
            " [0.9955433 ]\n",
            " [0.00679841]]\n",
            "Step: 3482 -> Loss: 0.004959858953952789 -> Predictions: [[0.00409108]\n",
            " [0.9955576 ]\n",
            " [0.99554354]\n",
            " [0.00679805]]\n",
            "Step: 3483 -> Loss: 0.004959597252309322 -> Predictions: [[0.00409088]\n",
            " [0.99555784]\n",
            " [0.9955438 ]\n",
            " [0.00679767]]\n",
            "Step: 3484 -> Loss: 0.004959337413311005 -> Predictions: [[0.00409067]\n",
            " [0.9955581 ]\n",
            " [0.995544  ]\n",
            " [0.00679731]]\n",
            "Step: 3485 -> Loss: 0.004959082696586847 -> Predictions: [[0.00409048]\n",
            " [0.99555826]\n",
            " [0.99554425]\n",
            " [0.00679695]]\n",
            "Step: 3486 -> Loss: 0.004958819132298231 -> Predictions: [[0.00409027]\n",
            " [0.9955585 ]\n",
            " [0.9955445 ]\n",
            " [0.00679658]]\n",
            "Step: 3487 -> Loss: 0.004958560690283775 -> Predictions: [[0.00409007]\n",
            " [0.99555874]\n",
            " [0.99554473]\n",
            " [0.00679622]]\n",
            "Step: 3488 -> Loss: 0.0049583036452531815 -> Predictions: [[0.00408987]\n",
            " [0.995559  ]\n",
            " [0.9955449 ]\n",
            " [0.00679585]]\n",
            "Step: 3489 -> Loss: 0.004958042874932289 -> Predictions: [[0.00408966]\n",
            " [0.9955592 ]\n",
            " [0.99554515]\n",
            " [0.00679549]]\n",
            "Step: 3490 -> Loss: 0.004957782570272684 -> Predictions: [[0.00408945]\n",
            " [0.99555945]\n",
            " [0.9955454 ]\n",
            " [0.00679512]]\n",
            "Step: 3491 -> Loss: 0.004957525059580803 -> Predictions: [[0.00408925]\n",
            " [0.9955597 ]\n",
            " [0.9955456 ]\n",
            " [0.00679476]]\n",
            "Step: 3492 -> Loss: 0.004957267548888922 -> Predictions: [[0.00408905]\n",
            " [0.99555993]\n",
            " [0.99554586]\n",
            " [0.0067944 ]]\n",
            "Step: 3493 -> Loss: 0.0049570053815841675 -> Predictions: [[0.00408884]\n",
            " [0.99556017]\n",
            " [0.9955461 ]\n",
            " [0.00679403]]\n",
            "Step: 3494 -> Loss: 0.00495675066486001 -> Predictions: [[0.00408864]\n",
            " [0.9955604 ]\n",
            " [0.99554634]\n",
            " [0.00679367]]\n",
            "Step: 3495 -> Loss: 0.004956487100571394 -> Predictions: [[0.00408843]\n",
            " [0.99556065]\n",
            " [0.9955466 ]\n",
            " [0.0067933 ]]\n",
            "Step: 3496 -> Loss: 0.004956230986863375 -> Predictions: [[0.00408823]\n",
            " [0.99556077]\n",
            " [0.9955468 ]\n",
            " [0.00679294]]\n",
            "Step: 3497 -> Loss: 0.004955967888236046 -> Predictions: [[0.00408802]\n",
            " [0.995561  ]\n",
            " [0.99554706]\n",
            " [0.00679258]]\n",
            "Step: 3498 -> Loss: 0.004955712705850601 -> Predictions: [[0.00408782]\n",
            " [0.99556124]\n",
            " [0.9955473 ]\n",
            " [0.00679221]]\n",
            "Step: 3499 -> Loss: 0.0049554528668522835 -> Predictions: [[0.00408762]\n",
            " [0.9955615 ]\n",
            " [0.99554753]\n",
            " [0.00679185]]\n",
            "Step: 3501 -> Loss: 0.004954933188855648 -> Predictions: [[0.00408721]\n",
            " [0.99556196]\n",
            " [0.995548  ]\n",
            " [0.00679111]]\n",
            "Step: 3502 -> Loss: 0.0049546752125024796 -> Predictions: [[0.00408701]\n",
            " [0.9955622 ]\n",
            " [0.99554825]\n",
            " [0.00679075]]\n",
            "Step: 3503 -> Loss: 0.004954415839165449 -> Predictions: [[0.0040868 ]\n",
            " [0.99556243]\n",
            " [0.9955485 ]\n",
            " [0.00679039]]\n",
            "Step: 3504 -> Loss: 0.004954156465828419 -> Predictions: [[0.0040866 ]\n",
            " [0.9955627 ]\n",
            " [0.9955486 ]\n",
            " [0.00679002]]\n",
            "Step: 3505 -> Loss: 0.004953897558152676 -> Predictions: [[0.00408639]\n",
            " [0.9955629 ]\n",
            " [0.99554884]\n",
            " [0.00678966]]\n",
            "Step: 3506 -> Loss: 0.004953641444444656 -> Predictions: [[0.00408619]\n",
            " [0.99556315]\n",
            " [0.9955491 ]\n",
            " [0.0067893 ]]\n",
            "Step: 3507 -> Loss: 0.004953379742801189 -> Predictions: [[0.00408599]\n",
            " [0.9955634 ]\n",
            " [0.9955493 ]\n",
            " [0.00678893]]\n",
            "Step: 3508 -> Loss: 0.004953119438141584 -> Predictions: [[0.00408578]\n",
            " [0.9955636 ]\n",
            " [0.99554956]\n",
            " [0.00678857]]\n",
            "Step: 3509 -> Loss: 0.0049528637900948524 -> Predictions: [[0.00408559]\n",
            " [0.99556386]\n",
            " [0.9955498 ]\n",
            " [0.00678821]]\n",
            "Step: 3510 -> Loss: 0.004952603951096535 -> Predictions: [[0.00408537]\n",
            " [0.9955641 ]\n",
            " [0.99555004]\n",
            " [0.00678785]]\n",
            "Step: 3511 -> Loss: 0.004952344577759504 -> Predictions: [[0.00408518]\n",
            " [0.99556434]\n",
            " [0.9955503 ]\n",
            " [0.00678748]]\n",
            "Step: 3512 -> Loss: 0.004952084273099899 -> Predictions: [[0.00408497]\n",
            " [0.9955646 ]\n",
            " [0.9955505 ]\n",
            " [0.00678712]]\n",
            "Step: 3513 -> Loss: 0.004951829556375742 -> Predictions: [[0.00408477]\n",
            " [0.99556476]\n",
            " [0.99555075]\n",
            " [0.00678677]]\n",
            "Step: 3514 -> Loss: 0.004951571114361286 -> Predictions: [[0.00408456]\n",
            " [0.995565  ]\n",
            " [0.995551  ]\n",
            " [0.00678641]]\n",
            "Step: 3515 -> Loss: 0.0049513098783791065 -> Predictions: [[0.00408437]\n",
            " [0.99556524]\n",
            " [0.9955512 ]\n",
            " [0.00678604]]\n",
            "Step: 3516 -> Loss: 0.004951051436364651 -> Predictions: [[0.00408416]\n",
            " [0.9955655 ]\n",
            " [0.9955514 ]\n",
            " [0.00678568]]\n",
            "Step: 3517 -> Loss: 0.004950791597366333 -> Predictions: [[0.00408395]\n",
            " [0.9955657 ]\n",
            " [0.99555165]\n",
            " [0.00678531]]\n",
            "Step: 3518 -> Loss: 0.004950532224029303 -> Predictions: [[0.00408375]\n",
            " [0.99556595]\n",
            " [0.9955519 ]\n",
            " [0.00678494]]\n",
            "Step: 3519 -> Loss: 0.004950276575982571 -> Predictions: [[0.00408354]\n",
            " [0.9955662 ]\n",
            " [0.9955521 ]\n",
            " [0.00678459]]\n",
            "Step: 3520 -> Loss: 0.004950016271322966 -> Predictions: [[0.00408334]\n",
            " [0.9955664 ]\n",
            " [0.99555236]\n",
            " [0.00678423]]\n",
            "Step: 3521 -> Loss: 0.004949758294969797 -> Predictions: [[0.00408314]\n",
            " [0.99556667]\n",
            " [0.9955526 ]\n",
            " [0.00678387]]\n",
            "Step: 3522 -> Loss: 0.004949501715600491 -> Predictions: [[0.00408294]\n",
            " [0.9955669 ]\n",
            " [0.99555284]\n",
            " [0.00678351]]\n",
            "Step: 3523 -> Loss: 0.004949239082634449 -> Predictions: [[0.00408272]\n",
            " [0.995567  ]\n",
            " [0.9955531 ]\n",
            " [0.00678315]]\n",
            "Step: 3524 -> Loss: 0.004948982037603855 -> Predictions: [[0.00408253]\n",
            " [0.99556726]\n",
            " [0.9955533 ]\n",
            " [0.00678278]]\n",
            "Step: 3525 -> Loss: 0.004948724061250687 -> Predictions: [[0.00408233]\n",
            " [0.9955675 ]\n",
            " [0.99555355]\n",
            " [0.00678242]]\n",
            "Step: 3526 -> Loss: 0.004948464222252369 -> Predictions: [[0.00408212]\n",
            " [0.99556774]\n",
            " [0.9955538 ]\n",
            " [0.00678206]]\n",
            "Step: 3527 -> Loss: 0.0049482062458992004 -> Predictions: [[0.00408192]\n",
            " [0.995568  ]\n",
            " [0.99555403]\n",
            " [0.00678169]]\n",
            "Step: 3528 -> Loss: 0.004947945941239595 -> Predictions: [[0.00408172]\n",
            " [0.9955682 ]\n",
            " [0.99555427]\n",
            " [0.00678133]]\n",
            "Step: 3529 -> Loss: 0.004947692155838013 -> Predictions: [[0.00408151]\n",
            " [0.99556845]\n",
            " [0.9955545 ]\n",
            " [0.00678098]]\n",
            "Step: 3530 -> Loss: 0.00494743138551712 -> Predictions: [[0.00408131]\n",
            " [0.9955687 ]\n",
            " [0.9955546 ]\n",
            " [0.00678061]]\n",
            "Step: 3531 -> Loss: 0.00494717201218009 -> Predictions: [[0.0040811 ]\n",
            " [0.99556893]\n",
            " [0.99555486]\n",
            " [0.00678025]]\n",
            "Step: 3532 -> Loss: 0.00494691077619791 -> Predictions: [[0.0040809 ]\n",
            " [0.99556917]\n",
            " [0.9955551 ]\n",
            " [0.00677988]]\n",
            "Step: 3533 -> Loss: 0.004946654662489891 -> Predictions: [[0.0040807 ]\n",
            " [0.9955694 ]\n",
            " [0.99555534]\n",
            " [0.00677953]]\n",
            "Step: 3534 -> Loss: 0.0049463966861367226 -> Predictions: [[0.0040805 ]\n",
            " [0.99556965]\n",
            " [0.9955556 ]\n",
            " [0.00677917]]\n",
            "Step: 3535 -> Loss: 0.004946139641106129 -> Predictions: [[0.00408029]\n",
            " [0.9955699 ]\n",
            " [0.9955558 ]\n",
            " [0.0067788 ]]\n",
            "Step: 3536 -> Loss: 0.004945881199091673 -> Predictions: [[0.00408009]\n",
            " [0.9955701 ]\n",
            " [0.99555606]\n",
            " [0.00677845]]\n",
            "Step: 3537 -> Loss: 0.004945620894432068 -> Predictions: [[0.00407989]\n",
            " [0.99557036]\n",
            " [0.9955563 ]\n",
            " [0.00677808]]\n",
            "Step: 3538 -> Loss: 0.004945364780724049 -> Predictions: [[0.00407968]\n",
            " [0.9955706 ]\n",
            " [0.99555653]\n",
            " [0.00677772]]\n",
            "Step: 3539 -> Loss: 0.004945105407387018 -> Predictions: [[0.00407948]\n",
            " [0.99557084]\n",
            " [0.9955568 ]\n",
            " [0.00677736]]\n",
            "Step: 3540 -> Loss: 0.004944846965372562 -> Predictions: [[0.00407928]\n",
            " [0.9955711 ]\n",
            " [0.995557  ]\n",
            " [0.006777  ]]\n",
            "Step: 3541 -> Loss: 0.004944588989019394 -> Predictions: [[0.00407907]\n",
            " [0.9955713 ]\n",
            " [0.99555725]\n",
            " [0.00677663]]\n",
            "Step: 3542 -> Loss: 0.004944329150021076 -> Predictions: [[0.00407887]\n",
            " [0.9955715 ]\n",
            " [0.9955575 ]\n",
            " [0.00677628]]\n",
            "Step: 3543 -> Loss: 0.004944072104990482 -> Predictions: [[0.00407866]\n",
            " [0.99557173]\n",
            " [0.9955577 ]\n",
            " [0.00677592]]\n",
            "Step: 3544 -> Loss: 0.004943812265992165 -> Predictions: [[0.00407846]\n",
            " [0.995572  ]\n",
            " [0.99555796]\n",
            " [0.00677555]]\n",
            "Step: 3545 -> Loss: 0.004943555220961571 -> Predictions: [[0.00407826]\n",
            " [0.9955722 ]\n",
            " [0.99555814]\n",
            " [0.00677519]]\n",
            "Step: 3546 -> Loss: 0.004943298175930977 -> Predictions: [[0.00407805]\n",
            " [0.99557245]\n",
            " [0.9955584 ]\n",
            " [0.00677483]]\n",
            "Step: 3547 -> Loss: 0.0049430388025939465 -> Predictions: [[0.00407786]\n",
            " [0.9955727 ]\n",
            " [0.9955586 ]\n",
            " [0.00677447]]\n",
            "Step: 3548 -> Loss: 0.004942778963595629 -> Predictions: [[0.00407765]\n",
            " [0.9955729 ]\n",
            " [0.99555886]\n",
            " [0.00677411]]\n",
            "Step: 3549 -> Loss: 0.0049425214529037476 -> Predictions: [[0.00407745]\n",
            " [0.99557316]\n",
            " [0.9955591 ]\n",
            " [0.00677374]]\n",
            "Step: 3550 -> Loss: 0.004942265339195728 -> Predictions: [[0.00407725]\n",
            " [0.9955734 ]\n",
            " [0.99555933]\n",
            " [0.00677338]]\n",
            "Step: 3551 -> Loss: 0.004942004103213549 -> Predictions: [[0.00407704]\n",
            " [0.9955735 ]\n",
            " [0.9955596 ]\n",
            " [0.00677302]]\n",
            "Step: 3552 -> Loss: 0.0049417465925216675 -> Predictions: [[0.00407684]\n",
            " [0.99557376]\n",
            " [0.9955598 ]\n",
            " [0.00677266]]\n",
            "Step: 3553 -> Loss: 0.004941490013152361 -> Predictions: [[0.00407664]\n",
            " [0.995574  ]\n",
            " [0.99556005]\n",
            " [0.00677231]]\n",
            "Step: 3554 -> Loss: 0.004941227845847607 -> Predictions: [[0.00407643]\n",
            " [0.99557424]\n",
            " [0.9955603 ]\n",
            " [0.00677193]]\n",
            "Step: 3555 -> Loss: 0.004940974526107311 -> Predictions: [[0.00407623]\n",
            " [0.9955745 ]\n",
            " [0.9955604 ]\n",
            " [0.00677159]]\n",
            "Step: 3556 -> Loss: 0.004940716549754143 -> Predictions: [[0.00407602]\n",
            " [0.9955747 ]\n",
            " [0.99556065]\n",
            " [0.00677123]]\n",
            "Step: 3557 -> Loss: 0.004940458107739687 -> Predictions: [[0.00407582]\n",
            " [0.99557495]\n",
            " [0.9955609 ]\n",
            " [0.00677087]]\n",
            "Step: 3558 -> Loss: 0.004940200597047806 -> Predictions: [[0.00407562]\n",
            " [0.9955752 ]\n",
            " [0.9955611 ]\n",
            " [0.00677051]]\n",
            "Step: 3559 -> Loss: 0.004939943552017212 -> Predictions: [[0.00407542]\n",
            " [0.9955754 ]\n",
            " [0.99556136]\n",
            " [0.00677015]]\n",
            "Step: 3560 -> Loss: 0.004939683713018894 -> Predictions: [[0.00407521]\n",
            " [0.99557567]\n",
            " [0.9955616 ]\n",
            " [0.00676978]]\n",
            "Step: 3561 -> Loss: 0.004939424805343151 -> Predictions: [[0.00407501]\n",
            " [0.9955759 ]\n",
            " [0.99556184]\n",
            " [0.00676943]]\n",
            "Step: 3562 -> Loss: 0.0049391696229577065 -> Predictions: [[0.00407481]\n",
            " [0.99557614]\n",
            " [0.9955621 ]\n",
            " [0.00676907]]\n",
            "Step: 3563 -> Loss: 0.004938909318298101 -> Predictions: [[0.0040746 ]\n",
            " [0.9955764 ]\n",
            " [0.9955623 ]\n",
            " [0.00676872]]\n",
            "Step: 3564 -> Loss: 0.004938651341944933 -> Predictions: [[0.0040744 ]\n",
            " [0.9955766 ]\n",
            " [0.99556255]\n",
            " [0.00676835]]\n",
            "Step: 3565 -> Loss: 0.004938395693898201 -> Predictions: [[0.0040742 ]\n",
            " [0.99557686]\n",
            " [0.9955628 ]\n",
            " [0.006768  ]]\n",
            "Step: 3566 -> Loss: 0.004938138648867607 -> Predictions: [[0.00407401]\n",
            " [0.9955771 ]\n",
            " [0.99556303]\n",
            " [0.00676763]]\n",
            "Step: 3567 -> Loss: 0.004937878809869289 -> Predictions: [[0.00407381]\n",
            " [0.99557734]\n",
            " [0.99556327]\n",
            " [0.00676727]]\n",
            "Step: 3568 -> Loss: 0.004937623627483845 -> Predictions: [[0.00407361]\n",
            " [0.9955776 ]\n",
            " [0.9955635 ]\n",
            " [0.00676691]]\n",
            "Step: 3569 -> Loss: 0.0049373675137758255 -> Predictions: [[0.00407341]\n",
            " [0.9955778 ]\n",
            " [0.99556375]\n",
            " [0.00676656]]\n",
            "Step: 3570 -> Loss: 0.004937111400067806 -> Predictions: [[0.00407321]\n",
            " [0.99557805]\n",
            " [0.995564  ]\n",
            " [0.0067662 ]]\n",
            "Step: 3571 -> Loss: 0.0049368548206985 -> Predictions: [[0.00407301]\n",
            " [0.9955782 ]\n",
            " [0.9955642 ]\n",
            " [0.00676585]]\n",
            "Step: 3572 -> Loss: 0.004936598241329193 -> Predictions: [[0.00407281]\n",
            " [0.99557847]\n",
            " [0.99556446]\n",
            " [0.00676548]]\n",
            "Step: 3573 -> Loss: 0.004936341196298599 -> Predictions: [[0.00407261]\n",
            " [0.9955787 ]\n",
            " [0.9955647 ]\n",
            " [0.00676513]]\n",
            "Step: 3574 -> Loss: 0.00493608508259058 -> Predictions: [[0.00407241]\n",
            " [0.99557894]\n",
            " [0.9955649 ]\n",
            " [0.00676477]]\n",
            "Step: 3575 -> Loss: 0.004935826174914837 -> Predictions: [[0.00407222]\n",
            " [0.9955792 ]\n",
            " [0.9955651 ]\n",
            " [0.00676441]]\n",
            "Step: 3576 -> Loss: 0.004935570061206818 -> Predictions: [[0.00407201]\n",
            " [0.9955793 ]\n",
            " [0.99556535]\n",
            " [0.00676405]]\n",
            "Step: 3577 -> Loss: 0.004935314413160086 -> Predictions: [[0.00407181]\n",
            " [0.99557954]\n",
            " [0.9955656 ]\n",
            " [0.00676369]]\n",
            "Step: 3578 -> Loss: 0.004935058765113354 -> Predictions: [[0.00407162]\n",
            " [0.9955798 ]\n",
            " [0.99556583]\n",
            " [0.00676333]]\n",
            "Step: 3579 -> Loss: 0.004934799391776323 -> Predictions: [[0.00407142]\n",
            " [0.99558   ]\n",
            " [0.99556607]\n",
            " [0.00676297]]\n",
            "Step: 3580 -> Loss: 0.004934546537697315 -> Predictions: [[0.00407122]\n",
            " [0.99558026]\n",
            " [0.9955663 ]\n",
            " [0.00676262]]\n",
            "Step: 3581 -> Loss: 0.004934285301715136 -> Predictions: [[0.00407102]\n",
            " [0.9955805 ]\n",
            " [0.99556655]\n",
            " [0.00676226]]\n",
            "Step: 3582 -> Loss: 0.004934029653668404 -> Predictions: [[0.00407082]\n",
            " [0.99558073]\n",
            " [0.9955668 ]\n",
            " [0.00676189]]\n",
            "Step: 3583 -> Loss: 0.004933774471282959 -> Predictions: [[0.00407062]\n",
            " [0.995581  ]\n",
            " [0.995567  ]\n",
            " [0.00676154]]\n",
            "Step: 3584 -> Loss: 0.0049335164949297905 -> Predictions: [[0.00407041]\n",
            " [0.9955812 ]\n",
            " [0.99556726]\n",
            " [0.00676117]]\n",
            "Step: 3585 -> Loss: 0.004933263175189495 -> Predictions: [[0.00407021]\n",
            " [0.99558145]\n",
            " [0.9955674 ]\n",
            " [0.00676082]]\n",
            "Step: 3586 -> Loss: 0.004933007061481476 -> Predictions: [[0.00407001]\n",
            " [0.9955817 ]\n",
            " [0.9955676 ]\n",
            " [0.00676046]]\n",
            "Step: 3587 -> Loss: 0.0049327523447573185 -> Predictions: [[0.00406981]\n",
            " [0.9955819 ]\n",
            " [0.99556786]\n",
            " [0.0067601 ]]\n",
            "Step: 3588 -> Loss: 0.004932495765388012 -> Predictions: [[0.0040696 ]\n",
            " [0.99558216]\n",
            " [0.9955681 ]\n",
            " [0.00675974]]\n",
            "Step: 3589 -> Loss: 0.004932241514325142 -> Predictions: [[0.0040694 ]\n",
            " [0.9955824 ]\n",
            " [0.99556834]\n",
            " [0.00675939]]\n",
            "Step: 3590 -> Loss: 0.004931986797600985 -> Predictions: [[0.0040692 ]\n",
            " [0.99558264]\n",
            " [0.9955686 ]\n",
            " [0.00675903]]\n",
            "Step: 3591 -> Loss: 0.0049317264929413795 -> Predictions: [[0.00406899]\n",
            " [0.9955829 ]\n",
            " [0.9955688 ]\n",
            " [0.00675866]]\n",
            "Step: 3592 -> Loss: 0.004931473173201084 -> Predictions: [[0.00406879]\n",
            " [0.995583  ]\n",
            " [0.99556905]\n",
            " [0.0067583 ]]\n",
            "Step: 3593 -> Loss: 0.0049312179908156395 -> Predictions: [[0.00406859]\n",
            " [0.99558324]\n",
            " [0.9955693 ]\n",
            " [0.00675795]]\n",
            "Step: 3594 -> Loss: 0.004930958151817322 -> Predictions: [[0.00406838]\n",
            " [0.9955835 ]\n",
            " [0.9955695 ]\n",
            " [0.00675758]]\n",
            "Step: 3595 -> Loss: 0.004930709023028612 -> Predictions: [[0.00406818]\n",
            " [0.9955837 ]\n",
            " [0.99556977]\n",
            " [0.00675724]]\n",
            "Step: 3596 -> Loss: 0.004930452443659306 -> Predictions: [[0.00406798]\n",
            " [0.99558395]\n",
            " [0.99557   ]\n",
            " [0.00675687]]\n",
            "Step: 3597 -> Loss: 0.004930196795612574 -> Predictions: [[0.00406778]\n",
            " [0.9955842 ]\n",
            " [0.99557024]\n",
            " [0.00675652]]\n",
            "Step: 3598 -> Loss: 0.0049299378879368305 -> Predictions: [[0.00406757]\n",
            " [0.9955844 ]\n",
            " [0.9955705 ]\n",
            " [0.00675615]]\n",
            "Step: 3599 -> Loss: 0.004929685033857822 -> Predictions: [[0.00406737]\n",
            " [0.99558467]\n",
            " [0.9955707 ]\n",
            " [0.0067558 ]]\n",
            "Step: 3600 -> Loss: 0.0049294279888272285 -> Predictions: [[0.00406716]\n",
            " [0.99558485]\n",
            " [0.99557084]\n",
            " [0.00675543]]\n",
            "Step: 3601 -> Loss: 0.00492917001247406 -> Predictions: [[0.00406696]\n",
            " [0.9955851 ]\n",
            " [0.9955711 ]\n",
            " [0.00675508]]\n",
            "Step: 3602 -> Loss: 0.004928918089717627 -> Predictions: [[0.00406676]\n",
            " [0.9955853 ]\n",
            " [0.9955713 ]\n",
            " [0.00675471]]\n",
            "Step: 3603 -> Loss: 0.004928662441670895 -> Predictions: [[0.00406656]\n",
            " [0.99558556]\n",
            " [0.9955715 ]\n",
            " [0.00675437]]\n",
            "Step: 3604 -> Loss: 0.004928406327962875 -> Predictions: [[0.00406635]\n",
            " [0.9955857 ]\n",
            " [0.99557173]\n",
            " [0.006754  ]]\n",
            "Step: 3605 -> Loss: 0.004928150214254856 -> Predictions: [[0.00406615]\n",
            " [0.9955859 ]\n",
            " [0.995572  ]\n",
            " [0.00675364]]\n",
            "Step: 3606 -> Loss: 0.004927895497530699 -> Predictions: [[0.00406595]\n",
            " [0.99558616]\n",
            " [0.9955722 ]\n",
            " [0.00675328]]\n",
            "Step: 3607 -> Loss: 0.004927641712129116 -> Predictions: [[0.00406575]\n",
            " [0.9955864 ]\n",
            " [0.99557245]\n",
            " [0.00675293]]\n",
            "Step: 3608 -> Loss: 0.004927385598421097 -> Predictions: [[0.00406554]\n",
            " [0.99558663]\n",
            " [0.9955727 ]\n",
            " [0.00675257]]\n",
            "Step: 3609 -> Loss: 0.004927131347358227 -> Predictions: [[0.00406535]\n",
            " [0.9955869 ]\n",
            " [0.9955729 ]\n",
            " [0.00675221]]\n",
            "Step: 3610 -> Loss: 0.004926876164972782 -> Predictions: [[0.00406514]\n",
            " [0.9955871 ]\n",
            " [0.99557316]\n",
            " [0.00675185]]\n",
            "Step: 3611 -> Loss: 0.004926621448248625 -> Predictions: [[0.00406494]\n",
            " [0.99558735]\n",
            " [0.9955734 ]\n",
            " [0.0067515 ]]\n",
            "Step: 3612 -> Loss: 0.004926364868879318 -> Predictions: [[0.00406473]\n",
            " [0.9955876 ]\n",
            " [0.99557364]\n",
            " [0.00675114]]\n",
            "Step: 3613 -> Loss: 0.004926108755171299 -> Predictions: [[0.00406453]\n",
            " [0.9955878 ]\n",
            " [0.9955739 ]\n",
            " [0.00675078]]\n",
            "Step: 3614 -> Loss: 0.0049258507788181305 -> Predictions: [[0.00406432]\n",
            " [0.99558806]\n",
            " [0.9955741 ]\n",
            " [0.00675042]]\n",
            "Step: 3615 -> Loss: 0.004925599321722984 -> Predictions: [[0.00406413]\n",
            " [0.9955883 ]\n",
            " [0.99557424]\n",
            " [0.00675006]]\n",
            "Step: 3616 -> Loss: 0.0049253422766923904 -> Predictions: [[0.00406392]\n",
            " [0.99558854]\n",
            " [0.9955745 ]\n",
            " [0.00674971]]\n",
            "Step: 3617 -> Loss: 0.004925085697323084 -> Predictions: [[0.00406372]\n",
            " [0.99558866]\n",
            " [0.9955747 ]\n",
            " [0.00674934]]\n",
            "Step: 3618 -> Loss: 0.004924831911921501 -> Predictions: [[0.00406351]\n",
            " [0.9955889 ]\n",
            " [0.99557495]\n",
            " [0.00674899]]\n",
            "Step: 3619 -> Loss: 0.0049245781265199184 -> Predictions: [[0.00406332]\n",
            " [0.99558914]\n",
            " [0.9955752 ]\n",
            " [0.00674864]]\n",
            "Step: 3620 -> Loss: 0.00492432015016675 -> Predictions: [[0.00406312]\n",
            " [0.9955894 ]\n",
            " [0.9955754 ]\n",
            " [0.00674826]]\n",
            "Step: 3621 -> Loss: 0.004924066364765167 -> Predictions: [[0.00406291]\n",
            " [0.9955896 ]\n",
            " [0.99557567]\n",
            " [0.00674791]]\n",
            "Step: 3622 -> Loss: 0.004923811182379723 -> Predictions: [[0.00406271]\n",
            " [0.99558985]\n",
            " [0.9955759 ]\n",
            " [0.00674755]]\n",
            "Step: 3623 -> Loss: 0.004923556931316853 -> Predictions: [[0.0040625 ]\n",
            " [0.9955901 ]\n",
            " [0.99557614]\n",
            " [0.0067472 ]]\n",
            "Step: 3624 -> Loss: 0.004923300351947546 -> Predictions: [[0.00406231]\n",
            " [0.9955903 ]\n",
            " [0.9955764 ]\n",
            " [0.00674683]]\n",
            "Step: 3625 -> Loss: 0.004923046100884676 -> Predictions: [[0.0040621 ]\n",
            " [0.99559057]\n",
            " [0.9955766 ]\n",
            " [0.00674648]]\n",
            "Step: 3626 -> Loss: 0.004922789987176657 -> Predictions: [[0.0040619 ]\n",
            " [0.9955908 ]\n",
            " [0.99557686]\n",
            " [0.00674612]]\n",
            "Step: 3627 -> Loss: 0.004922535270452499 -> Predictions: [[0.00406169]\n",
            " [0.99559104]\n",
            " [0.9955771 ]\n",
            " [0.00674577]]\n",
            "Step: 3628 -> Loss: 0.0049222796224057674 -> Predictions: [[0.0040615 ]\n",
            " [0.9955913 ]\n",
            " [0.99557734]\n",
            " [0.0067454 ]]\n",
            "Step: 3629 -> Loss: 0.004922025371342897 -> Predictions: [[0.00406129]\n",
            " [0.9955914 ]\n",
            " [0.99557745]\n",
            " [0.00674505]]\n",
            "Step: 3630 -> Loss: 0.004921767860651016 -> Predictions: [[0.00406109]\n",
            " [0.9955916 ]\n",
            " [0.9955777 ]\n",
            " [0.00674468]]\n",
            "Step: 3631 -> Loss: 0.004921514540910721 -> Predictions: [[0.00406088]\n",
            " [0.9955918 ]\n",
            " [0.99557793]\n",
            " [0.00674433]]\n",
            "Step: 3632 -> Loss: 0.004921261221170425 -> Predictions: [[0.00406069]\n",
            " [0.99559206]\n",
            " [0.9955781 ]\n",
            " [0.00674397]]\n",
            "Step: 3633 -> Loss: 0.004921005107462406 -> Predictions: [[0.00406048]\n",
            " [0.9955923 ]\n",
            " [0.99557835]\n",
            " [0.00674362]]\n",
            "Step: 3634 -> Loss: 0.0049207485280931 -> Predictions: [[0.00406028]\n",
            " [0.99559253]\n",
            " [0.9955786 ]\n",
            " [0.00674326]]\n",
            "Step: 3635 -> Loss: 0.0049204956740140915 -> Predictions: [[0.00406007]\n",
            " [0.9955928 ]\n",
            " [0.9955788 ]\n",
            " [0.0067429 ]]\n",
            "Step: 3636 -> Loss: 0.004920238628983498 -> Predictions: [[0.00405988]\n",
            " [0.995593  ]\n",
            " [0.99557906]\n",
            " [0.00674254]]\n",
            "Step: 3637 -> Loss: 0.004919986240565777 -> Predictions: [[0.00405967]\n",
            " [0.99559325]\n",
            " [0.9955793 ]\n",
            " [0.00674218]]\n",
            "Step: 3638 -> Loss: 0.004919729195535183 -> Predictions: [[0.00405947]\n",
            " [0.9955935 ]\n",
            " [0.99557954]\n",
            " [0.00674182]]\n",
            "Step: 3639 -> Loss: 0.0049194758757948875 -> Predictions: [[0.00405926]\n",
            " [0.9955937 ]\n",
            " [0.9955798 ]\n",
            " [0.00674148]]\n",
            "Step: 3640 -> Loss: 0.004919217899441719 -> Predictions: [[0.00405907]\n",
            " [0.99559397]\n",
            " [0.99558   ]\n",
            " [0.0067411 ]]\n",
            "Step: 3641 -> Loss: 0.004918965511023998 -> Predictions: [[0.00405886]\n",
            " [0.9955941 ]\n",
            " [0.99558026]\n",
            " [0.00674076]]\n",
            "Step: 3642 -> Loss: 0.004918709862977266 -> Predictions: [[0.00405866]\n",
            " [0.9955943 ]\n",
            " [0.9955805 ]\n",
            " [0.0067404 ]]\n",
            "Step: 3643 -> Loss: 0.004918456077575684 -> Predictions: [[0.00405846]\n",
            " [0.99559456]\n",
            " [0.99558073]\n",
            " [0.00674005]]\n",
            "Step: 3644 -> Loss: 0.004918199498206377 -> Predictions: [[0.00405826]\n",
            " [0.9955948 ]\n",
            " [0.99558085]\n",
            " [0.00673969]]\n",
            "Step: 3645 -> Loss: 0.004917947109788656 -> Predictions: [[0.00405806]\n",
            " [0.99559504]\n",
            " [0.9955811 ]\n",
            " [0.00673934]]\n",
            "Step: 3646 -> Loss: 0.004917692393064499 -> Predictions: [[0.00405787]\n",
            " [0.9955953 ]\n",
            " [0.9955813 ]\n",
            " [0.00673898]]\n",
            "Step: 3647 -> Loss: 0.004917440004646778 -> Predictions: [[0.00405766]\n",
            " [0.9955955 ]\n",
            " [0.99558157]\n",
            " [0.00673864]]\n",
            "Step: 3648 -> Loss: 0.004917181562632322 -> Predictions: [[0.00405746]\n",
            " [0.99559575]\n",
            " [0.9955818 ]\n",
            " [0.00673827]]\n",
            "Step: 3649 -> Loss: 0.004916928708553314 -> Predictions: [[0.00405726]\n",
            " [0.995596  ]\n",
            " [0.99558204]\n",
            " [0.00673793]]\n",
            "Step: 3650 -> Loss: 0.004916671197861433 -> Predictions: [[0.00405706]\n",
            " [0.99559623]\n",
            " [0.9955823 ]\n",
            " [0.00673756]]\n",
            "Step: 3651 -> Loss: 0.00491641741245985 -> Predictions: [[0.00405686]\n",
            " [0.99559647]\n",
            " [0.9955825 ]\n",
            " [0.00673721]]\n",
            "Step: 3652 -> Loss: 0.004916164092719555 -> Predictions: [[0.00405666]\n",
            " [0.9955967 ]\n",
            " [0.99558276]\n",
            " [0.00673686]]\n",
            "Step: 3653 -> Loss: 0.004915911704301834 -> Predictions: [[0.00405646]\n",
            " [0.99559695]\n",
            " [0.995583  ]\n",
            " [0.0067365 ]]\n",
            "Step: 3654 -> Loss: 0.004915651399642229 -> Predictions: [[0.00405625]\n",
            " [0.9955972 ]\n",
            " [0.99558324]\n",
            " [0.00673615]]\n",
            "Step: 3655 -> Loss: 0.004915401805192232 -> Predictions: [[0.00405606]\n",
            " [0.9955973 ]\n",
            " [0.9955835 ]\n",
            " [0.0067358 ]]\n",
            "Step: 3656 -> Loss: 0.0049151461571455 -> Predictions: [[0.00405586]\n",
            " [0.99559754]\n",
            " [0.9955837 ]\n",
            " [0.00673544]]\n",
            "Step: 3657 -> Loss: 0.0049148923717439175 -> Predictions: [[0.00405565]\n",
            " [0.9955978 ]\n",
            " [0.99558395]\n",
            " [0.00673509]]\n",
            "Step: 3658 -> Loss: 0.0049146367236971855 -> Predictions: [[0.00405545]\n",
            " [0.995598  ]\n",
            " [0.9955842 ]\n",
            " [0.00673473]]\n",
            "Step: 3659 -> Loss: 0.004914381541311741 -> Predictions: [[0.00405525]\n",
            " [0.99559826]\n",
            " [0.9955844 ]\n",
            " [0.00673438]]\n",
            "Step: 3660 -> Loss: 0.004914127290248871 -> Predictions: [[0.00405505]\n",
            " [0.99559844]\n",
            " [0.99558467]\n",
            " [0.00673401]]\n",
            "Step: 3661 -> Loss: 0.004913874436169863 -> Predictions: [[0.00405485]\n",
            " [0.9955987 ]\n",
            " [0.99558485]\n",
            " [0.00673367]]\n",
            "Step: 3662 -> Loss: 0.004913616925477982 -> Predictions: [[0.00405465]\n",
            " [0.9955989 ]\n",
            " [0.99558496]\n",
            " [0.00673331]]\n",
            "Step: 3663 -> Loss: 0.004913365002721548 -> Predictions: [[0.00405446]\n",
            " [0.99559915]\n",
            " [0.9955852 ]\n",
            " [0.00673296]]\n",
            "Step: 3664 -> Loss: 0.004913110285997391 -> Predictions: [[0.00405426]\n",
            " [0.9955994 ]\n",
            " [0.99558544]\n",
            " [0.0067326 ]]\n",
            "Step: 3665 -> Loss: 0.004912856034934521 -> Predictions: [[0.00405406]\n",
            " [0.9955996 ]\n",
            " [0.9955857 ]\n",
            " [0.00673225]]\n",
            "Step: 3666 -> Loss: 0.004912600386887789 -> Predictions: [[0.00405385]\n",
            " [0.99559987]\n",
            " [0.9955859 ]\n",
            " [0.0067319 ]]\n",
            "Step: 3667 -> Loss: 0.004912347532808781 -> Predictions: [[0.00405365]\n",
            " [0.9956001 ]\n",
            " [0.99558616]\n",
            " [0.00673155]]\n",
            "Step: 3668 -> Loss: 0.0049120900221168995 -> Predictions: [[0.00405345]\n",
            " [0.99560034]\n",
            " [0.9955864 ]\n",
            " [0.00673118]]\n",
            "Step: 3669 -> Loss: 0.004911839962005615 -> Predictions: [[0.00405326]\n",
            " [0.9956006 ]\n",
            " [0.99558663]\n",
            " [0.00673084]]\n",
            "Step: 3670 -> Loss: 0.004911583848297596 -> Predictions: [[0.00405306]\n",
            " [0.9956008 ]\n",
            " [0.9955869 ]\n",
            " [0.00673048]]\n",
            "Step: 3671 -> Loss: 0.004911334253847599 -> Predictions: [[0.00405286]\n",
            " [0.99560094]\n",
            " [0.9955871 ]\n",
            " [0.00673013]]\n",
            "Step: 3672 -> Loss: 0.004911070689558983 -> Predictions: [[0.00405265]\n",
            " [0.9956012 ]\n",
            " [0.99558735]\n",
            " [0.00672976]]\n",
            "Step: 3673 -> Loss: 0.004910821095108986 -> Predictions: [[0.00405245]\n",
            " [0.9956014 ]\n",
            " [0.9955876 ]\n",
            " [0.00672942]]\n",
            "Step: 3674 -> Loss: 0.004910564050078392 -> Predictions: [[0.00405225]\n",
            " [0.99560165]\n",
            " [0.9955878 ]\n",
            " [0.00672906]]\n",
            "Step: 3675 -> Loss: 0.004910312592983246 -> Predictions: [[0.00405206]\n",
            " [0.9956019 ]\n",
            " [0.99558806]\n",
            " [0.00672871]]\n",
            "Step: 3676 -> Loss: 0.00491005415096879 -> Predictions: [[0.00405185]\n",
            " [0.99560213]\n",
            " [0.9955883 ]\n",
            " [0.00672836]]\n",
            "Step: 3677 -> Loss: 0.004909804090857506 -> Predictions: [[0.00405165]\n",
            " [0.99560237]\n",
            " [0.99558854]\n",
            " [0.006728  ]]\n",
            "Step: 3678 -> Loss: 0.0049095479771494865 -> Predictions: [[0.00405145]\n",
            " [0.9956026 ]\n",
            " [0.9955888 ]\n",
            " [0.00672764]]\n",
            "Step: 3679 -> Loss: 0.004909291863441467 -> Predictions: [[0.00405125]\n",
            " [0.99560285]\n",
            " [0.995589  ]\n",
            " [0.00672729]]\n",
            "Step: 3680 -> Loss: 0.004909042734652758 -> Predictions: [[0.00405106]\n",
            " [0.9956031 ]\n",
            " [0.99558914]\n",
            " [0.00672694]]\n",
            "Step: 3681 -> Loss: 0.004908785689622164 -> Predictions: [[0.00405085]\n",
            " [0.9956033 ]\n",
            " [0.9955894 ]\n",
            " [0.00672659]]\n",
            "Step: 3682 -> Loss: 0.004908532369881868 -> Predictions: [[0.00405066]\n",
            " [0.99560356]\n",
            " [0.9955896 ]\n",
            " [0.00672623]]\n",
            "Step: 3683 -> Loss: 0.004908277653157711 -> Predictions: [[0.00405045]\n",
            " [0.9956038 ]\n",
            " [0.99558985]\n",
            " [0.00672588]]\n",
            "Step: 3684 -> Loss: 0.004908021539449692 -> Predictions: [[0.00405025]\n",
            " [0.99560404]\n",
            " [0.9955901 ]\n",
            " [0.00672552]]\n",
            "Step: 3685 -> Loss: 0.00490777101367712 -> Predictions: [[0.00405005]\n",
            " [0.99560416]\n",
            " [0.9955903 ]\n",
            " [0.00672517]]\n",
            "Step: 3686 -> Loss: 0.004907512106001377 -> Predictions: [[0.00404985]\n",
            " [0.9956044 ]\n",
            " [0.99559057]\n",
            " [0.00672482]]\n",
            "Step: 3687 -> Loss: 0.004907259717583656 -> Predictions: [[0.00404965]\n",
            " [0.99560463]\n",
            " [0.9955908 ]\n",
            " [0.00672446]]\n",
            "Step: 3688 -> Loss: 0.004907004535198212 -> Predictions: [[0.00404945]\n",
            " [0.9956049 ]\n",
            " [0.99559104]\n",
            " [0.0067241 ]]\n",
            "Step: 3689 -> Loss: 0.0049067530781030655 -> Predictions: [[0.00404925]\n",
            " [0.99560505]\n",
            " [0.9955913 ]\n",
            " [0.00672376]]\n",
            "Step: 3690 -> Loss: 0.00490649975836277 -> Predictions: [[0.00404905]\n",
            " [0.9956053 ]\n",
            " [0.9955915 ]\n",
            " [0.0067234 ]]\n",
            "Step: 3691 -> Loss: 0.004906248301267624 -> Predictions: [[0.00404885]\n",
            " [0.9956055 ]\n",
            " [0.9955917 ]\n",
            " [0.00672306]]\n",
            "Step: 3692 -> Loss: 0.004905990790575743 -> Predictions: [[0.00404865]\n",
            " [0.99560577]\n",
            " [0.99559194]\n",
            " [0.00672269]]\n",
            "Step: 3693 -> Loss: 0.004905737936496735 -> Predictions: [[0.00404845]\n",
            " [0.995606  ]\n",
            " [0.9955922 ]\n",
            " [0.00672234]]\n",
            "Step: 3694 -> Loss: 0.004905479960143566 -> Predictions: [[0.00404825]\n",
            " [0.99560624]\n",
            " [0.9955924 ]\n",
            " [0.00672198]]\n",
            "Step: 3695 -> Loss: 0.004905227571725845 -> Predictions: [[0.00404805]\n",
            " [0.9956065 ]\n",
            " [0.99559265]\n",
            " [0.00672164]]\n",
            "Step: 3696 -> Loss: 0.004904973786324263 -> Predictions: [[0.00404785]\n",
            " [0.9956067 ]\n",
            " [0.9955929 ]\n",
            " [0.00672127]]\n",
            "Step: 3697 -> Loss: 0.004904718603938818 -> Predictions: [[0.00404765]\n",
            " [0.99560696]\n",
            " [0.995593  ]\n",
            " [0.00672093]]\n",
            "Step: 3698 -> Loss: 0.004904464352875948 -> Predictions: [[0.00404745]\n",
            " [0.9956072 ]\n",
            " [0.99559325]\n",
            " [0.00672057]]\n",
            "Step: 3699 -> Loss: 0.004904212895780802 -> Predictions: [[0.00404725]\n",
            " [0.9956073 ]\n",
            " [0.9955935 ]\n",
            " [0.00672022]]\n",
            "Step: 3700 -> Loss: 0.004903953522443771 -> Predictions: [[0.00404705]\n",
            " [0.99560755]\n",
            " [0.9955937 ]\n",
            " [0.00671986]]\n",
            "Step: 3701 -> Loss: 0.004903702065348625 -> Predictions: [[0.00404685]\n",
            " [0.9956078 ]\n",
            " [0.99559397]\n",
            " [0.00671951]]\n",
            "Step: 3702 -> Loss: 0.004903450142592192 -> Predictions: [[0.00404665]\n",
            " [0.99560803]\n",
            " [0.9955942 ]\n",
            " [0.00671916]]\n",
            "Step: 3703 -> Loss: 0.004903195425868034 -> Predictions: [[0.00404645]\n",
            " [0.99560827]\n",
            " [0.99559444]\n",
            " [0.00671881]]\n",
            "Step: 3704 -> Loss: 0.004902942571789026 -> Predictions: [[0.00404625]\n",
            " [0.9956085 ]\n",
            " [0.9955947 ]\n",
            " [0.00671845]]\n",
            "Step: 3705 -> Loss: 0.0049026887863874435 -> Predictions: [[0.00404605]\n",
            " [0.99560875]\n",
            " [0.9955949 ]\n",
            " [0.0067181 ]]\n",
            "Step: 3706 -> Loss: 0.004902434069663286 -> Predictions: [[0.00404585]\n",
            " [0.995609  ]\n",
            " [0.99559516]\n",
            " [0.00671774]]\n",
            "Step: 3707 -> Loss: 0.0049021802842617035 -> Predictions: [[0.00404565]\n",
            " [0.9956092 ]\n",
            " [0.9955954 ]\n",
            " [0.00671739]]\n",
            "Step: 3708 -> Loss: 0.004901923704892397 -> Predictions: [[0.00404545]\n",
            " [0.99560946]\n",
            " [0.99559563]\n",
            " [0.00671703]]\n",
            "Step: 3709 -> Loss: 0.0049016717821359634 -> Predictions: [[0.00404525]\n",
            " [0.9956097 ]\n",
            " [0.9955959 ]\n",
            " [0.00671669]]\n",
            "Step: 3710 -> Loss: 0.004901415668427944 -> Predictions: [[0.00404505]\n",
            " [0.99560994]\n",
            " [0.9955961 ]\n",
            " [0.00671632]]\n",
            "Step: 3711 -> Loss: 0.004901166073977947 -> Predictions: [[0.00404485]\n",
            " [0.9956102 ]\n",
            " [0.99559635]\n",
            " [0.00671598]]\n",
            "Step: 3712 -> Loss: 0.004900907166302204 -> Predictions: [[0.00404465]\n",
            " [0.9956104 ]\n",
            " [0.9955966 ]\n",
            " [0.00671562]]\n",
            "Step: 3713 -> Loss: 0.004900661297142506 -> Predictions: [[0.00404446]\n",
            " [0.99561054]\n",
            " [0.9955968 ]\n",
            " [0.00671527]]\n",
            "Step: 3714 -> Loss: 0.0049004037864506245 -> Predictions: [[0.00404425]\n",
            " [0.9956108 ]\n",
            " [0.99559695]\n",
            " [0.00671492]]\n",
            "Step: 3715 -> Loss: 0.004900146275758743 -> Predictions: [[0.00404406]\n",
            " [0.995611  ]\n",
            " [0.9955972 ]\n",
            " [0.00671456]]\n",
            "Step: 3716 -> Loss: 0.004899897146970034 -> Predictions: [[0.00404386]\n",
            " [0.99561125]\n",
            " [0.9955974 ]\n",
            " [0.00671421]]\n",
            "Step: 3717 -> Loss: 0.004899643827229738 -> Predictions: [[0.00404366]\n",
            " [0.9956115 ]\n",
            " [0.99559766]\n",
            " [0.00671386]]\n",
            "Step: 3718 -> Loss: 0.004899386782199144 -> Predictions: [[0.00404345]\n",
            " [0.9956117 ]\n",
            " [0.9955979 ]\n",
            " [0.0067135 ]]\n",
            "Step: 3719 -> Loss: 0.00489913672208786 -> Predictions: [[0.00404326]\n",
            " [0.9956119 ]\n",
            " [0.99559814]\n",
            " [0.00671316]]\n",
            "Step: 3720 -> Loss: 0.004898876883089542 -> Predictions: [[0.00404305]\n",
            " [0.99561214]\n",
            " [0.9955983 ]\n",
            " [0.00671279]]\n",
            "Step: 3721 -> Loss: 0.004898629151284695 -> Predictions: [[0.00404286]\n",
            " [0.9956124 ]\n",
            " [0.99559855]\n",
            " [0.00671244]]\n",
            "Step: 3722 -> Loss: 0.004898375831544399 -> Predictions: [[0.00404266]\n",
            " [0.9956126 ]\n",
            " [0.9955988 ]\n",
            " [0.00671209]]\n",
            "Step: 3723 -> Loss: 0.004898120649158955 -> Predictions: [[0.00404246]\n",
            " [0.99561286]\n",
            " [0.99559903]\n",
            " [0.00671174]]\n",
            "Step: 3724 -> Loss: 0.004897866398096085 -> Predictions: [[0.00404226]\n",
            " [0.9956131 ]\n",
            " [0.99559927]\n",
            " [0.00671138]]\n",
            "Step: 3725 -> Loss: 0.004897614009678364 -> Predictions: [[0.00404207]\n",
            " [0.99561334]\n",
            " [0.9955995 ]\n",
            " [0.00671103]]\n",
            "Step: 3726 -> Loss: 0.004897356033325195 -> Predictions: [[0.00404186]\n",
            " [0.9956136 ]\n",
            " [0.99559975]\n",
            " [0.00671067]]\n",
            "Step: 3727 -> Loss: 0.0048971036449074745 -> Predictions: [[0.00404166]\n",
            " [0.9956138 ]\n",
            " [0.9956    ]\n",
            " [0.00671032]]\n",
            "Step: 3728 -> Loss: 0.004896853119134903 -> Predictions: [[0.00404147]\n",
            " [0.99561393]\n",
            " [0.9956002 ]\n",
            " [0.00670997]]\n",
            "Step: 3729 -> Loss: 0.004896600265055895 -> Predictions: [[0.00404127]\n",
            " [0.9956142 ]\n",
            " [0.99560046]\n",
            " [0.00670962]]\n",
            "Step: 3730 -> Loss: 0.004896342754364014 -> Predictions: [[0.00404106]\n",
            " [0.9956144 ]\n",
            " [0.9956006 ]\n",
            " [0.00670926]]\n",
            "Step: 3731 -> Loss: 0.00489609083160758 -> Predictions: [[0.00404087]\n",
            " [0.99561465]\n",
            " [0.9956008 ]\n",
            " [0.00670891]]\n",
            "Step: 3732 -> Loss: 0.004895837511867285 -> Predictions: [[0.00404067]\n",
            " [0.9956149 ]\n",
            " [0.99560106]\n",
            " [0.00670855]]\n",
            "Step: 3733 -> Loss: 0.004895585123449564 -> Predictions: [[0.00404047]\n",
            " [0.9956151 ]\n",
            " [0.9956013 ]\n",
            " [0.00670821]]\n",
            "Step: 3734 -> Loss: 0.004895330406725407 -> Predictions: [[0.00404027]\n",
            " [0.99561536]\n",
            " [0.99560153]\n",
            " [0.00670786]]\n",
            "Step: 3735 -> Loss: 0.004895077086985111 -> Predictions: [[0.00404007]\n",
            " [0.9956156 ]\n",
            " [0.9956018 ]\n",
            " [0.0067075 ]]\n",
            "Step: 3736 -> Loss: 0.004894823767244816 -> Predictions: [[0.00403987]\n",
            " [0.99561584]\n",
            " [0.995602  ]\n",
            " [0.00670714]]\n",
            "Step: 3737 -> Loss: 0.004894571378827095 -> Predictions: [[0.00403967]\n",
            " [0.9956161 ]\n",
            " [0.99560225]\n",
            " [0.00670679]]\n",
            "Step: 3738 -> Loss: 0.004894315730780363 -> Predictions: [[0.00403947]\n",
            " [0.9956163 ]\n",
            " [0.9956025 ]\n",
            " [0.00670643]]\n",
            "Step: 3739 -> Loss: 0.004894064739346504 -> Predictions: [[0.00403928]\n",
            " [0.99561656]\n",
            " [0.9956027 ]\n",
            " [0.00670608]]\n",
            "Step: 3740 -> Loss: 0.004893810488283634 -> Predictions: [[0.00403907]\n",
            " [0.9956167 ]\n",
            " [0.99560297]\n",
            " [0.00670571]]\n",
            "Step: 3741 -> Loss: 0.0048935613594949245 -> Predictions: [[0.00403888]\n",
            " [0.9956169 ]\n",
            " [0.9956032 ]\n",
            " [0.00670537]]\n",
            "Step: 3742 -> Loss: 0.004893306642770767 -> Predictions: [[0.00403868]\n",
            " [0.99561715]\n",
            " [0.99560344]\n",
            " [0.006705  ]]\n",
            "Step: 3743 -> Loss: 0.004893054720014334 -> Predictions: [[0.00403848]\n",
            " [0.9956174 ]\n",
            " [0.9956037 ]\n",
            " [0.00670465]]\n",
            "Step: 3744 -> Loss: 0.0048927972093224525 -> Predictions: [[0.00403828]\n",
            " [0.9956176 ]\n",
            " [0.9956038 ]\n",
            " [0.00670429]]\n",
            "Step: 3745 -> Loss: 0.004892546683549881 -> Predictions: [[0.00403808]\n",
            " [0.99561787]\n",
            " [0.99560404]\n",
            " [0.00670394]]\n",
            "Step: 3746 -> Loss: 0.004892295226454735 -> Predictions: [[0.00403788]\n",
            " [0.9956181 ]\n",
            " [0.9956043 ]\n",
            " [0.00670358]]\n",
            "Step: 3747 -> Loss: 0.004892042838037014 -> Predictions: [[0.00403768]\n",
            " [0.99561834]\n",
            " [0.9956045 ]\n",
            " [0.00670322]]\n",
            "Step: 3748 -> Loss: 0.004891789518296719 -> Predictions: [[0.00403748]\n",
            " [0.9956185 ]\n",
            " [0.99560475]\n",
            " [0.00670286]]\n",
            "Step: 3749 -> Loss: 0.0048915366642177105 -> Predictions: [[0.00403729]\n",
            " [0.99561876]\n",
            " [0.995605  ]\n",
            " [0.00670251]]\n",
            "Step: 3750 -> Loss: 0.004891281481832266 -> Predictions: [[0.00403708]\n",
            " [0.9956189 ]\n",
            " [0.9956052 ]\n",
            " [0.00670215]]\n",
            "Step: 3751 -> Loss: 0.00489103002473712 -> Predictions: [[0.00403689]\n",
            " [0.9956191 ]\n",
            " [0.9956054 ]\n",
            " [0.0067018 ]]\n",
            "Step: 3752 -> Loss: 0.004890774842351675 -> Predictions: [[0.00403668]\n",
            " [0.99561936]\n",
            " [0.99560565]\n",
            " [0.00670144]]\n",
            "Step: 3753 -> Loss: 0.004890525247901678 -> Predictions: [[0.00403649]\n",
            " [0.9956196 ]\n",
            " [0.9956059 ]\n",
            " [0.00670108]]\n",
            "Step: 3754 -> Loss: 0.004890270531177521 -> Predictions: [[0.00403629]\n",
            " [0.99561983]\n",
            " [0.9956061 ]\n",
            " [0.00670072]]\n",
            "Step: 3755 -> Loss: 0.004890020936727524 -> Predictions: [[0.00403609]\n",
            " [0.9956201 ]\n",
            " [0.99560624]\n",
            " [0.00670037]]\n",
            "Step: 3756 -> Loss: 0.0048897662200033665 -> Predictions: [[0.0040359 ]\n",
            " [0.9956203 ]\n",
            " [0.9956065 ]\n",
            " [0.00670001]]\n",
            "Step: 3757 -> Loss: 0.004889511503279209 -> Predictions: [[0.00403569]\n",
            " [0.99562055]\n",
            " [0.9956067 ]\n",
            " [0.00669965]]\n",
            "Step: 3758 -> Loss: 0.004889260977506638 -> Predictions: [[0.0040355 ]\n",
            " [0.9956208 ]\n",
            " [0.99560696]\n",
            " [0.0066993 ]]\n",
            "Step: 3759 -> Loss: 0.004889007192105055 -> Predictions: [[0.0040353 ]\n",
            " [0.995621  ]\n",
            " [0.9956072 ]\n",
            " [0.00669894]]\n",
            "Step: 3760 -> Loss: 0.004888754338026047 -> Predictions: [[0.00403509]\n",
            " [0.99562114]\n",
            " [0.99560744]\n",
            " [0.00669858]]\n",
            "Step: 3761 -> Loss: 0.004888501949608326 -> Predictions: [[0.0040349 ]\n",
            " [0.9956214 ]\n",
            " [0.9956077 ]\n",
            " [0.00669823]]\n",
            "Step: 3762 -> Loss: 0.004888249561190605 -> Predictions: [[0.0040347 ]\n",
            " [0.9956216 ]\n",
            " [0.9956079 ]\n",
            " [0.00669787]]\n",
            "Step: 3763 -> Loss: 0.004887997172772884 -> Predictions: [[0.0040345 ]\n",
            " [0.99562186]\n",
            " [0.99560815]\n",
            " [0.00669752]]\n",
            "Step: 3764 -> Loss: 0.004887742921710014 -> Predictions: [[0.0040343 ]\n",
            " [0.9956221 ]\n",
            " [0.9956084 ]\n",
            " [0.00669715]]\n",
            "Step: 3765 -> Loss: 0.0048874905332922935 -> Predictions: [[0.0040341 ]\n",
            " [0.99562234]\n",
            " [0.9956086 ]\n",
            " [0.0066968 ]]\n",
            "Step: 3766 -> Loss: 0.004887239541858435 -> Predictions: [[0.0040339 ]\n",
            " [0.9956226 ]\n",
            " [0.99560875]\n",
            " [0.00669644]]\n",
            "Step: 3767 -> Loss: 0.004886987153440714 -> Predictions: [[0.00403371]\n",
            " [0.9956228 ]\n",
            " [0.995609  ]\n",
            " [0.00669609]]\n",
            "Step: 3768 -> Loss: 0.004886733368039131 -> Predictions: [[0.00403351]\n",
            " [0.99562305]\n",
            " [0.9956092 ]\n",
            " [0.00669573]]\n",
            "Step: 3769 -> Loss: 0.004886481910943985 -> Predictions: [[0.00403331]\n",
            " [0.9956233 ]\n",
            " [0.99560946]\n",
            " [0.00669538]]\n",
            "Step: 3770 -> Loss: 0.004886227659881115 -> Predictions: [[0.00403311]\n",
            " [0.9956234 ]\n",
            " [0.9956097 ]\n",
            " [0.00669501]]\n",
            "Step: 3771 -> Loss: 0.004885973408818245 -> Predictions: [[0.00403291]\n",
            " [0.99562365]\n",
            " [0.99560994]\n",
            " [0.00669466]]\n",
            "Step: 3772 -> Loss: 0.004885722417384386 -> Predictions: [[0.00403271]\n",
            " [0.9956239 ]\n",
            " [0.9956102 ]\n",
            " [0.00669431]]\n",
            "Step: 3773 -> Loss: 0.004885472357273102 -> Predictions: [[0.00403252]\n",
            " [0.9956241 ]\n",
            " [0.9956104 ]\n",
            " [0.00669395]]\n",
            "Step: 3774 -> Loss: 0.0048852176405489445 -> Predictions: [[0.00403232]\n",
            " [0.99562436]\n",
            " [0.99561065]\n",
            " [0.00669359]]\n",
            "Step: 3775 -> Loss: 0.00488496758043766 -> Predictions: [[0.00403212]\n",
            " [0.9956246 ]\n",
            " [0.9956109 ]\n",
            " [0.00669324]]\n",
            "Step: 3776 -> Loss: 0.004884712398052216 -> Predictions: [[0.00403192]\n",
            " [0.99562484]\n",
            " [0.99561113]\n",
            " [0.00669288]]\n",
            "Step: 3777 -> Loss: 0.0048844655975699425 -> Predictions: [[0.00403173]\n",
            " [0.9956251 ]\n",
            " [0.99561125]\n",
            " [0.00669253]]\n",
            "Step: 3778 -> Loss: 0.004884210415184498 -> Predictions: [[0.00403154]\n",
            " [0.99562526]\n",
            " [0.9956115 ]\n",
            " [0.00669217]]\n",
            "Step: 3779 -> Loss: 0.004883958958089352 -> Predictions: [[0.00403134]\n",
            " [0.9956255 ]\n",
            " [0.9956117 ]\n",
            " [0.00669182]]\n",
            "Step: 3780 -> Loss: 0.00488370843231678 -> Predictions: [[0.00403114]\n",
            " [0.9956256 ]\n",
            " [0.9956119 ]\n",
            " [0.00669146]]\n",
            "Step: 3781 -> Loss: 0.004883456975221634 -> Predictions: [[0.00403095]\n",
            " [0.99562585]\n",
            " [0.99561214]\n",
            " [0.00669111]]\n",
            "Step: 3782 -> Loss: 0.004883207380771637 -> Predictions: [[0.00403075]\n",
            " [0.9956261 ]\n",
            " [0.9956124 ]\n",
            " [0.00669076]]\n",
            "Step: 3783 -> Loss: 0.0048829554580152035 -> Predictions: [[0.00403055]\n",
            " [0.99562633]\n",
            " [0.9956126 ]\n",
            " [0.0066904 ]]\n",
            "Step: 3784 -> Loss: 0.004882705397903919 -> Predictions: [[0.00403035]\n",
            " [0.99562657]\n",
            " [0.99561286]\n",
            " [0.00669005]]\n",
            "Step: 3785 -> Loss: 0.00488245440647006 -> Predictions: [[0.00403016]\n",
            " [0.9956268 ]\n",
            " [0.9956131 ]\n",
            " [0.00668969]]\n",
            "Step: 3786 -> Loss: 0.004882205277681351 -> Predictions: [[0.00402995]\n",
            " [0.99562705]\n",
            " [0.99561334]\n",
            " [0.00668934]]\n",
            "Step: 3787 -> Loss: 0.0048819552175700665 -> Predictions: [[0.00402976]\n",
            " [0.9956273 ]\n",
            " [0.99561346]\n",
            " [0.00668898]]\n",
            "Step: 3788 -> Loss: 0.004881702363491058 -> Predictions: [[0.00402956]\n",
            " [0.9956274 ]\n",
            " [0.9956137 ]\n",
            " [0.00668862]]\n",
            "Step: 3789 -> Loss: 0.0048814513720571995 -> Predictions: [[0.00402935]\n",
            " [0.99562764]\n",
            " [0.99561393]\n",
            " [0.00668827]]\n",
            "Step: 3790 -> Loss: 0.004881202708929777 -> Predictions: [[0.00402916]\n",
            " [0.9956279 ]\n",
            " [0.9956142 ]\n",
            " [0.00668792]]\n",
            "Step: 3791 -> Loss: 0.004880950320512056 -> Predictions: [[0.00402896]\n",
            " [0.9956281 ]\n",
            " [0.9956144 ]\n",
            " [0.00668756]]\n",
            "Step: 3792 -> Loss: 0.004880704917013645 -> Predictions: [[0.00402877]\n",
            " [0.99562836]\n",
            " [0.99561465]\n",
            " [0.00668721]]\n",
            "Step: 3793 -> Loss: 0.00488045159727335 -> Predictions: [[0.00402857]\n",
            " [0.9956286 ]\n",
            " [0.9956149 ]\n",
            " [0.00668686]]\n",
            "Step: 3794 -> Loss: 0.004880205728113651 -> Predictions: [[0.00402837]\n",
            " [0.99562883]\n",
            " [0.9956151 ]\n",
            " [0.00668651]]\n",
            "Step: 3795 -> Loss: 0.004879952408373356 -> Predictions: [[0.00402817]\n",
            " [0.9956291 ]\n",
            " [0.99561524]\n",
            " [0.00668615]]\n",
            "Step: 3796 -> Loss: 0.004879700019955635 -> Predictions: [[0.00402797]\n",
            " [0.9956293 ]\n",
            " [0.9956155 ]\n",
            " [0.00668579]]\n",
            "Step: 3797 -> Loss: 0.004879449959844351 -> Predictions: [[0.00402777]\n",
            " [0.99562943]\n",
            " [0.9956157 ]\n",
            " [0.00668544]]\n",
            "Step: 3798 -> Loss: 0.0048791998997330666 -> Predictions: [[0.00402757]\n",
            " [0.99562967]\n",
            " [0.99561596]\n",
            " [0.00668509]]\n",
            "Step: 3799 -> Loss: 0.00487894844263792 -> Predictions: [[0.00402737]\n",
            " [0.9956299 ]\n",
            " [0.9956162 ]\n",
            " [0.00668473]]\n",
            "Step: 3800 -> Loss: 0.004878698848187923 -> Predictions: [[0.00402717]\n",
            " [0.99563015]\n",
            " [0.99561644]\n",
            " [0.00668437]]\n",
            "Step: 3801 -> Loss: 0.00487845204770565 -> Predictions: [[0.00402698]\n",
            " [0.9956304 ]\n",
            " [0.9956167 ]\n",
            " [0.00668402]]\n",
            "Step: 3802 -> Loss: 0.0048782010562717915 -> Predictions: [[0.00402678]\n",
            " [0.9956306 ]\n",
            " [0.9956169 ]\n",
            " [0.00668367]]\n",
            "Step: 3803 -> Loss: 0.004877949133515358 -> Predictions: [[0.00402658]\n",
            " [0.99563086]\n",
            " [0.99561703]\n",
            " [0.00668331]]\n",
            "Step: 3804 -> Loss: 0.004877700004726648 -> Predictions: [[0.00402638]\n",
            " [0.9956311 ]\n",
            " [0.9956173 ]\n",
            " [0.00668296]]\n",
            "Step: 3805 -> Loss: 0.004877450875937939 -> Predictions: [[0.00402618]\n",
            " [0.9956312 ]\n",
            " [0.9956175 ]\n",
            " [0.00668261]]\n",
            "Step: 3806 -> Loss: 0.0048771994188427925 -> Predictions: [[0.00402598]\n",
            " [0.99563146]\n",
            " [0.99561775]\n",
            " [0.00668226]]\n",
            "Step: 3807 -> Loss: 0.004876951687037945 -> Predictions: [[0.00402579]\n",
            " [0.9956317 ]\n",
            " [0.995618  ]\n",
            " [0.0066819 ]]\n",
            "Step: 3808 -> Loss: 0.004876699764281511 -> Predictions: [[0.00402559]\n",
            " [0.99563193]\n",
            " [0.9956182 ]\n",
            " [0.00668154]]\n",
            "Step: 3809 -> Loss: 0.004876447841525078 -> Predictions: [[0.00402538]\n",
            " [0.9956321 ]\n",
            " [0.99561846]\n",
            " [0.00668119]]\n",
            "Step: 3810 -> Loss: 0.004876198247075081 -> Predictions: [[0.00402519]\n",
            " [0.99563235]\n",
            " [0.99561864]\n",
            " [0.00668084]]\n",
            "Step: 3811 -> Loss: 0.004875950515270233 -> Predictions: [[0.00402499]\n",
            " [0.9956326 ]\n",
            " [0.99561876]\n",
            " [0.00668049]]\n",
            "Step: 3812 -> Loss: 0.004875697195529938 -> Predictions: [[0.00402479]\n",
            " [0.9956328 ]\n",
            " [0.995619  ]\n",
            " [0.00668013]]\n",
            "Step: 3813 -> Loss: 0.004875448998063803 -> Predictions: [[0.00402459]\n",
            " [0.99563295]\n",
            " [0.99561924]\n",
            " [0.00667978]]\n",
            "Step: 3814 -> Loss: 0.004875198006629944 -> Predictions: [[0.00402439]\n",
            " [0.9956332 ]\n",
            " [0.9956195 ]\n",
            " [0.00667942]]\n",
            "Step: 3815 -> Loss: 0.004874950274825096 -> Predictions: [[0.0040242 ]\n",
            " [0.9956334 ]\n",
            " [0.9956197 ]\n",
            " [0.00667907]]\n",
            "Step: 3816 -> Loss: 0.004874696023762226 -> Predictions: [[0.004024  ]\n",
            " [0.99563366]\n",
            " [0.99561995]\n",
            " [0.00667871]]\n",
            "Step: 3817 -> Loss: 0.004874447826296091 -> Predictions: [[0.0040238 ]\n",
            " [0.9956339 ]\n",
            " [0.9956202 ]\n",
            " [0.00667836]]\n",
            "Step: 3818 -> Loss: 0.004874195903539658 -> Predictions: [[0.0040236 ]\n",
            " [0.99563414]\n",
            " [0.9956204 ]\n",
            " [0.00667801]]\n",
            "Step: 3819 -> Loss: 0.004873947706073523 -> Predictions: [[0.0040234 ]\n",
            " [0.9956344 ]\n",
            " [0.99562055]\n",
            " [0.00667765]]\n",
            "Step: 3820 -> Loss: 0.004873692989349365 -> Predictions: [[0.0040232 ]\n",
            " [0.9956346 ]\n",
            " [0.9956208 ]\n",
            " [0.00667729]]\n",
            "Step: 3821 -> Loss: 0.0048734466545283794 -> Predictions: [[0.00402301]\n",
            " [0.99563473]\n",
            " [0.995621  ]\n",
            " [0.00667694]]\n",
            "Step: 3822 -> Loss: 0.00487319752573967 -> Predictions: [[0.0040228 ]\n",
            " [0.995635  ]\n",
            " [0.99562126]\n",
            " [0.0066766 ]]\n",
            "Step: 3823 -> Loss: 0.004872946534305811 -> Predictions: [[0.00402261]\n",
            " [0.9956352 ]\n",
            " [0.9956215 ]\n",
            " [0.00667624]]\n",
            "Step: 3824 -> Loss: 0.0048726946115493774 -> Predictions: [[0.00402241]\n",
            " [0.99563545]\n",
            " [0.99562174]\n",
            " [0.00667588]]\n",
            "Step: 3825 -> Loss: 0.00487244687974453 -> Predictions: [[0.00402221]\n",
            " [0.9956357 ]\n",
            " [0.995622  ]\n",
            " [0.00667554]]\n",
            "Step: 3826 -> Loss: 0.00487219775095582 -> Predictions: [[0.00402202]\n",
            " [0.9956359 ]\n",
            " [0.9956222 ]\n",
            " [0.00667519]]\n",
            "Step: 3827 -> Loss: 0.004871947690844536 -> Predictions: [[0.00402181]\n",
            " [0.99563617]\n",
            " [0.99562234]\n",
            " [0.00667483]]\n",
            "Step: 3828 -> Loss: 0.004871698096394539 -> Predictions: [[0.00402162]\n",
            " [0.9956364 ]\n",
            " [0.9956226 ]\n",
            " [0.00667448]]\n",
            "Step: 3829 -> Loss: 0.004871446639299393 -> Predictions: [[0.00402142]\n",
            " [0.9956365 ]\n",
            " [0.9956228 ]\n",
            " [0.00667413]]\n",
            "Step: 3830 -> Loss: 0.004871199373155832 -> Predictions: [[0.00402122]\n",
            " [0.99563676]\n",
            " [0.99562305]\n",
            " [0.00667378]]\n",
            "Step: 3831 -> Loss: 0.004870951641350985 -> Predictions: [[0.00402103]\n",
            " [0.995637  ]\n",
            " [0.9956233 ]\n",
            " [0.00667344]]\n",
            "Step: 3832 -> Loss: 0.004870702046900988 -> Predictions: [[0.00402083]\n",
            " [0.99563724]\n",
            " [0.9956235 ]\n",
            " [0.00667309]]\n",
            "Step: 3833 -> Loss: 0.004870450124144554 -> Predictions: [[0.00402064]\n",
            " [0.9956375 ]\n",
            " [0.99562377]\n",
            " [0.00667274]]\n",
            "Step: 3834 -> Loss: 0.004870201461017132 -> Predictions: [[0.00402043]\n",
            " [0.9956377 ]\n",
            " [0.995624  ]\n",
            " [0.00667239]]\n",
            "Step: 3835 -> Loss: 0.004869952332228422 -> Predictions: [[0.00402024]\n",
            " [0.99563795]\n",
            " [0.99562424]\n",
            " [0.00667204]]\n",
            "Step: 3836 -> Loss: 0.004869701340794563 -> Predictions: [[0.00402004]\n",
            " [0.9956382 ]\n",
            " [0.9956245 ]\n",
            " [0.0066717 ]]\n",
            "Step: 3837 -> Loss: 0.004869455471634865 -> Predictions: [[0.00401985]\n",
            " [0.9956383 ]\n",
            " [0.9956246 ]\n",
            " [0.00667135]]\n",
            "Step: 3838 -> Loss: 0.004869203548878431 -> Predictions: [[0.00401965]\n",
            " [0.99563855]\n",
            " [0.99562484]\n",
            " [0.006671  ]]\n",
            "Step: 3839 -> Loss: 0.00486895302310586 -> Predictions: [[0.00401946]\n",
            " [0.9956388 ]\n",
            " [0.9956251 ]\n",
            " [0.00667065]]\n",
            "Step: 3840 -> Loss: 0.00486870389431715 -> Predictions: [[0.00401926]\n",
            " [0.99563897]\n",
            " [0.99562526]\n",
            " [0.00667031]]\n",
            "Step: 3841 -> Loss: 0.004868458956480026 -> Predictions: [[0.00401907]\n",
            " [0.9956392 ]\n",
            " [0.9956255 ]\n",
            " [0.00666996]]\n",
            "Step: 3842 -> Loss: 0.0048682065680623055 -> Predictions: [[0.00401887]\n",
            " [0.99563944]\n",
            " [0.99562573]\n",
            " [0.0066696 ]]\n",
            "Step: 3843 -> Loss: 0.004867956507951021 -> Predictions: [[0.00401867]\n",
            " [0.9956397 ]\n",
            " [0.995626  ]\n",
            " [0.00666926]]\n",
            "Step: 3844 -> Loss: 0.004867708310484886 -> Predictions: [[0.00401848]\n",
            " [0.9956399 ]\n",
            " [0.9956262 ]\n",
            " [0.00666891]]\n",
            "Step: 3845 -> Loss: 0.004867458716034889 -> Predictions: [[0.00401828]\n",
            " [0.99564016]\n",
            " [0.99562645]\n",
            " [0.00666856]]\n",
            "Step: 3846 -> Loss: 0.004867205396294594 -> Predictions: [[0.00401808]\n",
            " [0.9956403 ]\n",
            " [0.9956267 ]\n",
            " [0.0066682 ]]\n",
            "Step: 3847 -> Loss: 0.004866957664489746 -> Predictions: [[0.00401788]\n",
            " [0.9956405 ]\n",
            " [0.9956268 ]\n",
            " [0.00666786]]\n",
            "Step: 3848 -> Loss: 0.004866709001362324 -> Predictions: [[0.00401769]\n",
            " [0.99564075]\n",
            " [0.99562705]\n",
            " [0.00666751]]\n",
            "Step: 3849 -> Loss: 0.004866460338234901 -> Predictions: [[0.00401749]\n",
            " [0.995641  ]\n",
            " [0.9956273 ]\n",
            " [0.00666717]]\n",
            "Step: 3850 -> Loss: 0.004866211675107479 -> Predictions: [[0.0040173 ]\n",
            " [0.99564123]\n",
            " [0.9956275 ]\n",
            " [0.00666682]]\n",
            "Step: 3851 -> Loss: 0.0048659625463187695 -> Predictions: [[0.0040171 ]\n",
            " [0.99564147]\n",
            " [0.99562776]\n",
            " [0.00666647]]\n",
            "Step: 3852 -> Loss: 0.004865711089223623 -> Predictions: [[0.0040169 ]\n",
            " [0.9956417 ]\n",
            " [0.995628  ]\n",
            " [0.00666612]]\n",
            "Step: 3853 -> Loss: 0.004865461029112339 -> Predictions: [[0.0040167 ]\n",
            " [0.99564195]\n",
            " [0.99562824]\n",
            " [0.00666577]]\n",
            "Step: 3854 -> Loss: 0.004865216091275215 -> Predictions: [[0.00401652]\n",
            " [0.9956422 ]\n",
            " [0.9956285 ]\n",
            " [0.00666543]]\n",
            "Step: 3855 -> Loss: 0.004864965565502644 -> Predictions: [[0.00401631]\n",
            " [0.9956423 ]\n",
            " [0.9956287 ]\n",
            " [0.00666507]]\n",
            "Step: 3856 -> Loss: 0.004864716436713934 -> Predictions: [[0.00401612]\n",
            " [0.99564254]\n",
            " [0.99562895]\n",
            " [0.00666473]]\n",
            "Step: 3857 -> Loss: 0.00486447149887681 -> Predictions: [[0.00401592]\n",
            " [0.9956428 ]\n",
            " [0.9956291 ]\n",
            " [0.00666439]]\n",
            "Step: 3858 -> Loss: 0.004864220507442951 -> Predictions: [[0.00401573]\n",
            " [0.995643  ]\n",
            " [0.9956293 ]\n",
            " [0.00666404]]\n",
            "Step: 3859 -> Loss: 0.004863970912992954 -> Predictions: [[0.00401553]\n",
            " [0.99564326]\n",
            " [0.99562955]\n",
            " [0.00666369]]\n",
            "Step: 3860 -> Loss: 0.004863721318542957 -> Predictions: [[0.00401534]\n",
            " [0.9956435 ]\n",
            " [0.9956298 ]\n",
            " [0.00666334]]\n",
            "Step: 3861 -> Loss: 0.004863473121076822 -> Predictions: [[0.00401514]\n",
            " [0.99564373]\n",
            " [0.99563   ]\n",
            " [0.006663  ]]\n",
            "Step: 3862 -> Loss: 0.004863223060965538 -> Predictions: [[0.00401494]\n",
            " [0.995644  ]\n",
            " [0.99563026]\n",
            " [0.00666264]]\n",
            "Step: 3863 -> Loss: 0.004862974397838116 -> Predictions: [[0.00401474]\n",
            " [0.9956442 ]\n",
            " [0.9956305 ]\n",
            " [0.0066623 ]]\n",
            "Step: 3864 -> Loss: 0.004862725734710693 -> Predictions: [[0.00401455]\n",
            " [0.99564433]\n",
            " [0.99563074]\n",
            " [0.00666195]]\n",
            "Step: 3865 -> Loss: 0.004862476605921984 -> Predictions: [[0.00401435]\n",
            " [0.99564457]\n",
            " [0.995631  ]\n",
            " [0.0066616 ]]\n",
            "Step: 3866 -> Loss: 0.004862227477133274 -> Predictions: [[0.00401416]\n",
            " [0.9956448 ]\n",
            " [0.9956312 ]\n",
            " [0.00666126]]\n",
            "Step: 3867 -> Loss: 0.004861979745328426 -> Predictions: [[0.00401396]\n",
            " [0.99564505]\n",
            " [0.99563134]\n",
            " [0.00666091]]\n",
            "Step: 3868 -> Loss: 0.004861731082201004 -> Predictions: [[0.00401377]\n",
            " [0.9956453 ]\n",
            " [0.9956316 ]\n",
            " [0.00666056]]\n",
            "Step: 3869 -> Loss: 0.00486148102208972 -> Predictions: [[0.00401357]\n",
            " [0.9956455 ]\n",
            " [0.9956318 ]\n",
            " [0.00666021]]\n",
            "Step: 3870 -> Loss: 0.004861232824623585 -> Predictions: [[0.00401337]\n",
            " [0.9956457 ]\n",
            " [0.99563205]\n",
            " [0.00665987]]\n",
            "Step: 3871 -> Loss: 0.004860983695834875 -> Predictions: [[0.00401318]\n",
            " [0.99564594]\n",
            " [0.99563223]\n",
            " [0.00665951]]\n",
            "Step: 3872 -> Loss: 0.004860734101384878 -> Predictions: [[0.00401298]\n",
            " [0.9956462 ]\n",
            " [0.99563247]\n",
            " [0.00665917]]\n",
            "Step: 3873 -> Loss: 0.004860486835241318 -> Predictions: [[0.00401278]\n",
            " [0.9956463 ]\n",
            " [0.9956327 ]\n",
            " [0.00665882]]\n",
            "Step: 3874 -> Loss: 0.004860235843807459 -> Predictions: [[0.00401259]\n",
            " [0.99564654]\n",
            " [0.99563295]\n",
            " [0.00665847]]\n",
            "Step: 3875 -> Loss: 0.004859986715018749 -> Predictions: [[0.00401239]\n",
            " [0.9956468 ]\n",
            " [0.99563307]\n",
            " [0.00665812]]\n",
            "Step: 3876 -> Loss: 0.004859739448875189 -> Predictions: [[0.0040122 ]\n",
            " [0.995647  ]\n",
            " [0.9956333 ]\n",
            " [0.00665778]]\n",
            "Step: 3877 -> Loss: 0.004859488923102617 -> Predictions: [[0.004012  ]\n",
            " [0.99564725]\n",
            " [0.99563354]\n",
            " [0.00665743]]\n",
            "Step: 3878 -> Loss: 0.004859239794313908 -> Predictions: [[0.0040118 ]\n",
            " [0.9956475 ]\n",
            " [0.9956338 ]\n",
            " [0.00665708]]\n",
            "Step: 3879 -> Loss: 0.004858991131186485 -> Predictions: [[0.00401161]\n",
            " [0.9956477 ]\n",
            " [0.995634  ]\n",
            " [0.00665673]]\n",
            "Step: 3880 -> Loss: 0.004858741536736488 -> Predictions: [[0.00401141]\n",
            " [0.99564797]\n",
            " [0.99563426]\n",
            " [0.00665638]]\n",
            "Step: 3881 -> Loss: 0.0048584965988993645 -> Predictions: [[0.00401122]\n",
            " [0.9956482 ]\n",
            " [0.9956345 ]\n",
            " [0.00665605]]\n",
            "Step: 3882 -> Loss: 0.004858246073126793 -> Predictions: [[0.00401102]\n",
            " [0.9956483 ]\n",
            " [0.99563473]\n",
            " [0.00665569]]\n",
            "Step: 3883 -> Loss: 0.004857998341321945 -> Predictions: [[0.00401082]\n",
            " [0.99564856]\n",
            " [0.995635  ]\n",
            " [0.00665535]]\n",
            "Step: 3884 -> Loss: 0.004857746884226799 -> Predictions: [[0.00401063]\n",
            " [0.9956488 ]\n",
            " [0.9956352 ]\n",
            " [0.00665499]]\n",
            "Step: 3885 -> Loss: 0.004857500549405813 -> Predictions: [[0.00401043]\n",
            " [0.99564904]\n",
            " [0.99563533]\n",
            " [0.00665465]]\n",
            "Step: 3886 -> Loss: 0.004857251420617104 -> Predictions: [[0.00401024]\n",
            " [0.9956493 ]\n",
            " [0.99563557]\n",
            " [0.00665431]]\n",
            "Step: 3887 -> Loss: 0.004857004154473543 -> Predictions: [[0.00401004]\n",
            " [0.9956495 ]\n",
            " [0.9956358 ]\n",
            " [0.00665396]]\n",
            "Step: 3888 -> Loss: 0.004856755957007408 -> Predictions: [[0.00400985]\n",
            " [0.99564976]\n",
            " [0.99563605]\n",
            " [0.00665361]]\n",
            "Step: 3889 -> Loss: 0.004856505896896124 -> Predictions: [[0.00400965]\n",
            " [0.99565   ]\n",
            " [0.9956363 ]\n",
            " [0.00665326]]\n",
            "Step: 3890 -> Loss: 0.0048562586307525635 -> Predictions: [[0.00400946]\n",
            " [0.9956501 ]\n",
            " [0.9956365 ]\n",
            " [0.00665292]]\n",
            "Step: 3891 -> Loss: 0.004856010898947716 -> Predictions: [[0.00400926]\n",
            " [0.99565035]\n",
            " [0.99563676]\n",
            " [0.00665257]]\n",
            "Step: 3892 -> Loss: 0.00485575944185257 -> Predictions: [[0.00400906]\n",
            " [0.9956506 ]\n",
            " [0.995637  ]\n",
            " [0.00665222]]\n",
            "Step: 3893 -> Loss: 0.004855511710047722 -> Predictions: [[0.00400887]\n",
            " [0.9956508 ]\n",
            " [0.99563724]\n",
            " [0.00665187]]\n",
            "Step: 3894 -> Loss: 0.0048552630469202995 -> Predictions: [[0.00400867]\n",
            " [0.99565107]\n",
            " [0.9956375 ]\n",
            " [0.00665153]]\n",
            "Step: 3895 -> Loss: 0.004855013452470303 -> Predictions: [[0.00400847]\n",
            " [0.9956513 ]\n",
            " [0.9956376 ]\n",
            " [0.00665118]]\n",
            "Step: 3896 -> Loss: 0.004854761529713869 -> Predictions: [[0.00400828]\n",
            " [0.99565154]\n",
            " [0.99563783]\n",
            " [0.00665083]]\n",
            "Step: 3897 -> Loss: 0.004854516126215458 -> Predictions: [[0.00400808]\n",
            " [0.9956518 ]\n",
            " [0.9956381 ]\n",
            " [0.00665049]]\n",
            "Step: 3898 -> Loss: 0.004854266531765461 -> Predictions: [[0.00400788]\n",
            " [0.995652  ]\n",
            " [0.9956383 ]\n",
            " [0.00665013]]\n",
            "Step: 3899 -> Loss: 0.004854016937315464 -> Predictions: [[0.00400769]\n",
            " [0.99565214]\n",
            " [0.99563855]\n",
            " [0.00664979]]\n",
            "Step: 3900 -> Loss: 0.004853768274188042 -> Predictions: [[0.00400749]\n",
            " [0.9956524 ]\n",
            " [0.9956388 ]\n",
            " [0.00664944]]\n",
            "Step: 3901 -> Loss: 0.004853519145399332 -> Predictions: [[0.0040073 ]\n",
            " [0.99565256]\n",
            " [0.99563897]\n",
            " [0.00664909]]\n",
            "Step: 3902 -> Loss: 0.004853269085288048 -> Predictions: [[0.0040071 ]\n",
            " [0.9956528 ]\n",
            " [0.9956392 ]\n",
            " [0.00664875]]\n",
            "Step: 3903 -> Loss: 0.004853022284805775 -> Predictions: [[0.0040069 ]\n",
            " [0.99565303]\n",
            " [0.99563944]\n",
            " [0.0066484 ]]\n",
            "Step: 3904 -> Loss: 0.004852775949984789 -> Predictions: [[0.00400672]\n",
            " [0.9956533 ]\n",
            " [0.99563956]\n",
            " [0.00664805]]\n",
            "Step: 3905 -> Loss: 0.004852525889873505 -> Predictions: [[0.00400651]\n",
            " [0.9956535 ]\n",
            " [0.9956398 ]\n",
            " [0.00664771]]\n",
            "Step: 3906 -> Loss: 0.004852278158068657 -> Predictions: [[0.00400632]\n",
            " [0.99565375]\n",
            " [0.99564004]\n",
            " [0.00664736]]\n",
            "Step: 3907 -> Loss: 0.004852031357586384 -> Predictions: [[0.00400613]\n",
            " [0.995654  ]\n",
            " [0.9956403 ]\n",
            " [0.00664701]]\n",
            "Step: 3908 -> Loss: 0.0048517826944589615 -> Predictions: [[0.00400593]\n",
            " [0.9956541 ]\n",
            " [0.9956405 ]\n",
            " [0.00664667]]\n",
            "Step: 3909 -> Loss: 0.004851534962654114 -> Predictions: [[0.00400573]\n",
            " [0.99565434]\n",
            " [0.99564075]\n",
            " [0.00664632]]\n",
            "Step: 3910 -> Loss: 0.004851286765187979 -> Predictions: [[0.00400554]\n",
            " [0.9956546 ]\n",
            " [0.995641  ]\n",
            " [0.00664597]]\n",
            "Step: 3911 -> Loss: 0.0048510367050766945 -> Predictions: [[0.00400534]\n",
            " [0.9956548 ]\n",
            " [0.99564123]\n",
            " [0.00664563]]\n",
            "Step: 3912 -> Loss: 0.004850787576287985 -> Predictions: [[0.00400515]\n",
            " [0.99565506]\n",
            " [0.99564147]\n",
            " [0.00664528]]\n",
            "Step: 3913 -> Loss: 0.004850541707128286 -> Predictions: [[0.00400495]\n",
            " [0.9956553 ]\n",
            " [0.9956416 ]\n",
            " [0.00664494]]\n",
            "Step: 3914 -> Loss: 0.00485029025003314 -> Predictions: [[0.00400475]\n",
            " [0.99565554]\n",
            " [0.9956418 ]\n",
            " [0.00664458]]\n",
            "Step: 3915 -> Loss: 0.004850046243518591 -> Predictions: [[0.00400456]\n",
            " [0.9956558 ]\n",
            " [0.99564207]\n",
            " [0.00664424]]\n",
            "Step: 3916 -> Loss: 0.004849798046052456 -> Predictions: [[0.00400436]\n",
            " [0.9956559 ]\n",
            " [0.9956423 ]\n",
            " [0.0066439 ]]\n",
            "Step: 3917 -> Loss: 0.0048495447263121605 -> Predictions: [[0.00400417]\n",
            " [0.99565613]\n",
            " [0.99564254]\n",
            " [0.00664354]]\n",
            "Step: 3918 -> Loss: 0.004849298857152462 -> Predictions: [[0.00400398]\n",
            " [0.9956564 ]\n",
            " [0.9956428 ]\n",
            " [0.0066432 ]]\n",
            "Step: 3919 -> Loss: 0.004849051125347614 -> Predictions: [[0.00400378]\n",
            " [0.9956566 ]\n",
            " [0.995643  ]\n",
            " [0.00664285]]\n",
            "Step: 3920 -> Loss: 0.004848801530897617 -> Predictions: [[0.00400358]\n",
            " [0.99565685]\n",
            " [0.99564326]\n",
            " [0.0066425 ]]\n",
            "Step: 3921 -> Loss: 0.004848552402108908 -> Predictions: [[0.00400338]\n",
            " [0.9956571 ]\n",
            " [0.9956435 ]\n",
            " [0.00664216]]\n",
            "Step: 3922 -> Loss: 0.00484830467030406 -> Predictions: [[0.00400319]\n",
            " [0.9956573 ]\n",
            " [0.9956436 ]\n",
            " [0.00664181]]\n",
            "Step: 3923 -> Loss: 0.0048480574041605 -> Predictions: [[0.00400299]\n",
            " [0.99565756]\n",
            " [0.99564385]\n",
            " [0.00664147]]\n",
            "Step: 3924 -> Loss: 0.00484780827537179 -> Predictions: [[0.00400279]\n",
            " [0.9956578 ]\n",
            " [0.9956441 ]\n",
            " [0.00664112]]\n",
            "Step: 3925 -> Loss: 0.0048475610092282295 -> Predictions: [[0.0040026 ]\n",
            " [0.9956579 ]\n",
            " [0.99564433]\n",
            " [0.00664077]]\n",
            "Step: 3926 -> Loss: 0.004847313277423382 -> Predictions: [[0.00400241]\n",
            " [0.99565816]\n",
            " [0.99564457]\n",
            " [0.00664043]]\n",
            "Step: 3927 -> Loss: 0.004847065079957247 -> Predictions: [[0.00400222]\n",
            " [0.9956584 ]\n",
            " [0.9956448 ]\n",
            " [0.00664007]]\n",
            "Step: 3928 -> Loss: 0.004846813157200813 -> Predictions: [[0.00400202]\n",
            " [0.99565864]\n",
            " [0.99564505]\n",
            " [0.00663972]]\n",
            "Step: 3929 -> Loss: 0.004846570082008839 -> Predictions: [[0.00400183]\n",
            " [0.9956589 ]\n",
            " [0.9956453 ]\n",
            " [0.00663939]]\n",
            "Step: 3930 -> Loss: 0.004846322350203991 -> Predictions: [[0.00400163]\n",
            " [0.9956591 ]\n",
            " [0.9956455 ]\n",
            " [0.00663904]]\n",
            "Step: 3931 -> Loss: 0.004846073221415281 -> Predictions: [[0.00400143]\n",
            " [0.9956593 ]\n",
            " [0.9956456 ]\n",
            " [0.00663869]]\n",
            "Step: 3932 -> Loss: 0.00484582269564271 -> Predictions: [[0.00400123]\n",
            " [0.99565953]\n",
            " [0.9956458 ]\n",
            " [0.00663834]]\n",
            "Step: 3933 -> Loss: 0.004845573566854 -> Predictions: [[0.00400104]\n",
            " [0.99565965]\n",
            " [0.99564606]\n",
            " [0.006638  ]]\n",
            "Step: 3934 -> Loss: 0.004845325835049152 -> Predictions: [[0.00400084]\n",
            " [0.9956599 ]\n",
            " [0.9956463 ]\n",
            " [0.00663765]]\n",
            "Step: 3935 -> Loss: 0.004845080431550741 -> Predictions: [[0.00400065]\n",
            " [0.9956601 ]\n",
            " [0.99564654]\n",
            " [0.0066373 ]]\n",
            "Step: 3936 -> Loss: 0.004844830837100744 -> Predictions: [[0.00400045]\n",
            " [0.99566036]\n",
            " [0.9956468 ]\n",
            " [0.00663696]]\n",
            "Step: 3937 -> Loss: 0.004844582173973322 -> Predictions: [[0.00400026]\n",
            " [0.9956606 ]\n",
            " [0.995647  ]\n",
            " [0.00663661]]\n",
            "Step: 3938 -> Loss: 0.00484433863312006 -> Predictions: [[0.00400007]\n",
            " [0.99566084]\n",
            " [0.99564725]\n",
            " [0.00663627]]\n",
            "Step: 3939 -> Loss: 0.004844089969992638 -> Predictions: [[0.00399987]\n",
            " [0.9956611 ]\n",
            " [0.9956475 ]\n",
            " [0.00663592]]\n",
            "Step: 3940 -> Loss: 0.004843841306865215 -> Predictions: [[0.00399968]\n",
            " [0.9956613 ]\n",
            " [0.9956476 ]\n",
            " [0.00663557]]\n",
            "Step: 3941 -> Loss: 0.004843590781092644 -> Predictions: [[0.00399947]\n",
            " [0.99566156]\n",
            " [0.99564785]\n",
            " [0.00663523]]\n",
            "Step: 3942 -> Loss: 0.004843341652303934 -> Predictions: [[0.00399928]\n",
            " [0.9956617 ]\n",
            " [0.9956481 ]\n",
            " [0.00663488]]\n",
            "Step: 3943 -> Loss: 0.004843092989176512 -> Predictions: [[0.00399908]\n",
            " [0.9956619 ]\n",
            " [0.9956483 ]\n",
            " [0.00663453]]\n",
            "Step: 3944 -> Loss: 0.004842846654355526 -> Predictions: [[0.00399889]\n",
            " [0.99566215]\n",
            " [0.99564856]\n",
            " [0.00663419]]\n",
            "Step: 3945 -> Loss: 0.00484260031953454 -> Predictions: [[0.0039987 ]\n",
            " [0.9956624 ]\n",
            " [0.9956488 ]\n",
            " [0.00663384]]\n",
            "Step: 3946 -> Loss: 0.004842353519052267 -> Predictions: [[0.0039985 ]\n",
            " [0.9956626 ]\n",
            " [0.99564904]\n",
            " [0.00663349]]\n",
            "Step: 3947 -> Loss: 0.0048421043902635574 -> Predictions: [[0.0039983 ]\n",
            " [0.99566287]\n",
            " [0.9956493 ]\n",
            " [0.00663315]]\n",
            "Step: 3948 -> Loss: 0.004841857589781284 -> Predictions: [[0.00399811]\n",
            " [0.9956631 ]\n",
            " [0.9956495 ]\n",
            " [0.0066328 ]]\n",
            "Step: 3949 -> Loss: 0.0048416065983474255 -> Predictions: [[0.00399791]\n",
            " [0.99566334]\n",
            " [0.99564964]\n",
            " [0.00663246]]\n",
            "Step: 3950 -> Loss: 0.004841360729187727 -> Predictions: [[0.00399772]\n",
            " [0.99566346]\n",
            " [0.9956499 ]\n",
            " [0.00663211]]\n",
            "Step: 3951 -> Loss: 0.004841112531721592 -> Predictions: [[0.00399752]\n",
            " [0.9956637 ]\n",
            " [0.9956501 ]\n",
            " [0.00663176]]\n",
            "Step: 3952 -> Loss: 0.004840864334255457 -> Predictions: [[0.00399733]\n",
            " [0.99566394]\n",
            " [0.99565035]\n",
            " [0.00663141]]\n",
            "Step: 3953 -> Loss: 0.004840615205466747 -> Predictions: [[0.00399713]\n",
            " [0.9956642 ]\n",
            " [0.9956506 ]\n",
            " [0.00663106]]\n",
            "Step: 3954 -> Loss: 0.004840367939323187 -> Predictions: [[0.00399694]\n",
            " [0.9956644 ]\n",
            " [0.9956508 ]\n",
            " [0.00663072]]\n",
            "Step: 3955 -> Loss: 0.0048401206731796265 -> Predictions: [[0.00399675]\n",
            " [0.99566466]\n",
            " [0.99565107]\n",
            " [0.00663038]]\n",
            "Step: 3956 -> Loss: 0.004839875269681215 -> Predictions: [[0.00399655]\n",
            " [0.9956649 ]\n",
            " [0.9956513 ]\n",
            " [0.00663004]]\n",
            "Step: 3957 -> Loss: 0.004839626606553793 -> Predictions: [[0.00399635]\n",
            " [0.99566513]\n",
            " [0.99565154]\n",
            " [0.00662968]]\n",
            "Step: 3958 -> Loss: 0.004839377012103796 -> Predictions: [[0.00399616]\n",
            " [0.99566525]\n",
            " [0.99565166]\n",
            " [0.00662934]]\n",
            "Step: 3959 -> Loss: 0.004839127883315086 -> Predictions: [[0.00399596]\n",
            " [0.9956655 ]\n",
            " [0.9956519 ]\n",
            " [0.00662899]]\n",
            "Step: 3960 -> Loss: 0.004838881082832813 -> Predictions: [[0.00399577]\n",
            " [0.9956657 ]\n",
            " [0.99565214]\n",
            " [0.00662865]]\n",
            "Step: 3961 -> Loss: 0.004838635213673115 -> Predictions: [[0.00399557]\n",
            " [0.99566597]\n",
            " [0.9956524 ]\n",
            " [0.0066283 ]]\n",
            "Step: 3962 -> Loss: 0.004838388878852129 -> Predictions: [[0.00399538]\n",
            " [0.99566615]\n",
            " [0.99565256]\n",
            " [0.00662796]]\n",
            "Step: 3963 -> Loss: 0.00483813788741827 -> Predictions: [[0.00399518]\n",
            " [0.9956664 ]\n",
            " [0.9956528 ]\n",
            " [0.00662761]]\n",
            "Step: 3964 -> Loss: 0.00483789062127471 -> Predictions: [[0.00399499]\n",
            " [0.9956666 ]\n",
            " [0.99565303]\n",
            " [0.00662727]]\n",
            "Step: 3965 -> Loss: 0.004837641492486 -> Predictions: [[0.0039948 ]\n",
            " [0.99566686]\n",
            " [0.9956533 ]\n",
            " [0.00662691]]\n",
            "Step: 3966 -> Loss: 0.004837393760681152 -> Predictions: [[0.00399459]\n",
            " [0.995667  ]\n",
            " [0.9956535 ]\n",
            " [0.00662657]]\n",
            "Step: 3967 -> Loss: 0.004837146028876305 -> Predictions: [[0.0039944 ]\n",
            " [0.9956672 ]\n",
            " [0.9956536 ]\n",
            " [0.00662622]]\n",
            "Step: 3968 -> Loss: 0.004836900159716606 -> Predictions: [[0.00399421]\n",
            " [0.99566746]\n",
            " [0.99565387]\n",
            " [0.00662588]]\n",
            "Step: 3969 -> Loss: 0.004836650099605322 -> Predictions: [[0.00399401]\n",
            " [0.9956677 ]\n",
            " [0.9956541 ]\n",
            " [0.00662553]]\n",
            "Step: 3970 -> Loss: 0.004836404230445623 -> Predictions: [[0.00399381]\n",
            " [0.99566793]\n",
            " [0.99565434]\n",
            " [0.00662519]]\n",
            "Step: 3971 -> Loss: 0.004836155101656914 -> Predictions: [[0.00399362]\n",
            " [0.9956682 ]\n",
            " [0.9956546 ]\n",
            " [0.00662484]]\n",
            "Step: 3972 -> Loss: 0.004835909232497215 -> Predictions: [[0.00399342]\n",
            " [0.9956684 ]\n",
            " [0.9956548 ]\n",
            " [0.0066245 ]]\n",
            "Step: 3973 -> Loss: 0.0048356628976762295 -> Predictions: [[0.00399323]\n",
            " [0.99566865]\n",
            " [0.99565506]\n",
            " [0.00662415]]\n",
            "Step: 3974 -> Loss: 0.0048354147002100945 -> Predictions: [[0.00399303]\n",
            " [0.99566877]\n",
            " [0.9956553 ]\n",
            " [0.00662381]]\n",
            "Step: 3975 -> Loss: 0.004835165571421385 -> Predictions: [[0.00399284]\n",
            " [0.995669  ]\n",
            " [0.9956554 ]\n",
            " [0.00662346]]\n",
            "Step: 3976 -> Loss: 0.004834919702261686 -> Predictions: [[0.00399265]\n",
            " [0.99566925]\n",
            " [0.99565566]\n",
            " [0.00662311]]\n",
            "Step: 3977 -> Loss: 0.004834670573472977 -> Predictions: [[0.00399245]\n",
            " [0.9956695 ]\n",
            " [0.9956559 ]\n",
            " [0.00662276]]\n",
            "Step: 3978 -> Loss: 0.0048344191163778305 -> Predictions: [[0.00399225]\n",
            " [0.9956697 ]\n",
            " [0.99565613]\n",
            " [0.00662242]]\n",
            "Step: 3979 -> Loss: 0.0048341769725084305 -> Predictions: [[0.00399206]\n",
            " [0.99566996]\n",
            " [0.9956564 ]\n",
            " [0.00662207]]\n",
            "Step: 3980 -> Loss: 0.004833928309381008 -> Predictions: [[0.00399187]\n",
            " [0.9956702 ]\n",
            " [0.9956566 ]\n",
            " [0.00662173]]\n",
            "Step: 3981 -> Loss: 0.00483368057757616 -> Predictions: [[0.00399167]\n",
            " [0.99567044]\n",
            " [0.99565685]\n",
            " [0.00662138]]\n",
            "Step: 3982 -> Loss: 0.004833431914448738 -> Predictions: [[0.00399147]\n",
            " [0.9956707 ]\n",
            " [0.9956571 ]\n",
            " [0.00662104]]\n",
            "Step: 3983 -> Loss: 0.004833185579627752 -> Predictions: [[0.00399128]\n",
            " [0.9956708 ]\n",
            " [0.9956573 ]\n",
            " [0.00662069]]\n",
            "Step: 3984 -> Loss: 0.004832936450839043 -> Predictions: [[0.00399108]\n",
            " [0.99567103]\n",
            " [0.99565744]\n",
            " [0.00662035]]\n",
            "Step: 3985 -> Loss: 0.004832691513001919 -> Predictions: [[0.00399089]\n",
            " [0.9956713 ]\n",
            " [0.9956577 ]\n",
            " [0.00662   ]]\n",
            "Step: 3986 -> Loss: 0.004832444712519646 -> Predictions: [[0.00399069]\n",
            " [0.9956715 ]\n",
            " [0.9956579 ]\n",
            " [0.00661966]]\n",
            "Step: 3987 -> Loss: 0.00483219837769866 -> Predictions: [[0.00399048]\n",
            " [0.99567175]\n",
            " [0.99565816]\n",
            " [0.00661931]]\n",
            "Step: 3988 -> Loss: 0.004831950645893812 -> Predictions: [[0.00399029]\n",
            " [0.995672  ]\n",
            " [0.9956584 ]\n",
            " [0.00661896]]\n",
            "Step: 3989 -> Loss: 0.00483170710504055 -> Predictions: [[0.00399009]\n",
            " [0.9956721 ]\n",
            " [0.99565864]\n",
            " [0.00661862]]\n",
            "Step: 3990 -> Loss: 0.004831461235880852 -> Predictions: [[0.0039899 ]\n",
            " [0.99567235]\n",
            " [0.9956589 ]\n",
            " [0.00661827]]\n",
            "Step: 3991 -> Loss: 0.004831215366721153 -> Predictions: [[0.00398971]\n",
            " [0.9956726 ]\n",
            " [0.995659  ]\n",
            " [0.00661793]]\n",
            "Step: 3992 -> Loss: 0.00483096856623888 -> Predictions: [[0.00398951]\n",
            " [0.9956728 ]\n",
            " [0.99565923]\n",
            " [0.00661758]]\n",
            "Step: 3993 -> Loss: 0.004830725025385618 -> Predictions: [[0.00398932]\n",
            " [0.995673  ]\n",
            " [0.9956594 ]\n",
            " [0.00661723]]\n",
            "Step: 3994 -> Loss: 0.004830478224903345 -> Predictions: [[0.00398911]\n",
            " [0.99567324]\n",
            " [0.99565965]\n",
            " [0.00661689]]\n",
            "Step: 3995 -> Loss: 0.004830232821404934 -> Predictions: [[0.00398892]\n",
            " [0.9956735 ]\n",
            " [0.9956599 ]\n",
            " [0.00661655]]\n",
            "Step: 3996 -> Loss: 0.004829985089600086 -> Predictions: [[0.00398873]\n",
            " [0.9956736 ]\n",
            " [0.9956601 ]\n",
            " [0.00661619]]\n",
            "Step: 3997 -> Loss: 0.004829740151762962 -> Predictions: [[0.00398853]\n",
            " [0.99567384]\n",
            " [0.99566036]\n",
            " [0.00661585]]\n",
            "Step: 3998 -> Loss: 0.004829496145248413 -> Predictions: [[0.00398834]\n",
            " [0.9956741 ]\n",
            " [0.9956605 ]\n",
            " [0.00661551]]\n",
            "Step: 3999 -> Loss: 0.00482924934476614 -> Predictions: [[0.00398814]\n",
            " [0.9956743 ]\n",
            " [0.9956607 ]\n",
            " [0.00661516]]\n",
            "Step: 4001 -> Loss: 0.004828757606446743 -> Predictions: [[0.00398775]\n",
            " [0.9956748 ]\n",
            " [0.9956612 ]\n",
            " [0.00661446]]\n",
            "Step: 4002 -> Loss: 0.0048285131342709064 -> Predictions: [[0.00398756]\n",
            " [0.9956749 ]\n",
            " [0.99566144]\n",
            " [0.00661412]]\n",
            "Step: 4003 -> Loss: 0.00482826866209507 -> Predictions: [[0.00398737]\n",
            " [0.99567515]\n",
            " [0.9956617 ]\n",
            " [0.00661378]]\n",
            "Step: 4004 -> Loss: 0.004828024189919233 -> Predictions: [[0.00398717]\n",
            " [0.9956754 ]\n",
            " [0.9956618 ]\n",
            " [0.00661343]]\n",
            "Step: 4005 -> Loss: 0.004827778786420822 -> Predictions: [[0.00398697]\n",
            " [0.9956756 ]\n",
            " [0.99566203]\n",
            " [0.00661308]]\n",
            "Step: 4006 -> Loss: 0.004827531520277262 -> Predictions: [[0.00398677]\n",
            " [0.99567586]\n",
            " [0.9956623 ]\n",
            " [0.00661274]]\n",
            "Step: 4007 -> Loss: 0.004827284719794989 -> Predictions: [[0.00398658]\n",
            " [0.9956761 ]\n",
            " [0.9956625 ]\n",
            " [0.00661239]]\n",
            "Step: 4008 -> Loss: 0.004827041178941727 -> Predictions: [[0.00398639]\n",
            " [0.9956762 ]\n",
            " [0.99566275]\n",
            " [0.00661205]]\n",
            "Step: 4009 -> Loss: 0.00482679670676589 -> Predictions: [[0.00398619]\n",
            " [0.99567646]\n",
            " [0.995663  ]\n",
            " [0.0066117 ]]\n",
            "Step: 4010 -> Loss: 0.004826551768928766 -> Predictions: [[0.003986  ]\n",
            " [0.9956767 ]\n",
            " [0.9956632 ]\n",
            " [0.00661137]]\n",
            "Step: 4011 -> Loss: 0.004826304968446493 -> Predictions: [[0.0039858 ]\n",
            " [0.99567693]\n",
            " [0.99566334]\n",
            " [0.00661102]]\n",
            "Step: 4012 -> Loss: 0.004826060030609369 -> Predictions: [[0.00398561]\n",
            " [0.9956772 ]\n",
            " [0.9956636 ]\n",
            " [0.00661067]]\n",
            "Step: 4013 -> Loss: 0.004825815558433533 -> Predictions: [[0.00398541]\n",
            " [0.9956774 ]\n",
            " [0.9956638 ]\n",
            " [0.00661032]]\n",
            "Step: 4014 -> Loss: 0.004825571086257696 -> Predictions: [[0.00398522]\n",
            " [0.99567753]\n",
            " [0.99566406]\n",
            " [0.00660997]]\n",
            "Step: 4015 -> Loss: 0.004825322423130274 -> Predictions: [[0.00398503]\n",
            " [0.99567777]\n",
            " [0.9956643 ]\n",
            " [0.00660963]]\n",
            "Step: 4016 -> Loss: 0.004825081210583448 -> Predictions: [[0.00398483]\n",
            " [0.995678  ]\n",
            " [0.99566454]\n",
            " [0.00660929]]\n",
            "Step: 4017 -> Loss: 0.004824834875762463 -> Predictions: [[0.00398464]\n",
            " [0.99567825]\n",
            " [0.9956648 ]\n",
            " [0.00660894]]\n",
            "Step: 4018 -> Loss: 0.004824589006602764 -> Predictions: [[0.00398444]\n",
            " [0.9956785 ]\n",
            " [0.9956649 ]\n",
            " [0.0066086 ]]\n",
            "Step: 4019 -> Loss: 0.004824342671781778 -> Predictions: [[0.00398425]\n",
            " [0.9956787 ]\n",
            " [0.99566513]\n",
            " [0.00660825]]\n",
            "Step: 4020 -> Loss: 0.004824097268283367 -> Predictions: [[0.00398405]\n",
            " [0.99567896]\n",
            " [0.9956654 ]\n",
            " [0.0066079 ]]\n",
            "Step: 4021 -> Loss: 0.004823850467801094 -> Predictions: [[0.00398386]\n",
            " [0.9956791 ]\n",
            " [0.9956656 ]\n",
            " [0.00660755]]\n",
            "Step: 4022 -> Loss: 0.0048236059956252575 -> Predictions: [[0.00398366]\n",
            " [0.9956793 ]\n",
            " [0.99566585]\n",
            " [0.00660721]]\n",
            "Step: 4023 -> Loss: 0.004823360126465559 -> Predictions: [[0.00398346]\n",
            " [0.99567956]\n",
            " [0.995666  ]\n",
            " [0.00660687]]\n",
            "Step: 4024 -> Loss: 0.004823116585612297 -> Predictions: [[0.00398327]\n",
            " [0.99567974]\n",
            " [0.99566615]\n",
            " [0.00660653]]\n",
            "Step: 4025 -> Loss: 0.004822871647775173 -> Predictions: [[0.00398308]\n",
            " [0.99568   ]\n",
            " [0.9956664 ]\n",
            " [0.00660618]]\n",
            "Step: 4026 -> Loss: 0.004822626244276762 -> Predictions: [[0.00398289]\n",
            " [0.9956802 ]\n",
            " [0.9956666 ]\n",
            " [0.00660584]]\n",
            "Step: 4027 -> Loss: 0.0048223803751170635 -> Predictions: [[0.00398269]\n",
            " [0.99568033]\n",
            " [0.99566686]\n",
            " [0.00660549]]\n",
            "Step: 4028 -> Loss: 0.004822134971618652 -> Predictions: [[0.00398249]\n",
            " [0.9956806 ]\n",
            " [0.9956671 ]\n",
            " [0.00660515]]\n",
            "Step: 4029 -> Loss: 0.004821891896426678 -> Predictions: [[0.00398231]\n",
            " [0.9956808 ]\n",
            " [0.99566734]\n",
            " [0.00660481]]\n",
            "Step: 4030 -> Loss: 0.004821650218218565 -> Predictions: [[0.00398212]\n",
            " [0.99568105]\n",
            " [0.9956676 ]\n",
            " [0.00660447]]\n",
            "Step: 4031 -> Loss: 0.004821401089429855 -> Predictions: [[0.00398192]\n",
            " [0.9956813 ]\n",
            " [0.9956677 ]\n",
            " [0.00660413]]\n",
            "Step: 4032 -> Loss: 0.0048211561515927315 -> Predictions: [[0.00398173]\n",
            " [0.9956815 ]\n",
            " [0.99566793]\n",
            " [0.00660379]]\n",
            "Step: 4033 -> Loss: 0.004820911213755608 -> Predictions: [[0.00398153]\n",
            " [0.99568176]\n",
            " [0.9956682 ]\n",
            " [0.00660345]]\n",
            "Step: 4034 -> Loss: 0.004820665810257196 -> Predictions: [[0.00398135]\n",
            " [0.9956819 ]\n",
            " [0.9956684 ]\n",
            " [0.0066031 ]]\n",
            "Step: 4035 -> Loss: 0.0048204222694039345 -> Predictions: [[0.00398115]\n",
            " [0.9956821 ]\n",
            " [0.99566865]\n",
            " [0.00660276]]\n",
            "Step: 4036 -> Loss: 0.004820178262889385 -> Predictions: [[0.00398096]\n",
            " [0.99568236]\n",
            " [0.9956689 ]\n",
            " [0.00660242]]\n",
            "Step: 4037 -> Loss: 0.004819931462407112 -> Predictions: [[0.00398076]\n",
            " [0.9956826 ]\n",
            " [0.9956691 ]\n",
            " [0.00660208]]\n",
            "Step: 4038 -> Loss: 0.0048196883872151375 -> Predictions: [[0.00398057]\n",
            " [0.99568284]\n",
            " [0.99566936]\n",
            " [0.00660173]]\n",
            "Step: 4039 -> Loss: 0.004819444380700588 -> Predictions: [[0.00398038]\n",
            " [0.9956831 ]\n",
            " [0.9956695 ]\n",
            " [0.00660139]]\n",
            "Step: 4040 -> Loss: 0.00481919851154089 -> Predictions: [[0.00398018]\n",
            " [0.9956833 ]\n",
            " [0.9956697 ]\n",
            " [0.00660105]]\n",
            "Step: 4041 -> Loss: 0.004818954970687628 -> Predictions: [[0.00398   ]\n",
            " [0.99568343]\n",
            " [0.99566996]\n",
            " [0.00660071]]\n",
            "Step: 4042 -> Loss: 0.004818708170205355 -> Predictions: [[0.0039798 ]\n",
            " [0.99568367]\n",
            " [0.9956702 ]\n",
            " [0.00660037]]\n",
            "Step: 4043 -> Loss: 0.004818464629352093 -> Predictions: [[0.00397961]\n",
            " [0.9956839 ]\n",
            " [0.99567044]\n",
            " [0.00660002]]\n",
            "Step: 4044 -> Loss: 0.004818221554160118 -> Predictions: [[0.00397942]\n",
            " [0.99568415]\n",
            " [0.9956707 ]\n",
            " [0.00659968]]\n",
            "Step: 4045 -> Loss: 0.004817977547645569 -> Predictions: [[0.00397923]\n",
            " [0.9956844 ]\n",
            " [0.9956709 ]\n",
            " [0.00659934]]\n",
            "Step: 4046 -> Loss: 0.0048177302815020084 -> Predictions: [[0.00397904]\n",
            " [0.9956846 ]\n",
            " [0.99567103]\n",
            " [0.006599  ]]\n",
            "Step: 4047 -> Loss: 0.004817490000277758 -> Predictions: [[0.00397885]\n",
            " [0.99568486]\n",
            " [0.9956713 ]\n",
            " [0.00659866]]\n",
            "Step: 4048 -> Loss: 0.004817241337150335 -> Predictions: [[0.00397864]\n",
            " [0.995685  ]\n",
            " [0.9956715 ]\n",
            " [0.00659832]]\n",
            "Step: 4049 -> Loss: 0.004816993605345488 -> Predictions: [[0.00397845]\n",
            " [0.9956852 ]\n",
            " [0.99567175]\n",
            " [0.00659797]]\n",
            "Step: 4050 -> Loss: 0.004816751927137375 -> Predictions: [[0.00397826]\n",
            " [0.99568546]\n",
            " [0.995672  ]\n",
            " [0.00659764]]\n",
            "Step: 4051 -> Loss: 0.004816507920622826 -> Predictions: [[0.00397807]\n",
            " [0.9956857 ]\n",
            " [0.9956722 ]\n",
            " [0.0065973 ]]\n",
            "Step: 4052 -> Loss: 0.004816263914108276 -> Predictions: [[0.00397788]\n",
            " [0.99568594]\n",
            " [0.99567246]\n",
            " [0.00659696]]\n",
            "Step: 4053 -> Loss: 0.004816020838916302 -> Predictions: [[0.00397769]\n",
            " [0.9956862 ]\n",
            " [0.9956727 ]\n",
            " [0.00659662]]\n",
            "Step: 4054 -> Loss: 0.0048157754354178905 -> Predictions: [[0.0039775 ]\n",
            " [0.9956864 ]\n",
            " [0.9956728 ]\n",
            " [0.00659627]]\n",
            "Step: 4055 -> Loss: 0.004815533757209778 -> Predictions: [[0.0039773 ]\n",
            " [0.99568653]\n",
            " [0.995673  ]\n",
            " [0.00659594]]\n",
            "Step: 4056 -> Loss: 0.004815288353711367 -> Predictions: [[0.00397712]\n",
            " [0.9956867 ]\n",
            " [0.99567324]\n",
            " [0.0065956 ]]\n",
            "Step: 4057 -> Loss: 0.00481504388153553 -> Predictions: [[0.00397692]\n",
            " [0.99568695]\n",
            " [0.9956735 ]\n",
            " [0.00659526]]\n",
            "Step: 4058 -> Loss: 0.004814797081053257 -> Predictions: [[0.00397672]\n",
            " [0.9956872 ]\n",
            " [0.9956737 ]\n",
            " [0.00659492]]\n",
            "Step: 4059 -> Loss: 0.004814554937183857 -> Predictions: [[0.00397654]\n",
            " [0.9956874 ]\n",
            " [0.99567395]\n",
            " [0.00659458]]\n",
            "Step: 4060 -> Loss: 0.004814311861991882 -> Predictions: [[0.00397635]\n",
            " [0.99568766]\n",
            " [0.9956742 ]\n",
            " [0.00659424]]\n",
            "Step: 4061 -> Loss: 0.004814065061509609 -> Predictions: [[0.00397615]\n",
            " [0.9956879 ]\n",
            " [0.9956743 ]\n",
            " [0.0065939 ]]\n",
            "Step: 4062 -> Loss: 0.004813820123672485 -> Predictions: [[0.00397596]\n",
            " [0.99568814]\n",
            " [0.99567455]\n",
            " [0.00659356]]\n",
            "Step: 4063 -> Loss: 0.00481357891112566 -> Predictions: [[0.00397577]\n",
            " [0.99568826]\n",
            " [0.9956748 ]\n",
            " [0.00659323]]\n",
            "Step: 4064 -> Loss: 0.004813333507627249 -> Predictions: [[0.00397558]\n",
            " [0.9956885 ]\n",
            " [0.995675  ]\n",
            " [0.00659288]]\n",
            "Step: 4065 -> Loss: 0.0048130895011126995 -> Predictions: [[0.00397538]\n",
            " [0.99568874]\n",
            " [0.99567527]\n",
            " [0.00659255]]\n",
            "Step: 4066 -> Loss: 0.004812843166291714 -> Predictions: [[0.00397519]\n",
            " [0.995689  ]\n",
            " [0.9956755 ]\n",
            " [0.00659221]]\n",
            "Step: 4067 -> Loss: 0.004812601953744888 -> Predictions: [[0.003975  ]\n",
            " [0.9956892 ]\n",
            " [0.99567574]\n",
            " [0.00659187]]\n",
            "Step: 4068 -> Loss: 0.0048123570159077644 -> Predictions: [[0.00397481]\n",
            " [0.99568945]\n",
            " [0.995676  ]\n",
            " [0.00659153]]\n",
            "Step: 4069 -> Loss: 0.0048121120780706406 -> Predictions: [[0.00397462]\n",
            " [0.9956897 ]\n",
            " [0.9956761 ]\n",
            " [0.00659119]]\n",
            "Step: 4070 -> Loss: 0.004811865743249655 -> Predictions: [[0.00397442]\n",
            " [0.9956898 ]\n",
            " [0.99567634]\n",
            " [0.00659084]]\n",
            "Step: 4071 -> Loss: 0.004811625927686691 -> Predictions: [[0.00397423]\n",
            " [0.99569005]\n",
            " [0.9956766 ]\n",
            " [0.00659051]]\n",
            "Step: 4072 -> Loss: 0.004811379127204418 -> Predictions: [[0.00397404]\n",
            " [0.9956903 ]\n",
            " [0.9956768 ]\n",
            " [0.00659016]]\n",
            "Step: 4073 -> Loss: 0.004811135586351156 -> Predictions: [[0.00397385]\n",
            " [0.9956905 ]\n",
            " [0.99567705]\n",
            " [0.00658983]]\n",
            "Step: 4074 -> Loss: 0.004810890648514032 -> Predictions: [[0.00397366]\n",
            " [0.99569076]\n",
            " [0.9956773 ]\n",
            " [0.00658948]]\n",
            "Step: 4075 -> Loss: 0.004810649435967207 -> Predictions: [[0.00397347]\n",
            " [0.995691  ]\n",
            " [0.9956774 ]\n",
            " [0.00658915]]\n",
            "Step: 4076 -> Loss: 0.0048104035668075085 -> Predictions: [[0.00397327]\n",
            " [0.99569124]\n",
            " [0.99567765]\n",
            " [0.00658881]]\n",
            "Step: 4077 -> Loss: 0.004810158163309097 -> Predictions: [[0.00397308]\n",
            " [0.99569136]\n",
            " [0.9956779 ]\n",
            " [0.00658847]]\n",
            "Step: 4078 -> Loss: 0.004809913691133261 -> Predictions: [[0.00397289]\n",
            " [0.9956916 ]\n",
            " [0.9956781 ]\n",
            " [0.00658813]]\n",
            "Step: 4079 -> Loss: 0.004809676203876734 -> Predictions: [[0.0039727 ]\n",
            " [0.99569184]\n",
            " [0.99567837]\n",
            " [0.00658781]]\n",
            "Step: 4080 -> Loss: 0.0048094275407493114 -> Predictions: [[0.0039725 ]\n",
            " [0.9956921 ]\n",
            " [0.9956786 ]\n",
            " [0.00658746]]\n",
            "Step: 4081 -> Loss: 0.0048091839998960495 -> Predictions: [[0.00397232]\n",
            " [0.9956923 ]\n",
            " [0.99567884]\n",
            " [0.00658712]]\n",
            "Step: 4082 -> Loss: 0.004808939527720213 -> Predictions: [[0.00397212]\n",
            " [0.99569255]\n",
            " [0.9956791 ]\n",
            " [0.00658678]]\n",
            "Step: 4083 -> Loss: 0.004808696918189526 -> Predictions: [[0.00397193]\n",
            " [0.9956928 ]\n",
            " [0.9956792 ]\n",
            " [0.00658644]]\n",
            "Step: 4084 -> Loss: 0.004808451980352402 -> Predictions: [[0.00397173]\n",
            " [0.9956929 ]\n",
            " [0.99567944]\n",
            " [0.0065861 ]]\n",
            "Step: 4085 -> Loss: 0.004808206111192703 -> Predictions: [[0.00397155]\n",
            " [0.99569315]\n",
            " [0.9956797 ]\n",
            " [0.00658576]]\n",
            "Step: 4086 -> Loss: 0.004807963036000729 -> Predictions: [[0.00397136]\n",
            " [0.9956934 ]\n",
            " [0.99567986]\n",
            " [0.00658542]]\n",
            "Step: 4087 -> Loss: 0.004807719029486179 -> Predictions: [[0.00397116]\n",
            " [0.99569356]\n",
            " [0.9956801 ]\n",
            " [0.00658508]]\n",
            "Step: 4088 -> Loss: 0.004807476885616779 -> Predictions: [[0.00397097]\n",
            " [0.9956938 ]\n",
            " [0.99568033]\n",
            " [0.00658475]]\n",
            "Step: 4089 -> Loss: 0.004807231482118368 -> Predictions: [[0.00397078]\n",
            " [0.99569404]\n",
            " [0.9956806 ]\n",
            " [0.00658441]]\n",
            "Step: 4090 -> Loss: 0.004806989338248968 -> Predictions: [[0.00397059]\n",
            " [0.9956943 ]\n",
            " [0.9956807 ]\n",
            " [0.00658407]]\n",
            "Step: 4091 -> Loss: 0.00480674346908927 -> Predictions: [[0.0039704 ]\n",
            " [0.9956945 ]\n",
            " [0.9956809 ]\n",
            " [0.00658373]]\n",
            "Step: 4092 -> Loss: 0.004806499928236008 -> Predictions: [[0.0039702 ]\n",
            " [0.99569464]\n",
            " [0.99568117]\n",
            " [0.00658339]]\n",
            "Step: 4093 -> Loss: 0.00480625731870532 -> Predictions: [[0.00397001]\n",
            " [0.9956949 ]\n",
            " [0.9956814 ]\n",
            " [0.00658304]]\n",
            "Step: 4094 -> Loss: 0.004806014243513346 -> Predictions: [[0.00396983]\n",
            " [0.9956951 ]\n",
            " [0.99568164]\n",
            " [0.0065827 ]]\n",
            "Step: 4095 -> Loss: 0.004805771633982658 -> Predictions: [[0.00396963]\n",
            " [0.99569535]\n",
            " [0.9956819 ]\n",
            " [0.00658236]]\n",
            "Step: 4096 -> Loss: 0.0048055266961455345 -> Predictions: [[0.00396944]\n",
            " [0.9956956 ]\n",
            " [0.9956821 ]\n",
            " [0.00658202]]\n",
            "Step: 4097 -> Loss: 0.0048052845522761345 -> Predictions: [[0.00396924]\n",
            " [0.9956958 ]\n",
            " [0.99568224]\n",
            " [0.00658167]]\n",
            "Step: 4098 -> Loss: 0.004805040545761585 -> Predictions: [[0.00396905]\n",
            " [0.99569595]\n",
            " [0.9956825 ]\n",
            " [0.00658133]]\n",
            "Step: 4099 -> Loss: 0.0048048002645373344 -> Predictions: [[0.00396886]\n",
            " [0.9956962 ]\n",
            " [0.9956827 ]\n",
            " [0.00658099]]\n",
            "Step: 4100 -> Loss: 0.004804553464055061 -> Predictions: [[0.00396867]\n",
            " [0.9956964 ]\n",
            " [0.99568295]\n",
            " [0.00658064]]\n",
            "Step: 4101 -> Loss: 0.004804310388863087 -> Predictions: [[0.00396848]\n",
            " [0.99569666]\n",
            " [0.9956832 ]\n",
            " [0.0065803 ]]\n",
            "Step: 4102 -> Loss: 0.004804070107638836 -> Predictions: [[0.00396829]\n",
            " [0.9956969 ]\n",
            " [0.9956833 ]\n",
            " [0.00657997]]\n",
            "Step: 4103 -> Loss: 0.004803824238479137 -> Predictions: [[0.00396809]\n",
            " [0.99569714]\n",
            " [0.99568355]\n",
            " [0.00657962]]\n",
            "Step: 4104 -> Loss: 0.004803580231964588 -> Predictions: [[0.0039679 ]\n",
            " [0.99569726]\n",
            " [0.9956838 ]\n",
            " [0.00657928]]\n",
            "Step: 4105 -> Loss: 0.0048033385537564754 -> Predictions: [[0.00396771]\n",
            " [0.9956975 ]\n",
            " [0.995684  ]\n",
            " [0.00657894]]\n",
            "Step: 4106 -> Loss: 0.004803094547241926 -> Predictions: [[0.00396752]\n",
            " [0.99569774]\n",
            " [0.99568427]\n",
            " [0.0065786 ]]\n",
            "Step: 4107 -> Loss: 0.004802849609404802 -> Predictions: [[0.00396732]\n",
            " [0.995698  ]\n",
            " [0.9956845 ]\n",
            " [0.00657825]]\n",
            "Step: 4108 -> Loss: 0.004802608862519264 -> Predictions: [[0.00396714]\n",
            " [0.9956982 ]\n",
            " [0.99568474]\n",
            " [0.00657792]]\n",
            "Step: 4109 -> Loss: 0.00480236392468214 -> Predictions: [[0.00396694]\n",
            " [0.99569845]\n",
            " [0.99568486]\n",
            " [0.00657757]]\n",
            "Step: 4110 -> Loss: 0.004802124109119177 -> Predictions: [[0.00396675]\n",
            " [0.9956986 ]\n",
            " [0.9956851 ]\n",
            " [0.00657724]]\n",
            "Step: 4111 -> Loss: 0.004801878705620766 -> Predictions: [[0.00396656]\n",
            " [0.9956988 ]\n",
            " [0.99568534]\n",
            " [0.0065769 ]]\n",
            "Step: 4112 -> Loss: 0.00480163749307394 -> Predictions: [[0.00396637]\n",
            " [0.99569905]\n",
            " [0.9956856 ]\n",
            " [0.00657656]]\n",
            "Step: 4113 -> Loss: 0.00480139022693038 -> Predictions: [[0.00396617]\n",
            " [0.9956993 ]\n",
            " [0.9956858 ]\n",
            " [0.00657621]]\n",
            "Step: 4114 -> Loss: 0.004801150411367416 -> Predictions: [[0.00396599]\n",
            " [0.9956995 ]\n",
            " [0.99568605]\n",
            " [0.00657587]]\n",
            "Step: 4115 -> Loss: 0.004800905007869005 -> Predictions: [[0.00396579]\n",
            " [0.99569976]\n",
            " [0.9956863 ]\n",
            " [0.00657553]]\n",
            "Step: 4116 -> Loss: 0.0048006633296608925 -> Predictions: [[0.0039656]\n",
            " [0.9956999]\n",
            " [0.9956864]\n",
            " [0.0065752]]\n",
            "Step: 4117 -> Loss: 0.004800416063517332 -> Predictions: [[0.00396541]\n",
            " [0.9957001 ]\n",
            " [0.9956866 ]\n",
            " [0.00657484]]\n",
            "Step: 4118 -> Loss: 0.0048001790419220924 -> Predictions: [[0.00396522]\n",
            " [0.99570036]\n",
            " [0.9956868 ]\n",
            " [0.00657451]]\n",
            "Step: 4119 -> Loss: 0.004799935035407543 -> Predictions: [[0.00396503]\n",
            " [0.99570054]\n",
            " [0.99568707]\n",
            " [0.00657417]]\n",
            "Step: 4120 -> Loss: 0.004799692891538143 -> Predictions: [[0.00396484]\n",
            " [0.9957008 ]\n",
            " [0.9956873 ]\n",
            " [0.00657383]]\n",
            "Step: 4121 -> Loss: 0.0047994498163461685 -> Predictions: [[0.00396465]\n",
            " [0.995701  ]\n",
            " [0.99568754]\n",
            " [0.00657349]]\n",
            "Step: 4122 -> Loss: 0.004799206741154194 -> Predictions: [[0.00396445]\n",
            " [0.99570113]\n",
            " [0.99568766]\n",
            " [0.00657315]]\n",
            "Step: 4123 -> Loss: 0.004798962734639645 -> Predictions: [[0.00396426]\n",
            " [0.9957014 ]\n",
            " [0.9956879 ]\n",
            " [0.00657281]]\n",
            "Step: 4124 -> Loss: 0.0047987219877541065 -> Predictions: [[0.00396407]\n",
            " [0.9957016 ]\n",
            " [0.99568814]\n",
            " [0.00657247]]\n",
            "Step: 4125 -> Loss: 0.004798475652933121 -> Predictions: [[0.00396388]\n",
            " [0.99570185]\n",
            " [0.9956884 ]\n",
            " [0.00657212]]\n",
            "Step: 4126 -> Loss: 0.0047982363030314445 -> Predictions: [[0.00396369]\n",
            " [0.9957021 ]\n",
            " [0.9956886 ]\n",
            " [0.00657179]]\n",
            "Step: 4127 -> Loss: 0.004797992296516895 -> Predictions: [[0.0039635 ]\n",
            " [0.9957023 ]\n",
            " [0.99568886]\n",
            " [0.00657145]]\n",
            "Step: 4128 -> Loss: 0.004797747358679771 -> Predictions: [[0.00396331]\n",
            " [0.99570245]\n",
            " [0.9956891 ]\n",
            " [0.00657111]]\n",
            "Step: 4129 -> Loss: 0.004797507077455521 -> Predictions: [[0.00396312]\n",
            " [0.9957027 ]\n",
            " [0.9956892 ]\n",
            " [0.00657077]]\n",
            "Step: 4130 -> Loss: 0.004797264933586121 -> Predictions: [[0.00396293]\n",
            " [0.9957029 ]\n",
            " [0.99568945]\n",
            " [0.00657043]]\n",
            "Step: 4131 -> Loss: 0.004797019995748997 -> Predictions: [[0.00396273]\n",
            " [0.99570316]\n",
            " [0.9956897 ]\n",
            " [0.00657008]]\n",
            "Step: 4132 -> Loss: 0.004796778783202171 -> Predictions: [[0.00396254]\n",
            " [0.9957034 ]\n",
            " [0.9956899 ]\n",
            " [0.00656975]]\n",
            "Step: 4133 -> Loss: 0.004796534311026335 -> Predictions: [[0.00396235]\n",
            " [0.99570364]\n",
            " [0.99569017]\n",
            " [0.0065694 ]]\n",
            "Step: 4134 -> Loss: 0.004796291701495647 -> Predictions: [[0.00396216]\n",
            " [0.99570376]\n",
            " [0.9956904 ]\n",
            " [0.00656907]]\n",
            "Step: 4135 -> Loss: 0.004796050023287535 -> Predictions: [[0.00396197]\n",
            " [0.995704  ]\n",
            " [0.9956905 ]\n",
            " [0.00656873]]\n",
            "Step: 4136 -> Loss: 0.0047958046197891235 -> Predictions: [[0.00396178]\n",
            " [0.99570423]\n",
            " [0.99569076]\n",
            " [0.00656838]]\n",
            "Step: 4137 -> Loss: 0.004795565269887447 -> Predictions: [[0.00396158]\n",
            " [0.9957045 ]\n",
            " [0.995691  ]\n",
            " [0.00656805]]\n",
            "Step: 4138 -> Loss: 0.004795323126018047 -> Predictions: [[0.00396139]\n",
            " [0.9957047 ]\n",
            " [0.99569124]\n",
            " [0.00656771]]\n",
            "Step: 4139 -> Loss: 0.0047950781881809235 -> Predictions: [[0.0039612 ]\n",
            " [0.99570495]\n",
            " [0.9956915 ]\n",
            " [0.00656737]]\n",
            "Step: 4140 -> Loss: 0.004794837441295385 -> Predictions: [[0.00396101]\n",
            " [0.99570507]\n",
            " [0.9956917 ]\n",
            " [0.00656703]]\n",
            "Step: 4141 -> Loss: 0.004794592969119549 -> Predictions: [[0.00396082]\n",
            " [0.9957053 ]\n",
            " [0.99569184]\n",
            " [0.00656668]]\n",
            "Step: 4142 -> Loss: 0.004794350825250149 -> Predictions: [[0.00396063]\n",
            " [0.99570554]\n",
            " [0.9956921 ]\n",
            " [0.00656635]]\n",
            "Step: 4143 -> Loss: 0.004794105421751738 -> Predictions: [[0.00396043]\n",
            " [0.9957058 ]\n",
            " [0.9956923 ]\n",
            " [0.006566  ]]\n",
            "Step: 4144 -> Loss: 0.004793863277882338 -> Predictions: [[0.00396024]\n",
            " [0.995706  ]\n",
            " [0.99569255]\n",
            " [0.00656566]]\n",
            "Step: 4145 -> Loss: 0.004793622996658087 -> Predictions: [[0.00396006]\n",
            " [0.99570626]\n",
            " [0.9956928 ]\n",
            " [0.00656532]]\n",
            "Step: 4146 -> Loss: 0.004793376196175814 -> Predictions: [[0.00395985]\n",
            " [0.9957064 ]\n",
            " [0.995693  ]\n",
            " [0.00656498]]\n",
            "Step: 4147 -> Loss: 0.00479313638061285 -> Predictions: [[0.00395967]\n",
            " [0.9957066 ]\n",
            " [0.99569327]\n",
            " [0.00656464]]\n",
            "Step: 4148 -> Loss: 0.004792892374098301 -> Predictions: [[0.00395948]\n",
            " [0.99570686]\n",
            " [0.9956934 ]\n",
            " [0.0065643 ]]\n",
            "Step: 4149 -> Loss: 0.00479265209287405 -> Predictions: [[0.00395929]\n",
            " [0.9957071 ]\n",
            " [0.99569356]\n",
            " [0.00656396]]\n",
            "Step: 4150 -> Loss: 0.004792410414665937 -> Predictions: [[0.00395909]\n",
            " [0.9957073 ]\n",
            " [0.9956938 ]\n",
            " [0.00656363]]\n",
            "Step: 4151 -> Loss: 0.0047921668738126755 -> Predictions: [[0.0039589 ]\n",
            " [0.9957075 ]\n",
            " [0.99569404]\n",
            " [0.00656328]]\n",
            "Step: 4152 -> Loss: 0.004791926126927137 -> Predictions: [[0.00395872]\n",
            " [0.99570763]\n",
            " [0.9956943 ]\n",
            " [0.00656294]]\n",
            "Step: 4153 -> Loss: 0.004791681654751301 -> Predictions: [[0.00395853]\n",
            " [0.99570787]\n",
            " [0.9956945 ]\n",
            " [0.0065626 ]]\n",
            "Step: 4154 -> Loss: 0.00479144137352705 -> Predictions: [[0.00395833]\n",
            " [0.9957081 ]\n",
            " [0.99569464]\n",
            " [0.00656227]]\n",
            "Step: 4155 -> Loss: 0.004791197367012501 -> Predictions: [[0.00395814]\n",
            " [0.99570835]\n",
            " [0.9956949 ]\n",
            " [0.00656192]]\n",
            "Step: 4156 -> Loss: 0.004790955223143101 -> Predictions: [[0.00395795]\n",
            " [0.9957086 ]\n",
            " [0.9956951 ]\n",
            " [0.00656159]]\n",
            "Step: 4157 -> Loss: 0.0047907098196446896 -> Predictions: [[0.00395775]\n",
            " [0.9957088 ]\n",
            " [0.99569535]\n",
            " [0.00656124]]\n",
            "Step: 4158 -> Loss: 0.004790466744452715 -> Predictions: [[0.00395756]\n",
            " [0.99570894]\n",
            " [0.9956956 ]\n",
            " [0.0065609 ]]\n",
            "Step: 4159 -> Loss: 0.004790227860212326 -> Predictions: [[0.00395738]\n",
            " [0.9957092 ]\n",
            " [0.9956958 ]\n",
            " [0.00656056]]\n",
            "Step: 4160 -> Loss: 0.004789985250681639 -> Predictions: [[0.00395719]\n",
            " [0.9957094 ]\n",
            " [0.99569607]\n",
            " [0.00656023]]\n",
            "Step: 4161 -> Loss: 0.004789742641150951 -> Predictions: [[0.003957  ]\n",
            " [0.99570966]\n",
            " [0.9956962 ]\n",
            " [0.00655988]]\n",
            "Step: 4162 -> Loss: 0.004789500497281551 -> Predictions: [[0.0039568 ]\n",
            " [0.9957099 ]\n",
            " [0.9956964 ]\n",
            " [0.00655954]]\n",
            "Step: 4163 -> Loss: 0.004789258819073439 -> Predictions: [[0.00395661]\n",
            " [0.99571013]\n",
            " [0.99569666]\n",
            " [0.00655921]]\n",
            "Step: 4164 -> Loss: 0.004789014812558889 -> Predictions: [[0.00395642]\n",
            " [0.99571025]\n",
            " [0.9956969 ]\n",
            " [0.00655887]]\n",
            "Step: 4165 -> Loss: 0.004788772203028202 -> Predictions: [[0.00395623]\n",
            " [0.9957105 ]\n",
            " [0.99569714]\n",
            " [0.00655853]]\n",
            "Step: 4166 -> Loss: 0.004788528196513653 -> Predictions: [[0.00395604]\n",
            " [0.99571073]\n",
            " [0.9956974 ]\n",
            " [0.00655819]]\n",
            "Step: 4167 -> Loss: 0.004788287915289402 -> Predictions: [[0.00395584]\n",
            " [0.99571097]\n",
            " [0.9956975 ]\n",
            " [0.00655785]]\n",
            "Step: 4168 -> Loss: 0.004788046237081289 -> Predictions: [[0.00395566]\n",
            " [0.9957112 ]\n",
            " [0.99569774]\n",
            " [0.00655751]]\n",
            "Step: 4169 -> Loss: 0.004787800367921591 -> Predictions: [[0.00395547]\n",
            " [0.99571145]\n",
            " [0.995698  ]\n",
            " [0.00655716]]\n",
            "Step: 4170 -> Loss: 0.004787561018019915 -> Predictions: [[0.00395528]\n",
            " [0.99571157]\n",
            " [0.9956982 ]\n",
            " [0.00655683]]\n",
            "Step: 4171 -> Loss: 0.004787315148860216 -> Predictions: [[0.00395508]\n",
            " [0.9957118 ]\n",
            " [0.99569845]\n",
            " [0.00655648]]\n",
            "Step: 4172 -> Loss: 0.004787074867635965 -> Predictions: [[0.00395489]\n",
            " [0.99571204]\n",
            " [0.9956987 ]\n",
            " [0.00655615]]\n",
            "Step: 4173 -> Loss: 0.004786830861121416 -> Predictions: [[0.0039547]\n",
            " [0.9957123]\n",
            " [0.9956988]\n",
            " [0.0065558]]\n",
            "Step: 4174 -> Loss: 0.004786590114235878 -> Predictions: [[0.00395451]\n",
            " [0.9957125 ]\n",
            " [0.99569905]\n",
            " [0.00655547]]\n",
            "Step: 4175 -> Loss: 0.00478634936735034 -> Predictions: [[0.00395432]\n",
            " [0.99571276]\n",
            " [0.9956993 ]\n",
            " [0.00655513]]\n",
            "Step: 4176 -> Loss: 0.004786108620464802 -> Predictions: [[0.00395413]\n",
            " [0.9957129 ]\n",
            " [0.9956995 ]\n",
            " [0.00655479]]\n",
            "Step: 4177 -> Loss: 0.0047858646139502525 -> Predictions: [[0.00395393]\n",
            " [0.9957131 ]\n",
            " [0.99569976]\n",
            " [0.00655445]]\n",
            "Step: 4178 -> Loss: 0.0047856224700808525 -> Predictions: [[0.00395375]\n",
            " [0.99571335]\n",
            " [0.9957    ]\n",
            " [0.00655411]]\n",
            "Step: 4179 -> Loss: 0.004785379394888878 -> Predictions: [[0.00395356]\n",
            " [0.9957136 ]\n",
            " [0.9957001 ]\n",
            " [0.00655377]]\n",
            "Step: 4180 -> Loss: 0.0047851367853581905 -> Predictions: [[0.00395336]\n",
            " [0.99571383]\n",
            " [0.99570036]\n",
            " [0.00655343]]\n",
            "Step: 4181 -> Loss: 0.004784892778843641 -> Predictions: [[0.00395317]\n",
            " [0.99571407]\n",
            " [0.99570054]\n",
            " [0.00655309]]\n",
            "Step: 4182 -> Loss: 0.004784652031958103 -> Predictions: [[0.00395298]\n",
            " [0.9957141 ]\n",
            " [0.9957008 ]\n",
            " [0.00655275]]\n",
            "Step: 4183 -> Loss: 0.004784410819411278 -> Predictions: [[0.00395279]\n",
            " [0.99571437]\n",
            " [0.995701  ]\n",
            " [0.00655242]]\n",
            "Step: 4184 -> Loss: 0.0047841682098805904 -> Predictions: [[0.0039526 ]\n",
            " [0.9957146 ]\n",
            " [0.99570125]\n",
            " [0.00655207]]\n",
            "Step: 4185 -> Loss: 0.004783925600349903 -> Predictions: [[0.00395241]\n",
            " [0.99571484]\n",
            " [0.9957015 ]\n",
            " [0.00655173]]\n",
            "Step: 4186 -> Loss: 0.00478368392214179 -> Predictions: [[0.00395222]\n",
            " [0.9957151 ]\n",
            " [0.9957016 ]\n",
            " [0.00655139]]\n",
            "Step: 4187 -> Loss: 0.004783441312611103 -> Predictions: [[0.00395203]\n",
            " [0.9957152 ]\n",
            " [0.99570185]\n",
            " [0.00655106]]\n",
            "Step: 4188 -> Loss: 0.004783202428370714 -> Predictions: [[0.00395184]\n",
            " [0.99571544]\n",
            " [0.9957021 ]\n",
            " [0.00655072]]\n",
            "Step: 4189 -> Loss: 0.004782957024872303 -> Predictions: [[0.00395164]\n",
            " [0.9957157 ]\n",
            " [0.9957023 ]\n",
            " [0.00655038]]\n",
            "Step: 4190 -> Loss: 0.004782716277986765 -> Predictions: [[0.00395146]\n",
            " [0.9957159 ]\n",
            " [0.99570256]\n",
            " [0.00655004]]\n",
            "Step: 4191 -> Loss: 0.004782473668456078 -> Predictions: [[0.00395126]\n",
            " [0.99571615]\n",
            " [0.9957028 ]\n",
            " [0.0065497 ]]\n",
            "Step: 4192 -> Loss: 0.00478223105892539 -> Predictions: [[0.00395106]\n",
            " [0.9957164 ]\n",
            " [0.9957029 ]\n",
            " [0.00654936]]\n",
            "Step: 4193 -> Loss: 0.0047819893807172775 -> Predictions: [[0.00395087]\n",
            " [0.9957165 ]\n",
            " [0.99570316]\n",
            " [0.00654902]]\n",
            "Step: 4194 -> Loss: 0.004781750962138176 -> Predictions: [[0.00395068]\n",
            " [0.99571675]\n",
            " [0.9957034 ]\n",
            " [0.00654868]]\n",
            "Step: 4195 -> Loss: 0.004781507886946201 -> Predictions: [[0.00395048]\n",
            " [0.995717  ]\n",
            " [0.99570364]\n",
            " [0.00654834]]\n",
            "Step: 4196 -> Loss: 0.004781269934028387 -> Predictions: [[0.00395029]\n",
            " [0.9957172 ]\n",
            " [0.9957039 ]\n",
            " [0.00654801]]\n",
            "Step: 4197 -> Loss: 0.004781026393175125 -> Predictions: [[0.0039501 ]\n",
            " [0.99571747]\n",
            " [0.995704  ]\n",
            " [0.00654766]]\n",
            "Step: 4198 -> Loss: 0.0047807833179831505 -> Predictions: [[0.0039499 ]\n",
            " [0.9957176 ]\n",
            " [0.99570423]\n",
            " [0.00654732]]\n",
            "Step: 4199 -> Loss: 0.0047805472277104855 -> Predictions: [[0.00394971]\n",
            " [0.9957178 ]\n",
            " [0.9957045 ]\n",
            " [0.00654698]]\n",
            "Step: 4200 -> Loss: 0.004780301824212074 -> Predictions: [[0.00394951]\n",
            " [0.99571806]\n",
            " [0.9957047 ]\n",
            " [0.00654664]]\n",
            "Step: 4201 -> Loss: 0.004780061077326536 -> Predictions: [[0.00394931]\n",
            " [0.9957183 ]\n",
            " [0.99570495]\n",
            " [0.00654631]]\n",
            "Step: 4202 -> Loss: 0.004779823124408722 -> Predictions: [[0.00394912]\n",
            " [0.9957184 ]\n",
            " [0.99570507]\n",
            " [0.00654597]]\n",
            "Step: 4203 -> Loss: 0.00477957958355546 -> Predictions: [[0.00394893]\n",
            " [0.99571866]\n",
            " [0.9957053 ]\n",
            " [0.00654563]]\n",
            "Step: 4204 -> Loss: 0.004779338836669922 -> Predictions: [[0.00394873]\n",
            " [0.9957189 ]\n",
            " [0.99570554]\n",
            " [0.00654529]]\n",
            "Step: 4205 -> Loss: 0.0047790976241230965 -> Predictions: [[0.00394855]\n",
            " [0.99571913]\n",
            " [0.9957058 ]\n",
            " [0.00654494]]\n",
            "Step: 4206 -> Loss: 0.0047788554802536964 -> Predictions: [[0.00394834]\n",
            " [0.9957194 ]\n",
            " [0.995706  ]\n",
            " [0.00654461]]\n",
            "Step: 4207 -> Loss: 0.004778613336384296 -> Predictions: [[0.00394814]\n",
            " [0.9957196 ]\n",
            " [0.99570614]\n",
            " [0.00654427]]\n",
            "Step: 4208 -> Loss: 0.0047783758491277695 -> Predictions: [[0.00394796]\n",
            " [0.99571973]\n",
            " [0.9957064 ]\n",
            " [0.00654393]]\n",
            "Step: 4209 -> Loss: 0.004778135567903519 -> Predictions: [[0.00394777]\n",
            " [0.99571997]\n",
            " [0.9957066 ]\n",
            " [0.00654358]]\n",
            "Step: 4210 -> Loss: 0.004777894821017981 -> Predictions: [[0.00394758]\n",
            " [0.9957202 ]\n",
            " [0.99570686]\n",
            " [0.00654325]]\n",
            "Step: 4211 -> Loss: 0.004777656868100166 -> Predictions: [[0.00394739]\n",
            " [0.99572045]\n",
            " [0.9957071 ]\n",
            " [0.00654291]]\n",
            "Step: 4212 -> Loss: 0.004777414724230766 -> Predictions: [[0.00394719]\n",
            " [0.99572057]\n",
            " [0.9957072 ]\n",
            " [0.00654257]]\n",
            "Step: 4213 -> Loss: 0.00477717537432909 -> Predictions: [[0.003947  ]\n",
            " [0.9957208 ]\n",
            " [0.9957074 ]\n",
            " [0.00654223]]\n",
            "Step: 4214 -> Loss: 0.004776934161782265 -> Predictions: [[0.00394681]\n",
            " [0.99572104]\n",
            " [0.99570763]\n",
            " [0.00654189]]\n",
            "Step: 4215 -> Loss: 0.004776693414896727 -> Predictions: [[0.00394662]\n",
            " [0.9957212 ]\n",
            " [0.99570787]\n",
            " [0.00654155]]\n",
            "Step: 4216 -> Loss: 0.004776456393301487 -> Predictions: [[0.00394643]\n",
            " [0.99572146]\n",
            " [0.9957081 ]\n",
            " [0.00654122]]\n",
            "Step: 4217 -> Loss: 0.004776213318109512 -> Predictions: [[0.00394624]\n",
            " [0.9957216 ]\n",
            " [0.99570835]\n",
            " [0.00654088]]\n",
            "Step: 4218 -> Loss: 0.004775972571223974 -> Predictions: [[0.00394605]\n",
            " [0.9957218 ]\n",
            " [0.99570847]\n",
            " [0.00654054]]\n",
            "Step: 4219 -> Loss: 0.004775733686983585 -> Predictions: [[0.00394586]\n",
            " [0.99572206]\n",
            " [0.9957087 ]\n",
            " [0.00654019]]\n",
            "Step: 4220 -> Loss: 0.004775496665388346 -> Predictions: [[0.00394567]\n",
            " [0.9957223 ]\n",
            " [0.99570894]\n",
            " [0.00653987]]\n",
            "Step: 4221 -> Loss: 0.004775256849825382 -> Predictions: [[0.00394549]\n",
            " [0.99572253]\n",
            " [0.9957092 ]\n",
            " [0.00653952]]\n",
            "Step: 4222 -> Loss: 0.0047750165686011314 -> Predictions: [[0.00394529]\n",
            " [0.99572265]\n",
            " [0.9957094 ]\n",
            " [0.00653919]]\n",
            "Step: 4223 -> Loss: 0.004774777218699455 -> Predictions: [[0.00394511]\n",
            " [0.9957229 ]\n",
            " [0.99570954]\n",
            " [0.00653885]]\n",
            "Step: 4224 -> Loss: 0.004774536471813917 -> Predictions: [[0.00394491]\n",
            " [0.9957231 ]\n",
            " [0.9957098 ]\n",
            " [0.00653852]]\n",
            "Step: 4225 -> Loss: 0.004774297121912241 -> Predictions: [[0.00394473]\n",
            " [0.99572337]\n",
            " [0.99571   ]\n",
            " [0.00653818]]\n",
            "Step: 4226 -> Loss: 0.00477405684068799 -> Predictions: [[0.00394454]\n",
            " [0.9957236 ]\n",
            " [0.99571025]\n",
            " [0.00653785]]\n",
            "Step: 4227 -> Loss: 0.004773815628141165 -> Predictions: [[0.00394435]\n",
            " [0.99572384]\n",
            " [0.9957105 ]\n",
            " [0.00653751]]\n",
            "Step: 4228 -> Loss: 0.004773576743900776 -> Predictions: [[0.00394416]\n",
            " [0.99572396]\n",
            " [0.99571073]\n",
            " [0.00653718]]\n",
            "Step: 4229 -> Loss: 0.004773336462676525 -> Predictions: [[0.00394397]\n",
            " [0.9957242 ]\n",
            " [0.99571085]\n",
            " [0.00653683]]\n",
            "Step: 4230 -> Loss: 0.0047730994410812855 -> Predictions: [[0.00394378]\n",
            " [0.99572444]\n",
            " [0.9957111 ]\n",
            " [0.00653651]]\n",
            "Step: 4231 -> Loss: 0.0047728572972118855 -> Predictions: [[0.0039436 ]\n",
            " [0.9957247 ]\n",
            " [0.9957113 ]\n",
            " [0.00653616]]\n",
            "Step: 4232 -> Loss: 0.004772617481648922 -> Predictions: [[0.0039434 ]\n",
            " [0.9957249 ]\n",
            " [0.99571157]\n",
            " [0.00653583]]\n",
            "Step: 4233 -> Loss: 0.004772379528731108 -> Predictions: [[0.00394322]\n",
            " [0.99572504]\n",
            " [0.9957118 ]\n",
            " [0.0065355 ]]\n",
            "Step: 4234 -> Loss: 0.004772140644490719 -> Predictions: [[0.00394303]\n",
            " [0.9957253 ]\n",
            " [0.9957119 ]\n",
            " [0.00653516]]\n",
            "Step: 4235 -> Loss: 0.00477189663797617 -> Predictions: [[0.00394283]\n",
            " [0.9957255 ]\n",
            " [0.99571216]\n",
            " [0.00653482]]\n",
            "Step: 4236 -> Loss: 0.004771661479026079 -> Predictions: [[0.00394265]\n",
            " [0.99572575]\n",
            " [0.9957124 ]\n",
            " [0.00653449]]\n",
            "Step: 4237 -> Loss: 0.0047714198008179665 -> Predictions: [[0.00394246]\n",
            " [0.995726  ]\n",
            " [0.99571264]\n",
            " [0.00653415]]\n",
            "Step: 4238 -> Loss: 0.004771183244884014 -> Predictions: [[0.00394227]\n",
            " [0.9957261 ]\n",
            " [0.9957129 ]\n",
            " [0.00653382]]\n",
            "Step: 4239 -> Loss: 0.004770942963659763 -> Predictions: [[0.00394208]\n",
            " [0.99572635]\n",
            " [0.9957131 ]\n",
            " [0.00653348]]\n",
            "Step: 4240 -> Loss: 0.004770702216774225 -> Predictions: [[0.00394189]\n",
            " [0.9957266 ]\n",
            " [0.99571323]\n",
            " [0.00653315]]\n",
            "Step: 4241 -> Loss: 0.004770461469888687 -> Predictions: [[0.00394171]\n",
            " [0.9957268 ]\n",
            " [0.9957135 ]\n",
            " [0.00653281]]\n",
            "Step: 4242 -> Loss: 0.004770221654325724 -> Predictions: [[0.00394151]\n",
            " [0.99572706]\n",
            " [0.9957137 ]\n",
            " [0.00653247]]\n",
            "Step: 4243 -> Loss: 0.004769984167069197 -> Predictions: [[0.00394133]\n",
            " [0.9957272 ]\n",
            " [0.99571395]\n",
            " [0.00653214]]\n",
            "Step: 4244 -> Loss: 0.004769744351506233 -> Predictions: [[0.00394114]\n",
            " [0.9957274 ]\n",
            " [0.9957141 ]\n",
            " [0.0065318 ]]\n",
            "Step: 4245 -> Loss: 0.004769507795572281 -> Predictions: [[0.00394095]\n",
            " [0.99572766]\n",
            " [0.99571425]\n",
            " [0.00653147]]\n",
            "Step: 4246 -> Loss: 0.004769267048686743 -> Predictions: [[0.00394076]\n",
            " [0.9957279 ]\n",
            " [0.9957145 ]\n",
            " [0.00653113]]\n",
            "Step: 4247 -> Loss: 0.004769027233123779 -> Predictions: [[0.00394057]\n",
            " [0.9957281 ]\n",
            " [0.9957147 ]\n",
            " [0.00653079]]\n",
            "Step: 4248 -> Loss: 0.004768787883222103 -> Predictions: [[0.00394039]\n",
            " [0.9957282 ]\n",
            " [0.99571496]\n",
            " [0.00653046]]\n",
            "Step: 4249 -> Loss: 0.004768545739352703 -> Predictions: [[0.0039402 ]\n",
            " [0.99572843]\n",
            " [0.9957152 ]\n",
            " [0.00653012]]\n",
            "Step: 4250 -> Loss: 0.004768306855112314 -> Predictions: [[0.00394001]\n",
            " [0.9957287 ]\n",
            " [0.99571544]\n",
            " [0.00652979]]\n",
            "Step: 4251 -> Loss: 0.004768067039549351 -> Predictions: [[0.00393982]\n",
            " [0.9957289 ]\n",
            " [0.99571556]\n",
            " [0.00652945]]\n",
            "Step: 4252 -> Loss: 0.004767829552292824 -> Predictions: [[0.00393963]\n",
            " [0.99572915]\n",
            " [0.9957158 ]\n",
            " [0.00652912]]\n",
            "Step: 4253 -> Loss: 0.00476758973672986 -> Predictions: [[0.00393944]\n",
            " [0.99572927]\n",
            " [0.99571604]\n",
            " [0.00652878]]\n",
            "Step: 4254 -> Loss: 0.004767351783812046 -> Predictions: [[0.00393926]\n",
            " [0.9957295 ]\n",
            " [0.9957163 ]\n",
            " [0.00652845]]\n",
            "Step: 4255 -> Loss: 0.004767111502587795 -> Predictions: [[0.00393907]\n",
            " [0.99572974]\n",
            " [0.9957165 ]\n",
            " [0.00652811]]\n",
            "Step: 4256 -> Loss: 0.0047668698243796825 -> Predictions: [[0.00393888]\n",
            " [0.99573   ]\n",
            " [0.99571663]\n",
            " [0.00652777]]\n",
            "Step: 4257 -> Loss: 0.004766631871461868 -> Predictions: [[0.00393869]\n",
            " [0.9957302 ]\n",
            " [0.99571687]\n",
            " [0.00652744]]\n",
            "Step: 4258 -> Loss: 0.0047663915902376175 -> Predictions: [[0.0039385 ]\n",
            " [0.99573046]\n",
            " [0.9957171 ]\n",
            " [0.00652711]]\n",
            "Step: 4259 -> Loss: 0.004766151774674654 -> Predictions: [[0.00393831]\n",
            " [0.9957306 ]\n",
            " [0.99571735]\n",
            " [0.00652677]]\n",
            "Step: 4260 -> Loss: 0.004765914753079414 -> Predictions: [[0.00393812]\n",
            " [0.9957308 ]\n",
            " [0.9957176 ]\n",
            " [0.00652644]]\n",
            "Step: 4261 -> Loss: 0.004765674937516451 -> Predictions: [[0.00393793]\n",
            " [0.99573106]\n",
            " [0.9957178 ]\n",
            " [0.0065261 ]]\n",
            "Step: 4262 -> Loss: 0.004765436053276062 -> Predictions: [[0.00393775]\n",
            " [0.9957313 ]\n",
            " [0.99571794]\n",
            " [0.00652577]]\n",
            "Step: 4263 -> Loss: 0.004765197169035673 -> Predictions: [[0.00393755]\n",
            " [0.99573153]\n",
            " [0.9957182 ]\n",
            " [0.00652543]]\n",
            "Step: 4264 -> Loss: 0.004764958750456572 -> Predictions: [[0.00393737]\n",
            " [0.99573165]\n",
            " [0.9957184 ]\n",
            " [0.0065251 ]]\n",
            "Step: 4265 -> Loss: 0.004764718934893608 -> Predictions: [[0.00393719]\n",
            " [0.9957319 ]\n",
            " [0.99571866]\n",
            " [0.00652475]]\n",
            "Step: 4266 -> Loss: 0.0047644805163145065 -> Predictions: [[0.003937  ]\n",
            " [0.9957321 ]\n",
            " [0.9957189 ]\n",
            " [0.00652443]]\n",
            "Step: 4267 -> Loss: 0.004764236509799957 -> Predictions: [[0.0039368 ]\n",
            " [0.99573237]\n",
            " [0.995719  ]\n",
            " [0.00652408]]\n",
            "Step: 4268 -> Loss: 0.004763999953866005 -> Predictions: [[0.00393661]\n",
            " [0.9957326 ]\n",
            " [0.99571925]\n",
            " [0.00652376]]\n",
            "Step: 4269 -> Loss: 0.004763757809996605 -> Predictions: [[0.00393642]\n",
            " [0.9957327 ]\n",
            " [0.9957195 ]\n",
            " [0.00652341]]\n",
            "Step: 4270 -> Loss: 0.004763523582369089 -> Predictions: [[0.00393624]\n",
            " [0.99573296]\n",
            " [0.99571973]\n",
            " [0.00652308]]\n",
            "Step: 4271 -> Loss: 0.004763280972838402 -> Predictions: [[0.00393604]\n",
            " [0.9957332 ]\n",
            " [0.99571997]\n",
            " [0.00652275]]\n",
            "Step: 4272 -> Loss: 0.004763043485581875 -> Predictions: [[0.00393586]\n",
            " [0.99573344]\n",
            " [0.9957202 ]\n",
            " [0.00652241]]\n",
            "Step: 4273 -> Loss: 0.004762804135680199 -> Predictions: [[0.00393568]\n",
            " [0.9957337 ]\n",
            " [0.9957203 ]\n",
            " [0.00652207]]\n",
            "Step: 4274 -> Loss: 0.0047625647857785225 -> Predictions: [[0.00393549]\n",
            " [0.9957338 ]\n",
            " [0.99572057]\n",
            " [0.00652174]]\n",
            "Step: 4275 -> Loss: 0.0047623272985219955 -> Predictions: [[0.0039353 ]\n",
            " [0.99573404]\n",
            " [0.9957208 ]\n",
            " [0.00652141]]\n",
            "Step: 4276 -> Loss: 0.004762085620313883 -> Predictions: [[0.00393511]\n",
            " [0.9957343 ]\n",
            " [0.99572104]\n",
            " [0.00652107]]\n",
            "Step: 4277 -> Loss: 0.0047618490643799305 -> Predictions: [[0.00393492]\n",
            " [0.9957345 ]\n",
            " [0.9957212 ]\n",
            " [0.00652074]]\n",
            "Step: 4278 -> Loss: 0.004761611111462116 -> Predictions: [[0.00393473]\n",
            " [0.99573475]\n",
            " [0.99572134]\n",
            " [0.0065204 ]]\n",
            "Step: 4279 -> Loss: 0.004761368036270142 -> Predictions: [[0.00393454]\n",
            " [0.9957349 ]\n",
            " [0.9957216 ]\n",
            " [0.00652006]]\n",
            "Step: 4280 -> Loss: 0.004761132411658764 -> Predictions: [[0.00393435]\n",
            " [0.99573505]\n",
            " [0.9957218 ]\n",
            " [0.00651973]]\n",
            "Step: 4281 -> Loss: 0.0047608911991119385 -> Predictions: [[0.00393417]\n",
            " [0.9957353 ]\n",
            " [0.99572206]\n",
            " [0.00651939]]\n",
            "Step: 4282 -> Loss: 0.004760655574500561 -> Predictions: [[0.00393398]\n",
            " [0.9957355 ]\n",
            " [0.9957223 ]\n",
            " [0.00651907]]\n",
            "Step: 4283 -> Loss: 0.004760414361953735 -> Predictions: [[0.00393379]\n",
            " [0.99573576]\n",
            " [0.99572253]\n",
            " [0.00651872]]\n",
            "Step: 4284 -> Loss: 0.004760175012052059 -> Predictions: [[0.0039336 ]\n",
            " [0.995736  ]\n",
            " [0.99572265]\n",
            " [0.00651839]]\n",
            "Step: 4285 -> Loss: 0.004759935196489096 -> Predictions: [[0.00393341]\n",
            " [0.9957361 ]\n",
            " [0.9957229 ]\n",
            " [0.00651805]]\n",
            "Step: 4286 -> Loss: 0.004759698174893856 -> Predictions: [[0.00393322]\n",
            " [0.99573636]\n",
            " [0.9957231 ]\n",
            " [0.00651772]]\n",
            "Step: 4287 -> Loss: 0.004759456031024456 -> Predictions: [[0.00393303]\n",
            " [0.9957366 ]\n",
            " [0.99572337]\n",
            " [0.00651738]]\n",
            "Step: 4288 -> Loss: 0.004759217146784067 -> Predictions: [[0.00393284]\n",
            " [0.99573684]\n",
            " [0.9957236 ]\n",
            " [0.00651705]]\n",
            "Step: 4289 -> Loss: 0.004758979193866253 -> Predictions: [[0.00393266]\n",
            " [0.9957371 ]\n",
            " [0.9957237 ]\n",
            " [0.00651671]]\n",
            "Step: 4290 -> Loss: 0.004758743103593588 -> Predictions: [[0.00393247]\n",
            " [0.9957372 ]\n",
            " [0.99572396]\n",
            " [0.00651639]]\n",
            "Step: 4291 -> Loss: 0.004758498631417751 -> Predictions: [[0.00393228]\n",
            " [0.99573743]\n",
            " [0.9957242 ]\n",
            " [0.00651604]]\n",
            "Step: 4292 -> Loss: 0.004758262075483799 -> Predictions: [[0.00393209]\n",
            " [0.9957377 ]\n",
            " [0.99572444]\n",
            " [0.00651571]]\n",
            "Step: 4293 -> Loss: 0.004758022725582123 -> Predictions: [[0.00393191]\n",
            " [0.9957379 ]\n",
            " [0.9957247 ]\n",
            " [0.00651538]]\n",
            "Step: 4294 -> Loss: 0.004757785703986883 -> Predictions: [[0.00393172]\n",
            " [0.99573815]\n",
            " [0.9957249 ]\n",
            " [0.00651505]]\n",
            "Step: 4295 -> Loss: 0.00475754588842392 -> Predictions: [[0.00393153]\n",
            " [0.99573827]\n",
            " [0.99572504]\n",
            " [0.00651471]]\n",
            "Step: 4296 -> Loss: 0.00475730374455452 -> Predictions: [[0.00393134]\n",
            " [0.9957385 ]\n",
            " [0.9957253 ]\n",
            " [0.00651437]]\n",
            "Step: 4297 -> Loss: 0.004757067654281855 -> Predictions: [[0.00393115]\n",
            " [0.99573874]\n",
            " [0.9957255 ]\n",
            " [0.00651403]]\n",
            "Step: 4298 -> Loss: 0.004756833426654339 -> Predictions: [[0.00393097]\n",
            " [0.995739  ]\n",
            " [0.99572575]\n",
            " [0.00651371]]\n",
            "Step: 4299 -> Loss: 0.004756594076752663 -> Predictions: [[0.00393078]\n",
            " [0.9957392 ]\n",
            " [0.995726  ]\n",
            " [0.00651337]]\n",
            "Step: 4300 -> Loss: 0.0047563547268509865 -> Predictions: [[0.00393059]\n",
            " [0.99573934]\n",
            " [0.9957261 ]\n",
            " [0.00651304]]\n",
            "Step: 4301 -> Loss: 0.004756113979965448 -> Predictions: [[0.0039304 ]\n",
            " [0.9957396 ]\n",
            " [0.99572635]\n",
            " [0.0065127 ]]\n",
            "Step: 4302 -> Loss: 0.004755874164402485 -> Predictions: [[0.00393021]\n",
            " [0.9957398 ]\n",
            " [0.9957266 ]\n",
            " [0.00651237]]\n",
            "Step: 4303 -> Loss: 0.004755636677145958 -> Predictions: [[0.00393003]\n",
            " [0.99574006]\n",
            " [0.9957268 ]\n",
            " [0.00651203]]\n",
            "Step: 4304 -> Loss: 0.004755398724228144 -> Predictions: [[0.00392984]\n",
            " [0.9957403 ]\n",
            " [0.99572706]\n",
            " [0.0065117 ]]\n",
            "Step: 4305 -> Loss: 0.004755157046020031 -> Predictions: [[0.00392965]\n",
            " [0.9957404 ]\n",
            " [0.9957272 ]\n",
            " [0.00651135]]\n",
            "Step: 4306 -> Loss: 0.004754920490086079 -> Predictions: [[0.00392946]\n",
            " [0.99574065]\n",
            " [0.9957274 ]\n",
            " [0.00651103]]\n",
            "Step: 4307 -> Loss: 0.0047546811401844025 -> Predictions: [[0.00392927]\n",
            " [0.9957409 ]\n",
            " [0.99572766]\n",
            " [0.00651069]]\n",
            "Step: 4308 -> Loss: 0.0047544450499117374 -> Predictions: [[0.00392909]\n",
            " [0.9957411 ]\n",
            " [0.9957279 ]\n",
            " [0.00651036]]\n",
            "Step: 4309 -> Loss: 0.004754201974719763 -> Predictions: [[0.00392889]\n",
            " [0.99574137]\n",
            " [0.9957281 ]\n",
            " [0.00651002]]\n",
            "Step: 4310 -> Loss: 0.004753964953124523 -> Predictions: [[0.00392871]\n",
            " [0.9957415 ]\n",
            " [0.9957283 ]\n",
            " [0.00650969]]\n",
            "Step: 4311 -> Loss: 0.004753728397190571 -> Predictions: [[0.00392852]\n",
            " [0.9957417 ]\n",
            " [0.99572843]\n",
            " [0.00650935]]\n",
            "Step: 4312 -> Loss: 0.004753489512950182 -> Predictions: [[0.00392833]\n",
            " [0.9957419 ]\n",
            " [0.9957287 ]\n",
            " [0.00650903]]\n",
            "Step: 4313 -> Loss: 0.004753250163048506 -> Predictions: [[0.00392814]\n",
            " [0.99574214]\n",
            " [0.9957289 ]\n",
            " [0.00650868]]\n",
            "Step: 4314 -> Loss: 0.00475301081314683 -> Predictions: [[0.00392796]\n",
            " [0.9957424 ]\n",
            " [0.99572915]\n",
            " [0.00650835]]\n",
            "Step: 4315 -> Loss: 0.00475277379155159 -> Predictions: [[0.00392777]\n",
            " [0.9957425 ]\n",
            " [0.9957294 ]\n",
            " [0.00650801]]\n",
            "Step: 4316 -> Loss: 0.004752536304295063 -> Predictions: [[0.00392758]\n",
            " [0.99574274]\n",
            " [0.9957295 ]\n",
            " [0.00650768]]\n",
            "Step: 4317 -> Loss: 0.0047522964887320995 -> Predictions: [[0.00392739]\n",
            " [0.995743  ]\n",
            " [0.99572974]\n",
            " [0.00650735]]\n",
            "Step: 4318 -> Loss: 0.004752057138830423 -> Predictions: [[0.0039272 ]\n",
            " [0.9957432 ]\n",
            " [0.99573   ]\n",
            " [0.00650702]]\n",
            "Step: 4319 -> Loss: 0.00475181732326746 -> Predictions: [[0.00392701]\n",
            " [0.99574345]\n",
            " [0.9957302 ]\n",
            " [0.00650667]]\n",
            "Step: 4320 -> Loss: 0.004751581698656082 -> Predictions: [[0.00392682]\n",
            " [0.9957436 ]\n",
            " [0.99573046]\n",
            " [0.00650635]]\n",
            "Step: 4321 -> Loss: 0.004751341883093119 -> Predictions: [[0.00392664]\n",
            " [0.9957438 ]\n",
            " [0.9957306 ]\n",
            " [0.00650601]]\n",
            "Step: 4322 -> Loss: 0.004751103930175304 -> Predictions: [[0.00392645]\n",
            " [0.99574405]\n",
            " [0.9957308 ]\n",
            " [0.00650568]]\n",
            "Step: 4323 -> Loss: 0.004750864580273628 -> Predictions: [[0.00392626]\n",
            " [0.9957443 ]\n",
            " [0.99573106]\n",
            " [0.00650534]]\n",
            "Step: 4324 -> Loss: 0.004750627558678389 -> Predictions: [[0.00392608]\n",
            " [0.9957445 ]\n",
            " [0.9957313 ]\n",
            " [0.00650501]]\n",
            "Step: 4325 -> Loss: 0.0047503868117928505 -> Predictions: [[0.00392588]\n",
            " [0.99574465]\n",
            " [0.99573153]\n",
            " [0.00650467]]\n",
            "Step: 4326 -> Loss: 0.004750149790197611 -> Predictions: [[0.0039257 ]\n",
            " [0.9957449 ]\n",
            " [0.99573165]\n",
            " [0.00650434]]\n",
            "Step: 4327 -> Loss: 0.004749913699924946 -> Predictions: [[0.00392551]\n",
            " [0.9957451 ]\n",
            " [0.9957319 ]\n",
            " [0.00650401]]\n",
            "Step: 4328 -> Loss: 0.004749676212668419 -> Predictions: [[0.00392532]\n",
            " [0.99574536]\n",
            " [0.9957321 ]\n",
            " [0.00650368]]\n",
            "Step: 4329 -> Loss: 0.0047494350001215935 -> Predictions: [[0.00392513]\n",
            " [0.9957456 ]\n",
            " [0.99573237]\n",
            " [0.00650334]]\n",
            "Step: 4330 -> Loss: 0.004749196581542492 -> Predictions: [[0.00392495]\n",
            " [0.9957457 ]\n",
            " [0.9957326 ]\n",
            " [0.00650301]]\n",
            "Step: 4331 -> Loss: 0.004748957231640816 -> Predictions: [[0.00392476]\n",
            " [0.99574596]\n",
            " [0.9957327 ]\n",
            " [0.00650267]]\n",
            "Step: 4332 -> Loss: 0.004748719744384289 -> Predictions: [[0.00392457]\n",
            " [0.9957462 ]\n",
            " [0.99573296]\n",
            " [0.00650234]]\n",
            "Step: 4333 -> Loss: 0.004748481325805187 -> Predictions: [[0.00392438]\n",
            " [0.99574643]\n",
            " [0.9957332 ]\n",
            " [0.00650201]]\n",
            "Step: 4334 -> Loss: 0.004748242907226086 -> Predictions: [[0.00392419]\n",
            " [0.9957467 ]\n",
            " [0.99573344]\n",
            " [0.00650168]]\n",
            "Step: 4335 -> Loss: 0.004748006816953421 -> Predictions: [[0.00392401]\n",
            " [0.9957469 ]\n",
            " [0.9957337 ]\n",
            " [0.00650135]]\n",
            "Step: 4336 -> Loss: 0.0047477660700678825 -> Predictions: [[0.00392381]\n",
            " [0.995747  ]\n",
            " [0.9957339 ]\n",
            " [0.00650101]]\n",
            "Step: 4337 -> Loss: 0.004747527651488781 -> Predictions: [[0.00392363]\n",
            " [0.99574727]\n",
            " [0.99573404]\n",
            " [0.00650067]]\n",
            "Step: 4338 -> Loss: 0.004747293423861265 -> Predictions: [[0.00392345]\n",
            " [0.9957475 ]\n",
            " [0.9957343 ]\n",
            " [0.00650035]]\n",
            "Step: 4339 -> Loss: 0.004747054539620876 -> Predictions: [[0.00392326]\n",
            " [0.99574775]\n",
            " [0.9957345 ]\n",
            " [0.00650002]]\n",
            "Step: 4340 -> Loss: 0.0047468151897192 -> Predictions: [[0.00392307]\n",
            " [0.995748  ]\n",
            " [0.99573475]\n",
            " [0.00649968]]\n",
            "Step: 4341 -> Loss: 0.004746578633785248 -> Predictions: [[0.00392288]\n",
            " [0.9957481 ]\n",
            " [0.99573493]\n",
            " [0.00649936]]\n",
            "Step: 4342 -> Loss: 0.00474634300917387 -> Predictions: [[0.0039227 ]\n",
            " [0.99574834]\n",
            " [0.99573505]\n",
            " [0.00649903]]\n",
            "Step: 4343 -> Loss: 0.004746101796627045 -> Predictions: [[0.00392251]\n",
            " [0.9957486 ]\n",
            " [0.9957353 ]\n",
            " [0.00649869]]\n",
            "Step: 4344 -> Loss: 0.004745865240693092 -> Predictions: [[0.00392232]\n",
            " [0.9957488 ]\n",
            " [0.9957355 ]\n",
            " [0.00649836]]\n",
            "Step: 4345 -> Loss: 0.0047456249594688416 -> Predictions: [[0.00392213]\n",
            " [0.995749  ]\n",
            " [0.99573576]\n",
            " [0.00649803]]\n",
            "Step: 4346 -> Loss: 0.004745387472212315 -> Predictions: [[0.00392194]\n",
            " [0.9957491 ]\n",
            " [0.995736  ]\n",
            " [0.00649769]]\n",
            "Step: 4347 -> Loss: 0.004745149984955788 -> Predictions: [[0.00392175]\n",
            " [0.99574935]\n",
            " [0.9957361 ]\n",
            " [0.00649736]]\n",
            "Step: 4348 -> Loss: 0.004744907841086388 -> Predictions: [[0.00392156]\n",
            " [0.9957496 ]\n",
            " [0.99573636]\n",
            " [0.00649702]]\n",
            "Step: 4349 -> Loss: 0.004744671285152435 -> Predictions: [[0.00392137]\n",
            " [0.99574983]\n",
            " [0.9957366 ]\n",
            " [0.00649669]]\n",
            "Step: 4350 -> Loss: 0.004744435660541058 -> Predictions: [[0.00392119]\n",
            " [0.99575007]\n",
            " [0.99573684]\n",
            " [0.00649636]]\n",
            "Step: 4351 -> Loss: 0.004744199104607105 -> Predictions: [[0.003921  ]\n",
            " [0.9957502 ]\n",
            " [0.9957371 ]\n",
            " [0.00649603]]\n",
            "Step: 4352 -> Loss: 0.0047439588233828545 -> Predictions: [[0.00392082]\n",
            " [0.9957504 ]\n",
            " [0.9957372 ]\n",
            " [0.0064957 ]]\n",
            "Step: 4353 -> Loss: 0.004743724130094051 -> Predictions: [[0.00392063]\n",
            " [0.99575067]\n",
            " [0.99573743]\n",
            " [0.00649537]]\n",
            "Step: 4354 -> Loss: 0.004743484780192375 -> Predictions: [[0.00392044]\n",
            " [0.9957509 ]\n",
            " [0.9957377 ]\n",
            " [0.00649504]]\n",
            "Step: 4355 -> Loss: 0.004743244964629412 -> Predictions: [[0.00392025]\n",
            " [0.99575114]\n",
            " [0.9957379 ]\n",
            " [0.00649471]]\n",
            "Step: 4356 -> Loss: 0.0047430070117115974 -> Predictions: [[0.00392007]\n",
            " [0.9957514 ]\n",
            " [0.99573815]\n",
            " [0.00649437]]\n",
            "Step: 4357 -> Loss: 0.00474277138710022 -> Predictions: [[0.00391988]\n",
            " [0.9957515 ]\n",
            " [0.9957384 ]\n",
            " [0.00649405]]\n",
            "Step: 4358 -> Loss: 0.004742529708892107 -> Predictions: [[0.00391969]\n",
            " [0.99575174]\n",
            " [0.9957385 ]\n",
            " [0.00649371]]\n",
            "Step: 4359 -> Loss: 0.004742291755974293 -> Predictions: [[0.0039195 ]\n",
            " [0.995752  ]\n",
            " [0.99573874]\n",
            " [0.00649338]]\n",
            "Step: 4360 -> Loss: 0.004742052406072617 -> Predictions: [[0.00391931]\n",
            " [0.9957522 ]\n",
            " [0.995739  ]\n",
            " [0.00649304]]\n",
            "Step: 4361 -> Loss: 0.004741818178445101 -> Predictions: [[0.00391913]\n",
            " [0.99575245]\n",
            " [0.9957392 ]\n",
            " [0.00649271]]\n",
            "Step: 4362 -> Loss: 0.0047415816225111485 -> Predictions: [[0.00391894]\n",
            " [0.9957526 ]\n",
            " [0.99573946]\n",
            " [0.00649239]]\n",
            "Step: 4363 -> Loss: 0.004741343669593334 -> Predictions: [[0.00391876]\n",
            " [0.9957528 ]\n",
            " [0.9957396 ]\n",
            " [0.00649205]]\n",
            "Step: 4364 -> Loss: 0.004741104319691658 -> Predictions: [[0.00391856]\n",
            " [0.99575305]\n",
            " [0.9957398 ]\n",
            " [0.00649172]]\n",
            "Step: 4365 -> Loss: 0.004740867763757706 -> Predictions: [[0.00391838]\n",
            " [0.9957533 ]\n",
            " [0.99574006]\n",
            " [0.00649139]]\n",
            "Step: 4366 -> Loss: 0.004740631207823753 -> Predictions: [[0.0039182 ]\n",
            " [0.9957535 ]\n",
            " [0.9957403 ]\n",
            " [0.00649106]]\n",
            "Step: 4367 -> Loss: 0.004740391857922077 -> Predictions: [[0.003918  ]\n",
            " [0.99575365]\n",
            " [0.99574053]\n",
            " [0.00649073]]\n",
            "Step: 4368 -> Loss: 0.004740153439342976 -> Predictions: [[0.00391781]\n",
            " [0.9957539 ]\n",
            " [0.99574065]\n",
            " [0.00649039]]\n",
            "Step: 4369 -> Loss: 0.004739915952086449 -> Predictions: [[0.00391762]\n",
            " [0.9957541 ]\n",
            " [0.9957409 ]\n",
            " [0.00649006]]\n",
            "Step: 4370 -> Loss: 0.004739679396152496 -> Predictions: [[0.00391744]\n",
            " [0.99575436]\n",
            " [0.9957411 ]\n",
            " [0.00648974]]\n",
            "Step: 4371 -> Loss: 0.00473944004625082 -> Predictions: [[0.00391725]\n",
            " [0.9957546 ]\n",
            " [0.99574137]\n",
            " [0.0064894 ]]\n",
            "Step: 4372 -> Loss: 0.004739201162010431 -> Predictions: [[0.00391706]\n",
            " [0.9957547 ]\n",
            " [0.9957416 ]\n",
            " [0.00648907]]\n",
            "Step: 4373 -> Loss: 0.004738965537399054 -> Predictions: [[0.00391687]\n",
            " [0.99575496]\n",
            " [0.9957417 ]\n",
            " [0.00648874]]\n",
            "Step: 4374 -> Loss: 0.004738726187497377 -> Predictions: [[0.00391669]\n",
            " [0.9957552 ]\n",
            " [0.9957419 ]\n",
            " [0.00648841]]\n",
            "Step: 4375 -> Loss: 0.004738490562886 -> Predictions: [[0.0039165 ]\n",
            " [0.99575543]\n",
            " [0.99574214]\n",
            " [0.00648808]]\n",
            "Step: 4376 -> Loss: 0.004738252609968185 -> Predictions: [[0.00391631]\n",
            " [0.9957557 ]\n",
            " [0.9957424 ]\n",
            " [0.00648774]]\n",
            "Step: 4377 -> Loss: 0.0047380137257277966 -> Predictions: [[0.00391612]\n",
            " [0.99575585]\n",
            " [0.9957426 ]\n",
            " [0.00648741]]\n",
            "Step: 4378 -> Loss: 0.004737775772809982 -> Predictions: [[0.00391593]\n",
            " [0.995756  ]\n",
            " [0.99574274]\n",
            " [0.00648708]]\n",
            "Step: 4379 -> Loss: 0.004737539682537317 -> Predictions: [[0.00391576]\n",
            " [0.9957562 ]\n",
            " [0.995743  ]\n",
            " [0.00648675]]\n",
            "Step: 4380 -> Loss: 0.004737300332635641 -> Predictions: [[0.00391556]\n",
            " [0.99575645]\n",
            " [0.9957432 ]\n",
            " [0.00648642]]\n",
            "Step: 4381 -> Loss: 0.004737066105008125 -> Predictions: [[0.00391538]\n",
            " [0.9957567 ]\n",
            " [0.99574345]\n",
            " [0.00648609]]\n",
            "Step: 4382 -> Loss: 0.004736826755106449 -> Predictions: [[0.00391519]\n",
            " [0.9957569 ]\n",
            " [0.9957437 ]\n",
            " [0.00648576]]\n",
            "Step: 4383 -> Loss: 0.004736588802188635 -> Predictions: [[0.003915  ]\n",
            " [0.99575704]\n",
            " [0.9957438 ]\n",
            " [0.00648543]]\n",
            "Step: 4384 -> Loss: 0.004736349917948246 -> Predictions: [[0.00391481]\n",
            " [0.9957573 ]\n",
            " [0.99574405]\n",
            " [0.0064851 ]]\n",
            "Step: 4385 -> Loss: 0.0047361114993691444 -> Predictions: [[0.00391462]\n",
            " [0.9957575 ]\n",
            " [0.9957443 ]\n",
            " [0.00648477]]\n",
            "Step: 4386 -> Loss: 0.004735874477773905 -> Predictions: [[0.00391443]\n",
            " [0.99575776]\n",
            " [0.9957445 ]\n",
            " [0.00648444]]\n",
            "Step: 4387 -> Loss: 0.004735636990517378 -> Predictions: [[0.00391425]\n",
            " [0.995758  ]\n",
            " [0.99574476]\n",
            " [0.00648411]]\n",
            "Step: 4388 -> Loss: 0.004735400900244713 -> Predictions: [[0.00391407]\n",
            " [0.9957581 ]\n",
            " [0.995745  ]\n",
            " [0.00648378]]\n",
            "Step: 4389 -> Loss: 0.004735161550343037 -> Predictions: [[0.00391388]\n",
            " [0.99575835]\n",
            " [0.9957451 ]\n",
            " [0.00648345]]\n",
            "Step: 4390 -> Loss: 0.004734924994409084 -> Predictions: [[0.00391369]\n",
            " [0.9957586 ]\n",
            " [0.99574536]\n",
            " [0.00648313]]\n",
            "Step: 4391 -> Loss: 0.004734687507152557 -> Predictions: [[0.0039135 ]\n",
            " [0.99575883]\n",
            " [0.9957456 ]\n",
            " [0.00648279]]\n",
            "Step: 4392 -> Loss: 0.004734450485557318 -> Predictions: [[0.00391331]\n",
            " [0.99575907]\n",
            " [0.99574584]\n",
            " [0.00648246]]\n",
            "Step: 4393 -> Loss: 0.004734213463962078 -> Predictions: [[0.00391312]\n",
            " [0.9957592 ]\n",
            " [0.9957461 ]\n",
            " [0.00648214]]\n",
            "Step: 4394 -> Loss: 0.004733978305011988 -> Predictions: [[0.00391294]\n",
            " [0.9957594 ]\n",
            " [0.9957462 ]\n",
            " [0.00648181]]\n",
            "Step: 4395 -> Loss: 0.004733741749078035 -> Predictions: [[0.00391275]\n",
            " [0.99575967]\n",
            " [0.99574643]\n",
            " [0.00648148]]\n",
            "Step: 4396 -> Loss: 0.0047335014678537846 -> Predictions: [[0.00391256]\n",
            " [0.9957599 ]\n",
            " [0.9957467 ]\n",
            " [0.00648115]]\n",
            "Step: 4397 -> Loss: 0.004733264446258545 -> Predictions: [[0.00391238]\n",
            " [0.99576014]\n",
            " [0.9957469 ]\n",
            " [0.00648082]]\n",
            "Step: 4398 -> Loss: 0.0047330292873084545 -> Predictions: [[0.00391219]\n",
            " [0.99576026]\n",
            " [0.99574715]\n",
            " [0.0064805 ]]\n",
            "Step: 4399 -> Loss: 0.004732790403068066 -> Predictions: [[0.003912  ]\n",
            " [0.9957605 ]\n",
            " [0.9957474 ]\n",
            " [0.00648016]]\n",
            "Step: 4400 -> Loss: 0.004732555244117975 -> Predictions: [[0.00391182]\n",
            " [0.99576074]\n",
            " [0.9957475 ]\n",
            " [0.00647983]]\n",
            "Step: 4401 -> Loss: 0.004732317291200161 -> Predictions: [[0.00391163]\n",
            " [0.995761  ]\n",
            " [0.99574775]\n",
            " [0.00647951]]\n",
            "Step: 4402 -> Loss: 0.0047320774756371975 -> Predictions: [[0.00391145]\n",
            " [0.9957612 ]\n",
            " [0.995748  ]\n",
            " [0.00647917]]\n",
            "Step: 4403 -> Loss: 0.0047318413853645325 -> Predictions: [[0.00391126]\n",
            " [0.99576145]\n",
            " [0.9957482 ]\n",
            " [0.00647885]]\n",
            "Step: 4404 -> Loss: 0.004731605760753155 -> Predictions: [[0.00391107]\n",
            " [0.9957616 ]\n",
            " [0.99574846]\n",
            " [0.00647852]]\n",
            "Step: 4405 -> Loss: 0.004731368273496628 -> Predictions: [[0.00391087]\n",
            " [0.9957618 ]\n",
            " [0.9957486 ]\n",
            " [0.00647819]]\n",
            "Step: 4406 -> Loss: 0.004731132183223963 -> Predictions: [[0.00391069]\n",
            " [0.99576205]\n",
            " [0.9957488 ]\n",
            " [0.00647786]]\n",
            "Step: 4407 -> Loss: 0.004730896558612585 -> Predictions: [[0.0039105 ]\n",
            " [0.9957623 ]\n",
            " [0.995749  ]\n",
            " [0.00647753]]\n",
            "Step: 4408 -> Loss: 0.00473066046833992 -> Predictions: [[0.0039103 ]\n",
            " [0.9957624 ]\n",
            " [0.99574924]\n",
            " [0.0064772 ]]\n",
            "Step: 4409 -> Loss: 0.004730424378067255 -> Predictions: [[0.00391011]\n",
            " [0.99576265]\n",
            " [0.9957495 ]\n",
            " [0.00647687]]\n",
            "Step: 4410 -> Loss: 0.004730186425149441 -> Predictions: [[0.00390992]\n",
            " [0.9957628 ]\n",
            " [0.9957496 ]\n",
            " [0.00647654]]\n",
            "Step: 4411 -> Loss: 0.0047299531288445 -> Predictions: [[0.00390974]\n",
            " [0.99576306]\n",
            " [0.99574983]\n",
            " [0.00647621]]\n",
            "Step: 4412 -> Loss: 0.004729715175926685 -> Predictions: [[0.00390954]\n",
            " [0.9957633 ]\n",
            " [0.99575007]\n",
            " [0.00647588]]\n",
            "Step: 4413 -> Loss: 0.004729480016976595 -> Predictions: [[0.00390935]\n",
            " [0.9957634 ]\n",
            " [0.9957503 ]\n",
            " [0.00647555]]\n",
            "Step: 4414 -> Loss: 0.004729243461042643 -> Predictions: [[0.00390916]\n",
            " [0.99576366]\n",
            " [0.9957504 ]\n",
            " [0.00647523]]\n",
            "Step: 4415 -> Loss: 0.004729007370769978 -> Predictions: [[0.00390897]\n",
            " [0.9957639 ]\n",
            " [0.99575067]\n",
            " [0.0064749 ]]\n",
            "Step: 4416 -> Loss: 0.004728770349174738 -> Predictions: [[0.00390878]\n",
            " [0.99576414]\n",
            " [0.9957509 ]\n",
            " [0.00647457]]\n",
            "Step: 4417 -> Loss: 0.004728533327579498 -> Predictions: [[0.00390859]\n",
            " [0.99576426]\n",
            " [0.99575114]\n",
            " [0.00647424]]\n",
            "Step: 4418 -> Loss: 0.004728298168629408 -> Predictions: [[0.0039084 ]\n",
            " [0.9957645 ]\n",
            " [0.9957514 ]\n",
            " [0.00647391]]\n",
            "Step: 4419 -> Loss: 0.004728061147034168 -> Predictions: [[0.0039082 ]\n",
            " [0.99576473]\n",
            " [0.9957515 ]\n",
            " [0.00647358]]\n",
            "Step: 4420 -> Loss: 0.0047278269194066525 -> Predictions: [[0.00390802]\n",
            " [0.995765  ]\n",
            " [0.99575174]\n",
            " [0.00647325]]\n",
            "Step: 4421 -> Loss: 0.0047275903634727 -> Predictions: [[0.00390783]\n",
            " [0.9957652 ]\n",
            " [0.995752  ]\n",
            " [0.00647292]]\n",
            "Step: 4422 -> Loss: 0.004727354273200035 -> Predictions: [[0.00390764]\n",
            " [0.9957653 ]\n",
            " [0.9957522 ]\n",
            " [0.00647259]]\n",
            "Step: 4423 -> Loss: 0.004727120511233807 -> Predictions: [[0.00390745]\n",
            " [0.99576557]\n",
            " [0.99575233]\n",
            " [0.00647227]]\n",
            "Step: 4424 -> Loss: 0.004726883955299854 -> Predictions: [[0.00390726]\n",
            " [0.9957658 ]\n",
            " [0.9957526 ]\n",
            " [0.00647194]]\n",
            "Step: 4425 -> Loss: 0.004726647399365902 -> Predictions: [[0.00390708]\n",
            " [0.99576604]\n",
            " [0.9957528 ]\n",
            " [0.00647162]]\n",
            "Step: 4426 -> Loss: 0.004726410377770662 -> Predictions: [[0.00390689]\n",
            " [0.99576616]\n",
            " [0.99575305]\n",
            " [0.00647129]]\n",
            "Step: 4427 -> Loss: 0.00472617382183671 -> Predictions: [[0.0039067 ]\n",
            " [0.9957664 ]\n",
            " [0.9957533 ]\n",
            " [0.00647096]]\n",
            "Step: 4428 -> Loss: 0.00472593866288662 -> Predictions: [[0.00390651]\n",
            " [0.99576664]\n",
            " [0.9957534 ]\n",
            " [0.00647064]]\n",
            "Step: 4429 -> Loss: 0.004725705832242966 -> Predictions: [[0.00390633]\n",
            " [0.9957669 ]\n",
            " [0.99575365]\n",
            " [0.00647031]]\n",
            "Step: 4430 -> Loss: 0.004725468810647726 -> Predictions: [[0.00390613]\n",
            " [0.9957671 ]\n",
            " [0.9957539 ]\n",
            " [0.00646998]]\n",
            "Step: 4431 -> Loss: 0.004725235048681498 -> Predictions: [[0.00390595]\n",
            " [0.99576724]\n",
            " [0.9957541 ]\n",
            " [0.00646966]]\n",
            "Step: 4432 -> Loss: 0.004724997095763683 -> Predictions: [[0.00390576]\n",
            " [0.9957675 ]\n",
            " [0.99575436]\n",
            " [0.00646933]]\n",
            "Step: 4433 -> Loss: 0.004724761936813593 -> Predictions: [[0.00390558]\n",
            " [0.9957677 ]\n",
            " [0.9957545 ]\n",
            " [0.00646901]]\n",
            "Step: 4434 -> Loss: 0.00472452724352479 -> Predictions: [[0.0039054 ]\n",
            " [0.99576795]\n",
            " [0.9957547 ]\n",
            " [0.00646868]]\n",
            "Step: 4435 -> Loss: 0.004724291153252125 -> Predictions: [[0.00390521]\n",
            " [0.9957682 ]\n",
            " [0.99575496]\n",
            " [0.00646836]]\n",
            "Step: 4436 -> Loss: 0.004724055528640747 -> Predictions: [[0.00390502]\n",
            " [0.9957683 ]\n",
            " [0.9957552 ]\n",
            " [0.00646803]]\n",
            "Step: 4437 -> Loss: 0.004723820835351944 -> Predictions: [[0.00390483]\n",
            " [0.99576855]\n",
            " [0.99575543]\n",
            " [0.0064677 ]]\n",
            "Step: 4438 -> Loss: 0.004723585210740566 -> Predictions: [[0.00390465]\n",
            " [0.9957688 ]\n",
            " [0.99575555]\n",
            " [0.00646737]]\n",
            "Step: 4439 -> Loss: 0.004723351914435625 -> Predictions: [[0.00390447]\n",
            " [0.995769  ]\n",
            " [0.9957558 ]\n",
            " [0.00646706]]\n",
            "Step: 4440 -> Loss: 0.004723118618130684 -> Predictions: [[0.00390428]\n",
            " [0.99576926]\n",
            " [0.995756  ]\n",
            " [0.00646673]]\n",
            "Step: 4441 -> Loss: 0.004722882062196732 -> Predictions: [[0.0039041 ]\n",
            " [0.9957694 ]\n",
            " [0.9957562 ]\n",
            " [0.00646641]]\n",
            "Step: 4442 -> Loss: 0.0047226459719240665 -> Predictions: [[0.00390391]\n",
            " [0.9957696 ]\n",
            " [0.99575645]\n",
            " [0.00646607]]\n",
            "Step: 4443 -> Loss: 0.004722416866570711 -> Predictions: [[0.00390373]\n",
            " [0.9957698 ]\n",
            " [0.99575657]\n",
            " [0.00646576]]\n",
            "Step: 4444 -> Loss: 0.004722177982330322 -> Predictions: [[0.00390354]\n",
            " [0.99577004]\n",
            " [0.9957568 ]\n",
            " [0.00646543]]\n",
            "Step: 4445 -> Loss: 0.004721943289041519 -> Predictions: [[0.00390336]\n",
            " [0.99577016]\n",
            " [0.99575704]\n",
            " [0.0064651 ]]\n",
            "Step: 4446 -> Loss: 0.004721708595752716 -> Predictions: [[0.00390317]\n",
            " [0.9957704 ]\n",
            " [0.9957573 ]\n",
            " [0.00646477]]\n",
            "Step: 4447 -> Loss: 0.004721475765109062 -> Predictions: [[0.00390299]\n",
            " [0.99577063]\n",
            " [0.9957575 ]\n",
            " [0.00646445]]\n",
            "Step: 4448 -> Loss: 0.0047212401404976845 -> Predictions: [[0.0039028 ]\n",
            " [0.9957709 ]\n",
            " [0.99575764]\n",
            " [0.00646413]]\n",
            "Step: 4449 -> Loss: 0.004721007775515318 -> Predictions: [[0.00390262]\n",
            " [0.9957711 ]\n",
            " [0.9957579 ]\n",
            " [0.0064638 ]]\n",
            "Step: 4450 -> Loss: 0.004720769822597504 -> Predictions: [[0.00390244]\n",
            " [0.9957712 ]\n",
            " [0.9957581 ]\n",
            " [0.00646347]]\n",
            "Step: 4451 -> Loss: 0.004720534663647413 -> Predictions: [[0.00390225]\n",
            " [0.99577147]\n",
            " [0.99575835]\n",
            " [0.00646315]]\n",
            "Step: 4452 -> Loss: 0.004720301833003759 -> Predictions: [[0.00390206]\n",
            " [0.9957717 ]\n",
            " [0.9957586 ]\n",
            " [0.00646282]]\n",
            "Step: 4453 -> Loss: 0.004720068536698818 -> Predictions: [[0.00390189]\n",
            " [0.99577194]\n",
            " [0.9957587 ]\n",
            " [0.0064625 ]]\n",
            "Step: 4454 -> Loss: 0.004719830583781004 -> Predictions: [[0.0039017 ]\n",
            " [0.9957722 ]\n",
            " [0.99575895]\n",
            " [0.00646217]]\n",
            "Step: 4455 -> Loss: 0.004719600547105074 -> Predictions: [[0.00390152]\n",
            " [0.9957723 ]\n",
            " [0.9957592 ]\n",
            " [0.00646185]]\n",
            "Step: 4456 -> Loss: 0.00471936259418726 -> Predictions: [[0.00390132]\n",
            " [0.99577254]\n",
            " [0.9957594 ]\n",
            " [0.00646152]]\n",
            "Step: 4457 -> Loss: 0.004719130229204893 -> Predictions: [[0.00390115]\n",
            " [0.9957728 ]\n",
            " [0.99575967]\n",
            " [0.0064612 ]]\n",
            "Step: 4458 -> Loss: 0.00471889553591609 -> Predictions: [[0.00390096]\n",
            " [0.995773  ]\n",
            " [0.9957598 ]\n",
            " [0.00646087]]\n",
            "Step: 4459 -> Loss: 0.00471865851432085 -> Predictions: [[0.00390077]\n",
            " [0.99577326]\n",
            " [0.99576   ]\n",
            " [0.00646055]]\n",
            "Step: 4460 -> Loss: 0.004718425218015909 -> Predictions: [[0.00390059]\n",
            " [0.9957734 ]\n",
            " [0.99576026]\n",
            " [0.00646022]]\n",
            "Step: 4461 -> Loss: 0.004718190990388393 -> Predictions: [[0.00390041]\n",
            " [0.9957736 ]\n",
            " [0.9957605 ]\n",
            " [0.00645989]]\n",
            "Step: 4462 -> Loss: 0.004717957228422165 -> Predictions: [[0.00390022]\n",
            " [0.99577385]\n",
            " [0.99576074]\n",
            " [0.00645956]]\n",
            "Step: 4463 -> Loss: 0.004717722535133362 -> Predictions: [[0.00390003]\n",
            " [0.9957741 ]\n",
            " [0.99576086]\n",
            " [0.00645923]]\n",
            "Step: 4464 -> Loss: 0.004717487841844559 -> Predictions: [[0.00389985]\n",
            " [0.9957742 ]\n",
            " [0.9957611 ]\n",
            " [0.0064589 ]]\n",
            "Step: 4465 -> Loss: 0.004717253148555756 -> Predictions: [[0.00389966]\n",
            " [0.99577445]\n",
            " [0.99576133]\n",
            " [0.00645857]]\n",
            "Step: 4466 -> Loss: 0.004717020783573389 -> Predictions: [[0.00389948]\n",
            " [0.9957747 ]\n",
            " [0.9957616 ]\n",
            " [0.00645824]]\n",
            "Step: 4467 -> Loss: 0.004716790281236172 -> Predictions: [[0.0038993 ]\n",
            " [0.9957749 ]\n",
            " [0.9957617 ]\n",
            " [0.00645791]]\n",
            "Step: 4468 -> Loss: 0.00471655186265707 -> Predictions: [[0.00389911]\n",
            " [0.99577504]\n",
            " [0.99576193]\n",
            " [0.00645758]]\n",
            "Step: 4469 -> Loss: 0.004716319497674704 -> Predictions: [[0.00389893]\n",
            " [0.9957753 ]\n",
            " [0.99576217]\n",
            " [0.00645726]]\n",
            "Step: 4470 -> Loss: 0.004716085270047188 -> Predictions: [[0.00389874]\n",
            " [0.9957755 ]\n",
            " [0.9957624 ]\n",
            " [0.00645693]]\n",
            "Step: 4471 -> Loss: 0.004715851508080959 -> Predictions: [[0.00389855]\n",
            " [0.99577576]\n",
            " [0.9957625 ]\n",
            " [0.0064566 ]]\n",
            "Step: 4472 -> Loss: 0.004715615883469582 -> Predictions: [[0.00389837]\n",
            " [0.9957759 ]\n",
            " [0.99576277]\n",
            " [0.00645627]]\n",
            "Step: 4473 -> Loss: 0.004715380258858204 -> Predictions: [[0.00389819]\n",
            " [0.9957761 ]\n",
            " [0.99576294]\n",
            " [0.00645593]]\n",
            "Step: 4474 -> Loss: 0.004715151619166136 -> Predictions: [[0.00389801]\n",
            " [0.99577636]\n",
            " [0.9957632 ]\n",
            " [0.00645561]]\n",
            "Step: 4475 -> Loss: 0.0047149136662483215 -> Predictions: [[0.00389782]\n",
            " [0.9957766 ]\n",
            " [0.9957634 ]\n",
            " [0.00645528]]\n",
            "Step: 4476 -> Loss: 0.00471468223258853 -> Predictions: [[0.00389764]\n",
            " [0.9957767 ]\n",
            " [0.99576354]\n",
            " [0.00645495]]\n",
            "Step: 4477 -> Loss: 0.00471444521099329 -> Predictions: [[0.00389745]\n",
            " [0.9957769 ]\n",
            " [0.9957638 ]\n",
            " [0.00645462]]\n",
            "Step: 4478 -> Loss: 0.004714213777333498 -> Predictions: [[0.00389727]\n",
            " [0.99577713]\n",
            " [0.995764  ]\n",
            " [0.00645429]]\n",
            "Step: 4479 -> Loss: 0.0047139814123511314 -> Predictions: [[0.00389709]\n",
            " [0.99577737]\n",
            " [0.99576426]\n",
            " [0.00645396]]\n",
            "Step: 4480 -> Loss: 0.004713744390755892 -> Predictions: [[0.0038969 ]\n",
            " [0.9957776 ]\n",
            " [0.9957644 ]\n",
            " [0.00645363]]\n",
            "Step: 4481 -> Loss: 0.004713510163128376 -> Predictions: [[0.00389672]\n",
            " [0.9957777 ]\n",
            " [0.9957646 ]\n",
            " [0.00645331]]\n",
            "Step: 4482 -> Loss: 0.004713278263807297 -> Predictions: [[0.00389653]\n",
            " [0.99577796]\n",
            " [0.99576485]\n",
            " [0.00645298]]\n",
            "Step: 4483 -> Loss: 0.004713044036179781 -> Predictions: [[0.00389635]\n",
            " [0.9957782 ]\n",
            " [0.9957651 ]\n",
            " [0.00645264]]\n",
            "Step: 4484 -> Loss: 0.0047128088772296906 -> Predictions: [[0.00389616]\n",
            " [0.99577844]\n",
            " [0.9957652 ]\n",
            " [0.00645231]]\n",
            "Step: 4485 -> Loss: 0.004712576046586037 -> Predictions: [[0.00389598]\n",
            " [0.99577856]\n",
            " [0.99576545]\n",
            " [0.00645198]]\n",
            "Step: 4486 -> Loss: 0.0047123427502810955 -> Predictions: [[0.0038958 ]\n",
            " [0.9957788 ]\n",
            " [0.9957657 ]\n",
            " [0.00645166]]\n",
            "Step: 4487 -> Loss: 0.00471210852265358 -> Predictions: [[0.00389561]\n",
            " [0.99577904]\n",
            " [0.9957659 ]\n",
            " [0.00645134]]\n",
            "Step: 4488 -> Loss: 0.004711871035397053 -> Predictions: [[0.00389542]\n",
            " [0.9957793 ]\n",
            " [0.99576616]\n",
            " [0.006451  ]]\n",
            "Step: 4489 -> Loss: 0.004711640998721123 -> Predictions: [[0.00389524]\n",
            " [0.9957794 ]\n",
            " [0.9957663 ]\n",
            " [0.00645067]]\n",
            "Step: 4490 -> Loss: 0.004711408633738756 -> Predictions: [[0.00389506]\n",
            " [0.99577963]\n",
            " [0.9957665 ]\n",
            " [0.00645035]]\n",
            "Step: 4491 -> Loss: 0.0047111730091273785 -> Predictions: [[0.00389487]\n",
            " [0.9957799 ]\n",
            " [0.99576676]\n",
            " [0.00645002]]\n",
            "Step: 4492 -> Loss: 0.004710938315838575 -> Predictions: [[0.00389469]\n",
            " [0.9957801 ]\n",
            " [0.995767  ]\n",
            " [0.00644969]]\n",
            "Step: 4493 -> Loss: 0.004710705019533634 -> Predictions: [[0.0038945 ]\n",
            " [0.9957802 ]\n",
            " [0.9957671 ]\n",
            " [0.00644936]]\n",
            "Step: 4494 -> Loss: 0.0047104693949222565 -> Predictions: [[0.00389431]\n",
            " [0.99578047]\n",
            " [0.99576735]\n",
            " [0.00644903]]\n",
            "Step: 4495 -> Loss: 0.004710238426923752 -> Predictions: [[0.00389413]\n",
            " [0.9957807 ]\n",
            " [0.9957676 ]\n",
            " [0.00644871]]\n",
            "Step: 4496 -> Loss: 0.004710005596280098 -> Predictions: [[0.00389395]\n",
            " [0.99578094]\n",
            " [0.99576783]\n",
            " [0.00644838]]\n",
            "Step: 4497 -> Loss: 0.004709772765636444 -> Predictions: [[0.00389376]\n",
            " [0.99578106]\n",
            " [0.99576795]\n",
            " [0.00644805]]\n",
            "Step: 4498 -> Loss: 0.0047095357440412045 -> Predictions: [[0.00389358]\n",
            " [0.9957813 ]\n",
            " [0.9957682 ]\n",
            " [0.00644771]]\n",
            "Step: 4499 -> Loss: 0.004709303379058838 -> Predictions: [[0.0038934 ]\n",
            " [0.99578154]\n",
            " [0.9957684 ]\n",
            " [0.00644738]]\n",
            "Step: 4501 -> Loss: 0.004708834923803806 -> Predictions: [[0.00389303]\n",
            " [0.995782  ]\n",
            " [0.9957689 ]\n",
            " [0.00644673]]\n",
            "Step: 4502 -> Loss: 0.004708603955805302 -> Predictions: [[0.00389284]\n",
            " [0.99578214]\n",
            " [0.995769  ]\n",
            " [0.0064464 ]]\n",
            "Step: 4503 -> Loss: 0.004708367865532637 -> Predictions: [[0.00389266]\n",
            " [0.9957824 ]\n",
            " [0.99576926]\n",
            " [0.00644607]]\n",
            "Step: 4504 -> Loss: 0.0047081345692276955 -> Predictions: [[0.00389247]\n",
            " [0.9957826 ]\n",
            " [0.9957695 ]\n",
            " [0.00644574]]\n",
            "Step: 4505 -> Loss: 0.004707901738584042 -> Predictions: [[0.00389229]\n",
            " [0.99578285]\n",
            " [0.99576974]\n",
            " [0.00644542]]\n",
            "Step: 4506 -> Loss: 0.0047076670452952385 -> Predictions: [[0.0038921 ]\n",
            " [0.995783  ]\n",
            " [0.9957698 ]\n",
            " [0.00644509]]\n",
            "Step: 4507 -> Loss: 0.004707432817667723 -> Predictions: [[0.00389192]\n",
            " [0.9957832 ]\n",
            " [0.99577004]\n",
            " [0.00644476]]\n",
            "Step: 4508 -> Loss: 0.004707201384007931 -> Predictions: [[0.00389174]\n",
            " [0.99578345]\n",
            " [0.9957703 ]\n",
            " [0.00644443]]\n",
            "Step: 4509 -> Loss: 0.004706969019025564 -> Predictions: [[0.00389156]\n",
            " [0.9957837 ]\n",
            " [0.9957705 ]\n",
            " [0.0064441 ]]\n",
            "Step: 4510 -> Loss: 0.0047067333944141865 -> Predictions: [[0.00389137]\n",
            " [0.9957838 ]\n",
            " [0.99577075]\n",
            " [0.00644377]]\n",
            "Step: 4511 -> Loss: 0.004706499166786671 -> Predictions: [[0.00389119]\n",
            " [0.995784  ]\n",
            " [0.9957709 ]\n",
            " [0.00644344]]\n",
            "Step: 4512 -> Loss: 0.004706263076514006 -> Predictions: [[0.003891  ]\n",
            " [0.9957842 ]\n",
            " [0.9957711 ]\n",
            " [0.00644312]]\n",
            "Step: 4513 -> Loss: 0.004706033505499363 -> Predictions: [[0.00389082]\n",
            " [0.99578446]\n",
            " [0.99577135]\n",
            " [0.00644279]]\n",
            "Step: 4514 -> Loss: 0.004705801140516996 -> Predictions: [[0.00389064]\n",
            " [0.9957846 ]\n",
            " [0.9957716 ]\n",
            " [0.00644246]]\n",
            "Step: 4515 -> Loss: 0.004705566447228193 -> Predictions: [[0.00389045]\n",
            " [0.9957848 ]\n",
            " [0.9957717 ]\n",
            " [0.00644213]]\n",
            "Step: 4516 -> Loss: 0.004705331288278103 -> Predictions: [[0.00389026]\n",
            " [0.99578506]\n",
            " [0.99577194]\n",
            " [0.0064418 ]]\n",
            "Step: 4517 -> Loss: 0.004705100320279598 -> Predictions: [[0.00389008]\n",
            " [0.9957853 ]\n",
            " [0.9957722 ]\n",
            " [0.00644147]]\n",
            "Step: 4518 -> Loss: 0.004704863764345646 -> Predictions: [[0.0038899 ]\n",
            " [0.9957854 ]\n",
            " [0.9957724 ]\n",
            " [0.00644114]]\n",
            "Step: 4519 -> Loss: 0.004704631865024567 -> Predictions: [[0.00388971]\n",
            " [0.99578565]\n",
            " [0.99577254]\n",
            " [0.00644082]]\n",
            "Step: 4520 -> Loss: 0.004704396240413189 -> Predictions: [[0.00388952]\n",
            " [0.9957859 ]\n",
            " [0.9957728 ]\n",
            " [0.00644049]]\n",
            "Step: 4521 -> Loss: 0.004704166669398546 -> Predictions: [[0.00388935]\n",
            " [0.99578613]\n",
            " [0.995773  ]\n",
            " [0.00644016]]\n",
            "Step: 4522 -> Loss: 0.00470393244177103 -> Predictions: [[0.00388916]\n",
            " [0.99578625]\n",
            " [0.99577326]\n",
            " [0.00643984]]\n",
            "Step: 4523 -> Loss: 0.00470369728282094 -> Predictions: [[0.00388897]\n",
            " [0.9957865 ]\n",
            " [0.9957734 ]\n",
            " [0.0064395 ]]\n",
            "Step: 4524 -> Loss: 0.004703467711806297 -> Predictions: [[0.0038888 ]\n",
            " [0.9957867 ]\n",
            " [0.9957736 ]\n",
            " [0.00643918]]\n",
            "Step: 4525 -> Loss: 0.004703234415501356 -> Predictions: [[0.00388861]\n",
            " [0.99578696]\n",
            " [0.99577385]\n",
            " [0.00643885]]\n",
            "Step: 4526 -> Loss: 0.004702999722212553 -> Predictions: [[0.00388843]\n",
            " [0.9957872 ]\n",
            " [0.9957741 ]\n",
            " [0.00643852]]\n",
            "Step: 4527 -> Loss: 0.004702766891568899 -> Predictions: [[0.00388823]\n",
            " [0.9957873 ]\n",
            " [0.9957742 ]\n",
            " [0.00643819]]\n",
            "Step: 4528 -> Loss: 0.004702532663941383 -> Predictions: [[0.00388806]\n",
            " [0.99578756]\n",
            " [0.99577445]\n",
            " [0.00643786]]\n",
            "Step: 4529 -> Loss: 0.004702297039330006 -> Predictions: [[0.00388787]\n",
            " [0.9957878 ]\n",
            " [0.9957747 ]\n",
            " [0.00643753]]\n",
            "Step: 4530 -> Loss: 0.004702064208686352 -> Predictions: [[0.00388768]\n",
            " [0.99578804]\n",
            " [0.9957749 ]\n",
            " [0.0064372 ]]\n",
            "Step: 4531 -> Loss: 0.004701831843703985 -> Predictions: [[0.0038875 ]\n",
            " [0.99578816]\n",
            " [0.99577516]\n",
            " [0.00643688]]\n",
            "Step: 4532 -> Loss: 0.004701598081737757 -> Predictions: [[0.00388732]\n",
            " [0.9957884 ]\n",
            " [0.9957753 ]\n",
            " [0.00643655]]\n",
            "Step: 4533 -> Loss: 0.0047013661824166775 -> Predictions: [[0.00388714]\n",
            " [0.99578863]\n",
            " [0.9957755 ]\n",
            " [0.00643623]]\n",
            "Step: 4534 -> Loss: 0.004701132886111736 -> Predictions: [[0.00388695]\n",
            " [0.9957889 ]\n",
            " [0.99577576]\n",
            " [0.0064359 ]]\n",
            "Step: 4535 -> Loss: 0.004700897261500359 -> Predictions: [[0.00388677]\n",
            " [0.995789  ]\n",
            " [0.995776  ]\n",
            " [0.00643556]]\n",
            "Step: 4536 -> Loss: 0.004700666293501854 -> Predictions: [[0.00388659]\n",
            " [0.99578923]\n",
            " [0.9957761 ]\n",
            " [0.00643524]]\n",
            "Step: 4537 -> Loss: 0.004700432065874338 -> Predictions: [[0.00388639]\n",
            " [0.99578947]\n",
            " [0.99577636]\n",
            " [0.00643491]]\n",
            "Step: 4538 -> Loss: 0.004700199235230684 -> Predictions: [[0.00388622]\n",
            " [0.9957897 ]\n",
            " [0.9957766 ]\n",
            " [0.00643458]]\n",
            "Step: 4539 -> Loss: 0.004699968732893467 -> Predictions: [[0.00388603]\n",
            " [0.9957898 ]\n",
            " [0.9957768 ]\n",
            " [0.00643425]]\n",
            "Step: 4540 -> Loss: 0.004699732176959515 -> Predictions: [[0.00388585]\n",
            " [0.99579006]\n",
            " [0.9957769 ]\n",
            " [0.00643392]]\n",
            "Step: 4541 -> Loss: 0.004699499346315861 -> Predictions: [[0.00388566]\n",
            " [0.9957903 ]\n",
            " [0.99577713]\n",
            " [0.0064336 ]]\n",
            "Step: 4542 -> Loss: 0.0046992674469947815 -> Predictions: [[0.00388548]\n",
            " [0.99579054]\n",
            " [0.99577737]\n",
            " [0.00643327]]\n",
            "Step: 4543 -> Loss: 0.004699034616351128 -> Predictions: [[0.0038853 ]\n",
            " [0.99579066]\n",
            " [0.9957776 ]\n",
            " [0.00643294]]\n",
            "Step: 4544 -> Loss: 0.004698802251368761 -> Predictions: [[0.00388511]\n",
            " [0.99579084]\n",
            " [0.99577785]\n",
            " [0.00643261]]\n",
            "Step: 4545 -> Loss: 0.004698568023741245 -> Predictions: [[0.00388492]\n",
            " [0.9957911 ]\n",
            " [0.99577796]\n",
            " [0.00643229]]\n",
            "Step: 4546 -> Loss: 0.004698334261775017 -> Predictions: [[0.00388474]\n",
            " [0.9957913 ]\n",
            " [0.9957782 ]\n",
            " [0.00643196]]\n",
            "Step: 4547 -> Loss: 0.004698100499808788 -> Predictions: [[0.00388456]\n",
            " [0.99579144]\n",
            " [0.99577844]\n",
            " [0.00643163]]\n",
            "Step: 4548 -> Loss: 0.004697869066148996 -> Predictions: [[0.00388438]\n",
            " [0.9957917 ]\n",
            " [0.9957787 ]\n",
            " [0.0064313 ]]\n",
            "Step: 4549 -> Loss: 0.004697635769844055 -> Predictions: [[0.00388419]\n",
            " [0.9957919 ]\n",
            " [0.9957788 ]\n",
            " [0.00643098]]\n",
            "Step: 4550 -> Loss: 0.004697403404861689 -> Predictions: [[0.00388401]\n",
            " [0.99579215]\n",
            " [0.99577904]\n",
            " [0.00643065]]\n",
            "Step: 4551 -> Loss: 0.004697168245911598 -> Predictions: [[0.00388382]\n",
            " [0.99579227]\n",
            " [0.9957793 ]\n",
            " [0.00643032]]\n",
            "Step: 4552 -> Loss: 0.004696935880929232 -> Predictions: [[0.00388364]\n",
            " [0.9957925 ]\n",
            " [0.9957795 ]\n",
            " [0.00642999]]\n",
            "Step: 4553 -> Loss: 0.00469670444726944 -> Predictions: [[0.00388345]\n",
            " [0.99579275]\n",
            " [0.99577963]\n",
            " [0.00642967]]\n",
            "Step: 4554 -> Loss: 0.0046964711509644985 -> Predictions: [[0.00388327]\n",
            " [0.995793  ]\n",
            " [0.9957799 ]\n",
            " [0.00642934]]\n",
            "Step: 4555 -> Loss: 0.004696235526353121 -> Predictions: [[0.00388309]\n",
            " [0.9957931 ]\n",
            " [0.9957801 ]\n",
            " [0.006429  ]]\n",
            "Step: 4556 -> Loss: 0.0046960050240159035 -> Predictions: [[0.0038829 ]\n",
            " [0.99579334]\n",
            " [0.99578035]\n",
            " [0.00642868]]\n",
            "Step: 4557 -> Loss: 0.0046957735903561115 -> Predictions: [[0.00388272]\n",
            " [0.9957936 ]\n",
            " [0.99578047]\n",
            " [0.00642836]]\n",
            "Step: 4558 -> Loss: 0.0046955375000834465 -> Predictions: [[0.00388254]\n",
            " [0.9957938 ]\n",
            " [0.9957807 ]\n",
            " [0.00642802]]\n",
            "Step: 4559 -> Loss: 0.004695306532084942 -> Predictions: [[0.00388236]\n",
            " [0.99579394]\n",
            " [0.99578094]\n",
            " [0.00642769]]\n",
            "Step: 4560 -> Loss: 0.004695072770118713 -> Predictions: [[0.00388217]\n",
            " [0.9957942 ]\n",
            " [0.9957812 ]\n",
            " [0.00642737]]\n",
            "Step: 4561 -> Loss: 0.004694839008152485 -> Predictions: [[0.00388199]\n",
            " [0.9957944 ]\n",
            " [0.9957814 ]\n",
            " [0.00642705]]\n",
            "Step: 4562 -> Loss: 0.0046946099027991295 -> Predictions: [[0.0038818 ]\n",
            " [0.99579465]\n",
            " [0.99578154]\n",
            " [0.00642672]]\n",
            "Step: 4563 -> Loss: 0.004694375675171614 -> Predictions: [[0.00388162]\n",
            " [0.9957948 ]\n",
            " [0.9957818 ]\n",
            " [0.00642639]]\n",
            "Step: 4564 -> Loss: 0.0046941423788666725 -> Predictions: [[0.00388144]\n",
            " [0.995795  ]\n",
            " [0.995782  ]\n",
            " [0.00642607]]\n",
            "Step: 4565 -> Loss: 0.004693907685577869 -> Predictions: [[0.00388125]\n",
            " [0.99579525]\n",
            " [0.99578226]\n",
            " [0.00642573]]\n",
            "Step: 4566 -> Loss: 0.004693675320595503 -> Predictions: [[0.00388107]\n",
            " [0.9957955 ]\n",
            " [0.9957824 ]\n",
            " [0.0064254 ]]\n",
            "Step: 4567 -> Loss: 0.004693441558629274 -> Predictions: [[0.00388088]\n",
            " [0.9957956 ]\n",
            " [0.9957826 ]\n",
            " [0.00642508]]\n",
            "Step: 4568 -> Loss: 0.004693208262324333 -> Predictions: [[0.0038807 ]\n",
            " [0.99579585]\n",
            " [0.99578285]\n",
            " [0.00642475]]\n",
            "Step: 4569 -> Loss: 0.004692975431680679 -> Predictions: [[0.00388052]\n",
            " [0.9957961 ]\n",
            " [0.9957831 ]\n",
            " [0.00642442]]\n",
            "Step: 4570 -> Loss: 0.004692745860666037 -> Predictions: [[0.00388033]\n",
            " [0.9957963 ]\n",
            " [0.9957832 ]\n",
            " [0.0064241 ]]\n",
            "Step: 4571 -> Loss: 0.004692513961344957 -> Predictions: [[0.00388015]\n",
            " [0.99579644]\n",
            " [0.99578345]\n",
            " [0.00642377]]\n",
            "Step: 4572 -> Loss: 0.004692282062023878 -> Predictions: [[0.00387997]\n",
            " [0.9957967 ]\n",
            " [0.9957837 ]\n",
            " [0.00642344]]\n",
            "Step: 4573 -> Loss: 0.004692048765718937 -> Predictions: [[0.00387979]\n",
            " [0.9957969 ]\n",
            " [0.99578387]\n",
            " [0.00642312]]\n",
            "Step: 4574 -> Loss: 0.004691812209784985 -> Predictions: [[0.0038796 ]\n",
            " [0.99579716]\n",
            " [0.995784  ]\n",
            " [0.00642278]]\n",
            "Step: 4575 -> Loss: 0.0046915821731090546 -> Predictions: [[0.00387942]\n",
            " [0.9957973 ]\n",
            " [0.9957842 ]\n",
            " [0.00642246]]\n",
            "Step: 4576 -> Loss: 0.004691348411142826 -> Predictions: [[0.00387923]\n",
            " [0.9957975 ]\n",
            " [0.99578446]\n",
            " [0.00642213]]\n",
            "Step: 4577 -> Loss: 0.004691118374466896 -> Predictions: [[0.00387905]\n",
            " [0.99579775]\n",
            " [0.9957847 ]\n",
            " [0.00642181]]\n",
            "Step: 4578 -> Loss: 0.004690883681178093 -> Predictions: [[0.00387887]\n",
            " [0.99579793]\n",
            " [0.99578494]\n",
            " [0.00642148]]\n",
            "Step: 4579 -> Loss: 0.004690648056566715 -> Predictions: [[0.00387868]\n",
            " [0.99579805]\n",
            " [0.99578506]\n",
            " [0.00642114]]\n",
            "Step: 4580 -> Loss: 0.004690418019890785 -> Predictions: [[0.0038785 ]\n",
            " [0.9957983 ]\n",
            " [0.9957853 ]\n",
            " [0.00642082]]\n",
            "Step: 4581 -> Loss: 0.004690186120569706 -> Predictions: [[0.00387831]\n",
            " [0.9957985 ]\n",
            " [0.99578553]\n",
            " [0.0064205 ]]\n",
            "Step: 4582 -> Loss: 0.004689953289926052 -> Predictions: [[0.00387813]\n",
            " [0.99579877]\n",
            " [0.9957858 ]\n",
            " [0.00642017]]\n",
            "Step: 4583 -> Loss: 0.004689719062298536 -> Predictions: [[0.00387795]\n",
            " [0.9957989 ]\n",
            " [0.9957859 ]\n",
            " [0.00641984]]\n",
            "Step: 4584 -> Loss: 0.004689488094300032 -> Predictions: [[0.00387776]\n",
            " [0.9957991 ]\n",
            " [0.99578613]\n",
            " [0.00641952]]\n",
            "Step: 4585 -> Loss: 0.004689255729317665 -> Predictions: [[0.00387758]\n",
            " [0.99579936]\n",
            " [0.99578637]\n",
            " [0.00641919]]\n",
            "Step: 4586 -> Loss: 0.004689023829996586 -> Predictions: [[0.0038774 ]\n",
            " [0.9957996 ]\n",
            " [0.9957866 ]\n",
            " [0.00641886]]\n",
            "Step: 4587 -> Loss: 0.004688789136707783 -> Predictions: [[0.00387721]\n",
            " [0.9957997 ]\n",
            " [0.9957867 ]\n",
            " [0.00641853]]\n",
            "Step: 4588 -> Loss: 0.004688555374741554 -> Predictions: [[0.00387703]\n",
            " [0.99579996]\n",
            " [0.99578696]\n",
            " [0.0064182 ]]\n",
            "Step: 4589 -> Loss: 0.004688323475420475 -> Predictions: [[0.00387685]\n",
            " [0.9958002 ]\n",
            " [0.9957872 ]\n",
            " [0.00641787]]\n",
            "Step: 4590 -> Loss: 0.004688091576099396 -> Predictions: [[0.00387666]\n",
            " [0.99580044]\n",
            " [0.99578744]\n",
            " [0.00641755]]\n",
            "Step: 4591 -> Loss: 0.00468785734847188 -> Predictions: [[0.00387648]\n",
            " [0.99580055]\n",
            " [0.99578756]\n",
            " [0.00641722]]\n",
            "Step: 4592 -> Loss: 0.004687625449150801 -> Predictions: [[0.00387629]\n",
            " [0.9958008 ]\n",
            " [0.9957878 ]\n",
            " [0.0064169 ]]\n",
            "Step: 4593 -> Loss: 0.004687394015491009 -> Predictions: [[0.00387611]\n",
            " [0.99580103]\n",
            " [0.99578804]\n",
            " [0.00641657]]\n",
            "Step: 4594 -> Loss: 0.0046871621161699295 -> Predictions: [[0.00387593]\n",
            " [0.99580127]\n",
            " [0.9957883 ]\n",
            " [0.00641624]]\n",
            "Step: 4595 -> Loss: 0.004686929285526276 -> Predictions: [[0.00387575]\n",
            " [0.9958014 ]\n",
            " [0.9957884 ]\n",
            " [0.00641591]]\n",
            "Step: 4596 -> Loss: 0.004686696454882622 -> Predictions: [[0.00387557]\n",
            " [0.9958016 ]\n",
            " [0.99578863]\n",
            " [0.00641559]]\n",
            "Step: 4597 -> Loss: 0.004686465486884117 -> Predictions: [[0.00387538]\n",
            " [0.99580187]\n",
            " [0.9957889 ]\n",
            " [0.00641526]]\n",
            "Step: 4598 -> Loss: 0.004686230793595314 -> Predictions: [[0.0038752 ]\n",
            " [0.9958021 ]\n",
            " [0.9957891 ]\n",
            " [0.00641493]]\n",
            "Step: 4599 -> Loss: 0.0046859984286129475 -> Predictions: [[0.00387501]\n",
            " [0.9958022 ]\n",
            " [0.99578923]\n",
            " [0.0064146 ]]\n",
            "Step: 4600 -> Loss: 0.0046857669949531555 -> Predictions: [[0.00387483]\n",
            " [0.99580246]\n",
            " [0.99578947]\n",
            " [0.00641428]]\n",
            "Step: 4601 -> Loss: 0.004685534164309502 -> Predictions: [[0.00387464]\n",
            " [0.9958027 ]\n",
            " [0.9957897 ]\n",
            " [0.00641395]]\n",
            "Step: 4602 -> Loss: 0.004685305058956146 -> Predictions: [[0.00387446]\n",
            " [0.99580294]\n",
            " [0.99578995]\n",
            " [0.00641363]]\n",
            "Step: 4603 -> Loss: 0.004685068503022194 -> Predictions: [[0.00387428]\n",
            " [0.99580306]\n",
            " [0.9957902 ]\n",
            " [0.0064133 ]]\n",
            "Step: 4604 -> Loss: 0.004684838466346264 -> Predictions: [[0.00387409]\n",
            " [0.9958033 ]\n",
            " [0.9957903 ]\n",
            " [0.00641298]]\n",
            "Step: 4605 -> Loss: 0.004684606567025185 -> Predictions: [[0.00387391]\n",
            " [0.99580353]\n",
            " [0.99579054]\n",
            " [0.00641265]]\n",
            "Step: 4606 -> Loss: 0.0046843718737363815 -> Predictions: [[0.00387372]\n",
            " [0.9958038 ]\n",
            " [0.9957908 ]\n",
            " [0.00641232]]\n",
            "Step: 4607 -> Loss: 0.004684139508754015 -> Predictions: [[0.00387355]\n",
            " [0.9958039 ]\n",
            " [0.99579096]\n",
            " [0.00641199]]\n",
            "Step: 4608 -> Loss: 0.004683909472078085 -> Predictions: [[0.00387337]\n",
            " [0.99580413]\n",
            " [0.9957911 ]\n",
            " [0.00641167]]\n",
            "Step: 4609 -> Loss: 0.004683676175773144 -> Predictions: [[0.00387318]\n",
            " [0.99580437]\n",
            " [0.9957913 ]\n",
            " [0.00641134]]\n",
            "Step: 4610 -> Loss: 0.004683442413806915 -> Predictions: [[0.00387299]\n",
            " [0.9958046 ]\n",
            " [0.99579155]\n",
            " [0.00641101]]\n",
            "Step: 4611 -> Loss: 0.00468321330845356 -> Predictions: [[0.00387281]\n",
            " [0.9958047 ]\n",
            " [0.9957918 ]\n",
            " [0.00641069]]\n",
            "Step: 4612 -> Loss: 0.004682980477809906 -> Predictions: [[0.00387263]\n",
            " [0.9958049 ]\n",
            " [0.9957919 ]\n",
            " [0.00641036]]\n",
            "Step: 4613 -> Loss: 0.004682745784521103 -> Predictions: [[0.00387244]\n",
            " [0.99580514]\n",
            " [0.99579215]\n",
            " [0.00641004]]\n",
            "Step: 4614 -> Loss: 0.004682512953877449 -> Predictions: [[0.00387226]\n",
            " [0.9958054 ]\n",
            " [0.9957924 ]\n",
            " [0.0064097 ]]\n",
            "Step: 4615 -> Loss: 0.004682282917201519 -> Predictions: [[0.00387208]\n",
            " [0.9958055 ]\n",
            " [0.9957926 ]\n",
            " [0.00640938]]\n",
            "Step: 4616 -> Loss: 0.004682049620896578 -> Predictions: [[0.0038719 ]\n",
            " [0.99580574]\n",
            " [0.99579275]\n",
            " [0.00640905]]\n",
            "Step: 4617 -> Loss: 0.004681815393269062 -> Predictions: [[0.00387171]\n",
            " [0.995806  ]\n",
            " [0.995793  ]\n",
            " [0.00640873]]\n",
            "Step: 4618 -> Loss: 0.004681582562625408 -> Predictions: [[0.00387152]\n",
            " [0.9958062 ]\n",
            " [0.9957932 ]\n",
            " [0.00640839]]\n",
            "Step: 4619 -> Loss: 0.004681350197643042 -> Predictions: [[0.00387135]\n",
            " [0.99580634]\n",
            " [0.99579346]\n",
            " [0.00640807]]\n",
            "Step: 4620 -> Loss: 0.004681125283241272 -> Predictions: [[0.00387116]\n",
            " [0.9958066 ]\n",
            " [0.9957936 ]\n",
            " [0.00640775]]\n",
            "Step: 4621 -> Loss: 0.004680891055613756 -> Predictions: [[0.00387097]\n",
            " [0.9958068 ]\n",
            " [0.9957938 ]\n",
            " [0.00640742]]\n",
            "Step: 4622 -> Loss: 0.00468065869063139 -> Predictions: [[0.00387078]\n",
            " [0.99580705]\n",
            " [0.99579406]\n",
            " [0.0064071 ]]\n",
            "Step: 4623 -> Loss: 0.004680429585278034 -> Predictions: [[0.0038706 ]\n",
            " [0.9958072 ]\n",
            " [0.9957943 ]\n",
            " [0.00640677]]\n",
            "Step: 4624 -> Loss: 0.004680197685956955 -> Predictions: [[0.00387041]\n",
            " [0.9958074 ]\n",
            " [0.9957944 ]\n",
            " [0.00640645]]\n",
            "Step: 4625 -> Loss: 0.004679963458329439 -> Predictions: [[0.00387022]\n",
            " [0.99580765]\n",
            " [0.99579465]\n",
            " [0.00640612]]\n",
            "Step: 4626 -> Loss: 0.004679735749959946 -> Predictions: [[0.00387004]\n",
            " [0.9958079 ]\n",
            " [0.9957949 ]\n",
            " [0.0064058 ]]\n",
            "Step: 4627 -> Loss: 0.004679507575929165 -> Predictions: [[0.00386986]\n",
            " [0.995808  ]\n",
            " [0.99579513]\n",
            " [0.00640548]]\n",
            "Step: 4628 -> Loss: 0.004679273813962936 -> Predictions: [[0.00386968]\n",
            " [0.99580824]\n",
            " [0.99579525]\n",
            " [0.00640516]]\n",
            "Step: 4629 -> Loss: 0.004679040051996708 -> Predictions: [[0.00386948]\n",
            " [0.9958085 ]\n",
            " [0.9957955 ]\n",
            " [0.00640483]]\n",
            "Step: 4630 -> Loss: 0.004678811877965927 -> Predictions: [[0.0038693 ]\n",
            " [0.9958086 ]\n",
            " [0.9957957 ]\n",
            " [0.00640452]]\n",
            "Step: 4631 -> Loss: 0.004678581841289997 -> Predictions: [[0.00386912]\n",
            " [0.99580884]\n",
            " [0.99579597]\n",
            " [0.0064042 ]]\n",
            "Step: 4632 -> Loss: 0.004678351804614067 -> Predictions: [[0.00386893]\n",
            " [0.9958091 ]\n",
            " [0.9957961 ]\n",
            " [0.00640387]]\n",
            "Step: 4633 -> Loss: 0.004678117111325264 -> Predictions: [[0.00386874]\n",
            " [0.9958093 ]\n",
            " [0.9957963 ]\n",
            " [0.00640355]]\n",
            "Step: 4634 -> Loss: 0.004677884746342897 -> Predictions: [[0.00386856]\n",
            " [0.99580944]\n",
            " [0.99579656]\n",
            " [0.00640322]]\n",
            "Step: 4635 -> Loss: 0.004677661694586277 -> Predictions: [[0.00386838]\n",
            " [0.9958097 ]\n",
            " [0.9957967 ]\n",
            " [0.00640291]]\n",
            "Step: 4636 -> Loss: 0.004677428863942623 -> Predictions: [[0.00386819]\n",
            " [0.9958099 ]\n",
            " [0.9957969 ]\n",
            " [0.00640258]]\n",
            "Step: 4637 -> Loss: 0.00467719417065382 -> Predictions: [[0.00386801]\n",
            " [0.99581015]\n",
            " [0.99579716]\n",
            " [0.00640226]]\n",
            "Step: 4638 -> Loss: 0.004676965065300465 -> Predictions: [[0.00386782]\n",
            " [0.9958103 ]\n",
            " [0.9957974 ]\n",
            " [0.00640194]]\n",
            "Step: 4639 -> Loss: 0.004676734562963247 -> Predictions: [[0.00386764]\n",
            " [0.9958105 ]\n",
            " [0.9957975 ]\n",
            " [0.00640162]]\n",
            "Step: 4640 -> Loss: 0.0046765063889324665 -> Predictions: [[0.00386746]\n",
            " [0.99581075]\n",
            " [0.99579775]\n",
            " [0.0064013 ]]\n",
            "Step: 4641 -> Loss: 0.004676272161304951 -> Predictions: [[0.00386727]\n",
            " [0.995811  ]\n",
            " [0.99579793]\n",
            " [0.00640098]]\n",
            "Step: 4642 -> Loss: 0.004676042590290308 -> Predictions: [[0.00386708]\n",
            " [0.9958111 ]\n",
            " [0.9957982 ]\n",
            " [0.00640066]]\n",
            "Step: 4643 -> Loss: 0.004675813019275665 -> Predictions: [[0.0038669 ]\n",
            " [0.99581134]\n",
            " [0.9957983 ]\n",
            " [0.00640033]]\n",
            "Step: 4644 -> Loss: 0.004675581119954586 -> Predictions: [[0.00386672]\n",
            " [0.9958116 ]\n",
            " [0.9957985 ]\n",
            " [0.00640001]]\n",
            "Step: 4645 -> Loss: 0.0046753473579883575 -> Predictions: [[0.00386653]\n",
            " [0.9958118 ]\n",
            " [0.99579877]\n",
            " [0.00639968]]\n",
            "Step: 4646 -> Loss: 0.004675122909247875 -> Predictions: [[0.00386635]\n",
            " [0.99581194]\n",
            " [0.995799  ]\n",
            " [0.00639937]]\n",
            "Step: 4647 -> Loss: 0.004674887750297785 -> Predictions: [[0.00386616]\n",
            " [0.9958121 ]\n",
            " [0.9957991 ]\n",
            " [0.00639904]]\n",
            "Step: 4648 -> Loss: 0.0046746572479605675 -> Predictions: [[0.00386598]\n",
            " [0.99581236]\n",
            " [0.99579936]\n",
            " [0.00639872]]\n",
            "Step: 4649 -> Loss: 0.004674428142607212 -> Predictions: [[0.00386579]\n",
            " [0.9958126 ]\n",
            " [0.9957996 ]\n",
            " [0.0063984 ]]\n",
            "Step: 4650 -> Loss: 0.00467419670894742 -> Predictions: [[0.00386561]\n",
            " [0.9958127 ]\n",
            " [0.99579984]\n",
            " [0.00639808]]\n",
            "Step: 4651 -> Loss: 0.004673967603594065 -> Predictions: [[0.00386542]\n",
            " [0.99581295]\n",
            " [0.99579996]\n",
            " [0.00639776]]\n",
            "Step: 4652 -> Loss: 0.004673735238611698 -> Predictions: [[0.00386523]\n",
            " [0.9958132 ]\n",
            " [0.9958002 ]\n",
            " [0.00639744]]\n",
            "Step: 4653 -> Loss: 0.004673505201935768 -> Predictions: [[0.00386505]\n",
            " [0.9958134 ]\n",
            " [0.99580044]\n",
            " [0.00639712]]\n",
            "Step: 4654 -> Loss: 0.004673273302614689 -> Predictions: [[0.00386487]\n",
            " [0.99581355]\n",
            " [0.9958007 ]\n",
            " [0.0063968 ]]\n",
            "Step: 4655 -> Loss: 0.004673046059906483 -> Predictions: [[0.00386468]\n",
            " [0.9958138 ]\n",
            " [0.9958008 ]\n",
            " [0.00639648]]\n",
            "Step: 4656 -> Loss: 0.004672811832278967 -> Predictions: [[0.00386449]\n",
            " [0.995814  ]\n",
            " [0.99580103]\n",
            " [0.00639616]]\n",
            "Step: 4657 -> Loss: 0.00467258132994175 -> Predictions: [[0.00386431]\n",
            " [0.99581414]\n",
            " [0.99580127]\n",
            " [0.00639582]]\n",
            "Step: 4658 -> Loss: 0.004672353155910969 -> Predictions: [[0.00386412]\n",
            " [0.9958144 ]\n",
            " [0.9958015 ]\n",
            " [0.00639551]]\n",
            "Step: 4659 -> Loss: 0.00467211939394474 -> Predictions: [[0.00386394]\n",
            " [0.9958146 ]\n",
            " [0.9958016 ]\n",
            " [0.00639519]]\n",
            "Step: 4660 -> Loss: 0.004671890754252672 -> Predictions: [[0.00386376]\n",
            " [0.99581486]\n",
            " [0.99580187]\n",
            " [0.00639487]]\n",
            "Step: 4661 -> Loss: 0.004671662114560604 -> Predictions: [[0.00386358]\n",
            " [0.995815  ]\n",
            " [0.9958021 ]\n",
            " [0.00639454]]\n",
            "Step: 4662 -> Loss: 0.004671433009207249 -> Predictions: [[0.0038634 ]\n",
            " [0.9958152 ]\n",
            " [0.99580234]\n",
            " [0.00639423]]\n",
            "Step: 4663 -> Loss: 0.004671202972531319 -> Predictions: [[0.00386321]\n",
            " [0.99581546]\n",
            " [0.99580246]\n",
            " [0.00639391]]\n",
            "Step: 4664 -> Loss: 0.004670972004532814 -> Predictions: [[0.00386304]\n",
            " [0.9958157 ]\n",
            " [0.9958027 ]\n",
            " [0.00639358]]\n",
            "Step: 4665 -> Loss: 0.004670743364840746 -> Predictions: [[0.00386286]\n",
            " [0.9958158 ]\n",
            " [0.99580294]\n",
            " [0.00639326]]\n",
            "Step: 4666 -> Loss: 0.004670513793826103 -> Predictions: [[0.00386267]\n",
            " [0.99581605]\n",
            " [0.99580306]\n",
            " [0.00639294]]\n",
            "Step: 4667 -> Loss: 0.004670287482440472 -> Predictions: [[0.0038625 ]\n",
            " [0.9958163 ]\n",
            " [0.9958033 ]\n",
            " [0.00639262]]\n",
            "Step: 4668 -> Loss: 0.00467005604878068 -> Predictions: [[0.00386231]\n",
            " [0.9958165 ]\n",
            " [0.99580353]\n",
            " [0.0063923 ]]\n",
            "Step: 4669 -> Loss: 0.004669826477766037 -> Predictions: [[0.00386213]\n",
            " [0.99581665]\n",
            " [0.9958038 ]\n",
            " [0.00639198]]\n",
            "Step: 4670 -> Loss: 0.004669595044106245 -> Predictions: [[0.00386195]\n",
            " [0.9958169 ]\n",
            " [0.9958039 ]\n",
            " [0.00639165]]\n",
            "Step: 4671 -> Loss: 0.004669365473091602 -> Predictions: [[0.00386177]\n",
            " [0.9958171 ]\n",
            " [0.99580413]\n",
            " [0.00639134]]\n",
            "Step: 4672 -> Loss: 0.0046691372990608215 -> Predictions: [[0.00386158]\n",
            " [0.99581736]\n",
            " [0.99580437]\n",
            " [0.00639102]]\n",
            "Step: 4673 -> Loss: 0.004668907728046179 -> Predictions: [[0.0038614 ]\n",
            " [0.9958175 ]\n",
            " [0.9958046 ]\n",
            " [0.00639069]]\n",
            "Step: 4674 -> Loss: 0.004668676760047674 -> Predictions: [[0.00386122]\n",
            " [0.9958177 ]\n",
            " [0.9958047 ]\n",
            " [0.00639037]]\n",
            "Step: 4675 -> Loss: 0.004668449517339468 -> Predictions: [[0.00386104]\n",
            " [0.99581796]\n",
            " [0.9958049 ]\n",
            " [0.00639006]]\n",
            "Step: 4676 -> Loss: 0.004668218083679676 -> Predictions: [[0.00386086]\n",
            " [0.9958182 ]\n",
            " [0.99580514]\n",
            " [0.00638974]]\n",
            "Step: 4677 -> Loss: 0.004667987115681171 -> Predictions: [[0.00386067]\n",
            " [0.9958183 ]\n",
            " [0.9958054 ]\n",
            " [0.00638942]]\n",
            "Step: 4678 -> Loss: 0.004667759872972965 -> Predictions: [[0.00386049]\n",
            " [0.99581856]\n",
            " [0.9958055 ]\n",
            " [0.0063891 ]]\n",
            "Step: 4679 -> Loss: 0.0046675303019583225 -> Predictions: [[0.00386032]\n",
            " [0.9958188 ]\n",
            " [0.99580574]\n",
            " [0.00638878]]\n",
            "Step: 4680 -> Loss: 0.004667302593588829 -> Predictions: [[0.00386014]\n",
            " [0.99581903]\n",
            " [0.995806  ]\n",
            " [0.00638846]]\n",
            "Step: 4681 -> Loss: 0.004667071625590324 -> Predictions: [[0.00385996]\n",
            " [0.9958191 ]\n",
            " [0.9958062 ]\n",
            " [0.00638814]]\n",
            "Step: 4682 -> Loss: 0.004666844382882118 -> Predictions: [[0.00385978]\n",
            " [0.99581933]\n",
            " [0.99580634]\n",
            " [0.00638782]]\n",
            "Step: 4683 -> Loss: 0.004666613414883614 -> Predictions: [[0.00385959]\n",
            " [0.99581957]\n",
            " [0.9958066 ]\n",
            " [0.0063875 ]]\n",
            "Step: 4684 -> Loss: 0.00466638570651412 -> Predictions: [[0.00385941]\n",
            " [0.9958197 ]\n",
            " [0.9958068 ]\n",
            " [0.00638719]]\n",
            "Step: 4685 -> Loss: 0.004666153807193041 -> Predictions: [[0.00385923]\n",
            " [0.9958199 ]\n",
            " [0.99580705]\n",
            " [0.00638686]]\n",
            "Step: 4686 -> Loss: 0.004665926098823547 -> Predictions: [[0.00385905]\n",
            " [0.99582016]\n",
            " [0.9958072 ]\n",
            " [0.00638655]]\n",
            "Step: 4687 -> Loss: 0.004665697459131479 -> Predictions: [[0.00385887]\n",
            " [0.9958204 ]\n",
            " [0.9958074 ]\n",
            " [0.00638624]]\n",
            "Step: 4688 -> Loss: 0.004665466025471687 -> Predictions: [[0.00385869]\n",
            " [0.9958205 ]\n",
            " [0.99580765]\n",
            " [0.00638591]]\n",
            "Step: 4689 -> Loss: 0.0046652378514409065 -> Predictions: [[0.00385851]\n",
            " [0.99582076]\n",
            " [0.9958079 ]\n",
            " [0.00638559]]\n",
            "Step: 4690 -> Loss: 0.004665008746087551 -> Predictions: [[0.00385832]\n",
            " [0.995821  ]\n",
            " [0.995808  ]\n",
            " [0.00638527]]\n",
            "Step: 4691 -> Loss: 0.004664778709411621 -> Predictions: [[0.00385814]\n",
            " [0.99582124]\n",
            " [0.99580824]\n",
            " [0.00638495]]\n",
            "Step: 4692 -> Loss: 0.00466455053538084 -> Predictions: [[0.00385797]\n",
            " [0.99582136]\n",
            " [0.9958085 ]\n",
            " [0.00638463]]\n",
            "Step: 4693 -> Loss: 0.004664321430027485 -> Predictions: [[0.00385779]\n",
            " [0.9958216 ]\n",
            " [0.9958087 ]\n",
            " [0.00638431]]\n",
            "Step: 4694 -> Loss: 0.004664093255996704 -> Predictions: [[0.0038576 ]\n",
            " [0.99582183]\n",
            " [0.99580884]\n",
            " [0.006384  ]]\n",
            "Step: 4695 -> Loss: 0.004663863219320774 -> Predictions: [[0.00385742]\n",
            " [0.9958221 ]\n",
            " [0.9958091 ]\n",
            " [0.00638368]]\n",
            "Step: 4696 -> Loss: 0.004663634579628706 -> Predictions: [[0.00385724]\n",
            " [0.9958222 ]\n",
            " [0.9958093 ]\n",
            " [0.00638336]]\n",
            "Step: 4697 -> Loss: 0.004663405474275351 -> Predictions: [[0.00385706]\n",
            " [0.9958224 ]\n",
            " [0.99580956]\n",
            " [0.00638304]]\n",
            "Step: 4698 -> Loss: 0.0046631754375994205 -> Predictions: [[0.00385688]\n",
            " [0.99582267]\n",
            " [0.9958097 ]\n",
            " [0.00638272]]\n",
            "Step: 4699 -> Loss: 0.004662949126213789 -> Predictions: [[0.0038567 ]\n",
            " [0.9958229 ]\n",
            " [0.9958099 ]\n",
            " [0.00638241]]\n",
            "Step: 4700 -> Loss: 0.004662714898586273 -> Predictions: [[0.00385652]\n",
            " [0.995823  ]\n",
            " [0.99581015]\n",
            " [0.00638208]]\n",
            "Step: 4701 -> Loss: 0.004662490449845791 -> Predictions: [[0.00385633]\n",
            " [0.99582326]\n",
            " [0.9958104 ]\n",
            " [0.00638177]]\n",
            "Step: 4702 -> Loss: 0.0046622599475085735 -> Predictions: [[0.00385615]\n",
            " [0.9958235 ]\n",
            " [0.9958105 ]\n",
            " [0.00638145]]\n",
            "Step: 4703 -> Loss: 0.004662027582526207 -> Predictions: [[0.00385597]\n",
            " [0.99582374]\n",
            " [0.99581075]\n",
            " [0.00638112]]\n",
            "Step: 4704 -> Loss: 0.004661801271140575 -> Predictions: [[0.00385579]\n",
            " [0.99582386]\n",
            " [0.995811  ]\n",
            " [0.00638081]]\n",
            "Step: 4705 -> Loss: 0.00466157216578722 -> Predictions: [[0.00385561]\n",
            " [0.9958241 ]\n",
            " [0.9958112 ]\n",
            " [0.00638049]]\n",
            "Step: 4706 -> Loss: 0.004661343991756439 -> Predictions: [[0.00385543]\n",
            " [0.99582434]\n",
            " [0.99581134]\n",
            " [0.00638018]]\n",
            "Step: 4707 -> Loss: 0.004661115817725658 -> Predictions: [[0.00385525]\n",
            " [0.99582446]\n",
            " [0.9958116 ]\n",
            " [0.00637985]]\n",
            "Step: 4708 -> Loss: 0.004660883918404579 -> Predictions: [[0.00385507]\n",
            " [0.9958247 ]\n",
            " [0.9958118 ]\n",
            " [0.00637953]]\n",
            "Step: 4709 -> Loss: 0.004660656675696373 -> Predictions: [[0.00385489]\n",
            " [0.99582493]\n",
            " [0.995812  ]\n",
            " [0.00637922]]\n",
            "Step: 4710 -> Loss: 0.004660425707697868 -> Predictions: [[0.00385471]\n",
            " [0.9958252 ]\n",
            " [0.9958121 ]\n",
            " [0.00637889]]\n",
            "Step: 4711 -> Loss: 0.004660196136683226 -> Predictions: [[0.00385453]\n",
            " [0.9958253 ]\n",
            " [0.99581236]\n",
            " [0.00637858]]\n",
            "Step: 4712 -> Loss: 0.004659972153604031 -> Predictions: [[0.00385435]\n",
            " [0.9958255 ]\n",
            " [0.9958126 ]\n",
            " [0.00637826]]\n",
            "Step: 4713 -> Loss: 0.004659740254282951 -> Predictions: [[0.00385417]\n",
            " [0.99582577]\n",
            " [0.99581283]\n",
            " [0.00637794]]\n",
            "Step: 4714 -> Loss: 0.004659510217607021 -> Predictions: [[0.00385398]\n",
            " [0.995826  ]\n",
            " [0.99581295]\n",
            " [0.00637762]]\n",
            "Step: 4715 -> Loss: 0.004659279249608517 -> Predictions: [[0.0038538]\n",
            " [0.9958261]\n",
            " [0.9958132]\n",
            " [0.0063773]]\n",
            "Step: 4716 -> Loss: 0.004659056197851896 -> Predictions: [[0.00385362]\n",
            " [0.9958263 ]\n",
            " [0.9958134 ]\n",
            " [0.00637699]]\n",
            "Step: 4717 -> Loss: 0.004658825229853392 -> Predictions: [[0.00385344]\n",
            " [0.99582654]\n",
            " [0.99581367]\n",
            " [0.00637667]]\n",
            "Step: 4718 -> Loss: 0.004658594727516174 -> Predictions: [[0.00385326]\n",
            " [0.9958268 ]\n",
            " [0.9958138 ]\n",
            " [0.00637635]]\n",
            "Step: 4719 -> Loss: 0.0046583679504692554 -> Predictions: [[0.00385309]\n",
            " [0.9958269 ]\n",
            " [0.995814  ]\n",
            " [0.00637603]]\n",
            "Step: 4720 -> Loss: 0.004658138379454613 -> Predictions: [[0.0038529 ]\n",
            " [0.99582714]\n",
            " [0.99581426]\n",
            " [0.00637572]]\n",
            "Step: 4721 -> Loss: 0.004657909274101257 -> Predictions: [[0.00385273]\n",
            " [0.9958274 ]\n",
            " [0.9958145 ]\n",
            " [0.00637539]]\n",
            "Step: 4722 -> Loss: 0.004657681565731764 -> Predictions: [[0.00385254]\n",
            " [0.9958276 ]\n",
            " [0.9958146 ]\n",
            " [0.00637508]]\n",
            "Step: 4723 -> Loss: 0.004657451529055834 -> Predictions: [[0.00385236]\n",
            " [0.99582773]\n",
            " [0.99581486]\n",
            " [0.00637475]]\n",
            "Step: 4724 -> Loss: 0.004657220095396042 -> Predictions: [[0.00385218]\n",
            " [0.995828  ]\n",
            " [0.9958151 ]\n",
            " [0.00637443]]\n",
            "Step: 4725 -> Loss: 0.004656992387026548 -> Predictions: [[0.00385199]\n",
            " [0.9958282 ]\n",
            " [0.99581534]\n",
            " [0.00637412]]\n",
            "Step: 4726 -> Loss: 0.0046567656099796295 -> Predictions: [[0.00385182]\n",
            " [0.99582833]\n",
            " [0.99581546]\n",
            " [0.0063738 ]]\n",
            "Step: 4727 -> Loss: 0.004656538832932711 -> Predictions: [[0.00385164]\n",
            " [0.99582857]\n",
            " [0.9958157 ]\n",
            " [0.00637349]]\n",
            "Step: 4728 -> Loss: 0.004656306933611631 -> Predictions: [[0.00385145]\n",
            " [0.9958288 ]\n",
            " [0.99581593]\n",
            " [0.00637317]]\n",
            "Step: 4729 -> Loss: 0.004656080622226 -> Predictions: [[0.00385128]\n",
            " [0.99582905]\n",
            " [0.9958162 ]\n",
            " [0.00637285]]\n",
            "Step: 4730 -> Loss: 0.004655849654227495 -> Predictions: [[0.0038511 ]\n",
            " [0.99582916]\n",
            " [0.9958163 ]\n",
            " [0.00637253]]\n",
            "Step: 4731 -> Loss: 0.004655621945858002 -> Predictions: [[0.00385091]\n",
            " [0.9958294 ]\n",
            " [0.9958165 ]\n",
            " [0.00637221]]\n",
            "Step: 4732 -> Loss: 0.004655393306165934 -> Predictions: [[0.00385073]\n",
            " [0.99582964]\n",
            " [0.99581677]\n",
            " [0.00637189]]\n",
            "Step: 4733 -> Loss: 0.00465516047552228 -> Predictions: [[0.00385055]\n",
            " [0.9958299 ]\n",
            " [0.995817  ]\n",
            " [0.00637157]]\n",
            "Step: 4734 -> Loss: 0.004654936026781797 -> Predictions: [[0.00385037]\n",
            " [0.99583   ]\n",
            " [0.9958171 ]\n",
            " [0.00637126]]\n",
            "Step: 4735 -> Loss: 0.004654706921428442 -> Predictions: [[0.00385019]\n",
            " [0.99583024]\n",
            " [0.99581736]\n",
            " [0.00637094]]\n",
            "Step: 4736 -> Loss: 0.004654477816075087 -> Predictions: [[0.00385001]\n",
            " [0.9958305 ]\n",
            " [0.9958176 ]\n",
            " [0.00637062]]\n",
            "Step: 4737 -> Loss: 0.004654248710721731 -> Predictions: [[0.00384983]\n",
            " [0.9958307 ]\n",
            " [0.99581784]\n",
            " [0.0063703 ]]\n",
            "Step: 4738 -> Loss: 0.004654020071029663 -> Predictions: [[0.00384965]\n",
            " [0.99583083]\n",
            " [0.99581796]\n",
            " [0.00636998]]\n",
            "Step: 4739 -> Loss: 0.004653790965676308 -> Predictions: [[0.00384947]\n",
            " [0.9958311 ]\n",
            " [0.9958182 ]\n",
            " [0.00636967]]\n",
            "Step: 4740 -> Loss: 0.004653561860322952 -> Predictions: [[0.00384929]\n",
            " [0.9958313 ]\n",
            " [0.99581844]\n",
            " [0.00636935]]\n",
            "Step: 4741 -> Loss: 0.004653334151953459 -> Predictions: [[0.00384911]\n",
            " [0.99583155]\n",
            " [0.9958187 ]\n",
            " [0.00636903]]\n",
            "Step: 4742 -> Loss: 0.004653105512261391 -> Predictions: [[0.00384893]\n",
            " [0.99583167]\n",
            " [0.9958188 ]\n",
            " [0.00636871]]\n",
            "Step: 4743 -> Loss: 0.0046528782695531845 -> Predictions: [[0.00384875]\n",
            " [0.9958319 ]\n",
            " [0.99581903]\n",
            " [0.00636839]]\n",
            "Step: 4744 -> Loss: 0.00465264730155468 -> Predictions: [[0.00384856]\n",
            " [0.99583215]\n",
            " [0.9958192 ]\n",
            " [0.00636807]]\n",
            "Step: 4745 -> Loss: 0.004652421455830336 -> Predictions: [[0.00384839]\n",
            " [0.99583226]\n",
            " [0.99581945]\n",
            " [0.00636776]]\n",
            "Step: 4746 -> Loss: 0.00465219235047698 -> Predictions: [[0.00384821]\n",
            " [0.9958325 ]\n",
            " [0.99581957]\n",
            " [0.00636743]]\n",
            "Step: 4747 -> Loss: 0.004651963710784912 -> Predictions: [[0.00384803]\n",
            " [0.99583274]\n",
            " [0.9958198 ]\n",
            " [0.00636712]]\n",
            "Step: 4748 -> Loss: 0.0046517327427864075 -> Predictions: [[0.00384784]\n",
            " [0.995833  ]\n",
            " [0.99582005]\n",
            " [0.0063668 ]]\n",
            "Step: 4749 -> Loss: 0.004651505500078201 -> Predictions: [[0.00384767]\n",
            " [0.9958331 ]\n",
            " [0.9958203 ]\n",
            " [0.00636648]]\n",
            "Step: 4750 -> Loss: 0.004651274532079697 -> Predictions: [[0.00384748]\n",
            " [0.9958333 ]\n",
            " [0.9958204 ]\n",
            " [0.00636617]]\n",
            "Step: 4751 -> Loss: 0.004651048220694065 -> Predictions: [[0.0038473 ]\n",
            " [0.9958335 ]\n",
            " [0.99582064]\n",
            " [0.00636585]]\n",
            "Step: 4752 -> Loss: 0.00465081911534071 -> Predictions: [[0.00384712]\n",
            " [0.99583375]\n",
            " [0.9958209 ]\n",
            " [0.00636553]]\n",
            "Step: 4753 -> Loss: 0.004650590941309929 -> Predictions: [[0.00384694]\n",
            " [0.9958339 ]\n",
            " [0.9958211 ]\n",
            " [0.00636521]]\n",
            "Step: 4754 -> Loss: 0.004650363698601723 -> Predictions: [[0.00384676]\n",
            " [0.9958341 ]\n",
            " [0.99582124]\n",
            " [0.0063649 ]]\n",
            "Step: 4755 -> Loss: 0.004650132730603218 -> Predictions: [[0.00384658]\n",
            " [0.99583435]\n",
            " [0.9958215 ]\n",
            " [0.00636458]]\n",
            "Step: 4756 -> Loss: 0.004649903625249863 -> Predictions: [[0.0038464 ]\n",
            " [0.9958346 ]\n",
            " [0.9958217 ]\n",
            " [0.00636426]]\n",
            "Step: 4757 -> Loss: 0.004649680107831955 -> Predictions: [[0.00384623]\n",
            " [0.9958347 ]\n",
            " [0.99582195]\n",
            " [0.00636394]]\n",
            "Step: 4758 -> Loss: 0.004649448674172163 -> Predictions: [[0.00384605]\n",
            " [0.99583495]\n",
            " [0.9958221 ]\n",
            " [0.00636362]]\n",
            "Step: 4759 -> Loss: 0.004649221897125244 -> Predictions: [[0.00384587]\n",
            " [0.9958352 ]\n",
            " [0.9958223 ]\n",
            " [0.00636331]]\n",
            "Step: 4760 -> Loss: 0.004648993723094463 -> Predictions: [[0.00384569]\n",
            " [0.9958353 ]\n",
            " [0.99582255]\n",
            " [0.00636299]]\n",
            "Step: 4761 -> Loss: 0.00464876601472497 -> Predictions: [[0.00384551]\n",
            " [0.99583554]\n",
            " [0.99582267]\n",
            " [0.00636267]]\n",
            "Step: 4762 -> Loss: 0.0046485369093716145 -> Predictions: [[0.00384533]\n",
            " [0.9958358 ]\n",
            " [0.9958229 ]\n",
            " [0.00636235]]\n",
            "Step: 4763 -> Loss: 0.0046483054757118225 -> Predictions: [[0.00384514]\n",
            " [0.995836  ]\n",
            " [0.99582314]\n",
            " [0.00636204]]\n",
            "Step: 4764 -> Loss: 0.004648079164326191 -> Predictions: [[0.00384496]\n",
            " [0.99583614]\n",
            " [0.9958234 ]\n",
            " [0.00636172]]\n",
            "Step: 4765 -> Loss: 0.004647850524634123 -> Predictions: [[0.00384478]\n",
            " [0.9958364 ]\n",
            " [0.9958235 ]\n",
            " [0.0063614 ]]\n",
            "Step: 4766 -> Loss: 0.004647622350603342 -> Predictions: [[0.0038446 ]\n",
            " [0.9958366 ]\n",
            " [0.99582374]\n",
            " [0.00636108]]\n",
            "Step: 4767 -> Loss: 0.004647393710911274 -> Predictions: [[0.00384442]\n",
            " [0.99583685]\n",
            " [0.995824  ]\n",
            " [0.00636076]]\n",
            "Step: 4768 -> Loss: 0.0046471646055579185 -> Predictions: [[0.00384424]\n",
            " [0.995837  ]\n",
            " [0.9958242 ]\n",
            " [0.00636044]]\n",
            "Step: 4769 -> Loss: 0.004646936897188425 -> Predictions: [[0.00384406]\n",
            " [0.9958372 ]\n",
            " [0.99582434]\n",
            " [0.00636013]]\n",
            "Step: 4770 -> Loss: 0.004646709188818932 -> Predictions: [[0.00384389]\n",
            " [0.99583745]\n",
            " [0.9958246 ]\n",
            " [0.00635981]]\n",
            "Step: 4771 -> Loss: 0.0046464828774333 -> Predictions: [[0.00384371]\n",
            " [0.9958377 ]\n",
            " [0.9958248 ]\n",
            " [0.0063595 ]]\n",
            "Step: 4772 -> Loss: 0.004646250046789646 -> Predictions: [[0.00384353]\n",
            " [0.9958378 ]\n",
            " [0.99582505]\n",
            " [0.00635917]]\n",
            "Step: 4773 -> Loss: 0.0046460251323878765 -> Predictions: [[0.00384334]\n",
            " [0.99583805]\n",
            " [0.9958252 ]\n",
            " [0.00635886]]\n",
            "Step: 4774 -> Loss: 0.004645795561373234 -> Predictions: [[0.00384317]\n",
            " [0.9958383 ]\n",
            " [0.9958254 ]\n",
            " [0.00635854]]\n",
            "Step: 4775 -> Loss: 0.004645568318665028 -> Predictions: [[0.00384299]\n",
            " [0.9958384 ]\n",
            " [0.99582565]\n",
            " [0.00635823]]\n",
            "Step: 4776 -> Loss: 0.004645340144634247 -> Predictions: [[0.0038428 ]\n",
            " [0.99583864]\n",
            " [0.9958259 ]\n",
            " [0.0063579 ]]\n",
            "Step: 4777 -> Loss: 0.004645111504942179 -> Predictions: [[0.00384263]\n",
            " [0.9958389 ]\n",
            " [0.995826  ]\n",
            " [0.00635759]]\n",
            "Step: 4778 -> Loss: 0.004644883796572685 -> Predictions: [[0.00384245]\n",
            " [0.9958391 ]\n",
            " [0.9958262 ]\n",
            " [0.00635727]]\n",
            "Step: 4779 -> Loss: 0.0046446542255580425 -> Predictions: [[0.00384226]\n",
            " [0.99583924]\n",
            " [0.9958264 ]\n",
            " [0.00635696]]\n",
            "Step: 4780 -> Loss: 0.004644428845494986 -> Predictions: [[0.00384209]\n",
            " [0.9958395 ]\n",
            " [0.99582666]\n",
            " [0.00635664]]\n",
            "Step: 4781 -> Loss: 0.004644197877496481 -> Predictions: [[0.00384191]\n",
            " [0.9958397 ]\n",
            " [0.9958268 ]\n",
            " [0.00635632]]\n",
            "Step: 4782 -> Loss: 0.004643971100449562 -> Predictions: [[0.00384173]\n",
            " [0.99583995]\n",
            " [0.995827  ]\n",
            " [0.006356  ]]\n",
            "Step: 4783 -> Loss: 0.004643741529434919 -> Predictions: [[0.00384155]\n",
            " [0.9958401 ]\n",
            " [0.99582726]\n",
            " [0.00635568]]\n",
            "Step: 4784 -> Loss: 0.004643516149371862 -> Predictions: [[0.00384137]\n",
            " [0.9958403 ]\n",
            " [0.9958275 ]\n",
            " [0.00635537]]\n",
            "Step: 4785 -> Loss: 0.004643287975341082 -> Predictions: [[0.00384119]\n",
            " [0.9958405 ]\n",
            " [0.9958276 ]\n",
            " [0.00635505]]\n",
            "Step: 4786 -> Loss: 0.0046430593356490135 -> Predictions: [[0.00384101]\n",
            " [0.9958407 ]\n",
            " [0.99582785]\n",
            " [0.00635474]]\n",
            "Step: 4787 -> Loss: 0.004642831161618233 -> Predictions: [[0.00384083]\n",
            " [0.99584085]\n",
            " [0.9958281 ]\n",
            " [0.00635442]]\n",
            "Step: 4788 -> Loss: 0.004642603453248739 -> Predictions: [[0.00384065]\n",
            " [0.9958411 ]\n",
            " [0.99582833]\n",
            " [0.0063541 ]]\n",
            "Step: 4789 -> Loss: 0.004642375744879246 -> Predictions: [[0.00384047]\n",
            " [0.9958413 ]\n",
            " [0.99582845]\n",
            " [0.00635378]]\n",
            "Step: 4790 -> Loss: 0.004642148036509752 -> Predictions: [[0.0038403 ]\n",
            " [0.99584144]\n",
            " [0.9958287 ]\n",
            " [0.00635346]]\n",
            "Step: 4791 -> Loss: 0.004641919396817684 -> Predictions: [[0.00384012]\n",
            " [0.9958417 ]\n",
            " [0.9958289 ]\n",
            " [0.00635314]]\n",
            "Step: 4792 -> Loss: 0.004641689360141754 -> Predictions: [[0.00383993]\n",
            " [0.9958419 ]\n",
            " [0.99582905]\n",
            " [0.00635282]]\n",
            "Step: 4793 -> Loss: 0.004641464911401272 -> Predictions: [[0.00383975]\n",
            " [0.99584216]\n",
            " [0.9958293 ]\n",
            " [0.00635251]]\n",
            "Step: 4794 -> Loss: 0.004641233943402767 -> Predictions: [[0.00383957]\n",
            " [0.9958423 ]\n",
            " [0.9958295 ]\n",
            " [0.00635219]]\n",
            "Step: 4795 -> Loss: 0.004641006700694561 -> Predictions: [[0.00383939]\n",
            " [0.9958425 ]\n",
            " [0.99582976]\n",
            " [0.00635187]]\n",
            "Step: 4796 -> Loss: 0.004640779923647642 -> Predictions: [[0.00383921]\n",
            " [0.99584275]\n",
            " [0.9958299 ]\n",
            " [0.00635156]]\n",
            "Step: 4797 -> Loss: 0.004640553612262011 -> Predictions: [[0.00383904]\n",
            " [0.995843  ]\n",
            " [0.9958301 ]\n",
            " [0.00635125]]\n",
            "Step: 4798 -> Loss: 0.004640325903892517 -> Predictions: [[0.00383886]\n",
            " [0.9958431 ]\n",
            " [0.99583036]\n",
            " [0.00635092]]\n",
            "Step: 4799 -> Loss: 0.004640096798539162 -> Predictions: [[0.00383868]\n",
            " [0.99584335]\n",
            " [0.9958306 ]\n",
            " [0.0063506 ]]\n",
            "Step: 4800 -> Loss: 0.004639867693185806 -> Predictions: [[0.00383849]\n",
            " [0.9958436 ]\n",
            " [0.9958307 ]\n",
            " [0.00635029]]\n",
            "Step: 4801 -> Loss: 0.004639637190848589 -> Predictions: [[0.00383831]\n",
            " [0.9958438 ]\n",
            " [0.99583095]\n",
            " [0.00634997]]\n",
            "Step: 4802 -> Loss: 0.004639409948140383 -> Predictions: [[0.00383813]\n",
            " [0.99584395]\n",
            " [0.9958312 ]\n",
            " [0.00634966]]\n",
            "Step: 4803 -> Loss: 0.0046391854993999004 -> Predictions: [[0.00383796]\n",
            " [0.9958442 ]\n",
            " [0.99583143]\n",
            " [0.00634934]]\n",
            "Step: 4804 -> Loss: 0.004638955928385258 -> Predictions: [[0.00383777]\n",
            " [0.9958444 ]\n",
            " [0.99583155]\n",
            " [0.00634902]]\n",
            "Step: 4805 -> Loss: 0.004638728220015764 -> Predictions: [[0.0038376 ]\n",
            " [0.99584454]\n",
            " [0.9958318 ]\n",
            " [0.0063487 ]]\n",
            "Step: 4806 -> Loss: 0.004638501908630133 -> Predictions: [[0.00383741]\n",
            " [0.9958448 ]\n",
            " [0.995832  ]\n",
            " [0.00634839]]\n",
            "Step: 4807 -> Loss: 0.004638273734599352 -> Predictions: [[0.00383724]\n",
            " [0.995845  ]\n",
            " [0.99583226]\n",
            " [0.00634807]]\n",
            "Step: 4808 -> Loss: 0.004638045094907284 -> Predictions: [[0.00383705]\n",
            " [0.99584526]\n",
            " [0.9958324 ]\n",
            " [0.00634775]]\n",
            "Step: 4809 -> Loss: 0.00463781738653779 -> Predictions: [[0.00383688]\n",
            " [0.9958454 ]\n",
            " [0.9958326 ]\n",
            " [0.00634743]]\n",
            "Step: 4810 -> Loss: 0.004637592472136021 -> Predictions: [[0.0038367 ]\n",
            " [0.9958456 ]\n",
            " [0.99583286]\n",
            " [0.00634712]]\n",
            "Step: 4811 -> Loss: 0.004637362901121378 -> Predictions: [[0.00383652]\n",
            " [0.99584585]\n",
            " [0.9958331 ]\n",
            " [0.0063468 ]]\n",
            "Step: 4812 -> Loss: 0.0046371351927518845 -> Predictions: [[0.00383634]\n",
            " [0.9958461 ]\n",
            " [0.9958332 ]\n",
            " [0.00634649]]\n",
            "Step: 4813 -> Loss: 0.00463690934702754 -> Predictions: [[0.00383616]\n",
            " [0.9958462 ]\n",
            " [0.9958334 ]\n",
            " [0.00634617]]\n",
            "Step: 4814 -> Loss: 0.004636677913367748 -> Predictions: [[0.00383598]\n",
            " [0.99584645]\n",
            " [0.99583364]\n",
            " [0.00634585]]\n",
            "Step: 4815 -> Loss: 0.004636452998965979 -> Predictions: [[0.0038358 ]\n",
            " [0.9958467 ]\n",
            " [0.99583375]\n",
            " [0.00634554]]\n",
            "Step: 4816 -> Loss: 0.004636223893612623 -> Predictions: [[0.00383562]\n",
            " [0.9958468 ]\n",
            " [0.995834  ]\n",
            " [0.00634522]]\n",
            "Step: 4817 -> Loss: 0.004635997582226992 -> Predictions: [[0.00383545]\n",
            " [0.99584705]\n",
            " [0.99583423]\n",
            " [0.0063449 ]]\n",
            "Step: 4818 -> Loss: 0.004635768011212349 -> Predictions: [[0.00383527]\n",
            " [0.9958473 ]\n",
            " [0.99583447]\n",
            " [0.00634458]]\n",
            "Step: 4819 -> Loss: 0.004635542631149292 -> Predictions: [[0.00383509]\n",
            " [0.9958475 ]\n",
            " [0.9958346 ]\n",
            " [0.00634427]]\n",
            "Step: 4820 -> Loss: 0.004635314457118511 -> Predictions: [[0.00383491]\n",
            " [0.9958476 ]\n",
            " [0.9958348 ]\n",
            " [0.00634395]]\n",
            "Step: 4821 -> Loss: 0.004635085351765156 -> Predictions: [[0.00383472]\n",
            " [0.9958478 ]\n",
            " [0.99583507]\n",
            " [0.00634363]]\n",
            "Step: 4822 -> Loss: 0.004634857177734375 -> Predictions: [[0.00383455]\n",
            " [0.99584806]\n",
            " [0.9958353 ]\n",
            " [0.00634331]]\n",
            "Step: 4823 -> Loss: 0.004634629003703594 -> Predictions: [[0.00383436]\n",
            " [0.9958483 ]\n",
            " [0.9958354 ]\n",
            " [0.00634299]]\n",
            "Step: 4824 -> Loss: 0.004634402692317963 -> Predictions: [[0.00383419]\n",
            " [0.9958484 ]\n",
            " [0.99583566]\n",
            " [0.00634268]]\n",
            "Step: 4825 -> Loss: 0.0046341740526258945 -> Predictions: [[0.00383401]\n",
            " [0.99584866]\n",
            " [0.9958359 ]\n",
            " [0.00634236]]\n",
            "Step: 4826 -> Loss: 0.004633947741240263 -> Predictions: [[0.00383383]\n",
            " [0.9958489 ]\n",
            " [0.99583614]\n",
            " [0.00634205]]\n",
            "Step: 4827 -> Loss: 0.004633719567209482 -> Predictions: [[0.00383365]\n",
            " [0.995849  ]\n",
            " [0.99583626]\n",
            " [0.00634173]]\n",
            "Step: 4828 -> Loss: 0.004633491858839989 -> Predictions: [[0.00383348]\n",
            " [0.99584925]\n",
            " [0.9958365 ]\n",
            " [0.00634141]]\n",
            "Step: 4829 -> Loss: 0.004633266478776932 -> Predictions: [[0.0038333 ]\n",
            " [0.9958495 ]\n",
            " [0.99583673]\n",
            " [0.0063411 ]]\n",
            "Step: 4830 -> Loss: 0.004633036442101002 -> Predictions: [[0.00383311]\n",
            " [0.9958497 ]\n",
            " [0.995837  ]\n",
            " [0.00634078]]\n",
            "Step: 4831 -> Loss: 0.004632809665054083 -> Predictions: [[0.00383293]\n",
            " [0.99584985]\n",
            " [0.9958371 ]\n",
            " [0.00634046]]\n",
            "Step: 4832 -> Loss: 0.004632582422345877 -> Predictions: [[0.00383275]\n",
            " [0.9958501 ]\n",
            " [0.99583733]\n",
            " [0.00634015]]\n",
            "Step: 4833 -> Loss: 0.0046323551796376705 -> Predictions: [[0.00383258]\n",
            " [0.9958503 ]\n",
            " [0.99583757]\n",
            " [0.00633983]]\n",
            "Step: 4834 -> Loss: 0.004632128402590752 -> Predictions: [[0.0038324 ]\n",
            " [0.99585056]\n",
            " [0.9958378 ]\n",
            " [0.00633952]]\n",
            "Step: 4835 -> Loss: 0.004631897434592247 -> Predictions: [[0.00383221]\n",
            " [0.9958507 ]\n",
            " [0.9958379 ]\n",
            " [0.0063392 ]]\n",
            "Step: 4836 -> Loss: 0.004631673451513052 -> Predictions: [[0.00383204]\n",
            " [0.9958509 ]\n",
            " [0.99583817]\n",
            " [0.00633888]]\n",
            "Step: 4837 -> Loss: 0.0046314457431435585 -> Predictions: [[0.00383186]\n",
            " [0.99585116]\n",
            " [0.9958384 ]\n",
            " [0.00633856]]\n",
            "Step: 4838 -> Loss: 0.004631218500435352 -> Predictions: [[0.00383168]\n",
            " [0.9958514 ]\n",
            " [0.9958385 ]\n",
            " [0.00633825]]\n",
            "Step: 4839 -> Loss: 0.004630993120372295 -> Predictions: [[0.0038315 ]\n",
            " [0.9958515 ]\n",
            " [0.99583876]\n",
            " [0.00633793]]\n",
            "Step: 4840 -> Loss: 0.004630764946341515 -> Predictions: [[0.00383132]\n",
            " [0.99585176]\n",
            " [0.995839  ]\n",
            " [0.00633761]]\n",
            "Step: 4841 -> Loss: 0.004630538634955883 -> Predictions: [[0.00383113]\n",
            " [0.995852  ]\n",
            " [0.99583924]\n",
            " [0.0063373 ]]\n",
            "Step: 4842 -> Loss: 0.004630310460925102 -> Predictions: [[0.00383095]\n",
            " [0.9958521 ]\n",
            " [0.99583936]\n",
            " [0.00633698]]\n",
            "Step: 4843 -> Loss: 0.0046300869435071945 -> Predictions: [[0.00383077]\n",
            " [0.99585235]\n",
            " [0.9958396 ]\n",
            " [0.00633667]]\n",
            "Step: 4844 -> Loss: 0.004629862029105425 -> Predictions: [[0.00383059]\n",
            " [0.9958526 ]\n",
            " [0.99583983]\n",
            " [0.00633635]]\n",
            "Step: 4845 -> Loss: 0.004629635252058506 -> Predictions: [[0.00383041]\n",
            " [0.9958527 ]\n",
            " [0.99583995]\n",
            " [0.00633604]]\n",
            "Step: 4846 -> Loss: 0.0046294080093503 -> Predictions: [[0.00383022]\n",
            " [0.99585295]\n",
            " [0.9958402 ]\n",
            " [0.00633571]]\n",
            "Step: 4847 -> Loss: 0.004629184026271105 -> Predictions: [[0.00383005]\n",
            " [0.9958532 ]\n",
            " [0.9958404 ]\n",
            " [0.0063354 ]]\n",
            "Step: 4848 -> Loss: 0.004628957249224186 -> Predictions: [[0.00382986]\n",
            " [0.9958533 ]\n",
            " [0.9958405 ]\n",
            " [0.00633508]]\n",
            "Step: 4849 -> Loss: 0.004628732800483704 -> Predictions: [[0.00382968]\n",
            " [0.99585354]\n",
            " [0.9958407 ]\n",
            " [0.00633476]]\n",
            "Step: 4850 -> Loss: 0.004628504626452923 -> Predictions: [[0.0038295 ]\n",
            " [0.9958538 ]\n",
            " [0.99584097]\n",
            " [0.00633444]]\n",
            "Step: 4851 -> Loss: 0.004628278315067291 -> Predictions: [[0.00382932]\n",
            " [0.995854  ]\n",
            " [0.9958412 ]\n",
            " [0.00633413]]\n",
            "Step: 4852 -> Loss: 0.004628053866326809 -> Predictions: [[0.00382914]\n",
            " [0.99585414]\n",
            " [0.9958413 ]\n",
            " [0.00633381]]\n",
            "Step: 4853 -> Loss: 0.004627829417586327 -> Predictions: [[0.00382896]\n",
            " [0.9958544 ]\n",
            " [0.99584156]\n",
            " [0.00633349]]\n",
            "Step: 4854 -> Loss: 0.004627603106200695 -> Predictions: [[0.00382878]\n",
            " [0.9958546 ]\n",
            " [0.9958418 ]\n",
            " [0.00633317]]\n",
            "Step: 4855 -> Loss: 0.004627375863492489 -> Predictions: [[0.0038286 ]\n",
            " [0.9958547 ]\n",
            " [0.9958419 ]\n",
            " [0.00633286]]\n",
            "Step: 4856 -> Loss: 0.004627152346074581 -> Predictions: [[0.00382842]\n",
            " [0.9958549 ]\n",
            " [0.99584216]\n",
            " [0.00633254]]\n",
            "Step: 4857 -> Loss: 0.0046269274316728115 -> Predictions: [[0.00382824]\n",
            " [0.99585515]\n",
            " [0.9958424 ]\n",
            " [0.00633223]]\n",
            "Step: 4858 -> Loss: 0.004626698791980743 -> Predictions: [[0.00382806]\n",
            " [0.9958553 ]\n",
            " [0.9958425 ]\n",
            " [0.0063319 ]]\n",
            "Step: 4859 -> Loss: 0.004626472480595112 -> Predictions: [[0.00382788]\n",
            " [0.9958555 ]\n",
            " [0.99584275]\n",
            " [0.00633158]]\n",
            "Step: 4860 -> Loss: 0.004626244306564331 -> Predictions: [[0.00382769]\n",
            " [0.99585575]\n",
            " [0.995843  ]\n",
            " [0.00633126]]\n",
            "Step: 4861 -> Loss: 0.004626021254807711 -> Predictions: [[0.00382751]\n",
            " [0.99585587]\n",
            " [0.99584323]\n",
            " [0.00633095]]\n",
            "Step: 4862 -> Loss: 0.004625793546438217 -> Predictions: [[0.00382733]\n",
            " [0.9958561 ]\n",
            " [0.99584335]\n",
            " [0.00633063]]\n",
            "Step: 4863 -> Loss: 0.0046255700290203094 -> Predictions: [[0.00382715]\n",
            " [0.99585634]\n",
            " [0.9958436 ]\n",
            " [0.00633032]]\n",
            "Step: 4864 -> Loss: 0.004625345580279827 -> Predictions: [[0.00382697]\n",
            " [0.9958566 ]\n",
            " [0.9958438 ]\n",
            " [0.00633   ]]\n",
            "Step: 4865 -> Loss: 0.0046251206658780575 -> Predictions: [[0.00382679]\n",
            " [0.9958567 ]\n",
            " [0.99584395]\n",
            " [0.00632969]]\n",
            "Step: 4866 -> Loss: 0.004624892491847277 -> Predictions: [[0.00382661]\n",
            " [0.99585694]\n",
            " [0.9958442 ]\n",
            " [0.00632936]]\n",
            "Step: 4867 -> Loss: 0.004624668508768082 -> Predictions: [[0.00382643]\n",
            " [0.9958572 ]\n",
            " [0.9958444 ]\n",
            " [0.00632904]]\n",
            "Step: 4868 -> Loss: 0.004624446853995323 -> Predictions: [[0.00382625]\n",
            " [0.9958573 ]\n",
            " [0.99584454]\n",
            " [0.00632874]]\n",
            "Step: 4869 -> Loss: 0.004624216817319393 -> Predictions: [[0.00382607]\n",
            " [0.99585754]\n",
            " [0.9958448 ]\n",
            " [0.00632841]]\n",
            "Step: 4870 -> Loss: 0.004623988643288612 -> Predictions: [[0.00382588]\n",
            " [0.9958578 ]\n",
            " [0.995845  ]\n",
            " [0.00632809]]\n",
            "Step: 4871 -> Loss: 0.004623766522854567 -> Predictions: [[0.0038257 ]\n",
            " [0.9958579 ]\n",
            " [0.99584514]\n",
            " [0.00632778]]\n",
            "Step: 4872 -> Loss: 0.00462353928014636 -> Predictions: [[0.00382552]\n",
            " [0.99585813]\n",
            " [0.9958454 ]\n",
            " [0.00632746]]\n",
            "Step: 4873 -> Loss: 0.00462331622838974 -> Predictions: [[0.00382534]\n",
            " [0.9958584 ]\n",
            " [0.9958456 ]\n",
            " [0.00632715]]\n",
            "Step: 4874 -> Loss: 0.004623090382665396 -> Predictions: [[0.00382516]\n",
            " [0.9958585 ]\n",
            " [0.99584585]\n",
            " [0.00632683]]\n",
            "Step: 4875 -> Loss: 0.0046228645369410515 -> Predictions: [[0.00382498]\n",
            " [0.9958587 ]\n",
            " [0.995846  ]\n",
            " [0.00632651]]\n",
            "Step: 4876 -> Loss: 0.00462263822555542 -> Predictions: [[0.0038248 ]\n",
            " [0.99585897]\n",
            " [0.9958462 ]\n",
            " [0.00632619]]\n",
            "Step: 4877 -> Loss: 0.004622413776814938 -> Predictions: [[0.00382461]\n",
            " [0.9958591 ]\n",
            " [0.99584645]\n",
            " [0.00632588]]\n",
            "Step: 4878 -> Loss: 0.004622189793735743 -> Predictions: [[0.00382444]\n",
            " [0.9958593 ]\n",
            " [0.99584657]\n",
            " [0.00632556]]\n",
            "Step: 4879 -> Loss: 0.004621963948011398 -> Predictions: [[0.00382426]\n",
            " [0.99585956]\n",
            " [0.9958468 ]\n",
            " [0.00632524]]\n",
            "Step: 4880 -> Loss: 0.004621736705303192 -> Predictions: [[0.00382408]\n",
            " [0.9958597 ]\n",
            " [0.99584705]\n",
            " [0.00632492]]\n",
            "Step: 4881 -> Loss: 0.004621512722223997 -> Predictions: [[0.0038239 ]\n",
            " [0.9958599 ]\n",
            " [0.99584717]\n",
            " [0.00632461]]\n",
            "Step: 4882 -> Loss: 0.004621289670467377 -> Predictions: [[0.00382372]\n",
            " [0.99586016]\n",
            " [0.9958474 ]\n",
            " [0.00632429]]\n",
            "Step: 4883 -> Loss: 0.004621061496436596 -> Predictions: [[0.00382354]\n",
            " [0.9958604 ]\n",
            " [0.9958476 ]\n",
            " [0.00632398]]\n",
            "Step: 4884 -> Loss: 0.004620837513357401 -> Predictions: [[0.00382336]\n",
            " [0.9958605 ]\n",
            " [0.9958477 ]\n",
            " [0.00632366]]\n",
            "Step: 4885 -> Loss: 0.004620608873665333 -> Predictions: [[0.00382318]\n",
            " [0.99586076]\n",
            " [0.99584794]\n",
            " [0.00632334]]\n",
            "Step: 4886 -> Loss: 0.004620384890586138 -> Predictions: [[0.003823  ]\n",
            " [0.995861  ]\n",
            " [0.9958482 ]\n",
            " [0.00632302]]\n",
            "Step: 4887 -> Loss: 0.004620158579200506 -> Predictions: [[0.00382281]\n",
            " [0.9958611 ]\n",
            " [0.9958484 ]\n",
            " [0.00632271]]\n",
            "Step: 4888 -> Loss: 0.004619932267814875 -> Predictions: [[0.00382263]\n",
            " [0.99586135]\n",
            " [0.99584854]\n",
            " [0.00632239]]\n",
            "Step: 4889 -> Loss: 0.004619707353413105 -> Predictions: [[0.00382245]\n",
            " [0.9958616 ]\n",
            " [0.9958488 ]\n",
            " [0.00632208]]\n",
            "Step: 4890 -> Loss: 0.00461948337033391 -> Predictions: [[0.00382227]\n",
            " [0.9958617 ]\n",
            " [0.995849  ]\n",
            " [0.00632175]]\n",
            "Step: 4891 -> Loss: 0.004619257524609566 -> Predictions: [[0.00382209]\n",
            " [0.9958619 ]\n",
            " [0.99584913]\n",
            " [0.00632144]]\n",
            "Step: 4892 -> Loss: 0.004619031213223934 -> Predictions: [[0.00382191]\n",
            " [0.9958621 ]\n",
            " [0.9958494 ]\n",
            " [0.00632112]]\n",
            "Step: 4893 -> Loss: 0.004618808627128601 -> Predictions: [[0.00382173]\n",
            " [0.99586225]\n",
            " [0.9958496 ]\n",
            " [0.00632081]]\n",
            "Step: 4894 -> Loss: 0.00461858045309782 -> Predictions: [[0.00382155]\n",
            " [0.9958625 ]\n",
            " [0.9958497 ]\n",
            " [0.00632048]]\n",
            "Step: 4895 -> Loss: 0.004618356470018625 -> Predictions: [[0.00382137]\n",
            " [0.9958627 ]\n",
            " [0.99584997]\n",
            " [0.00632017]]\n",
            "Step: 4896 -> Loss: 0.004618133418262005 -> Predictions: [[0.0038212 ]\n",
            " [0.99586284]\n",
            " [0.9958502 ]\n",
            " [0.00631985]]\n",
            "Step: 4897 -> Loss: 0.0046179103665053844 -> Predictions: [[0.00382102]\n",
            " [0.9958631 ]\n",
            " [0.99585044]\n",
            " [0.00631953]]\n",
            "Step: 4898 -> Loss: 0.004617686383426189 -> Predictions: [[0.00382085]\n",
            " [0.9958633 ]\n",
            " [0.99585056]\n",
            " [0.00631922]]\n",
            "Step: 4899 -> Loss: 0.004617459140717983 -> Predictions: [[0.00382066]\n",
            " [0.99586356]\n",
            " [0.9958508 ]\n",
            " [0.0063189 ]]\n",
            "Step: 4900 -> Loss: 0.00461723655462265 -> Predictions: [[0.00382049]\n",
            " [0.9958637 ]\n",
            " [0.99585104]\n",
            " [0.00631859]]\n",
            "Step: 4901 -> Loss: 0.004617009311914444 -> Predictions: [[0.00382031]\n",
            " [0.9958639 ]\n",
            " [0.99585116]\n",
            " [0.00631826]]\n",
            "Step: 4902 -> Loss: 0.004616787191480398 -> Predictions: [[0.00382013]\n",
            " [0.99586415]\n",
            " [0.9958514 ]\n",
            " [0.00631796]]\n",
            "Step: 4903 -> Loss: 0.004616560414433479 -> Predictions: [[0.00381996]\n",
            " [0.9958643 ]\n",
            " [0.99585164]\n",
            " [0.00631763]]\n",
            "Step: 4904 -> Loss: 0.004616336897015572 -> Predictions: [[0.00381978]\n",
            " [0.9958645 ]\n",
            " [0.99585176]\n",
            " [0.00631732]]\n",
            "Step: 4905 -> Loss: 0.004616112913936377 -> Predictions: [[0.0038196 ]\n",
            " [0.99586475]\n",
            " [0.995852  ]\n",
            " [0.006317  ]]\n",
            "Step: 4906 -> Loss: 0.004615889396518469 -> Predictions: [[0.00381943]\n",
            " [0.99586487]\n",
            " [0.99585223]\n",
            " [0.00631668]]\n",
            "Step: 4907 -> Loss: 0.004615665413439274 -> Predictions: [[0.00381925]\n",
            " [0.9958651 ]\n",
            " [0.99585235]\n",
            " [0.00631637]]\n",
            "Step: 4908 -> Loss: 0.004615439102053642 -> Predictions: [[0.00381907]\n",
            " [0.99586535]\n",
            " [0.9958526 ]\n",
            " [0.00631605]]\n",
            "Step: 4909 -> Loss: 0.004615216050297022 -> Predictions: [[0.00381889]\n",
            " [0.99586546]\n",
            " [0.9958528 ]\n",
            " [0.00631573]]\n",
            "Step: 4910 -> Loss: 0.004614990204572678 -> Predictions: [[0.00381872]\n",
            " [0.9958657 ]\n",
            " [0.99585307]\n",
            " [0.00631541]]\n",
            "Step: 4911 -> Loss: 0.004614763893187046 -> Predictions: [[0.00381854]\n",
            " [0.99586594]\n",
            " [0.9958532 ]\n",
            " [0.0063151 ]]\n",
            "Step: 4912 -> Loss: 0.0046145436353981495 -> Predictions: [[0.00381836]\n",
            " [0.99586606]\n",
            " [0.9958534 ]\n",
            " [0.00631478]]\n",
            "Step: 4913 -> Loss: 0.0046143196523189545 -> Predictions: [[0.00381819]\n",
            " [0.9958663 ]\n",
            " [0.99585366]\n",
            " [0.00631447]]\n",
            "Step: 4914 -> Loss: 0.0046140942722558975 -> Predictions: [[0.00381801]\n",
            " [0.99586654]\n",
            " [0.9958538 ]\n",
            " [0.00631415]]\n",
            "Step: 4915 -> Loss: 0.00461387075483799 -> Predictions: [[0.00381783]\n",
            " [0.9958668 ]\n",
            " [0.995854  ]\n",
            " [0.00631384]]\n",
            "Step: 4916 -> Loss: 0.004613647237420082 -> Predictions: [[0.00381766]\n",
            " [0.9958669 ]\n",
            " [0.99585426]\n",
            " [0.00631352]]\n",
            "Step: 4917 -> Loss: 0.0046134223230183125 -> Predictions: [[0.00381748]\n",
            " [0.99586713]\n",
            " [0.9958544 ]\n",
            " [0.0063132 ]]\n",
            "Step: 4918 -> Loss: 0.0046131969429552555 -> Predictions: [[0.0038173 ]\n",
            " [0.99586725]\n",
            " [0.9958546 ]\n",
            " [0.00631288]]\n",
            "Step: 4919 -> Loss: 0.0046129729598760605 -> Predictions: [[0.00381713]\n",
            " [0.9958675 ]\n",
            " [0.9958548 ]\n",
            " [0.00631257]]\n",
            "Step: 4920 -> Loss: 0.00461274990811944 -> Predictions: [[0.00381695]\n",
            " [0.9958677 ]\n",
            " [0.9958549 ]\n",
            " [0.00631225]]\n",
            "Step: 4921 -> Loss: 0.0046125249937176704 -> Predictions: [[0.00381677]\n",
            " [0.99586797]\n",
            " [0.99585515]\n",
            " [0.00631194]]\n",
            "Step: 4922 -> Loss: 0.004612300544977188 -> Predictions: [[0.00381659]\n",
            " [0.9958681 ]\n",
            " [0.9958554 ]\n",
            " [0.00631162]]\n",
            "Step: 4923 -> Loss: 0.004612076561897993 -> Predictions: [[0.00381642]\n",
            " [0.9958683 ]\n",
            " [0.9958556 ]\n",
            " [0.00631131]]\n",
            "Step: 4924 -> Loss: 0.004611852578818798 -> Predictions: [[0.00381624]\n",
            " [0.99586856]\n",
            " [0.99585575]\n",
            " [0.00631098]]\n",
            "Step: 4925 -> Loss: 0.004611630458384752 -> Predictions: [[0.00381607]\n",
            " [0.9958687 ]\n",
            " [0.995856  ]\n",
            " [0.00631067]]\n",
            "Step: 4926 -> Loss: 0.004611405078321695 -> Predictions: [[0.00381589]\n",
            " [0.9958689 ]\n",
            " [0.9958562 ]\n",
            " [0.00631035]]\n",
            "Step: 4927 -> Loss: 0.0046111810952425 -> Predictions: [[0.00381571]\n",
            " [0.9958691 ]\n",
            " [0.99585634]\n",
            " [0.00631004]]\n",
            "Step: 4928 -> Loss: 0.004610954783856869 -> Predictions: [[0.00381553]\n",
            " [0.9958692 ]\n",
            " [0.9958566 ]\n",
            " [0.00630972]]\n",
            "Step: 4929 -> Loss: 0.00461073312908411 -> Predictions: [[0.00381535]\n",
            " [0.99586946]\n",
            " [0.9958568 ]\n",
            " [0.00630941]]\n",
            "Step: 4930 -> Loss: 0.004610506352037191 -> Predictions: [[0.00381518]\n",
            " [0.9958697 ]\n",
            " [0.99585694]\n",
            " [0.0063091 ]]\n",
            "Step: 4931 -> Loss: 0.004610284231603146 -> Predictions: [[0.003815  ]\n",
            " [0.9958698 ]\n",
            " [0.9958572 ]\n",
            " [0.00630879]]\n",
            "Step: 4932 -> Loss: 0.004610060248523951 -> Predictions: [[0.00381483]\n",
            " [0.99587005]\n",
            " [0.9958574 ]\n",
            " [0.00630847]]\n",
            "Step: 4933 -> Loss: 0.0046098362654447556 -> Predictions: [[0.00381465]\n",
            " [0.9958703 ]\n",
            " [0.99585754]\n",
            " [0.00630815]]\n",
            "Step: 4934 -> Loss: 0.004609609022736549 -> Predictions: [[0.00381447]\n",
            " [0.99587053]\n",
            " [0.9958578 ]\n",
            " [0.00630784]]\n",
            "Step: 4935 -> Loss: 0.004609387367963791 -> Predictions: [[0.00381429]\n",
            " [0.99587065]\n",
            " [0.995858  ]\n",
            " [0.00630753]]\n",
            "Step: 4936 -> Loss: 0.0046091629192233086 -> Predictions: [[0.00381412]\n",
            " [0.9958709 ]\n",
            " [0.99585813]\n",
            " [0.00630721]]\n",
            "Step: 4937 -> Loss: 0.004608939401805401 -> Predictions: [[0.00381394]\n",
            " [0.9958711 ]\n",
            " [0.9958584 ]\n",
            " [0.0063069 ]]\n",
            "Step: 4938 -> Loss: 0.0046087149530649185 -> Predictions: [[0.00381376]\n",
            " [0.99587125]\n",
            " [0.9958586 ]\n",
            " [0.00630658]]\n",
            "Step: 4939 -> Loss: 0.004608491435647011 -> Predictions: [[0.00381358]\n",
            " [0.9958715 ]\n",
            " [0.99585885]\n",
            " [0.00630626]]\n",
            "Step: 4940 -> Loss: 0.004608267918229103 -> Predictions: [[0.00381341]\n",
            " [0.9958717 ]\n",
            " [0.99585897]\n",
            " [0.00630595]]\n",
            "Step: 4941 -> Loss: 0.00460804533213377 -> Predictions: [[0.00381324]\n",
            " [0.99587184]\n",
            " [0.9958592 ]\n",
            " [0.00630564]]\n",
            "Step: 4942 -> Loss: 0.0046078236773610115 -> Predictions: [[0.00381306]\n",
            " [0.9958721 ]\n",
            " [0.99585944]\n",
            " [0.00630533]]\n",
            "Step: 4943 -> Loss: 0.004607598762959242 -> Predictions: [[0.00381289]\n",
            " [0.9958723 ]\n",
            " [0.99585956]\n",
            " [0.00630501]]\n",
            "Step: 4944 -> Loss: 0.004607373382896185 -> Predictions: [[0.00381271]\n",
            " [0.99587256]\n",
            " [0.9958598 ]\n",
            " [0.0063047 ]]\n",
            "Step: 4945 -> Loss: 0.004607150796800852 -> Predictions: [[0.00381253]\n",
            " [0.9958727 ]\n",
            " [0.99586004]\n",
            " [0.00630438]]\n",
            "Step: 4946 -> Loss: 0.004606925882399082 -> Predictions: [[0.00381235]\n",
            " [0.9958729 ]\n",
            " [0.99586016]\n",
            " [0.00630407]]\n",
            "Step: 4947 -> Loss: 0.004606702830642462 -> Predictions: [[0.00381217]\n",
            " [0.99587315]\n",
            " [0.9958604 ]\n",
            " [0.00630376]]\n",
            "Step: 4948 -> Loss: 0.004606477450579405 -> Predictions: [[0.00381199]\n",
            " [0.9958733 ]\n",
            " [0.99586064]\n",
            " [0.00630344]]\n",
            "Step: 4949 -> Loss: 0.004606254398822784 -> Predictions: [[0.00381182]\n",
            " [0.9958735 ]\n",
            " [0.99586076]\n",
            " [0.00630313]]\n",
            "Step: 4950 -> Loss: 0.004606030881404877 -> Predictions: [[0.00381165]\n",
            " [0.99587375]\n",
            " [0.995861  ]\n",
            " [0.00630281]]\n",
            "Step: 4951 -> Loss: 0.004605807829648256 -> Predictions: [[0.00381147]\n",
            " [0.99587387]\n",
            " [0.99586123]\n",
            " [0.0063025 ]]\n",
            "Step: 4952 -> Loss: 0.004605581983923912 -> Predictions: [[0.00381129]\n",
            " [0.9958741 ]\n",
            " [0.9958615 ]\n",
            " [0.00630218]]\n",
            "Step: 4953 -> Loss: 0.004605359863489866 -> Predictions: [[0.00381111]\n",
            " [0.99587435]\n",
            " [0.9958616 ]\n",
            " [0.00630187]]\n",
            "Step: 4954 -> Loss: 0.004605135880410671 -> Predictions: [[0.00381093]\n",
            " [0.99587446]\n",
            " [0.99586177]\n",
            " [0.00630156]]\n",
            "Step: 4955 -> Loss: 0.004604910966008902 -> Predictions: [[0.00381076]\n",
            " [0.9958747 ]\n",
            " [0.995862  ]\n",
            " [0.00630124]]\n",
            "Step: 4956 -> Loss: 0.004604688845574856 -> Predictions: [[0.00381059]\n",
            " [0.99587494]\n",
            " [0.9958621 ]\n",
            " [0.00630093]]\n",
            "Step: 4957 -> Loss: 0.004604463931173086 -> Predictions: [[0.00381041]\n",
            " [0.9958752 ]\n",
            " [0.99586236]\n",
            " [0.00630061]]\n",
            "Step: 4958 -> Loss: 0.004604241345077753 -> Predictions: [[0.00381023]\n",
            " [0.9958753 ]\n",
            " [0.9958626 ]\n",
            " [0.0063003 ]]\n",
            "Step: 4959 -> Loss: 0.004604017361998558 -> Predictions: [[0.00381005]\n",
            " [0.99587554]\n",
            " [0.9958627 ]\n",
            " [0.00629999]]\n",
            "Step: 4960 -> Loss: 0.00460379384458065 -> Predictions: [[0.00380988]\n",
            " [0.9958758 ]\n",
            " [0.99586296]\n",
            " [0.00629967]]\n",
            "Step: 4961 -> Loss: 0.004603571258485317 -> Predictions: [[0.0038097 ]\n",
            " [0.9958759 ]\n",
            " [0.9958632 ]\n",
            " [0.00629936]]\n",
            "Step: 4962 -> Loss: 0.004603347275406122 -> Predictions: [[0.00380953]\n",
            " [0.99587613]\n",
            " [0.9958633 ]\n",
            " [0.00629904]]\n",
            "Step: 4963 -> Loss: 0.004603121895343065 -> Predictions: [[0.00380934]\n",
            " [0.9958763 ]\n",
            " [0.99586356]\n",
            " [0.00629872]]\n",
            "Step: 4964 -> Loss: 0.004602900706231594 -> Predictions: [[0.00380917]\n",
            " [0.99587643]\n",
            " [0.9958638 ]\n",
            " [0.00629842]]\n",
            "Step: 4965 -> Loss: 0.004602679051458836 -> Predictions: [[0.003809  ]\n",
            " [0.99587667]\n",
            " [0.9958639 ]\n",
            " [0.0062981 ]]\n",
            "Step: 4966 -> Loss: 0.004602450877428055 -> Predictions: [[0.00380882]\n",
            " [0.9958769 ]\n",
            " [0.99586415]\n",
            " [0.00629779]]\n",
            "Step: 4967 -> Loss: 0.004602228756994009 -> Predictions: [[0.00380864]\n",
            " [0.995877  ]\n",
            " [0.9958644 ]\n",
            " [0.00629747]]\n",
            "Step: 4968 -> Loss: 0.004602004773914814 -> Predictions: [[0.00380846]\n",
            " [0.99587727]\n",
            " [0.9958646 ]\n",
            " [0.00629716]]\n",
            "Step: 4969 -> Loss: 0.004601782187819481 -> Predictions: [[0.00380829]\n",
            " [0.9958775 ]\n",
            " [0.99586475]\n",
            " [0.00629684]]\n",
            "Step: 4970 -> Loss: 0.004601558670401573 -> Predictions: [[0.00380811]\n",
            " [0.9958776 ]\n",
            " [0.995865  ]\n",
            " [0.00629653]]\n",
            "Step: 4971 -> Loss: 0.0046013337559998035 -> Predictions: [[0.00380794]\n",
            " [0.99587786]\n",
            " [0.9958652 ]\n",
            " [0.00629622]]\n",
            "Step: 4972 -> Loss: 0.0046011097729206085 -> Predictions: [[0.00380776]\n",
            " [0.9958781 ]\n",
            " [0.99586535]\n",
            " [0.0062959 ]]\n",
            "Step: 4973 -> Loss: 0.004600887652486563 -> Predictions: [[0.00380758]\n",
            " [0.99587834]\n",
            " [0.9958656 ]\n",
            " [0.00629559]]\n",
            "Step: 4974 -> Loss: 0.004600664600729942 -> Predictions: [[0.00380741]\n",
            " [0.99587846]\n",
            " [0.9958658 ]\n",
            " [0.00629528]]\n",
            "Step: 4975 -> Loss: 0.004600441548973322 -> Predictions: [[0.00380723]\n",
            " [0.9958787 ]\n",
            " [0.99586594]\n",
            " [0.00629497]]\n",
            "Step: 4976 -> Loss: 0.004600217565894127 -> Predictions: [[0.00380705]\n",
            " [0.99587893]\n",
            " [0.9958662 ]\n",
            " [0.00629466]]\n",
            "Step: 4977 -> Loss: 0.004599992651492357 -> Predictions: [[0.00380687]\n",
            " [0.99587905]\n",
            " [0.9958664 ]\n",
            " [0.00629434]]\n",
            "Step: 4978 -> Loss: 0.004599772393703461 -> Predictions: [[0.0038067 ]\n",
            " [0.9958793 ]\n",
            " [0.99586654]\n",
            " [0.00629403]]\n",
            "Step: 4979 -> Loss: 0.004599547013640404 -> Predictions: [[0.00380652]\n",
            " [0.99587953]\n",
            " [0.9958668 ]\n",
            " [0.00629372]]\n",
            "Step: 4980 -> Loss: 0.0045993211679160595 -> Predictions: [[0.00380634]\n",
            " [0.99587965]\n",
            " [0.995867  ]\n",
            " [0.00629341]]\n",
            "Step: 4981 -> Loss: 0.00459910137578845 -> Predictions: [[0.00380617]\n",
            " [0.9958799 ]\n",
            " [0.99586725]\n",
            " [0.0062931 ]]\n",
            "Step: 4982 -> Loss: 0.0045988792553544044 -> Predictions: [[0.003806  ]\n",
            " [0.9958801 ]\n",
            " [0.9958674 ]\n",
            " [0.00629279]]\n",
            "Step: 4983 -> Loss: 0.004598652478307486 -> Predictions: [[0.00380581]\n",
            " [0.99588037]\n",
            " [0.9958676 ]\n",
            " [0.00629247]]\n",
            "Step: 4984 -> Loss: 0.004598429426550865 -> Predictions: [[0.00380564]\n",
            " [0.9958805 ]\n",
            " [0.99586785]\n",
            " [0.00629216]]\n",
            "Step: 4985 -> Loss: 0.004598207306116819 -> Predictions: [[0.00380546]\n",
            " [0.9958807 ]\n",
            " [0.99586797]\n",
            " [0.00629185]]\n",
            "Step: 4986 -> Loss: 0.004597986117005348 -> Predictions: [[0.00380529]\n",
            " [0.99588096]\n",
            " [0.9958682 ]\n",
            " [0.00629154]]\n",
            "Step: 4987 -> Loss: 0.004597761668264866 -> Predictions: [[0.00380511]\n",
            " [0.9958811 ]\n",
            " [0.99586844]\n",
            " [0.00629123]]\n",
            "Step: 4988 -> Loss: 0.004597538150846958 -> Predictions: [[0.00380494]\n",
            " [0.9958813 ]\n",
            " [0.99586856]\n",
            " [0.00629092]]\n",
            "Step: 4989 -> Loss: 0.004597318358719349 -> Predictions: [[0.00380476]\n",
            " [0.99588156]\n",
            " [0.9958688 ]\n",
            " [0.00629061]]\n",
            "Step: 4990 -> Loss: 0.004597092978656292 -> Predictions: [[0.00380458]\n",
            " [0.9958817 ]\n",
            " [0.995869  ]\n",
            " [0.0062903 ]]\n",
            "Step: 4991 -> Loss: 0.004596867598593235 -> Predictions: [[0.0038044 ]\n",
            " [0.9958819 ]\n",
            " [0.9958692 ]\n",
            " [0.00628998]]\n",
            "Step: 4992 -> Loss: 0.004596646409481764 -> Predictions: [[0.00380423]\n",
            " [0.99588215]\n",
            " [0.99586934]\n",
            " [0.00628967]]\n",
            "Step: 4993 -> Loss: 0.004596422426402569 -> Predictions: [[0.00380405]\n",
            " [0.9958823 ]\n",
            " [0.9958696 ]\n",
            " [0.00628936]]\n",
            "Step: 4994 -> Loss: 0.004596200305968523 -> Predictions: [[0.00380388]\n",
            " [0.9958825 ]\n",
            " [0.9958698 ]\n",
            " [0.00628905]]\n",
            "Step: 4995 -> Loss: 0.004595975857228041 -> Predictions: [[0.0038037 ]\n",
            " [0.99588275]\n",
            " [0.99586993]\n",
            " [0.00628873]]\n",
            "Step: 4996 -> Loss: 0.004595755599439144 -> Predictions: [[0.00380353]\n",
            " [0.99588287]\n",
            " [0.9958702 ]\n",
            " [0.00628843]]\n",
            "Step: 4997 -> Loss: 0.004595531150698662 -> Predictions: [[0.00380335]\n",
            " [0.9958831 ]\n",
            " [0.9958704 ]\n",
            " [0.00628811]]\n",
            "Step: 4998 -> Loss: 0.004595308564603329 -> Predictions: [[0.00380317]\n",
            " [0.99588335]\n",
            " [0.99587053]\n",
            " [0.0062878 ]]\n",
            "Step: 4999 -> Loss: 0.004595084115862846 -> Predictions: [[0.00380299]\n",
            " [0.9958835 ]\n",
            " [0.99587077]\n",
            " [0.00628749]]\n",
            "Step: 5001 -> Loss: 0.004594637081027031 -> Predictions: [[0.00380265]\n",
            " [0.9958839 ]\n",
            " [0.99587125]\n",
            " [0.00628686]]\n",
            "Step: 5002 -> Loss: 0.004594414960592985 -> Predictions: [[0.00380247]\n",
            " [0.9958841 ]\n",
            " [0.99587137]\n",
            " [0.00628655]]\n",
            "Step: 5003 -> Loss: 0.004594189114868641 -> Predictions: [[0.00380229]\n",
            " [0.99588424]\n",
            " [0.9958716 ]\n",
            " [0.00628624]]\n",
            "Step: 5004 -> Loss: 0.004593969788402319 -> Predictions: [[0.00380212]\n",
            " [0.9958845 ]\n",
            " [0.99587184]\n",
            " [0.00628594]]\n",
            "Step: 5005 -> Loss: 0.004593743942677975 -> Predictions: [[0.00380194]\n",
            " [0.9958847 ]\n",
            " [0.99587196]\n",
            " [0.00628562]]\n",
            "Step: 5006 -> Loss: 0.004593521356582642 -> Predictions: [[0.00380176]\n",
            " [0.99588484]\n",
            " [0.9958722 ]\n",
            " [0.00628531]]\n",
            "Step: 5007 -> Loss: 0.004593299701809883 -> Predictions: [[0.00380158]\n",
            " [0.9958851 ]\n",
            " [0.99587244]\n",
            " [0.006285  ]]\n",
            "Step: 5008 -> Loss: 0.004593076650053263 -> Predictions: [[0.00380141]\n",
            " [0.9958853 ]\n",
            " [0.99587256]\n",
            " [0.00628469]]\n",
            "Step: 5009 -> Loss: 0.004592852666974068 -> Predictions: [[0.00380123]\n",
            " [0.99588543]\n",
            " [0.9958728 ]\n",
            " [0.00628437]]\n",
            "Step: 5010 -> Loss: 0.004592629615217447 -> Predictions: [[0.00380106]\n",
            " [0.99588567]\n",
            " [0.99587303]\n",
            " [0.00628406]]\n",
            "Step: 5011 -> Loss: 0.004592406563460827 -> Predictions: [[0.00380088]\n",
            " [0.9958859 ]\n",
            " [0.99587315]\n",
            " [0.00628375]]\n",
            "Step: 5012 -> Loss: 0.004592184908688068 -> Predictions: [[0.0038007 ]\n",
            " [0.995886  ]\n",
            " [0.9958734 ]\n",
            " [0.00628344]]\n",
            "Step: 5013 -> Loss: 0.004591962322592735 -> Predictions: [[0.00380053]\n",
            " [0.99588627]\n",
            " [0.99587363]\n",
            " [0.00628313]]\n",
            "Step: 5014 -> Loss: 0.004591739736497402 -> Predictions: [[0.00380035]\n",
            " [0.9958865 ]\n",
            " [0.99587387]\n",
            " [0.00628282]]\n",
            "Step: 5015 -> Loss: 0.004591513890773058 -> Predictions: [[0.00380018]\n",
            " [0.99588674]\n",
            " [0.995874  ]\n",
            " [0.0062825 ]]\n",
            "Step: 5016 -> Loss: 0.004591292701661587 -> Predictions: [[0.0038    ]\n",
            " [0.99588686]\n",
            " [0.9958742 ]\n",
            " [0.00628219]]\n",
            "Step: 5017 -> Loss: 0.004591069649904966 -> Predictions: [[0.00379982]\n",
            " [0.9958871 ]\n",
            " [0.99587446]\n",
            " [0.00628188]]\n",
            "Step: 5018 -> Loss: 0.004590847063809633 -> Predictions: [[0.00379965]\n",
            " [0.99588734]\n",
            " [0.9958746 ]\n",
            " [0.00628157]]\n",
            "Step: 5019 -> Loss: 0.004590625409036875 -> Predictions: [[0.00379948]\n",
            " [0.99588746]\n",
            " [0.9958748 ]\n",
            " [0.00628126]]\n",
            "Step: 5020 -> Loss: 0.0045903995633125305 -> Predictions: [[0.00379929]\n",
            " [0.9958877 ]\n",
            " [0.99587506]\n",
            " [0.00628095]]\n",
            "Step: 5021 -> Loss: 0.004590178374201059 -> Predictions: [[0.00379912]\n",
            " [0.99588794]\n",
            " [0.9958752 ]\n",
            " [0.00628064]]\n",
            "Step: 5022 -> Loss: 0.004589955322444439 -> Predictions: [[0.00379894]\n",
            " [0.99588805]\n",
            " [0.9958754 ]\n",
            " [0.00628033]]\n",
            "Step: 5023 -> Loss: 0.004589730873703957 -> Predictions: [[0.00379876]\n",
            " [0.9958883 ]\n",
            " [0.99587566]\n",
            " [0.00628002]]\n",
            "Step: 5024 -> Loss: 0.00458951061591506 -> Predictions: [[0.00379859]\n",
            " [0.99588853]\n",
            " [0.9958758 ]\n",
            " [0.00627971]]\n",
            "Step: 5025 -> Loss: 0.004589286632835865 -> Predictions: [[0.00379842]\n",
            " [0.99588865]\n",
            " [0.995876  ]\n",
            " [0.00627939]]\n",
            "Step: 5026 -> Loss: 0.004589063581079245 -> Predictions: [[0.00379824]\n",
            " [0.9958889 ]\n",
            " [0.9958762 ]\n",
            " [0.00627909]]\n",
            "Step: 5027 -> Loss: 0.004588842857629061 -> Predictions: [[0.00379806]\n",
            " [0.9958891 ]\n",
            " [0.99587643]\n",
            " [0.00627878]]\n",
            "Step: 5028 -> Loss: 0.004588620271533728 -> Predictions: [[0.00379789]\n",
            " [0.99588925]\n",
            " [0.99587655]\n",
            " [0.00627846]]\n",
            "Step: 5029 -> Loss: 0.004588395357131958 -> Predictions: [[0.00379771]\n",
            " [0.9958895 ]\n",
            " [0.9958768 ]\n",
            " [0.00627815]]\n",
            "Step: 5030 -> Loss: 0.004588172771036625 -> Predictions: [[0.00379754]\n",
            " [0.9958897 ]\n",
            " [0.995877  ]\n",
            " [0.00627784]]\n",
            "Step: 5031 -> Loss: 0.004587952047586441 -> Predictions: [[0.00379736]\n",
            " [0.99588984]\n",
            " [0.99587715]\n",
            " [0.00627753]]\n",
            "Step: 5032 -> Loss: 0.004587727598845959 -> Predictions: [[0.00379718]\n",
            " [0.9958901 ]\n",
            " [0.9958774 ]\n",
            " [0.00627722]]\n",
            "Step: 5033 -> Loss: 0.0045875059440732 -> Predictions: [[0.00379701]\n",
            " [0.9958903 ]\n",
            " [0.9958776 ]\n",
            " [0.00627691]]\n",
            "Step: 5034 -> Loss: 0.004587281029671431 -> Predictions: [[0.00379683]\n",
            " [0.9958905 ]\n",
            " [0.99587774]\n",
            " [0.00627659]]\n",
            "Step: 5035 -> Loss: 0.004587061703205109 -> Predictions: [[0.00379666]\n",
            " [0.9958906 ]\n",
            " [0.995878  ]\n",
            " [0.00627629]]\n",
            "Step: 5036 -> Loss: 0.004586837720125914 -> Predictions: [[0.00379648]\n",
            " [0.99589086]\n",
            " [0.9958782 ]\n",
            " [0.00627598]]\n",
            "Step: 5037 -> Loss: 0.004586614202708006 -> Predictions: [[0.00379631]\n",
            " [0.9958911 ]\n",
            " [0.99587846]\n",
            " [0.00627566]]\n",
            "Step: 5038 -> Loss: 0.004586392547935247 -> Predictions: [[0.00379613]\n",
            " [0.9958912 ]\n",
            " [0.9958786 ]\n",
            " [0.00627535]]\n",
            "Step: 5039 -> Loss: 0.004586169961839914 -> Predictions: [[0.00379595]\n",
            " [0.99589145]\n",
            " [0.9958788 ]\n",
            " [0.00627504]]\n",
            "Step: 5040 -> Loss: 0.004585945978760719 -> Predictions: [[0.00379578]\n",
            " [0.9958917 ]\n",
            " [0.99587905]\n",
            " [0.00627473]]\n",
            "Step: 5041 -> Loss: 0.004585725720971823 -> Predictions: [[0.0037956 ]\n",
            " [0.9958918 ]\n",
            " [0.9958792 ]\n",
            " [0.00627443]]\n",
            "Step: 5042 -> Loss: 0.00458550127223134 -> Predictions: [[0.00379542]\n",
            " [0.99589205]\n",
            " [0.9958794 ]\n",
            " [0.00627411]]\n",
            "Step: 5043 -> Loss: 0.004585278686136007 -> Predictions: [[0.00379525]\n",
            " [0.9958923 ]\n",
            " [0.99587965]\n",
            " [0.0062738 ]]\n",
            "Step: 5044 -> Loss: 0.004585057031363249 -> Predictions: [[0.00379507]\n",
            " [0.9958924 ]\n",
            " [0.99587977]\n",
            " [0.00627349]]\n",
            "Step: 5045 -> Loss: 0.004584832116961479 -> Predictions: [[0.00379489]\n",
            " [0.99589264]\n",
            " [0.99588   ]\n",
            " [0.00627318]]\n",
            "Step: 5046 -> Loss: 0.00458461232483387 -> Predictions: [[0.00379472]\n",
            " [0.9958929 ]\n",
            " [0.99588025]\n",
            " [0.00627287]]\n",
            "Step: 5047 -> Loss: 0.0045843906700611115 -> Predictions: [[0.00379455]\n",
            " [0.995893  ]\n",
            " [0.99588037]\n",
            " [0.00627256]]\n",
            "Step: 5048 -> Loss: 0.004584166221320629 -> Predictions: [[0.00379437]\n",
            " [0.99589324]\n",
            " [0.9958806 ]\n",
            " [0.00627225]]\n",
            "Step: 5049 -> Loss: 0.004583944100886583 -> Predictions: [[0.00379419]\n",
            " [0.9958935 ]\n",
            " [0.99588084]\n",
            " [0.00627194]]\n",
            "Step: 5050 -> Loss: 0.004583720583468676 -> Predictions: [[0.00379402]\n",
            " [0.9958937 ]\n",
            " [0.9958811 ]\n",
            " [0.00627163]]\n",
            "Step: 5051 -> Loss: 0.004583501722663641 -> Predictions: [[0.00379385]\n",
            " [0.99589384]\n",
            " [0.9958812 ]\n",
            " [0.00627132]]\n",
            "Step: 5052 -> Loss: 0.004583279602229595 -> Predictions: [[0.00379367]\n",
            " [0.9958941 ]\n",
            " [0.99588144]\n",
            " [0.00627102]]\n",
            "Step: 5053 -> Loss: 0.004583055153489113 -> Predictions: [[0.0037935 ]\n",
            " [0.9958943 ]\n",
            " [0.9958817 ]\n",
            " [0.00627071]]\n",
            "Step: 5054 -> Loss: 0.004582834430038929 -> Predictions: [[0.00379333]\n",
            " [0.99589443]\n",
            " [0.9958818 ]\n",
            " [0.0062704 ]]\n",
            "Step: 5055 -> Loss: 0.004582610446959734 -> Predictions: [[0.00379315]\n",
            " [0.9958947 ]\n",
            " [0.99588203]\n",
            " [0.00627009]]\n",
            "Step: 5056 -> Loss: 0.004582390654832125 -> Predictions: [[0.00379298]\n",
            " [0.9958949 ]\n",
            " [0.9958823 ]\n",
            " [0.00626979]]\n",
            "Step: 5057 -> Loss: 0.004582167603075504 -> Predictions: [[0.00379281]\n",
            " [0.995895  ]\n",
            " [0.9958825 ]\n",
            " [0.00626947]]\n",
            "Step: 5058 -> Loss: 0.004581945016980171 -> Predictions: [[0.00379263]\n",
            " [0.99589527]\n",
            " [0.99588263]\n",
            " [0.00626917]]\n",
            "Step: 5059 -> Loss: 0.004581724293529987 -> Predictions: [[0.00379245]\n",
            " [0.9958955 ]\n",
            " [0.99588287]\n",
            " [0.00626887]]\n",
            "Step: 5060 -> Loss: 0.004581499379128218 -> Predictions: [[0.00379228]\n",
            " [0.99589574]\n",
            " [0.9958831 ]\n",
            " [0.00626856]]\n",
            "Step: 5061 -> Loss: 0.004581280052661896 -> Predictions: [[0.0037921 ]\n",
            " [0.99589586]\n",
            " [0.9958832 ]\n",
            " [0.00626825]]\n",
            "Step: 5062 -> Loss: 0.004581055603921413 -> Predictions: [[0.00379193]\n",
            " [0.9958961 ]\n",
            " [0.9958834 ]\n",
            " [0.00626794]]\n",
            "Step: 5063 -> Loss: 0.004580835346132517 -> Predictions: [[0.00379176]\n",
            " [0.99589634]\n",
            " [0.99588364]\n",
            " [0.00626764]]\n",
            "Step: 5064 -> Loss: 0.00458060996606946 -> Predictions: [[0.00379158]\n",
            " [0.99589646]\n",
            " [0.9958839 ]\n",
            " [0.00626732]]\n",
            "Step: 5065 -> Loss: 0.004580391570925713 -> Predictions: [[0.00379141]\n",
            " [0.9958967 ]\n",
            " [0.995884  ]\n",
            " [0.00626702]]\n",
            "Step: 5066 -> Loss: 0.004580170847475529 -> Predictions: [[0.00379123]\n",
            " [0.99589694]\n",
            " [0.99588424]\n",
            " [0.00626671]]\n",
            "Step: 5067 -> Loss: 0.004579948727041483 -> Predictions: [[0.00379105]\n",
            " [0.99589705]\n",
            " [0.9958845 ]\n",
            " [0.0062664 ]]\n",
            "Step: 5068 -> Loss: 0.004579729400575161 -> Predictions: [[0.00379088]\n",
            " [0.9958973 ]\n",
            " [0.9958846 ]\n",
            " [0.0062661 ]]\n",
            "Step: 5069 -> Loss: 0.00457950821146369 -> Predictions: [[0.0037907 ]\n",
            " [0.99589753]\n",
            " [0.99588484]\n",
            " [0.00626579]]\n",
            "Step: 5070 -> Loss: 0.004579284228384495 -> Predictions: [[0.00379052]\n",
            " [0.99589765]\n",
            " [0.9958851 ]\n",
            " [0.00626547]]\n",
            "Step: 5071 -> Loss: 0.004579064901918173 -> Predictions: [[0.00379034]\n",
            " [0.9958978 ]\n",
            " [0.9958852 ]\n",
            " [0.00626517]]\n",
            "Step: 5072 -> Loss: 0.004578843712806702 -> Predictions: [[0.00379017]\n",
            " [0.99589807]\n",
            " [0.99588543]\n",
            " [0.00626486]]\n",
            "Step: 5073 -> Loss: 0.004578623455017805 -> Predictions: [[0.00378999]\n",
            " [0.9958982 ]\n",
            " [0.99588567]\n",
            " [0.00626456]]\n",
            "Step: 5074 -> Loss: 0.004578402265906334 -> Predictions: [[0.00378981]\n",
            " [0.9958984 ]\n",
            " [0.9958858 ]\n",
            " [0.00626425]]\n",
            "Step: 5075 -> Loss: 0.0045781792141497135 -> Predictions: [[0.00378963]\n",
            " [0.99589866]\n",
            " [0.995886  ]\n",
            " [0.00626394]]\n",
            "Step: 5076 -> Loss: 0.004577957093715668 -> Predictions: [[0.00378945]\n",
            " [0.9958988 ]\n",
            " [0.99588627]\n",
            " [0.00626363]]\n",
            "Step: 5077 -> Loss: 0.0045777373015880585 -> Predictions: [[0.00378928]\n",
            " [0.995899  ]\n",
            " [0.9958864 ]\n",
            " [0.00626333]]\n",
            "Step: 5078 -> Loss: 0.004577517509460449 -> Predictions: [[0.0037891 ]\n",
            " [0.99589926]\n",
            " [0.9958866 ]\n",
            " [0.00626302]]\n",
            "Step: 5079 -> Loss: 0.004577294457703829 -> Predictions: [[0.00378892]\n",
            " [0.9958994 ]\n",
            " [0.99588686]\n",
            " [0.00626271]]\n",
            "Step: 5080 -> Loss: 0.004577075596898794 -> Predictions: [[0.00378875]\n",
            " [0.9958996 ]\n",
            " [0.995887  ]\n",
            " [0.0062624 ]]\n",
            "Step: 5081 -> Loss: 0.004576851613819599 -> Predictions: [[0.00378857]\n",
            " [0.99589986]\n",
            " [0.9958872 ]\n",
            " [0.0062621 ]]\n",
            "Step: 5082 -> Loss: 0.004576632287353277 -> Predictions: [[0.00378839]\n",
            " [0.9959    ]\n",
            " [0.99588746]\n",
            " [0.00626179]]\n",
            "Step: 5083 -> Loss: 0.0045764087699353695 -> Predictions: [[0.00378821]\n",
            " [0.9959002 ]\n",
            " [0.9958876 ]\n",
            " [0.00626148]]\n",
            "Step: 5084 -> Loss: 0.0045761894434690475 -> Predictions: [[0.00378804]\n",
            " [0.99590045]\n",
            " [0.9958878 ]\n",
            " [0.00626117]]\n",
            "Step: 5085 -> Loss: 0.004575967788696289 -> Predictions: [[0.00378786]\n",
            " [0.9959006 ]\n",
            " [0.99588805]\n",
            " [0.00626086]]\n",
            "Step: 5086 -> Loss: 0.004575748927891254 -> Predictions: [[0.00378768]\n",
            " [0.9959008 ]\n",
            " [0.9958882 ]\n",
            " [0.00626056]]\n",
            "Step: 5087 -> Loss: 0.004575524944812059 -> Predictions: [[0.0037875 ]\n",
            " [0.99590105]\n",
            " [0.9958884 ]\n",
            " [0.00626025]]\n",
            "Step: 5088 -> Loss: 0.004575306549668312 -> Predictions: [[0.00378733]\n",
            " [0.99590117]\n",
            " [0.99588865]\n",
            " [0.00625995]]\n",
            "Step: 5089 -> Loss: 0.004575086757540703 -> Predictions: [[0.00378715]\n",
            " [0.9959014 ]\n",
            " [0.99588877]\n",
            " [0.00625963]]\n",
            "Step: 5090 -> Loss: 0.004574862774461508 -> Predictions: [[0.00378697]\n",
            " [0.99590164]\n",
            " [0.995889  ]\n",
            " [0.00625933]]\n",
            "Step: 5091 -> Loss: 0.0045746429823338985 -> Predictions: [[0.00378679]\n",
            " [0.99590176]\n",
            " [0.99588925]\n",
            " [0.00625902]]\n",
            "Step: 5092 -> Loss: 0.004574424121528864 -> Predictions: [[0.00378662]\n",
            " [0.995902  ]\n",
            " [0.99588937]\n",
            " [0.00625872]]\n",
            "Step: 5093 -> Loss: 0.0045742010697722435 -> Predictions: [[0.00378644]\n",
            " [0.99590224]\n",
            " [0.9958896 ]\n",
            " [0.00625841]]\n",
            "Step: 5094 -> Loss: 0.004573978018015623 -> Predictions: [[0.00378626]\n",
            " [0.99590236]\n",
            " [0.99588984]\n",
            " [0.0062581 ]]\n",
            "Step: 5095 -> Loss: 0.004573758225888014 -> Predictions: [[0.00378608]\n",
            " [0.9959026 ]\n",
            " [0.99588996]\n",
            " [0.00625779]]\n",
            "Step: 5096 -> Loss: 0.004573538899421692 -> Predictions: [[0.0037859 ]\n",
            " [0.99590284]\n",
            " [0.9958902 ]\n",
            " [0.00625748]]\n",
            "Step: 5097 -> Loss: 0.004573316313326359 -> Predictions: [[0.00378573]\n",
            " [0.99590296]\n",
            " [0.99589044]\n",
            " [0.00625718]]\n",
            "Step: 5098 -> Loss: 0.004573099315166473 -> Predictions: [[0.00378556]\n",
            " [0.9959032 ]\n",
            " [0.9958905 ]\n",
            " [0.00625687]]\n",
            "Step: 5099 -> Loss: 0.004572878126055002 -> Predictions: [[0.00378538]\n",
            " [0.99590343]\n",
            " [0.99589074]\n",
            " [0.00625656]]\n",
            "Step: 5100 -> Loss: 0.004572656005620956 -> Predictions: [[0.0037852 ]\n",
            " [0.99590355]\n",
            " [0.995891  ]\n",
            " [0.00625625]]\n",
            "Step: 5101 -> Loss: 0.004572432022541761 -> Predictions: [[0.00378502]\n",
            " [0.9959038 ]\n",
            " [0.9958912 ]\n",
            " [0.00625594]]\n",
            "Step: 5102 -> Loss: 0.004572215024381876 -> Predictions: [[0.00378485]\n",
            " [0.995904  ]\n",
            " [0.99589133]\n",
            " [0.00625564]]\n",
            "Step: 5103 -> Loss: 0.004571992438286543 -> Predictions: [[0.00378466]\n",
            " [0.99590415]\n",
            " [0.9958916 ]\n",
            " [0.00625534]]\n",
            "Step: 5104 -> Loss: 0.00457176985219121 -> Predictions: [[0.00378448]\n",
            " [0.9959044 ]\n",
            " [0.9958918 ]\n",
            " [0.00625502]]\n",
            "Step: 5105 -> Loss: 0.004571549594402313 -> Predictions: [[0.00378431]\n",
            " [0.9959046 ]\n",
            " [0.9958919 ]\n",
            " [0.00625472]]\n",
            "Step: 5106 -> Loss: 0.004571328405290842 -> Predictions: [[0.00378413]\n",
            " [0.99590474]\n",
            " [0.99589217]\n",
            " [0.00625441]]\n",
            "Step: 5107 -> Loss: 0.004571109544485807 -> Predictions: [[0.00378395]\n",
            " [0.995905  ]\n",
            " [0.9958924 ]\n",
            " [0.00625411]]\n",
            "Step: 5108 -> Loss: 0.0045708902180194855 -> Predictions: [[0.00378378]\n",
            " [0.99590516]\n",
            " [0.9958925 ]\n",
            " [0.0062538 ]]\n",
            "Step: 5109 -> Loss: 0.004570668563246727 -> Predictions: [[0.00378361]\n",
            " [0.9959053 ]\n",
            " [0.99589276]\n",
            " [0.00625349]]\n",
            "Step: 5110 -> Loss: 0.00457044830545783 -> Predictions: [[0.00378343]\n",
            " [0.9959055 ]\n",
            " [0.995893  ]\n",
            " [0.00625318]]\n",
            "Step: 5111 -> Loss: 0.004570227116346359 -> Predictions: [[0.00378325]\n",
            " [0.99590576]\n",
            " [0.9958931 ]\n",
            " [0.00625288]]\n",
            "Step: 5112 -> Loss: 0.004570004530251026 -> Predictions: [[0.00378307]\n",
            " [0.9959059 ]\n",
            " [0.99589336]\n",
            " [0.00625257]]\n",
            "Step: 5113 -> Loss: 0.004569784738123417 -> Predictions: [[0.0037829 ]\n",
            " [0.9959061 ]\n",
            " [0.9958936 ]\n",
            " [0.00625226]]\n",
            "Step: 5114 -> Loss: 0.004569564945995808 -> Predictions: [[0.00378271]\n",
            " [0.99590635]\n",
            " [0.9958937 ]\n",
            " [0.00625196]]\n",
            "Step: 5115 -> Loss: 0.004569345153868198 -> Predictions: [[0.00378254]\n",
            " [0.9959065 ]\n",
            " [0.99589396]\n",
            " [0.00625165]]\n",
            "Step: 5116 -> Loss: 0.004569123033434153 -> Predictions: [[0.00378236]\n",
            " [0.9959067 ]\n",
            " [0.9958942 ]\n",
            " [0.00625134]]\n",
            "Step: 5117 -> Loss: 0.004568904172629118 -> Predictions: [[0.00378219]\n",
            " [0.99590683]\n",
            " [0.9958943 ]\n",
            " [0.00625103]]\n",
            "Step: 5118 -> Loss: 0.004568682052195072 -> Predictions: [[0.00378201]\n",
            " [0.99590707]\n",
            " [0.99589455]\n",
            " [0.00625073]]\n",
            "Step: 5119 -> Loss: 0.004568461794406176 -> Predictions: [[0.00378183]\n",
            " [0.9959073 ]\n",
            " [0.9958948 ]\n",
            " [0.00625042]]\n",
            "Step: 5120 -> Loss: 0.004568242467939854 -> Predictions: [[0.00378166]\n",
            " [0.9959074 ]\n",
            " [0.9958949 ]\n",
            " [0.00625012]]\n",
            "Step: 5121 -> Loss: 0.004568018019199371 -> Predictions: [[0.00378148]\n",
            " [0.99590766]\n",
            " [0.99589515]\n",
            " [0.0062498 ]]\n",
            "Step: 5122 -> Loss: 0.004567801021039486 -> Predictions: [[0.0037813]\n",
            " [0.9959079]\n",
            " [0.9958954]\n",
            " [0.0062495]]\n",
            "Step: 5123 -> Loss: 0.004567577503621578 -> Predictions: [[0.00378112]\n",
            " [0.99590814]\n",
            " [0.9958955 ]\n",
            " [0.00624919]]\n",
            "Step: 5124 -> Loss: 0.004567359574139118 -> Predictions: [[0.00378095]\n",
            " [0.99590826]\n",
            " [0.99589574]\n",
            " [0.00624889]]\n",
            "Step: 5125 -> Loss: 0.004567139782011509 -> Predictions: [[0.00378077]\n",
            " [0.9959085 ]\n",
            " [0.995896  ]\n",
            " [0.00624858]]\n",
            "Step: 5126 -> Loss: 0.004566918592900038 -> Predictions: [[0.00378059]\n",
            " [0.9959086 ]\n",
            " [0.9958961 ]\n",
            " [0.00624828]]\n",
            "Step: 5127 -> Loss: 0.004566696006804705 -> Predictions: [[0.00378041]\n",
            " [0.99590886]\n",
            " [0.99589634]\n",
            " [0.00624796]]\n",
            "Step: 5128 -> Loss: 0.004566473886370659 -> Predictions: [[0.00378024]\n",
            " [0.9959091 ]\n",
            " [0.9958966 ]\n",
            " [0.00624766]]\n",
            "Step: 5129 -> Loss: 0.004566258285194635 -> Predictions: [[0.00378006]\n",
            " [0.9959092 ]\n",
            " [0.9958967 ]\n",
            " [0.00624736]]\n",
            "Step: 5130 -> Loss: 0.004566036630421877 -> Predictions: [[0.00377989]\n",
            " [0.99590945]\n",
            " [0.99589694]\n",
            " [0.00624705]]\n",
            "Step: 5131 -> Loss: 0.004565813113003969 -> Predictions: [[0.00377971]\n",
            " [0.9959097 ]\n",
            " [0.9958972 ]\n",
            " [0.00624673]]\n",
            "Step: 5132 -> Loss: 0.004565594717860222 -> Predictions: [[0.00377953]\n",
            " [0.9959098 ]\n",
            " [0.9958973 ]\n",
            " [0.00624643]]\n",
            "Step: 5133 -> Loss: 0.004565373994410038 -> Predictions: [[0.00377936]\n",
            " [0.99591005]\n",
            " [0.99589753]\n",
            " [0.00624612]]\n",
            "Step: 5134 -> Loss: 0.004565155599266291 -> Predictions: [[0.00377919]\n",
            " [0.9959103 ]\n",
            " [0.9958977 ]\n",
            " [0.00624582]]\n",
            "Step: 5135 -> Loss: 0.004564936738461256 -> Predictions: [[0.00377902]\n",
            " [0.9959104 ]\n",
            " [0.9958978 ]\n",
            " [0.00624552]]\n",
            "Step: 5136 -> Loss: 0.004564716946333647 -> Predictions: [[0.00377885]\n",
            " [0.99591064]\n",
            " [0.99589807]\n",
            " [0.0062452 ]]\n",
            "Step: 5137 -> Loss: 0.004564495757222176 -> Predictions: [[0.00377868]\n",
            " [0.9959109 ]\n",
            " [0.9958983 ]\n",
            " [0.00624489]]\n",
            "Step: 5138 -> Loss: 0.004564276896417141 -> Predictions: [[0.0037785 ]\n",
            " [0.995911  ]\n",
            " [0.9958984 ]\n",
            " [0.00624459]]\n",
            "Step: 5139 -> Loss: 0.004564058035612106 -> Predictions: [[0.00377833]\n",
            " [0.99591124]\n",
            " [0.99589866]\n",
            " [0.00624429]]\n",
            "Step: 5140 -> Loss: 0.004563838243484497 -> Predictions: [[0.00377816]\n",
            " [0.9959115 ]\n",
            " [0.9958989 ]\n",
            " [0.00624397]]\n",
            "Step: 5141 -> Loss: 0.0045636179856956005 -> Predictions: [[0.00377798]\n",
            " [0.9959116 ]\n",
            " [0.995899  ]\n",
            " [0.00624367]]\n",
            "Step: 5142 -> Loss: 0.004563400521874428 -> Predictions: [[0.00377781]\n",
            " [0.99591184]\n",
            " [0.99589926]\n",
            " [0.00624337]]\n",
            "Step: 5143 -> Loss: 0.004563179332762957 -> Predictions: [[0.00377763]\n",
            " [0.9959121 ]\n",
            " [0.9958995 ]\n",
            " [0.00624305]]\n",
            "Step: 5144 -> Loss: 0.004562957677990198 -> Predictions: [[0.00377746]\n",
            " [0.9959122 ]\n",
            " [0.9958996 ]\n",
            " [0.00624275]]\n",
            "Step: 5145 -> Loss: 0.0045627388171851635 -> Predictions: [[0.00377728]\n",
            " [0.9959124 ]\n",
            " [0.99589986]\n",
            " [0.00624244]]\n",
            "Step: 5146 -> Loss: 0.004562520422041416 -> Predictions: [[0.00377712]\n",
            " [0.9959126 ]\n",
            " [0.9959001 ]\n",
            " [0.00624213]]\n",
            "Step: 5147 -> Loss: 0.004562303889542818 -> Predictions: [[0.00377694]\n",
            " [0.99591273]\n",
            " [0.9959002 ]\n",
            " [0.00624183]]\n",
            "Step: 5148 -> Loss: 0.004562079906463623 -> Predictions: [[0.00377677]\n",
            " [0.99591297]\n",
            " [0.99590045]\n",
            " [0.00624151]]\n",
            "Step: 5149 -> Loss: 0.004561863373965025 -> Predictions: [[0.0037766 ]\n",
            " [0.9959132 ]\n",
            " [0.9959007 ]\n",
            " [0.00624122]]\n",
            "Step: 5150 -> Loss: 0.004561644047498703 -> Predictions: [[0.00377642]\n",
            " [0.9959133 ]\n",
            " [0.9959008 ]\n",
            " [0.00624091]]\n",
            "Step: 5151 -> Loss: 0.0045614223927259445 -> Predictions: [[0.00377625]\n",
            " [0.99591357]\n",
            " [0.99590105]\n",
            " [0.0062406 ]]\n",
            "Step: 5152 -> Loss: 0.004561203066259623 -> Predictions: [[0.00377607]\n",
            " [0.9959138 ]\n",
            " [0.9959013 ]\n",
            " [0.0062403 ]]\n",
            "Step: 5153 -> Loss: 0.004560986068099737 -> Predictions: [[0.0037759 ]\n",
            " [0.9959139 ]\n",
            " [0.9959014 ]\n",
            " [0.00623999]]\n",
            "Step: 5154 -> Loss: 0.004560768138617277 -> Predictions: [[0.00377573]\n",
            " [0.99591416]\n",
            " [0.99590164]\n",
            " [0.00623969]]\n",
            "Step: 5155 -> Loss: 0.004560546949505806 -> Predictions: [[0.00377556]\n",
            " [0.9959144 ]\n",
            " [0.9959019 ]\n",
            " [0.00623938]]\n",
            "Step: 5156 -> Loss: 0.00456032482907176 -> Predictions: [[0.00377538]\n",
            " [0.9959145 ]\n",
            " [0.9959021 ]\n",
            " [0.00623907]]\n",
            "Step: 5157 -> Loss: 0.004560104571282864 -> Predictions: [[0.00377521]\n",
            " [0.99591476]\n",
            " [0.99590224]\n",
            " [0.00623876]]\n",
            "Step: 5158 -> Loss: 0.004559887573122978 -> Predictions: [[0.00377504]\n",
            " [0.995915  ]\n",
            " [0.9959025 ]\n",
            " [0.00623846]]\n",
            "Step: 5159 -> Loss: 0.004559667780995369 -> Predictions: [[0.00377487]\n",
            " [0.9959151 ]\n",
            " [0.9959027 ]\n",
            " [0.00623815]]\n",
            "Step: 5160 -> Loss: 0.004559448454529047 -> Predictions: [[0.00377469]\n",
            " [0.99591535]\n",
            " [0.99590284]\n",
            " [0.00623784]]\n",
            "Step: 5161 -> Loss: 0.0045592281967401505 -> Predictions: [[0.00377452]\n",
            " [0.9959156 ]\n",
            " [0.9959031 ]\n",
            " [0.00623753]]\n",
            "Step: 5162 -> Loss: 0.004559009335935116 -> Predictions: [[0.00377435]\n",
            " [0.9959157 ]\n",
            " [0.9959033 ]\n",
            " [0.00623723]]\n",
            "Step: 5163 -> Loss: 0.0045587909407913685 -> Predictions: [[0.00377418]\n",
            " [0.99591595]\n",
            " [0.99590343]\n",
            " [0.00623693]]\n",
            "Step: 5164 -> Loss: 0.00455856928601861 -> Predictions: [[0.003774  ]\n",
            " [0.9959162 ]\n",
            " [0.9959037 ]\n",
            " [0.00623662]]\n",
            "Step: 5165 -> Loss: 0.004558353219181299 -> Predictions: [[0.00377383]\n",
            " [0.9959163 ]\n",
            " [0.9959039 ]\n",
            " [0.00623631]]\n",
            "Step: 5166 -> Loss: 0.004558131098747253 -> Predictions: [[0.00377365]\n",
            " [0.99591655]\n",
            " [0.995904  ]\n",
            " [0.006236  ]]\n",
            "Step: 5167 -> Loss: 0.00455791549757123 -> Predictions: [[0.00377349]\n",
            " [0.9959168 ]\n",
            " [0.99590427]\n",
            " [0.0062357 ]]\n",
            "Step: 5168 -> Loss: 0.004557693377137184 -> Predictions: [[0.00377331]\n",
            " [0.9959169 ]\n",
            " [0.9959045 ]\n",
            " [0.00623539]]\n",
            "Step: 5169 -> Loss: 0.004557475913316011 -> Predictions: [[0.00377314]\n",
            " [0.99591714]\n",
            " [0.9959046 ]\n",
            " [0.00623509]]\n",
            "Step: 5170 -> Loss: 0.0045572565868496895 -> Predictions: [[0.00377297]\n",
            " [0.9959174 ]\n",
            " [0.99590486]\n",
            " [0.00623478]]\n",
            "Step: 5171 -> Loss: 0.004557037726044655 -> Predictions: [[0.0037728 ]\n",
            " [0.9959175 ]\n",
            " [0.99590504]\n",
            " [0.00623447]]\n",
            "Step: 5172 -> Loss: 0.0045568146742880344 -> Predictions: [[0.00377261]\n",
            " [0.99591774]\n",
            " [0.99590516]\n",
            " [0.00623417]]\n",
            "Step: 5173 -> Loss: 0.004556596744805574 -> Predictions: [[0.00377244]\n",
            " [0.995918  ]\n",
            " [0.9959054 ]\n",
            " [0.00623386]]\n",
            "Step: 5174 -> Loss: 0.004556379280984402 -> Predictions: [[0.00377227]\n",
            " [0.9959181 ]\n",
            " [0.99590564]\n",
            " [0.00623356]]\n",
            "Step: 5175 -> Loss: 0.004556160420179367 -> Predictions: [[0.0037721 ]\n",
            " [0.99591833]\n",
            " [0.99590576]\n",
            " [0.00623325]]\n",
            "Step: 5176 -> Loss: 0.004555939696729183 -> Predictions: [[0.00377193]\n",
            " [0.9959186 ]\n",
            " [0.995906  ]\n",
            " [0.00623295]]\n",
            "Step: 5177 -> Loss: 0.004555720370262861 -> Predictions: [[0.00377175]\n",
            " [0.9959187 ]\n",
            " [0.99590623]\n",
            " [0.00623264]]\n",
            "Step: 5178 -> Loss: 0.0045555029064416885 -> Predictions: [[0.00377158]\n",
            " [0.9959189 ]\n",
            " [0.99590635]\n",
            " [0.00623234]]\n",
            "Step: 5179 -> Loss: 0.004555283114314079 -> Predictions: [[0.00377141]\n",
            " [0.99591917]\n",
            " [0.9959066 ]\n",
            " [0.00623202]]\n",
            "Step: 5180 -> Loss: 0.00455506332218647 -> Predictions: [[0.00377123]\n",
            " [0.9959193 ]\n",
            " [0.99590683]\n",
            " [0.00623172]]\n",
            "Step: 5181 -> Loss: 0.004554844461381435 -> Predictions: [[0.00377107]\n",
            " [0.99591947]\n",
            " [0.99590695]\n",
            " [0.00623141]]\n",
            "Step: 5182 -> Loss: 0.004554625600576401 -> Predictions: [[0.00377089]\n",
            " [0.9959197 ]\n",
            " [0.9959072 ]\n",
            " [0.00623111]]\n",
            "Step: 5183 -> Loss: 0.004554406739771366 -> Predictions: [[0.00377072]\n",
            " [0.9959198 ]\n",
            " [0.9959074 ]\n",
            " [0.0062308 ]]\n",
            "Step: 5184 -> Loss: 0.004554185084998608 -> Predictions: [[0.00377055]\n",
            " [0.99592006]\n",
            " [0.99590755]\n",
            " [0.00623049]]\n",
            "Step: 5185 -> Loss: 0.00455396668985486 -> Predictions: [[0.00377037]\n",
            " [0.9959202 ]\n",
            " [0.9959078 ]\n",
            " [0.00623019]]\n",
            "Step: 5186 -> Loss: 0.004553749226033688 -> Predictions: [[0.0037702 ]\n",
            " [0.9959204 ]\n",
            " [0.995908  ]\n",
            " [0.00622989]]\n",
            "Step: 5187 -> Loss: 0.004553530365228653 -> Predictions: [[0.00377003]\n",
            " [0.99592066]\n",
            " [0.99590814]\n",
            " [0.00622958]]\n",
            "Step: 5188 -> Loss: 0.004553311504423618 -> Predictions: [[0.00376986]\n",
            " [0.9959208 ]\n",
            " [0.9959084 ]\n",
            " [0.00622927]]\n",
            "Step: 5189 -> Loss: 0.0045530907809734344 -> Predictions: [[0.00376968]\n",
            " [0.995921  ]\n",
            " [0.9959086 ]\n",
            " [0.00622897]]\n",
            "Step: 5190 -> Loss: 0.004552872851490974 -> Predictions: [[0.00376951]\n",
            " [0.99592125]\n",
            " [0.99590874]\n",
            " [0.00622866]]\n",
            "Step: 5191 -> Loss: 0.00455265399068594 -> Predictions: [[0.00376934]\n",
            " [0.9959214 ]\n",
            " [0.995909  ]\n",
            " [0.00622835]]\n",
            "Step: 5192 -> Loss: 0.004552434664219618 -> Predictions: [[0.00376916]\n",
            " [0.9959216 ]\n",
            " [0.9959092 ]\n",
            " [0.00622805]]\n",
            "Step: 5193 -> Loss: 0.004552219063043594 -> Predictions: [[0.003769  ]\n",
            " [0.99592185]\n",
            " [0.99590933]\n",
            " [0.00622775]]\n",
            "Step: 5194 -> Loss: 0.004551999270915985 -> Predictions: [[0.00376882]\n",
            " [0.99592197]\n",
            " [0.9959096 ]\n",
            " [0.00622744]]\n",
            "Step: 5195 -> Loss: 0.004551777616143227 -> Predictions: [[0.00376865]\n",
            " [0.9959222 ]\n",
            " [0.9959098 ]\n",
            " [0.00622713]]\n",
            "Step: 5196 -> Loss: 0.004551559686660767 -> Predictions: [[0.00376847]\n",
            " [0.99592245]\n",
            " [0.9959099 ]\n",
            " [0.00622683]]\n",
            "Step: 5197 -> Loss: 0.004551340360194445 -> Predictions: [[0.0037683 ]\n",
            " [0.99592257]\n",
            " [0.99591017]\n",
            " [0.00622652]]\n",
            "Step: 5198 -> Loss: 0.004551123362034559 -> Predictions: [[0.00376813]\n",
            " [0.9959228 ]\n",
            " [0.9959104 ]\n",
            " [0.00622622]]\n",
            "Step: 5199 -> Loss: 0.004550902638584375 -> Predictions: [[0.00376796]\n",
            " [0.99592304]\n",
            " [0.9959105 ]\n",
            " [0.0062259 ]]\n",
            "Step: 5200 -> Loss: 0.004550685174763203 -> Predictions: [[0.00376779]\n",
            " [0.99592316]\n",
            " [0.99591076]\n",
            " [0.0062256 ]]\n",
            "Step: 5201 -> Loss: 0.004550466313958168 -> Predictions: [[0.00376762]\n",
            " [0.9959234 ]\n",
            " [0.995911  ]\n",
            " [0.0062253 ]]\n",
            "Step: 5202 -> Loss: 0.004550244193524122 -> Predictions: [[0.00376744]\n",
            " [0.99592364]\n",
            " [0.9959111 ]\n",
            " [0.00622499]]\n",
            "Step: 5203 -> Loss: 0.004550025332719088 -> Predictions: [[0.00376727]\n",
            " [0.99592376]\n",
            " [0.99591136]\n",
            " [0.00622468]]\n",
            "Step: 5204 -> Loss: 0.004549807403236628 -> Predictions: [[0.00376709]\n",
            " [0.995924  ]\n",
            " [0.9959116 ]\n",
            " [0.00622438]]\n",
            "Step: 5205 -> Loss: 0.004549588076770306 -> Predictions: [[0.00376692]\n",
            " [0.99592423]\n",
            " [0.9959117 ]\n",
            " [0.00622407]]\n",
            "Step: 5206 -> Loss: 0.004549368284642696 -> Predictions: [[0.00376675]\n",
            " [0.99592435]\n",
            " [0.99591196]\n",
            " [0.00622376]]\n",
            "Step: 5207 -> Loss: 0.0045491489581763744 -> Predictions: [[0.00376657]\n",
            " [0.9959246 ]\n",
            " [0.9959122 ]\n",
            " [0.00622346]]\n",
            "Step: 5208 -> Loss: 0.004548929166048765 -> Predictions: [[0.00376641]\n",
            " [0.99592483]\n",
            " [0.99591225]\n",
            " [0.00622315]]\n",
            "Step: 5209 -> Loss: 0.004548713564872742 -> Predictions: [[0.00376623]\n",
            " [0.99592495]\n",
            " [0.9959125 ]\n",
            " [0.00622285]]\n",
            "Step: 5210 -> Loss: 0.0045484937727451324 -> Predictions: [[0.00376606]\n",
            " [0.9959252 ]\n",
            " [0.99591273]\n",
            " [0.00622254]]\n",
            "Step: 5211 -> Loss: 0.0045482744462788105 -> Predictions: [[0.00376588]\n",
            " [0.9959254 ]\n",
            " [0.99591285]\n",
            " [0.00622224]]\n",
            "Step: 5212 -> Loss: 0.0045480565167963505 -> Predictions: [[0.00376572]\n",
            " [0.99592555]\n",
            " [0.9959131 ]\n",
            " [0.00622193]]\n",
            "Step: 5213 -> Loss: 0.0045478371903300285 -> Predictions: [[0.00376554]\n",
            " [0.9959258 ]\n",
            " [0.9959133 ]\n",
            " [0.00622162]]\n",
            "Step: 5214 -> Loss: 0.0045476206578314304 -> Predictions: [[0.00376537]\n",
            " [0.995926  ]\n",
            " [0.99591345]\n",
            " [0.00622132]]\n",
            "Step: 5215 -> Loss: 0.004547398537397385 -> Predictions: [[0.0037652 ]\n",
            " [0.99592614]\n",
            " [0.9959137 ]\n",
            " [0.00622101]]\n",
            "Step: 5216 -> Loss: 0.004547180607914925 -> Predictions: [[0.00376503]\n",
            " [0.9959264 ]\n",
            " [0.9959139 ]\n",
            " [0.00622071]]\n",
            "Step: 5217 -> Loss: 0.004546962212771177 -> Predictions: [[0.00376485]\n",
            " [0.9959266 ]\n",
            " [0.99591404]\n",
            " [0.0062204 ]]\n",
            "Step: 5218 -> Loss: 0.004546742420643568 -> Predictions: [[0.00376468]\n",
            " [0.99592674]\n",
            " [0.9959143 ]\n",
            " [0.00622009]]\n",
            "Step: 5219 -> Loss: 0.004546524025499821 -> Predictions: [[0.00376451]\n",
            " [0.9959269 ]\n",
            " [0.9959145 ]\n",
            " [0.00621979]]\n",
            "Step: 5220 -> Loss: 0.004546306096017361 -> Predictions: [[0.00376433]\n",
            " [0.99592704]\n",
            " [0.99591464]\n",
            " [0.00621949]]\n",
            "Step: 5221 -> Loss: 0.0045460863038897514 -> Predictions: [[0.00376416]\n",
            " [0.9959273 ]\n",
            " [0.9959149 ]\n",
            " [0.00621918]]\n",
            "Step: 5222 -> Loss: 0.0045458655804395676 -> Predictions: [[0.00376398]\n",
            " [0.9959275 ]\n",
            " [0.9959151 ]\n",
            " [0.00621888]]\n",
            "Step: 5223 -> Loss: 0.004545650444924831 -> Predictions: [[0.00376382]\n",
            " [0.99592763]\n",
            " [0.99591523]\n",
            " [0.00621857]]\n",
            "Step: 5224 -> Loss: 0.004545431584119797 -> Predictions: [[0.00376364]\n",
            " [0.9959279 ]\n",
            " [0.9959155 ]\n",
            " [0.00621827]]\n",
            "Step: 5225 -> Loss: 0.004545213188976049 -> Predictions: [[0.00376347]\n",
            " [0.9959281 ]\n",
            " [0.9959157 ]\n",
            " [0.00621796]]\n",
            "Step: 5226 -> Loss: 0.004544994328171015 -> Predictions: [[0.0037633 ]\n",
            " [0.9959282 ]\n",
            " [0.99591583]\n",
            " [0.00621766]]\n",
            "Step: 5227 -> Loss: 0.004544775001704693 -> Predictions: [[0.00376313]\n",
            " [0.99592847]\n",
            " [0.99591607]\n",
            " [0.00621735]]\n",
            "Step: 5228 -> Loss: 0.004544558934867382 -> Predictions: [[0.00376296]\n",
            " [0.9959287 ]\n",
            " [0.9959163 ]\n",
            " [0.00621705]]\n",
            "Step: 5229 -> Loss: 0.004544335883110762 -> Predictions: [[0.00376278]\n",
            " [0.9959288 ]\n",
            " [0.9959164 ]\n",
            " [0.00621674]]\n",
            "Step: 5230 -> Loss: 0.004544118884950876 -> Predictions: [[0.00376261]\n",
            " [0.99592906]\n",
            " [0.99591666]\n",
            " [0.00621643]]\n",
            "Step: 5231 -> Loss: 0.0045439014211297035 -> Predictions: [[0.00376244]\n",
            " [0.9959293 ]\n",
            " [0.9959169 ]\n",
            " [0.00621613]]\n",
            "Step: 5232 -> Loss: 0.004543683957308531 -> Predictions: [[0.00376227]\n",
            " [0.9959294 ]\n",
            " [0.995917  ]\n",
            " [0.00621583]]\n",
            "Step: 5233 -> Loss: 0.004543465096503496 -> Predictions: [[0.00376209]\n",
            " [0.99592966]\n",
            " [0.99591726]\n",
            " [0.00621551]]\n",
            "Step: 5234 -> Loss: 0.004543244373053312 -> Predictions: [[0.00376192]\n",
            " [0.9959299 ]\n",
            " [0.9959175 ]\n",
            " [0.00621521]]\n",
            "Step: 5235 -> Loss: 0.00454302690923214 -> Predictions: [[0.00376175]\n",
            " [0.99593   ]\n",
            " [0.9959176 ]\n",
            " [0.0062149 ]]\n",
            "Step: 5236 -> Loss: 0.004542809911072254 -> Predictions: [[0.00376158]\n",
            " [0.99593025]\n",
            " [0.99591786]\n",
            " [0.0062146 ]]\n",
            "Step: 5237 -> Loss: 0.004542588256299496 -> Predictions: [[0.0037614 ]\n",
            " [0.9959305 ]\n",
            " [0.9959181 ]\n",
            " [0.00621429]]\n",
            "Step: 5238 -> Loss: 0.004542369861155748 -> Predictions: [[0.00376123]\n",
            " [0.9959306 ]\n",
            " [0.9959182 ]\n",
            " [0.00621399]]\n",
            "Step: 5239 -> Loss: 0.004542150534689426 -> Predictions: [[0.00376106]\n",
            " [0.99593085]\n",
            " [0.99591845]\n",
            " [0.00621368]]\n",
            "Step: 5240 -> Loss: 0.004541936330497265 -> Predictions: [[0.00376089]\n",
            " [0.9959311 ]\n",
            " [0.9959187 ]\n",
            " [0.00621339]]\n",
            "Step: 5241 -> Loss: 0.0045417132787406445 -> Predictions: [[0.00376072]\n",
            " [0.9959312 ]\n",
            " [0.9959188 ]\n",
            " [0.00621307]]\n",
            "Step: 5242 -> Loss: 0.004541496746242046 -> Predictions: [[0.00376055]\n",
            " [0.99593145]\n",
            " [0.99591905]\n",
            " [0.00621277]]\n",
            "Step: 5243 -> Loss: 0.004541276954114437 -> Predictions: [[0.00376037]\n",
            " [0.9959317 ]\n",
            " [0.9959193 ]\n",
            " [0.00621247]]\n",
            "Step: 5244 -> Loss: 0.004541060887277126 -> Predictions: [[0.0037602 ]\n",
            " [0.9959318 ]\n",
            " [0.9959194 ]\n",
            " [0.00621217]]\n",
            "Step: 5245 -> Loss: 0.004540842957794666 -> Predictions: [[0.00376003]\n",
            " [0.99593204]\n",
            " [0.9959196 ]\n",
            " [0.00621187]]\n",
            "Step: 5246 -> Loss: 0.00454062270000577 -> Predictions: [[0.00375985]\n",
            " [0.9959323 ]\n",
            " [0.9959198 ]\n",
            " [0.00621155]]\n",
            "Step: 5247 -> Loss: 0.004540405236184597 -> Predictions: [[0.00375968]\n",
            " [0.9959324 ]\n",
            " [0.99591994]\n",
            " [0.00621124]]\n",
            "Step: 5248 -> Loss: 0.004540189169347286 -> Predictions: [[0.00375951]\n",
            " [0.99593264]\n",
            " [0.9959202 ]\n",
            " [0.00621094]]\n",
            "Step: 5249 -> Loss: 0.00453996891155839 -> Predictions: [[0.00375934]\n",
            " [0.99593276]\n",
            " [0.9959204 ]\n",
            " [0.00621063]]\n",
            "Step: 5250 -> Loss: 0.0045397537760436535 -> Predictions: [[0.00375916]\n",
            " [0.995933  ]\n",
            " [0.99592054]\n",
            " [0.00621033]]\n",
            "Step: 5251 -> Loss: 0.0045395344495773315 -> Predictions: [[0.00375899]\n",
            " [0.99593323]\n",
            " [0.9959208 ]\n",
            " [0.00621002]]\n",
            "Step: 5252 -> Loss: 0.004539317451417446 -> Predictions: [[0.00375882]\n",
            " [0.99593335]\n",
            " [0.9959209 ]\n",
            " [0.00620971]]\n",
            "Step: 5253 -> Loss: 0.0045390985906124115 -> Predictions: [[0.00375864]\n",
            " [0.9959336 ]\n",
            " [0.99592113]\n",
            " [0.00620941]]\n",
            "Step: 5254 -> Loss: 0.004538881126791239 -> Predictions: [[0.00375847]\n",
            " [0.99593383]\n",
            " [0.9959214 ]\n",
            " [0.0062091 ]]\n",
            "Step: 5255 -> Loss: 0.004538663662970066 -> Predictions: [[0.00375831]\n",
            " [0.99593395]\n",
            " [0.9959215 ]\n",
            " [0.00620879]]\n",
            "Step: 5256 -> Loss: 0.004538446199148893 -> Predictions: [[0.00375814]\n",
            " [0.9959341 ]\n",
            " [0.99592173]\n",
            " [0.00620849]]\n",
            "Step: 5257 -> Loss: 0.004538227804005146 -> Predictions: [[0.00375796]\n",
            " [0.99593437]\n",
            " [0.99592197]\n",
            " [0.00620818]]\n",
            "Step: 5258 -> Loss: 0.004538010805845261 -> Predictions: [[0.00375779]\n",
            " [0.9959345 ]\n",
            " [0.9959221 ]\n",
            " [0.00620787]]\n",
            "Step: 5259 -> Loss: 0.004537791479378939 -> Predictions: [[0.00375762]\n",
            " [0.9959347 ]\n",
            " [0.9959223 ]\n",
            " [0.00620756]]\n",
            "Step: 5260 -> Loss: 0.004537574946880341 -> Predictions: [[0.00375744]\n",
            " [0.99593496]\n",
            " [0.99592257]\n",
            " [0.00620726]]\n",
            "Step: 5261 -> Loss: 0.004537356551736593 -> Predictions: [[0.00375727]\n",
            " [0.9959351 ]\n",
            " [0.9959227 ]\n",
            " [0.00620695]]\n",
            "Step: 5262 -> Loss: 0.004537137225270271 -> Predictions: [[0.0037571 ]\n",
            " [0.9959353 ]\n",
            " [0.9959229 ]\n",
            " [0.00620664]]\n",
            "Step: 5263 -> Loss: 0.004536921624094248 -> Predictions: [[0.00375693]\n",
            " [0.99593544]\n",
            " [0.99592304]\n",
            " [0.00620634]]\n",
            "Step: 5264 -> Loss: 0.004536702297627926 -> Predictions: [[0.00375675]\n",
            " [0.9959357 ]\n",
            " [0.9959233 ]\n",
            " [0.00620603]]\n",
            "Step: 5265 -> Loss: 0.004536484368145466 -> Predictions: [[0.00375658]\n",
            " [0.9959359 ]\n",
            " [0.9959235 ]\n",
            " [0.00620572]]\n",
            "Step: 5266 -> Loss: 0.004536266438663006 -> Predictions: [[0.00375641]\n",
            " [0.99593604]\n",
            " [0.99592364]\n",
            " [0.00620542]]\n",
            "Step: 5267 -> Loss: 0.00453604944050312 -> Predictions: [[0.00375624]\n",
            " [0.9959363 ]\n",
            " [0.9959239 ]\n",
            " [0.00620511]]\n",
            "Step: 5268 -> Loss: 0.004535832442343235 -> Predictions: [[0.00375606]\n",
            " [0.9959365 ]\n",
            " [0.9959241 ]\n",
            " [0.00620481]]\n",
            "Step: 5269 -> Loss: 0.004535614047199488 -> Predictions: [[0.0037559 ]\n",
            " [0.99593663]\n",
            " [0.99592423]\n",
            " [0.0062045 ]]\n",
            "Step: 5270 -> Loss: 0.004535397980362177 -> Predictions: [[0.00375573]\n",
            " [0.9959369 ]\n",
            " [0.9959245 ]\n",
            " [0.0062042 ]]\n",
            "Step: 5271 -> Loss: 0.004535180516541004 -> Predictions: [[0.00375556]\n",
            " [0.9959371 ]\n",
            " [0.9959247 ]\n",
            " [0.00620389]]\n",
            "Step: 5272 -> Loss: 0.0045349630527198315 -> Predictions: [[0.00375539]\n",
            " [0.9959372 ]\n",
            " [0.99592483]\n",
            " [0.0062036 ]]\n",
            "Step: 5273 -> Loss: 0.004534744657576084 -> Predictions: [[0.00375522]\n",
            " [0.99593747]\n",
            " [0.99592507]\n",
            " [0.00620329]]\n",
            "Step: 5274 -> Loss: 0.004534528125077486 -> Predictions: [[0.00375505]\n",
            " [0.9959377 ]\n",
            " [0.9959253 ]\n",
            " [0.00620298]]\n",
            "Step: 5275 -> Loss: 0.004534309729933739 -> Predictions: [[0.00375488]\n",
            " [0.9959378 ]\n",
            " [0.9959254 ]\n",
            " [0.00620268]]\n",
            "Step: 5276 -> Loss: 0.004534096922725439 -> Predictions: [[0.00375471]\n",
            " [0.99593806]\n",
            " [0.99592566]\n",
            " [0.00620238]]\n",
            "Step: 5277 -> Loss: 0.004533877596259117 -> Predictions: [[0.00375453]\n",
            " [0.9959383 ]\n",
            " [0.9959259 ]\n",
            " [0.00620207]]\n",
            "Step: 5278 -> Loss: 0.004533658269792795 -> Predictions: [[0.00375436]\n",
            " [0.9959384 ]\n",
            " [0.995926  ]\n",
            " [0.00620177]]\n",
            "Step: 5279 -> Loss: 0.004533442668616772 -> Predictions: [[0.0037542 ]\n",
            " [0.99593866]\n",
            " [0.99592626]\n",
            " [0.00620147]]\n",
            "Step: 5280 -> Loss: 0.004533225670456886 -> Predictions: [[0.00375402]\n",
            " [0.9959389 ]\n",
            " [0.9959264 ]\n",
            " [0.00620117]]\n",
            "Step: 5281 -> Loss: 0.004533010069280863 -> Predictions: [[0.00375386]\n",
            " [0.995939  ]\n",
            " [0.9959266 ]\n",
            " [0.00620086]]\n",
            "Step: 5282 -> Loss: 0.0045327916741371155 -> Predictions: [[0.00375369]\n",
            " [0.99593925]\n",
            " [0.9959268 ]\n",
            " [0.00620055]]\n",
            "Step: 5283 -> Loss: 0.004532574210315943 -> Predictions: [[0.00375352]\n",
            " [0.9959395 ]\n",
            " [0.9959269 ]\n",
            " [0.00620025]]\n",
            "Step: 5284 -> Loss: 0.004532358143478632 -> Predictions: [[0.00375335]\n",
            " [0.9959396 ]\n",
            " [0.99592716]\n",
            " [0.00619996]]\n",
            "Step: 5285 -> Loss: 0.004532139282673597 -> Predictions: [[0.00375318]\n",
            " [0.99593985]\n",
            " [0.9959274 ]\n",
            " [0.00619964]]\n",
            "Step: 5286 -> Loss: 0.004531922750174999 -> Predictions: [[0.00375301]\n",
            " [0.99593997]\n",
            " [0.9959275 ]\n",
            " [0.00619934]]\n",
            "Step: 5287 -> Loss: 0.0045317066833376884 -> Predictions: [[0.00375284]\n",
            " [0.9959402 ]\n",
            " [0.99592775]\n",
            " [0.00619904]]\n",
            "Step: 5288 -> Loss: 0.0045314873568713665 -> Predictions: [[0.00375266]\n",
            " [0.99594045]\n",
            " [0.995928  ]\n",
            " [0.00619873]]\n",
            "Step: 5289 -> Loss: 0.0045312680304050446 -> Predictions: [[0.00375249]\n",
            " [0.99594057]\n",
            " [0.9959281 ]\n",
            " [0.00619843]]\n",
            "Step: 5290 -> Loss: 0.004531052894890308 -> Predictions: [[0.00375232]\n",
            " [0.9959408 ]\n",
            " [0.99592835]\n",
            " [0.00619813]]\n",
            "Step: 5291 -> Loss: 0.004530836828052998 -> Predictions: [[0.00375216]\n",
            " [0.99594104]\n",
            " [0.9959286 ]\n",
            " [0.00619783]]\n",
            "Step: 5292 -> Loss: 0.004530619364231825 -> Predictions: [[0.00375198]\n",
            " [0.99594116]\n",
            " [0.9959287 ]\n",
            " [0.00619753]]\n",
            "Step: 5293 -> Loss: 0.004530401434749365 -> Predictions: [[0.00375181]\n",
            " [0.99594134]\n",
            " [0.99592894]\n",
            " [0.00619722]]\n",
            "Step: 5294 -> Loss: 0.00453018955886364 -> Predictions: [[0.00375165]\n",
            " [0.9959416 ]\n",
            " [0.9959292 ]\n",
            " [0.00619693]]\n",
            "Step: 5295 -> Loss: 0.004529966972768307 -> Predictions: [[0.00375146]\n",
            " [0.9959417 ]\n",
            " [0.9959293 ]\n",
            " [0.00619662]]\n",
            "Step: 5296 -> Loss: 0.0045297532342374325 -> Predictions: [[0.0037513 ]\n",
            " [0.99594194]\n",
            " [0.99592954]\n",
            " [0.00619632]]\n",
            "Step: 5297 -> Loss: 0.0045295339077711105 -> Predictions: [[0.00375112]\n",
            " [0.9959422 ]\n",
            " [0.9959298 ]\n",
            " [0.00619601]]\n",
            "Step: 5298 -> Loss: 0.004529319703578949 -> Predictions: [[0.00375095]\n",
            " [0.9959423 ]\n",
            " [0.9959299 ]\n",
            " [0.00619571]]\n",
            "Step: 5299 -> Loss: 0.004529106430709362 -> Predictions: [[0.00375077]\n",
            " [0.99594253]\n",
            " [0.99593014]\n",
            " [0.00619542]]\n",
            "Step: 5300 -> Loss: 0.004528888501226902 -> Predictions: [[0.0037506 ]\n",
            " [0.99594265]\n",
            " [0.9959304 ]\n",
            " [0.00619512]]\n",
            "Step: 5301 -> Loss: 0.004528672434389591 -> Predictions: [[0.00375043]\n",
            " [0.9959429 ]\n",
            " [0.9959305 ]\n",
            " [0.00619481]]\n",
            "Step: 5302 -> Loss: 0.004528455901890993 -> Predictions: [[0.00375025]\n",
            " [0.9959431 ]\n",
            " [0.99593073]\n",
            " [0.00619451]]\n",
            "Step: 5303 -> Loss: 0.004528238903731108 -> Predictions: [[0.00375008]\n",
            " [0.99594325]\n",
            " [0.99593085]\n",
            " [0.00619421]]\n",
            "Step: 5304 -> Loss: 0.0045280237682163715 -> Predictions: [[0.00374991]\n",
            " [0.9959435 ]\n",
            " [0.9959311 ]\n",
            " [0.00619391]]\n",
            "Step: 5305 -> Loss: 0.0045278058387339115 -> Predictions: [[0.00374973]\n",
            " [0.9959437 ]\n",
            " [0.9959313 ]\n",
            " [0.0061936 ]]\n",
            "Step: 5306 -> Loss: 0.004527592100203037 -> Predictions: [[0.00374956]\n",
            " [0.99594384]\n",
            " [0.99593145]\n",
            " [0.0061933 ]]\n",
            "Step: 5307 -> Loss: 0.0045273760333657265 -> Predictions: [[0.00374939]\n",
            " [0.9959441 ]\n",
            " [0.9959317 ]\n",
            " [0.00619301]]\n",
            "Step: 5308 -> Loss: 0.00452716089785099 -> Predictions: [[0.00374921]\n",
            " [0.9959442 ]\n",
            " [0.9959319 ]\n",
            " [0.0061927 ]]\n",
            "Step: 5309 -> Loss: 0.004526940640062094 -> Predictions: [[0.00374904]\n",
            " [0.99594444]\n",
            " [0.99593204]\n",
            " [0.00619239]]\n",
            "Step: 5310 -> Loss: 0.004526729229837656 -> Predictions: [[0.00374887]\n",
            " [0.9959447 ]\n",
            " [0.9959323 ]\n",
            " [0.0061921 ]]\n",
            "Step: 5311 -> Loss: 0.004526511766016483 -> Predictions: [[0.0037487 ]\n",
            " [0.9959448 ]\n",
            " [0.9959324 ]\n",
            " [0.00619179]]\n",
            "Step: 5312 -> Loss: 0.004526298027485609 -> Predictions: [[0.00374852]\n",
            " [0.99594504]\n",
            " [0.99593264]\n",
            " [0.0061915 ]]\n",
            "Step: 5313 -> Loss: 0.004526079632341862 -> Predictions: [[0.00374835]\n",
            " [0.9959453 ]\n",
            " [0.9959329 ]\n",
            " [0.00619119]]\n",
            "Step: 5314 -> Loss: 0.004525866359472275 -> Predictions: [[0.00374817]\n",
            " [0.9959454 ]\n",
            " [0.995933  ]\n",
            " [0.0061909 ]]\n",
            "Step: 5315 -> Loss: 0.00452564749866724 -> Predictions: [[0.003748  ]\n",
            " [0.99594563]\n",
            " [0.99593323]\n",
            " [0.00619058]]\n",
            "Step: 5316 -> Loss: 0.004525432363152504 -> Predictions: [[0.00374783]\n",
            " [0.99594575]\n",
            " [0.9959335 ]\n",
            " [0.00619029]]\n",
            "Step: 5317 -> Loss: 0.004525218158960342 -> Predictions: [[0.00374766]\n",
            " [0.995946  ]\n",
            " [0.9959336 ]\n",
            " [0.00618999]]\n",
            "Step: 5318 -> Loss: 0.004525001160800457 -> Predictions: [[0.00374748]\n",
            " [0.9959462 ]\n",
            " [0.99593383]\n",
            " [0.00618968]]\n",
            "Step: 5319 -> Loss: 0.004524786025285721 -> Predictions: [[0.00374731]\n",
            " [0.99594635]\n",
            " [0.99593395]\n",
            " [0.00618938]]\n",
            "Step: 5320 -> Loss: 0.004524568095803261 -> Predictions: [[0.00374713]\n",
            " [0.9959466 ]\n",
            " [0.9959341 ]\n",
            " [0.00618908]]\n",
            "Step: 5321 -> Loss: 0.0045243543572723866 -> Predictions: [[0.00374696]\n",
            " [0.9959468 ]\n",
            " [0.99593437]\n",
            " [0.00618878]]\n",
            "Step: 5322 -> Loss: 0.004524138290435076 -> Predictions: [[0.00374678]\n",
            " [0.99594694]\n",
            " [0.9959345 ]\n",
            " [0.00618849]]\n",
            "Step: 5323 -> Loss: 0.004523920826613903 -> Predictions: [[0.00374661]\n",
            " [0.9959472 ]\n",
            " [0.9959347 ]\n",
            " [0.00618818]]\n",
            "Step: 5324 -> Loss: 0.004523703828454018 -> Predictions: [[0.00374644]\n",
            " [0.9959473 ]\n",
            " [0.99593496]\n",
            " [0.00618787]]\n",
            "Step: 5325 -> Loss: 0.004523489158600569 -> Predictions: [[0.00374626]\n",
            " [0.99594754]\n",
            " [0.9959351 ]\n",
            " [0.00618758]]\n",
            "Step: 5326 -> Loss: 0.004523274023085833 -> Predictions: [[0.00374609]\n",
            " [0.9959478 ]\n",
            " [0.9959353 ]\n",
            " [0.00618728]]\n",
            "Step: 5327 -> Loss: 0.0045230574905872345 -> Predictions: [[0.00374592]\n",
            " [0.9959479 ]\n",
            " [0.99593544]\n",
            " [0.00618696]]\n",
            "Step: 5328 -> Loss: 0.004522842355072498 -> Predictions: [[0.00374574]\n",
            " [0.99594814]\n",
            " [0.9959357 ]\n",
            " [0.00618667]]\n",
            "Step: 5329 -> Loss: 0.0045226258225739 -> Predictions: [[0.00374558]\n",
            " [0.9959484 ]\n",
            " [0.9959359 ]\n",
            " [0.00618637]]\n",
            "Step: 5330 -> Loss: 0.004522412549704313 -> Predictions: [[0.0037454 ]\n",
            " [0.9959485 ]\n",
            " [0.99593604]\n",
            " [0.00618607]]\n",
            "Step: 5331 -> Loss: 0.0045221950858831406 -> Predictions: [[0.00374522]\n",
            " [0.9959487 ]\n",
            " [0.9959363 ]\n",
            " [0.00618577]]\n",
            "Step: 5332 -> Loss: 0.004521979484707117 -> Predictions: [[0.00374505]\n",
            " [0.9959488 ]\n",
            " [0.9959365 ]\n",
            " [0.00618547]]\n",
            "Step: 5333 -> Loss: 0.0045217652805149555 -> Predictions: [[0.00374488]\n",
            " [0.99594903]\n",
            " [0.99593663]\n",
            " [0.00618516]]\n",
            "Step: 5334 -> Loss: 0.004521546419709921 -> Predictions: [[0.0037447 ]\n",
            " [0.99594927]\n",
            " [0.9959369 ]\n",
            " [0.00618487]]\n",
            "Step: 5335 -> Loss: 0.004521329887211323 -> Predictions: [[0.00374453]\n",
            " [0.9959494 ]\n",
            " [0.9959371 ]\n",
            " [0.00618456]]\n",
            "Step: 5336 -> Loss: 0.004521115217357874 -> Predictions: [[0.00374436]\n",
            " [0.9959496 ]\n",
            " [0.9959372 ]\n",
            " [0.00618426]]\n",
            "Step: 5337 -> Loss: 0.004520900547504425 -> Predictions: [[0.00374418]\n",
            " [0.99594975]\n",
            " [0.99593747]\n",
            " [0.00618396]]\n",
            "Step: 5338 -> Loss: 0.004520687274634838 -> Predictions: [[0.00374401]\n",
            " [0.99595   ]\n",
            " [0.9959376 ]\n",
            " [0.00618366]]\n",
            "Step: 5339 -> Loss: 0.004520468879491091 -> Predictions: [[0.00374384]\n",
            " [0.9959502 ]\n",
            " [0.9959378 ]\n",
            " [0.00618335]]\n",
            "Step: 5340 -> Loss: 0.0045202551409602165 -> Predictions: [[0.00374367]\n",
            " [0.99595034]\n",
            " [0.99593806]\n",
            " [0.00618306]]\n",
            "Step: 5341 -> Loss: 0.004520040471106768 -> Predictions: [[0.0037435 ]\n",
            " [0.9959506 ]\n",
            " [0.9959382 ]\n",
            " [0.00618276]]\n",
            "Step: 5342 -> Loss: 0.004519823007285595 -> Predictions: [[0.00374331]\n",
            " [0.9959508 ]\n",
            " [0.9959384 ]\n",
            " [0.00618246]]\n",
            "Step: 5343 -> Loss: 0.0045196074061095715 -> Predictions: [[0.00374315]\n",
            " [0.99595094]\n",
            " [0.99593866]\n",
            " [0.00618215]]\n",
            "Step: 5344 -> Loss: 0.004519392270594835 -> Predictions: [[0.00374297]\n",
            " [0.9959512 ]\n",
            " [0.9959388 ]\n",
            " [0.00618185]]\n",
            "Step: 5345 -> Loss: 0.004519175738096237 -> Predictions: [[0.0037428 ]\n",
            " [0.9959513 ]\n",
            " [0.995939  ]\n",
            " [0.00618155]]\n",
            "Step: 5346 -> Loss: 0.004518958739936352 -> Predictions: [[0.00374263]\n",
            " [0.99595153]\n",
            " [0.99593914]\n",
            " [0.00618125]]\n",
            "Step: 5347 -> Loss: 0.0045187450014054775 -> Predictions: [[0.00374246]\n",
            " [0.9959518 ]\n",
            " [0.9959394 ]\n",
            " [0.00618095]]\n",
            "Step: 5348 -> Loss: 0.004518527537584305 -> Predictions: [[0.00374228]\n",
            " [0.9959519 ]\n",
            " [0.9959396 ]\n",
            " [0.00618065]]\n",
            "Step: 5349 -> Loss: 0.004518313333392143 -> Predictions: [[0.0037421 ]\n",
            " [0.9959521 ]\n",
            " [0.99593973]\n",
            " [0.00618035]]\n",
            "Step: 5350 -> Loss: 0.004518096335232258 -> Predictions: [[0.00374193]\n",
            " [0.99595237]\n",
            " [0.99593997]\n",
            " [0.00618004]]\n",
            "Step: 5351 -> Loss: 0.004517882131040096 -> Predictions: [[0.00374176]\n",
            " [0.9959525 ]\n",
            " [0.9959402 ]\n",
            " [0.00617974]]\n",
            "Step: 5352 -> Loss: 0.00451766699552536 -> Predictions: [[0.00374159]\n",
            " [0.9959527 ]\n",
            " [0.9959403 ]\n",
            " [0.00617944]]\n",
            "Step: 5353 -> Loss: 0.0045174490660429 -> Predictions: [[0.00374141]\n",
            " [0.99595284]\n",
            " [0.99594057]\n",
            " [0.00617914]]\n",
            "Step: 5354 -> Loss: 0.004517234396189451 -> Predictions: [[0.00374124]\n",
            " [0.9959531 ]\n",
            " [0.9959407 ]\n",
            " [0.00617884]]\n",
            "Step: 5355 -> Loss: 0.00451701832935214 -> Predictions: [[0.00374106]\n",
            " [0.9959533 ]\n",
            " [0.9959409 ]\n",
            " [0.00617854]]\n",
            "Step: 5356 -> Loss: 0.004516804125159979 -> Predictions: [[0.00374089]\n",
            " [0.99595344]\n",
            " [0.99594116]\n",
            " [0.00617825]]\n",
            "Step: 5357 -> Loss: 0.0045165871270000935 -> Predictions: [[0.00374072]\n",
            " [0.9959537 ]\n",
            " [0.9959413 ]\n",
            " [0.00617794]]\n",
            "Step: 5358 -> Loss: 0.004516372457146645 -> Predictions: [[0.00374054]\n",
            " [0.9959539 ]\n",
            " [0.99594146]\n",
            " [0.00617764]]\n",
            "Step: 5359 -> Loss: 0.004516157787293196 -> Predictions: [[0.00374037]\n",
            " [0.99595404]\n",
            " [0.9959417 ]\n",
            " [0.00617734]]\n",
            "Step: 5360 -> Loss: 0.004515942186117172 -> Predictions: [[0.0037402 ]\n",
            " [0.9959543 ]\n",
            " [0.9959418 ]\n",
            " [0.00617704]]\n",
            "Step: 5361 -> Loss: 0.0045157261192798615 -> Predictions: [[0.00374003]\n",
            " [0.9959544 ]\n",
            " [0.99594206]\n",
            " [0.00617673]]\n",
            "Step: 5362 -> Loss: 0.0045155119150877 -> Predictions: [[0.00373985]\n",
            " [0.99595463]\n",
            " [0.9959422 ]\n",
            " [0.00617644]]\n",
            "Step: 5363 -> Loss: 0.004515291657298803 -> Predictions: [[0.00373968]\n",
            " [0.9959549 ]\n",
            " [0.9959424 ]\n",
            " [0.00617613]]\n",
            "Step: 5364 -> Loss: 0.004515080712735653 -> Predictions: [[0.00373951]\n",
            " [0.995955  ]\n",
            " [0.99594265]\n",
            " [0.00617583]]\n",
            "Step: 5365 -> Loss: 0.004514864180237055 -> Predictions: [[0.00373933]\n",
            " [0.9959552 ]\n",
            " [0.9959428 ]\n",
            " [0.00617553]]\n",
            "Step: 5366 -> Loss: 0.004514646250754595 -> Predictions: [[0.00373916]\n",
            " [0.99595535]\n",
            " [0.995943  ]\n",
            " [0.00617522]]\n",
            "Step: 5367 -> Loss: 0.0045144325122237206 -> Predictions: [[0.00373899]\n",
            " [0.9959556 ]\n",
            " [0.99594325]\n",
            " [0.00617493]]\n",
            "Step: 5368 -> Loss: 0.00451421644538641 -> Predictions: [[0.00373881]\n",
            " [0.9959558 ]\n",
            " [0.99594337]\n",
            " [0.00617463]]\n",
            "Step: 5369 -> Loss: 0.00451400363817811 -> Predictions: [[0.00373864]\n",
            " [0.9959559 ]\n",
            " [0.9959436 ]\n",
            " [0.00617433]]\n",
            "Step: 5370 -> Loss: 0.004513786174356937 -> Predictions: [[0.00373847]\n",
            " [0.9959561 ]\n",
            " [0.99594384]\n",
            " [0.00617403]]\n",
            "Step: 5371 -> Loss: 0.004513572435826063 -> Predictions: [[0.0037383 ]\n",
            " [0.99595636]\n",
            " [0.99594396]\n",
            " [0.00617373]]\n",
            "Step: 5372 -> Loss: 0.0045133596286177635 -> Predictions: [[0.00373813]\n",
            " [0.9959565 ]\n",
            " [0.9959442 ]\n",
            " [0.00617343]]\n",
            "Step: 5373 -> Loss: 0.004513140302151442 -> Predictions: [[0.00373795]\n",
            " [0.9959567 ]\n",
            " [0.9959443 ]\n",
            " [0.00617312]]\n",
            "Step: 5374 -> Loss: 0.004512925632297993 -> Predictions: [[0.00373777]\n",
            " [0.99595684]\n",
            " [0.99594456]\n",
            " [0.00617283]]\n",
            "Step: 5375 -> Loss: 0.004512710031121969 -> Predictions: [[0.0037376 ]\n",
            " [0.9959571 ]\n",
            " [0.9959448 ]\n",
            " [0.00617252]]\n",
            "Step: 5376 -> Loss: 0.00451249722391367 -> Predictions: [[0.00373744]\n",
            " [0.9959573 ]\n",
            " [0.9959449 ]\n",
            " [0.00617223]]\n",
            "Step: 5377 -> Loss: 0.004512281157076359 -> Predictions: [[0.00373727]\n",
            " [0.99595743]\n",
            " [0.99594516]\n",
            " [0.00617191]]\n",
            "Step: 5378 -> Loss: 0.004512066952884197 -> Predictions: [[0.00373709]\n",
            " [0.9959577 ]\n",
            " [0.9959453 ]\n",
            " [0.00617162]]\n",
            "Step: 5379 -> Loss: 0.004511854145675898 -> Predictions: [[0.00373693]\n",
            " [0.9959578 ]\n",
            " [0.9959455 ]\n",
            " [0.00617132]]\n",
            "Step: 5380 -> Loss: 0.004511640407145023 -> Predictions: [[0.00373676]\n",
            " [0.99595803]\n",
            " [0.99594575]\n",
            " [0.00617102]]\n",
            "Step: 5381 -> Loss: 0.004511423408985138 -> Predictions: [[0.00373659]\n",
            " [0.99595827]\n",
            " [0.9959459 ]\n",
            " [0.00617072]]\n",
            "Step: 5382 -> Loss: 0.004511210601776838 -> Predictions: [[0.00373642]\n",
            " [0.9959584 ]\n",
            " [0.9959461 ]\n",
            " [0.00617042]]\n",
            "Step: 5383 -> Loss: 0.004510993137955666 -> Predictions: [[0.00373625]\n",
            " [0.9959586 ]\n",
            " [0.99594635]\n",
            " [0.00617011]]\n",
            "Step: 5384 -> Loss: 0.004510783590376377 -> Predictions: [[0.00373608]\n",
            " [0.99595886]\n",
            " [0.99594647]\n",
            " [0.00616983]]\n",
            "Step: 5385 -> Loss: 0.004510566126555204 -> Predictions: [[0.00373591]\n",
            " [0.995959  ]\n",
            " [0.9959467 ]\n",
            " [0.00616952]]\n",
            "Step: 5386 -> Loss: 0.00451035238802433 -> Predictions: [[0.00373574]\n",
            " [0.9959592 ]\n",
            " [0.99594694]\n",
            " [0.00616922]]\n",
            "Step: 5387 -> Loss: 0.004510137252509594 -> Predictions: [[0.00373557]\n",
            " [0.99595934]\n",
            " [0.99594706]\n",
            " [0.00616891]]\n",
            "Step: 5388 -> Loss: 0.004509925842285156 -> Predictions: [[0.0037354 ]\n",
            " [0.9959596 ]\n",
            " [0.9959473 ]\n",
            " [0.00616862]]\n",
            "Step: 5389 -> Loss: 0.004509709309786558 -> Predictions: [[0.00373523]\n",
            " [0.9959598 ]\n",
            " [0.9959474 ]\n",
            " [0.00616831]]\n",
            "Step: 5390 -> Loss: 0.0045094965025782585 -> Predictions: [[0.00373506]\n",
            " [0.99595994]\n",
            " [0.99594766]\n",
            " [0.00616802]]\n",
            "Step: 5391 -> Loss: 0.004509282298386097 -> Predictions: [[0.0037349 ]\n",
            " [0.9959602 ]\n",
            " [0.9959479 ]\n",
            " [0.00616771]]\n",
            "Step: 5392 -> Loss: 0.004509067628532648 -> Predictions: [[0.00373472]\n",
            " [0.9959604 ]\n",
            " [0.995948  ]\n",
            " [0.00616742]]\n",
            "Step: 5393 -> Loss: 0.004508852027356625 -> Predictions: [[0.00373455]\n",
            " [0.99596053]\n",
            " [0.99594826]\n",
            " [0.00616712]]\n",
            "Step: 5394 -> Loss: 0.004508637823164463 -> Predictions: [[0.00373438]\n",
            " [0.9959608 ]\n",
            " [0.9959484 ]\n",
            " [0.00616681]]\n",
            "Step: 5395 -> Loss: 0.0045084236189723015 -> Predictions: [[0.00373421]\n",
            " [0.9959609 ]\n",
            " [0.9959486 ]\n",
            " [0.00616651]]\n",
            "Step: 5396 -> Loss: 0.0045082103461027145 -> Predictions: [[0.00373404]\n",
            " [0.9959611 ]\n",
            " [0.9959488 ]\n",
            " [0.00616622]]\n",
            "Step: 5397 -> Loss: 0.004507993347942829 -> Predictions: [[0.00373388]\n",
            " [0.99596137]\n",
            " [0.9959489 ]\n",
            " [0.00616591]]\n",
            "Step: 5398 -> Loss: 0.004507781937718391 -> Predictions: [[0.00373371]\n",
            " [0.9959615 ]\n",
            " [0.99594915]\n",
            " [0.00616561]]\n",
            "Step: 5399 -> Loss: 0.004507564939558506 -> Predictions: [[0.00373353]\n",
            " [0.9959617 ]\n",
            " [0.9959494 ]\n",
            " [0.00616531]]\n",
            "Step: 5400 -> Loss: 0.004507353529334068 -> Predictions: [[0.00373337]\n",
            " [0.99596184]\n",
            " [0.9959495 ]\n",
            " [0.00616501]]\n",
            "Step: 5401 -> Loss: 0.004507140256464481 -> Predictions: [[0.0037332 ]\n",
            " [0.9959621 ]\n",
            " [0.99594975]\n",
            " [0.00616472]]\n",
            "Step: 5402 -> Loss: 0.0045069241896271706 -> Predictions: [[0.00373303]\n",
            " [0.9959623 ]\n",
            " [0.99595   ]\n",
            " [0.00616441]]\n",
            "Step: 5403 -> Loss: 0.004506709054112434 -> Predictions: [[0.00373286]\n",
            " [0.99596244]\n",
            " [0.9959501 ]\n",
            " [0.0061641 ]]\n",
            "Step: 5404 -> Loss: 0.0045064957812428474 -> Predictions: [[0.00373269]\n",
            " [0.9959627 ]\n",
            " [0.99595034]\n",
            " [0.00616382]]\n",
            "Step: 5405 -> Loss: 0.004506278317421675 -> Predictions: [[0.00373252]\n",
            " [0.9959629 ]\n",
            " [0.99595046]\n",
            " [0.00616351]]\n",
            "Step: 5406 -> Loss: 0.004506066907197237 -> Predictions: [[0.00373235]\n",
            " [0.99596304]\n",
            " [0.9959507 ]\n",
            " [0.00616321]]\n",
            "Step: 5407 -> Loss: 0.004505849909037352 -> Predictions: [[0.00373218]\n",
            " [0.9959632 ]\n",
            " [0.99595094]\n",
            " [0.00616291]]\n",
            "Step: 5408 -> Loss: 0.004505637101829052 -> Predictions: [[0.00373201]\n",
            " [0.99596334]\n",
            " [0.99595106]\n",
            " [0.00616261]]\n",
            "Step: 5409 -> Loss: 0.004505426622927189 -> Predictions: [[0.00373185]\n",
            " [0.9959636 ]\n",
            " [0.9959513 ]\n",
            " [0.00616231]]\n",
            "Step: 5410 -> Loss: 0.004505208693444729 -> Predictions: [[0.00373167]\n",
            " [0.9959638 ]\n",
            " [0.99595153]\n",
            " [0.00616201]]\n",
            "Step: 5411 -> Loss: 0.0045049963518977165 -> Predictions: [[0.0037315 ]\n",
            " [0.99596393]\n",
            " [0.99595165]\n",
            " [0.00616171]]\n",
            "Step: 5412 -> Loss: 0.00450478307902813 -> Predictions: [[0.00373134]\n",
            " [0.99596417]\n",
            " [0.9959519 ]\n",
            " [0.00616141]]\n",
            "Step: 5413 -> Loss: 0.004504567012190819 -> Predictions: [[0.00373117]\n",
            " [0.9959643 ]\n",
            " [0.995952  ]\n",
            " [0.0061611 ]]\n",
            "Step: 5414 -> Loss: 0.0045043546706438065 -> Predictions: [[0.00373099]\n",
            " [0.9959645 ]\n",
            " [0.99595225]\n",
            " [0.00616081]]\n",
            "Step: 5415 -> Loss: 0.004504140932112932 -> Predictions: [[0.00373083]\n",
            " [0.99596477]\n",
            " [0.9959525 ]\n",
            " [0.00616051]]\n",
            "Step: 5416 -> Loss: 0.004503926262259483 -> Predictions: [[0.00373066]\n",
            " [0.9959649 ]\n",
            " [0.9959526 ]\n",
            " [0.00616021]]\n",
            "Step: 5417 -> Loss: 0.004503712989389896 -> Predictions: [[0.00373049]\n",
            " [0.9959651 ]\n",
            " [0.99595284]\n",
            " [0.00615991]]\n",
            "Step: 5418 -> Loss: 0.004503501113504171 -> Predictions: [[0.00373032]\n",
            " [0.99596536]\n",
            " [0.99595296]\n",
            " [0.00615962]]\n",
            "Step: 5419 -> Loss: 0.004503285512328148 -> Predictions: [[0.00373016]\n",
            " [0.9959655 ]\n",
            " [0.9959532 ]\n",
            " [0.00615931]]\n",
            "Step: 5420 -> Loss: 0.004503069911152124 -> Predictions: [[0.00372999]\n",
            " [0.9959657 ]\n",
            " [0.99595344]\n",
            " [0.00615901]]\n",
            "Step: 5421 -> Loss: 0.004502857569605112 -> Predictions: [[0.00372982]\n",
            " [0.99596584]\n",
            " [0.99595356]\n",
            " [0.00615871]]\n",
            "Step: 5422 -> Loss: 0.004502640105783939 -> Predictions: [[0.00372964]\n",
            " [0.9959661 ]\n",
            " [0.9959538 ]\n",
            " [0.00615841]]\n",
            "Step: 5423 -> Loss: 0.004502426832914352 -> Predictions: [[0.00372947]\n",
            " [0.9959663 ]\n",
            " [0.99595404]\n",
            " [0.00615811]]\n",
            "Step: 5424 -> Loss: 0.004502215888351202 -> Predictions: [[0.0037293 ]\n",
            " [0.99596643]\n",
            " [0.99595416]\n",
            " [0.00615782]]\n",
            "Step: 5425 -> Loss: 0.004501999355852604 -> Predictions: [[0.00372913]\n",
            " [0.9959667 ]\n",
            " [0.9959544 ]\n",
            " [0.00615751]]\n",
            "Step: 5426 -> Loss: 0.004501787479966879 -> Predictions: [[0.00372896]\n",
            " [0.9959668 ]\n",
            " [0.9959545 ]\n",
            " [0.00615722]]\n",
            "Step: 5427 -> Loss: 0.004501572344452143 -> Predictions: [[0.00372879]\n",
            " [0.99596703]\n",
            " [0.99595475]\n",
            " [0.00615691]]\n",
            "Step: 5428 -> Loss: 0.0045013572089374065 -> Predictions: [[0.00372862]\n",
            " [0.99596727]\n",
            " [0.995955  ]\n",
            " [0.00615661]]\n",
            "Step: 5429 -> Loss: 0.004501143470406532 -> Predictions: [[0.00372846]\n",
            " [0.9959674 ]\n",
            " [0.9959551 ]\n",
            " [0.00615631]]\n",
            "Step: 5430 -> Loss: 0.004500929731875658 -> Predictions: [[0.00372829]\n",
            " [0.9959676 ]\n",
            " [0.99595535]\n",
            " [0.00615601]]\n",
            "Step: 5431 -> Loss: 0.004500717855989933 -> Predictions: [[0.00372812]\n",
            " [0.99596786]\n",
            " [0.9959556 ]\n",
            " [0.00615572]]\n",
            "Step: 5432 -> Loss: 0.004500502720475197 -> Predictions: [[0.00372795]\n",
            " [0.995968  ]\n",
            " [0.9959557 ]\n",
            " [0.00615542]]\n",
            "Step: 5433 -> Loss: 0.004500287584960461 -> Predictions: [[0.00372778]\n",
            " [0.9959682 ]\n",
            " [0.9959559 ]\n",
            " [0.00615511]]\n",
            "Step: 5434 -> Loss: 0.004500075243413448 -> Predictions: [[0.00372761]\n",
            " [0.99596834]\n",
            " [0.995956  ]\n",
            " [0.00615481]]\n",
            "Step: 5435 -> Loss: 0.004499860107898712 -> Predictions: [[0.00372744]\n",
            " [0.9959686 ]\n",
            " [0.99595624]\n",
            " [0.00615452]]\n",
            "Step: 5436 -> Loss: 0.004499646835029125 -> Predictions: [[0.00372727]\n",
            " [0.9959688 ]\n",
            " [0.9959565 ]\n",
            " [0.00615421]]\n",
            "Step: 5437 -> Loss: 0.004499433562159538 -> Predictions: [[0.00372711]\n",
            " [0.99596894]\n",
            " [0.9959566 ]\n",
            " [0.00615392]]\n",
            "Step: 5438 -> Loss: 0.004499221220612526 -> Predictions: [[0.00372694]\n",
            " [0.9959692 ]\n",
            " [0.99595684]\n",
            " [0.00615361]]\n",
            "Step: 5439 -> Loss: 0.004499007016420364 -> Predictions: [[0.00372677]\n",
            " [0.9959693 ]\n",
            " [0.99595696]\n",
            " [0.00615331]]\n",
            "Step: 5440 -> Loss: 0.004498790949583054 -> Predictions: [[0.0037266 ]\n",
            " [0.99596953]\n",
            " [0.9959572 ]\n",
            " [0.00615302]]\n",
            "Step: 5441 -> Loss: 0.004498578142374754 -> Predictions: [[0.00372643]\n",
            " [0.9959698 ]\n",
            " [0.99595743]\n",
            " [0.00615271]]\n",
            "Step: 5442 -> Loss: 0.00449836440384388 -> Predictions: [[0.00372626]\n",
            " [0.9959699 ]\n",
            " [0.99595755]\n",
            " [0.00615242]]\n",
            "Step: 5443 -> Loss: 0.004498150199651718 -> Predictions: [[0.00372609]\n",
            " [0.99597013]\n",
            " [0.9959578 ]\n",
            " [0.00615211]]\n",
            "Step: 5444 -> Loss: 0.004497936926782131 -> Predictions: [[0.00372592]\n",
            " [0.99597037]\n",
            " [0.99595803]\n",
            " [0.00615182]]\n",
            "Step: 5445 -> Loss: 0.00449772085994482 -> Predictions: [[0.00372575]\n",
            " [0.9959705 ]\n",
            " [0.99595815]\n",
            " [0.00615151]]\n",
            "Step: 5446 -> Loss: 0.004497508052736521 -> Predictions: [[0.00372558]\n",
            " [0.99597067]\n",
            " [0.9959584 ]\n",
            " [0.00615122]]\n",
            "Step: 5447 -> Loss: 0.004497293848544359 -> Predictions: [[0.00372541]\n",
            " [0.9959708 ]\n",
            " [0.9959585 ]\n",
            " [0.00615092]]\n",
            "Step: 5448 -> Loss: 0.004497080575674772 -> Predictions: [[0.00372524]\n",
            " [0.995971  ]\n",
            " [0.99595875]\n",
            " [0.00615062]]\n",
            "Step: 5449 -> Loss: 0.004496865905821323 -> Predictions: [[0.00372507]\n",
            " [0.99597126]\n",
            " [0.995959  ]\n",
            " [0.00615031]]\n",
            "Step: 5450 -> Loss: 0.004496654495596886 -> Predictions: [[0.00372491]\n",
            " [0.9959714 ]\n",
            " [0.9959591 ]\n",
            " [0.00615002]]\n",
            "Step: 5451 -> Loss: 0.004496440757066011 -> Predictions: [[0.00372474]\n",
            " [0.9959716 ]\n",
            " [0.99595934]\n",
            " [0.00614972]]\n",
            "Step: 5452 -> Loss: 0.004496225155889988 -> Predictions: [[0.00372457]\n",
            " [0.99597174]\n",
            " [0.9959596 ]\n",
            " [0.00614942]]\n",
            "Step: 5453 -> Loss: 0.004496010486036539 -> Predictions: [[0.0037244 ]\n",
            " [0.995972  ]\n",
            " [0.9959597 ]\n",
            " [0.00614912]]\n",
            "Step: 5454 -> Loss: 0.004495800472795963 -> Predictions: [[0.00372423]\n",
            " [0.9959722 ]\n",
            " [0.99595994]\n",
            " [0.00614882]]\n",
            "Step: 5455 -> Loss: 0.004495583940297365 -> Predictions: [[0.00372406]\n",
            " [0.99597234]\n",
            " [0.99596006]\n",
            " [0.00614852]]\n",
            "Step: 5456 -> Loss: 0.004495371598750353 -> Predictions: [[0.00372389]\n",
            " [0.9959726 ]\n",
            " [0.9959603 ]\n",
            " [0.00614822]]\n",
            "Step: 5457 -> Loss: 0.004495158791542053 -> Predictions: [[0.00372373]\n",
            " [0.9959727 ]\n",
            " [0.99596053]\n",
            " [0.00614792]]\n",
            "Step: 5458 -> Loss: 0.004494944587349892 -> Predictions: [[0.00372356]\n",
            " [0.99597293]\n",
            " [0.99596065]\n",
            " [0.00614762]]\n",
            "Step: 5459 -> Loss: 0.004494728520512581 -> Predictions: [[0.00372339]\n",
            " [0.99597317]\n",
            " [0.9959609 ]\n",
            " [0.00614732]]\n",
            "Step: 5460 -> Loss: 0.004494517110288143 -> Predictions: [[0.00372321]\n",
            " [0.9959733 ]\n",
            " [0.9959611 ]\n",
            " [0.00614703]]\n",
            "Step: 5461 -> Loss: 0.004494303837418556 -> Predictions: [[0.00372305]\n",
            " [0.9959735 ]\n",
            " [0.99596125]\n",
            " [0.00614672]]\n",
            "Step: 5462 -> Loss: 0.004494090098887682 -> Predictions: [[0.00372288]\n",
            " [0.99597377]\n",
            " [0.9959615 ]\n",
            " [0.00614643]]\n",
            "Step: 5463 -> Loss: 0.004493875429034233 -> Predictions: [[0.00372271]\n",
            " [0.9959739 ]\n",
            " [0.9959616 ]\n",
            " [0.00614612]]\n",
            "Step: 5464 -> Loss: 0.004493665881454945 -> Predictions: [[0.00372254]\n",
            " [0.9959741 ]\n",
            " [0.99596184]\n",
            " [0.00614583]]\n",
            "Step: 5465 -> Loss: 0.004493451211601496 -> Predictions: [[0.00372237]\n",
            " [0.99597424]\n",
            " [0.9959621 ]\n",
            " [0.00614553]]\n",
            "Step: 5466 -> Loss: 0.004493236541748047 -> Predictions: [[0.0037222 ]\n",
            " [0.9959745 ]\n",
            " [0.9959622 ]\n",
            " [0.00614523]]\n",
            "Step: 5467 -> Loss: 0.004493019077926874 -> Predictions: [[0.00372203]\n",
            " [0.9959747 ]\n",
            " [0.99596244]\n",
            " [0.00614492]]\n",
            "Step: 5468 -> Loss: 0.004492807202041149 -> Predictions: [[0.00372186]\n",
            " [0.99597484]\n",
            " [0.9959627 ]\n",
            " [0.00614463]]\n",
            "Step: 5469 -> Loss: 0.004492593463510275 -> Predictions: [[0.0037217 ]\n",
            " [0.9959751 ]\n",
            " [0.9959628 ]\n",
            " [0.00614433]]\n",
            "Step: 5470 -> Loss: 0.00449238158762455 -> Predictions: [[0.00372153]\n",
            " [0.9959752 ]\n",
            " [0.99596304]\n",
            " [0.00614403]]\n",
            "Step: 5471 -> Loss: 0.004492166452109814 -> Predictions: [[0.00372136]\n",
            " [0.99597543]\n",
            " [0.99596316]\n",
            " [0.00614373]]\n",
            "Step: 5472 -> Loss: 0.004491955507546663 -> Predictions: [[0.00372119]\n",
            " [0.9959757 ]\n",
            " [0.99596334]\n",
            " [0.00614343]]\n",
            "Step: 5473 -> Loss: 0.004491738975048065 -> Predictions: [[0.00372102]\n",
            " [0.9959758 ]\n",
            " [0.9959636 ]\n",
            " [0.00614313]]\n",
            "Step: 5474 -> Loss: 0.004491530824452639 -> Predictions: [[0.00372085]\n",
            " [0.99597603]\n",
            " [0.9959637 ]\n",
            " [0.00614284]]\n",
            "Step: 5475 -> Loss: 0.004491311497986317 -> Predictions: [[0.00372068]\n",
            " [0.99597615]\n",
            " [0.99596393]\n",
            " [0.00614253]]\n",
            "Step: 5476 -> Loss: 0.0044911024160683155 -> Predictions: [[0.00372052]\n",
            " [0.9959764 ]\n",
            " [0.99596405]\n",
            " [0.00614224]]\n",
            "Step: 5477 -> Loss: 0.004490886814892292 -> Predictions: [[0.00372035]\n",
            " [0.9959766 ]\n",
            " [0.9959643 ]\n",
            " [0.00614194]]\n",
            "Step: 5478 -> Loss: 0.004490675404667854 -> Predictions: [[0.00372018]\n",
            " [0.99597675]\n",
            " [0.9959645 ]\n",
            " [0.00614164]]\n",
            "Step: 5479 -> Loss: 0.004490457940846682 -> Predictions: [[0.00372001]\n",
            " [0.995977  ]\n",
            " [0.99596465]\n",
            " [0.00614133]]\n",
            "Step: 5480 -> Loss: 0.004490246530622244 -> Predictions: [[0.00371984]\n",
            " [0.9959772 ]\n",
            " [0.9959649 ]\n",
            " [0.00614104]]\n",
            "Step: 5481 -> Loss: 0.004490031860768795 -> Predictions: [[0.00371967]\n",
            " [0.99597734]\n",
            " [0.9959651 ]\n",
            " [0.00614074]]\n",
            "Step: 5482 -> Loss: 0.0044898176565766335 -> Predictions: [[0.0037195 ]\n",
            " [0.9959776 ]\n",
            " [0.99596524]\n",
            " [0.00614043]]\n",
            "Step: 5483 -> Loss: 0.004489605780690908 -> Predictions: [[0.00371933]\n",
            " [0.9959777 ]\n",
            " [0.9959655 ]\n",
            " [0.00614014]]\n",
            "Step: 5484 -> Loss: 0.004489392973482609 -> Predictions: [[0.00371917]\n",
            " [0.99597794]\n",
            " [0.9959656 ]\n",
            " [0.00613984]]\n",
            "Step: 5485 -> Loss: 0.004489179700613022 -> Predictions: [[0.003719  ]\n",
            " [0.9959781 ]\n",
            " [0.99596584]\n",
            " [0.00613954]]\n",
            "Step: 5486 -> Loss: 0.00448896549642086 -> Predictions: [[0.00371882]\n",
            " [0.99597824]\n",
            " [0.9959661 ]\n",
            " [0.00613924]]\n",
            "Step: 5487 -> Loss: 0.004488750826567411 -> Predictions: [[0.00371866]\n",
            " [0.9959785 ]\n",
            " [0.9959662 ]\n",
            " [0.00613894]]\n",
            "Step: 5488 -> Loss: 0.004488540813326836 -> Predictions: [[0.00371849]\n",
            " [0.9959786 ]\n",
            " [0.99596643]\n",
            " [0.00613865]]\n",
            "Step: 5489 -> Loss: 0.004488327074795961 -> Predictions: [[0.00371832]\n",
            " [0.99597883]\n",
            " [0.9959667 ]\n",
            " [0.00613835]]\n",
            "Step: 5490 -> Loss: 0.004488116595894098 -> Predictions: [[0.00371816]\n",
            " [0.9959791 ]\n",
            " [0.9959668 ]\n",
            " [0.00613806]]\n",
            "Step: 5491 -> Loss: 0.004487898200750351 -> Predictions: [[0.00371799]\n",
            " [0.9959792 ]\n",
            " [0.99596703]\n",
            " [0.00613776]]\n",
            "Step: 5492 -> Loss: 0.004487689584493637 -> Predictions: [[0.00371783]\n",
            " [0.9959794 ]\n",
            " [0.99596715]\n",
            " [0.00613747]]\n",
            "Step: 5493 -> Loss: 0.004487473517656326 -> Predictions: [[0.00371766]\n",
            " [0.99597967]\n",
            " [0.9959674 ]\n",
            " [0.00613717]]\n",
            "Step: 5494 -> Loss: 0.004487263038754463 -> Predictions: [[0.00371749]\n",
            " [0.9959798 ]\n",
            " [0.9959676 ]\n",
            " [0.00613688]]\n",
            "Step: 5495 -> Loss: 0.00448704743757844 -> Predictions: [[0.00371732]\n",
            " [0.99598   ]\n",
            " [0.99596775]\n",
            " [0.00613658]]\n",
            "Step: 5496 -> Loss: 0.00448683463037014 -> Predictions: [[0.00371715]\n",
            " [0.99598014]\n",
            " [0.995968  ]\n",
            " [0.00613628]]\n",
            "Step: 5497 -> Loss: 0.004486622288823128 -> Predictions: [[0.00371699]\n",
            " [0.9959804 ]\n",
            " [0.9959682 ]\n",
            " [0.00613599]]\n",
            "Step: 5498 -> Loss: 0.004486408084630966 -> Predictions: [[0.00371682]\n",
            " [0.9959806 ]\n",
            " [0.99596834]\n",
            " [0.00613569]]\n",
            "Step: 5499 -> Loss: 0.004486195743083954 -> Predictions: [[0.00371666]\n",
            " [0.99598074]\n",
            " [0.9959686 ]\n",
            " [0.00613539]]\n",
            "Step: 5501 -> Loss: 0.004485767800360918 -> Predictions: [[0.00371632]\n",
            " [0.9959812 ]\n",
            " [0.99596894]\n",
            " [0.0061348 ]]\n",
            "Step: 5502 -> Loss: 0.0044855535961687565 -> Predictions: [[0.00371615]\n",
            " [0.99598134]\n",
            " [0.9959692 ]\n",
            " [0.0061345 ]]\n",
            "Step: 5503 -> Loss: 0.004485344514250755 -> Predictions: [[0.00371599]\n",
            " [0.9959816 ]\n",
            " [0.9959693 ]\n",
            " [0.00613421]]\n",
            "Step: 5504 -> Loss: 0.004485130775719881 -> Predictions: [[0.00371582]\n",
            " [0.9959817 ]\n",
            " [0.99596953]\n",
            " [0.00613391]]\n",
            "Step: 5505 -> Loss: 0.004484915640205145 -> Predictions: [[0.00371565]\n",
            " [0.99598193]\n",
            " [0.9959698 ]\n",
            " [0.00613361]]\n",
            "Step: 5506 -> Loss: 0.00448470376431942 -> Predictions: [[0.00371549]\n",
            " [0.99598217]\n",
            " [0.9959699 ]\n",
            " [0.00613332]]\n",
            "Step: 5507 -> Loss: 0.0044844914227724075 -> Predictions: [[0.00371532]\n",
            " [0.9959823 ]\n",
            " [0.99597013]\n",
            " [0.00613302]]\n",
            "Step: 5508 -> Loss: 0.0044842795468866825 -> Predictions: [[0.00371515]\n",
            " [0.9959825 ]\n",
            " [0.99597037]\n",
            " [0.00613274]]\n",
            "Step: 5509 -> Loss: 0.004484065808355808 -> Predictions: [[0.00371498]\n",
            " [0.99598277]\n",
            " [0.9959705 ]\n",
            " [0.00613243]]\n",
            "Step: 5510 -> Loss: 0.004483855329453945 -> Predictions: [[0.00371482]\n",
            " [0.9959829 ]\n",
            " [0.99597067]\n",
            " [0.00613214]]\n",
            "Step: 5511 -> Loss: 0.004483638796955347 -> Predictions: [[0.00371465]\n",
            " [0.9959831 ]\n",
            " [0.9959708 ]\n",
            " [0.00613184]]\n",
            "Step: 5512 -> Loss: 0.004483425989747047 -> Predictions: [[0.00371449]\n",
            " [0.99598336]\n",
            " [0.995971  ]\n",
            " [0.00613155]]\n",
            "Step: 5513 -> Loss: 0.0044832127168774605 -> Predictions: [[0.00371432]\n",
            " [0.9959835 ]\n",
            " [0.99597126]\n",
            " [0.00613125]]\n",
            "Step: 5514 -> Loss: 0.004482999909669161 -> Predictions: [[0.00371415]\n",
            " [0.9959837 ]\n",
            " [0.9959714 ]\n",
            " [0.00613096]]\n",
            "Step: 5515 -> Loss: 0.004482786636799574 -> Predictions: [[0.00371398]\n",
            " [0.99598384]\n",
            " [0.9959716 ]\n",
            " [0.00613066]]\n",
            "Step: 5516 -> Loss: 0.004482576623558998 -> Predictions: [[0.00371382]\n",
            " [0.9959841 ]\n",
            " [0.99597186]\n",
            " [0.00613037]]\n",
            "Step: 5517 -> Loss: 0.0044823624193668365 -> Predictions: [[0.00371365]\n",
            " [0.9959843 ]\n",
            " [0.995972  ]\n",
            " [0.00613007]]\n",
            "Step: 5518 -> Loss: 0.004482149612158537 -> Predictions: [[0.00371349]\n",
            " [0.99598444]\n",
            " [0.9959722 ]\n",
            " [0.00612977]]\n",
            "Step: 5519 -> Loss: 0.004481934010982513 -> Predictions: [[0.00371332]\n",
            " [0.9959847 ]\n",
            " [0.99597245]\n",
            " [0.00612947]]\n",
            "Step: 5520 -> Loss: 0.004481723066419363 -> Predictions: [[0.00371315]\n",
            " [0.9959848 ]\n",
            " [0.9959726 ]\n",
            " [0.00612918]]\n",
            "Step: 5521 -> Loss: 0.004481513053178787 -> Predictions: [[0.00371299]\n",
            " [0.99598503]\n",
            " [0.9959728 ]\n",
            " [0.00612889]]\n",
            "Step: 5522 -> Loss: 0.004481297917664051 -> Predictions: [[0.00371282]\n",
            " [0.99598527]\n",
            " [0.99597293]\n",
            " [0.00612859]]\n",
            "Step: 5523 -> Loss: 0.004481082782149315 -> Predictions: [[0.00371265]\n",
            " [0.9959853 ]\n",
            " [0.99597317]\n",
            " [0.00612829]]\n",
            "Step: 5524 -> Loss: 0.004480874165892601 -> Predictions: [[0.00371249]\n",
            " [0.99598557]\n",
            " [0.9959734 ]\n",
            " [0.006128  ]]\n",
            "Step: 5525 -> Loss: 0.00448065809905529 -> Predictions: [[0.00371232]\n",
            " [0.9959858 ]\n",
            " [0.9959735 ]\n",
            " [0.0061277 ]]\n",
            "Step: 5526 -> Loss: 0.004480449017137289 -> Predictions: [[0.00371216]\n",
            " [0.9959859 ]\n",
            " [0.99597377]\n",
            " [0.00612741]]\n",
            "Step: 5527 -> Loss: 0.00448023434728384 -> Predictions: [[0.00371199]\n",
            " [0.99598616]\n",
            " [0.995974  ]\n",
            " [0.00612711]]\n",
            "Step: 5528 -> Loss: 0.0044800229370594025 -> Predictions: [[0.00371182]\n",
            " [0.9959863 ]\n",
            " [0.9959741 ]\n",
            " [0.00612682]]\n",
            "Step: 5529 -> Loss: 0.004479808732867241 -> Predictions: [[0.00371166]\n",
            " [0.9959865 ]\n",
            " [0.99597436]\n",
            " [0.00612652]]\n",
            "Step: 5530 -> Loss: 0.004479598719626665 -> Predictions: [[0.00371149]\n",
            " [0.99598676]\n",
            " [0.9959745 ]\n",
            " [0.00612623]]\n",
            "Step: 5531 -> Loss: 0.004479384049773216 -> Predictions: [[0.00371132]\n",
            " [0.9959869 ]\n",
            " [0.9959747 ]\n",
            " [0.00612593]]\n",
            "Step: 5532 -> Loss: 0.004479173570871353 -> Predictions: [[0.00371115]\n",
            " [0.9959871 ]\n",
            " [0.99597496]\n",
            " [0.00612563]]\n",
            "Step: 5533 -> Loss: 0.004478960298001766 -> Predictions: [[0.00371098]\n",
            " [0.99598724]\n",
            " [0.9959751 ]\n",
            " [0.00612534]]\n",
            "Step: 5534 -> Loss: 0.004478750750422478 -> Predictions: [[0.00371081]\n",
            " [0.9959875 ]\n",
            " [0.9959753 ]\n",
            " [0.00612504]]\n",
            "Step: 5535 -> Loss: 0.0044785356149077415 -> Predictions: [[0.00371063]\n",
            " [0.9959877 ]\n",
            " [0.99597543]\n",
            " [0.00612474]]\n",
            "Step: 5536 -> Loss: 0.00447832653298974 -> Predictions: [[0.00371047]\n",
            " [0.99598783]\n",
            " [0.9959757 ]\n",
            " [0.00612446]]\n",
            "Step: 5537 -> Loss: 0.00447811046615243 -> Predictions: [[0.0037103 ]\n",
            " [0.9959881 ]\n",
            " [0.9959759 ]\n",
            " [0.00612414]]\n",
            "Step: 5538 -> Loss: 0.004477901384234428 -> Predictions: [[0.00371012]\n",
            " [0.9959882 ]\n",
            " [0.99597603]\n",
            " [0.00612386]]\n",
            "Step: 5539 -> Loss: 0.004477688577026129 -> Predictions: [[0.00370996]\n",
            " [0.9959884 ]\n",
            " [0.99597627]\n",
            " [0.00612355]]\n",
            "Step: 5540 -> Loss: 0.004477477632462978 -> Predictions: [[0.00370979]\n",
            " [0.99598867]\n",
            " [0.9959764 ]\n",
            " [0.00612326]]\n",
            "Step: 5541 -> Loss: 0.004477263428270817 -> Predictions: [[0.00370962]\n",
            " [0.9959888 ]\n",
            " [0.9959766 ]\n",
            " [0.00612297]]\n",
            "Step: 5542 -> Loss: 0.0044770571403205395 -> Predictions: [[0.00370945]\n",
            " [0.995989  ]\n",
            " [0.99597687]\n",
            " [0.00612268]]\n",
            "Step: 5543 -> Loss: 0.004476843401789665 -> Predictions: [[0.00370928]\n",
            " [0.99598914]\n",
            " [0.995977  ]\n",
            " [0.00612238]]\n",
            "Step: 5544 -> Loss: 0.00447663152590394 -> Predictions: [[0.00370911]\n",
            " [0.9959894 ]\n",
            " [0.9959772 ]\n",
            " [0.00612209]]\n",
            "Step: 5545 -> Loss: 0.0044764187186956406 -> Predictions: [[0.00370894]\n",
            " [0.9959896 ]\n",
            " [0.99597734]\n",
            " [0.00612178]]\n",
            "Step: 5546 -> Loss: 0.004476208705455065 -> Predictions: [[0.00370877]\n",
            " [0.99598974]\n",
            " [0.9959776 ]\n",
            " [0.00612149]]\n",
            "Step: 5547 -> Loss: 0.004475995432585478 -> Predictions: [[0.0037086 ]\n",
            " [0.99599   ]\n",
            " [0.9959778 ]\n",
            " [0.00612119]]\n",
            "Step: 5548 -> Loss: 0.004475786816328764 -> Predictions: [[0.00370844]\n",
            " [0.9959901 ]\n",
            " [0.99597794]\n",
            " [0.0061209 ]]\n",
            "Step: 5549 -> Loss: 0.004475576803088188 -> Predictions: [[0.00370827]\n",
            " [0.99599034]\n",
            " [0.9959781 ]\n",
            " [0.00612061]]\n",
            "Step: 5550 -> Loss: 0.004475364461541176 -> Predictions: [[0.00370809]\n",
            " [0.9959906 ]\n",
            " [0.99597824]\n",
            " [0.00612032]]\n",
            "Step: 5551 -> Loss: 0.004475148394703865 -> Predictions: [[0.00370793]\n",
            " [0.9959907 ]\n",
            " [0.9959785 ]\n",
            " [0.00612001]]\n",
            "Step: 5552 -> Loss: 0.004474937915802002 -> Predictions: [[0.00370775]\n",
            " [0.99599093]\n",
            " [0.9959787 ]\n",
            " [0.00611972]]\n",
            "Step: 5553 -> Loss: 0.004474725108593702 -> Predictions: [[0.00370758]\n",
            " [0.99599105]\n",
            " [0.99597883]\n",
            " [0.00611942]]\n",
            "Step: 5554 -> Loss: 0.004474514629691839 -> Predictions: [[0.00370742]\n",
            " [0.9959913 ]\n",
            " [0.9959791 ]\n",
            " [0.00611913]]\n",
            "Step: 5555 -> Loss: 0.004474302753806114 -> Predictions: [[0.00370725]\n",
            " [0.9959915 ]\n",
            " [0.9959792 ]\n",
            " [0.00611883]]\n",
            "Step: 5556 -> Loss: 0.004474091809242964 -> Predictions: [[0.00370708]\n",
            " [0.99599165]\n",
            " [0.9959794 ]\n",
            " [0.00611854]]\n",
            "Step: 5557 -> Loss: 0.004473880399018526 -> Predictions: [[0.00370691]\n",
            " [0.9959919 ]\n",
            " [0.99597967]\n",
            " [0.00611824]]\n",
            "Step: 5558 -> Loss: 0.00447367038577795 -> Predictions: [[0.00370674]\n",
            " [0.995992  ]\n",
            " [0.9959798 ]\n",
            " [0.00611795]]\n",
            "Step: 5559 -> Loss: 0.004473457578569651 -> Predictions: [[0.00370657]\n",
            " [0.99599224]\n",
            " [0.99598   ]\n",
            " [0.00611766]]\n",
            "Step: 5560 -> Loss: 0.004473246168345213 -> Predictions: [[0.0037064 ]\n",
            " [0.9959925 ]\n",
            " [0.99598014]\n",
            " [0.00611737]]\n",
            "Step: 5561 -> Loss: 0.004473034758120775 -> Predictions: [[0.00370623]\n",
            " [0.9959926 ]\n",
            " [0.9959804 ]\n",
            " [0.00611707]]\n",
            "Step: 5562 -> Loss: 0.004472823813557625 -> Predictions: [[0.00370606]\n",
            " [0.9959928 ]\n",
            " [0.9959806 ]\n",
            " [0.00611678]]\n",
            "Step: 5563 -> Loss: 0.004472614731639624 -> Predictions: [[0.00370589]\n",
            " [0.9959929 ]\n",
            " [0.99598074]\n",
            " [0.00611649]]\n",
            "Step: 5564 -> Loss: 0.004472401458770037 -> Predictions: [[0.00370572]\n",
            " [0.99599314]\n",
            " [0.995981  ]\n",
            " [0.00611619]]\n",
            "Step: 5565 -> Loss: 0.004472190514206886 -> Predictions: [[0.00370555]\n",
            " [0.9959934 ]\n",
            " [0.9959811 ]\n",
            " [0.0061159 ]]\n",
            "Step: 5566 -> Loss: 0.004471979569643736 -> Predictions: [[0.00370539]\n",
            " [0.9959935 ]\n",
            " [0.99598134]\n",
            " [0.0061156 ]]\n",
            "Step: 5567 -> Loss: 0.004471766762435436 -> Predictions: [[0.00370521]\n",
            " [0.99599373]\n",
            " [0.9959816 ]\n",
            " [0.00611531]]\n",
            "Step: 5568 -> Loss: 0.004471556283533573 -> Predictions: [[0.00370505]\n",
            " [0.99599385]\n",
            " [0.9959817 ]\n",
            " [0.00611502]]\n",
            "Step: 5569 -> Loss: 0.004471343941986561 -> Predictions: [[0.00370487]\n",
            " [0.9959941 ]\n",
            " [0.99598193]\n",
            " [0.00611472]]\n",
            "Step: 5570 -> Loss: 0.004471135325729847 -> Predictions: [[0.00370471]\n",
            " [0.9959943 ]\n",
            " [0.99598205]\n",
            " [0.00611443]]\n",
            "Step: 5571 -> Loss: 0.004470923449844122 -> Predictions: [[0.00370454]\n",
            " [0.99599445]\n",
            " [0.9959823 ]\n",
            " [0.00611413]]\n",
            "Step: 5572 -> Loss: 0.0044707125052809715 -> Predictions: [[0.00370437]\n",
            " [0.9959947 ]\n",
            " [0.9959825 ]\n",
            " [0.00611385]]\n",
            "Step: 5573 -> Loss: 0.004470499232411385 -> Predictions: [[0.0037042 ]\n",
            " [0.9959948 ]\n",
            " [0.99598265]\n",
            " [0.00611355]]\n",
            "Step: 5574 -> Loss: 0.004470289219170809 -> Predictions: [[0.00370403]\n",
            " [0.99599504]\n",
            " [0.9959829 ]\n",
            " [0.00611326]]\n",
            "Step: 5575 -> Loss: 0.004470076411962509 -> Predictions: [[0.00370386]\n",
            " [0.9959953 ]\n",
            " [0.995983  ]\n",
            " [0.00611297]]\n",
            "Step: 5576 -> Loss: 0.004469867330044508 -> Predictions: [[0.00370369]\n",
            " [0.9959954 ]\n",
            " [0.99598324]\n",
            " [0.00611268]]\n",
            "Step: 5577 -> Loss: 0.004469654522836208 -> Predictions: [[0.00370352]\n",
            " [0.99599564]\n",
            " [0.9959835 ]\n",
            " [0.00611238]]\n",
            "Step: 5578 -> Loss: 0.004469443112611771 -> Predictions: [[0.00370335]\n",
            " [0.99599576]\n",
            " [0.9959836 ]\n",
            " [0.00611208]]\n",
            "Step: 5579 -> Loss: 0.0044692340306937695 -> Predictions: [[0.00370318]\n",
            " [0.995996  ]\n",
            " [0.99598384]\n",
            " [0.00611179]]\n",
            "Step: 5580 -> Loss: 0.004469020292162895 -> Predictions: [[0.00370301]\n",
            " [0.99599624]\n",
            " [0.99598396]\n",
            " [0.0061115 ]]\n",
            "Step: 5581 -> Loss: 0.004468810278922319 -> Predictions: [[0.00370284]\n",
            " [0.99599636]\n",
            " [0.9959842 ]\n",
            " [0.0061112 ]]\n",
            "Step: 5582 -> Loss: 0.004468600265681744 -> Predictions: [[0.00370267]\n",
            " [0.9959966 ]\n",
            " [0.99598444]\n",
            " [0.00611092]]\n",
            "Step: 5583 -> Loss: 0.004468387924134731 -> Predictions: [[0.0037025 ]\n",
            " [0.9959967 ]\n",
            " [0.99598455]\n",
            " [0.00611062]]\n",
            "Step: 5584 -> Loss: 0.004468176513910294 -> Predictions: [[0.00370233]\n",
            " [0.99599695]\n",
            " [0.9959848 ]\n",
            " [0.00611033]]\n",
            "Step: 5585 -> Loss: 0.004467966966331005 -> Predictions: [[0.00370217]\n",
            " [0.9959972 ]\n",
            " [0.9959849 ]\n",
            " [0.00611003]]\n",
            "Step: 5586 -> Loss: 0.004467754624783993 -> Predictions: [[0.00370199]\n",
            " [0.9959973 ]\n",
            " [0.99598515]\n",
            " [0.00610974]]\n",
            "Step: 5587 -> Loss: 0.004467544611543417 -> Predictions: [[0.00370183]\n",
            " [0.99599755]\n",
            " [0.9959853 ]\n",
            " [0.00610945]]\n",
            "Step: 5588 -> Loss: 0.004467330873012543 -> Predictions: [[0.00370166]\n",
            " [0.99599767]\n",
            " [0.99598545]\n",
            " [0.00610915]]\n",
            "Step: 5589 -> Loss: 0.0044671217910945415 -> Predictions: [[0.00370149]\n",
            " [0.9959979 ]\n",
            " [0.9959857 ]\n",
            " [0.00610886]]\n",
            "Step: 5590 -> Loss: 0.0044669099152088165 -> Predictions: [[0.00370132]\n",
            " [0.99599814]\n",
            " [0.9959858 ]\n",
            " [0.00610857]]\n",
            "Step: 5591 -> Loss: 0.004466702230274677 -> Predictions: [[0.00370115]\n",
            " [0.99599826]\n",
            " [0.99598604]\n",
            " [0.00610828]]\n",
            "Step: 5592 -> Loss: 0.004466488026082516 -> Predictions: [[0.00370098]\n",
            " [0.9959985 ]\n",
            " [0.9959863 ]\n",
            " [0.00610797]]\n",
            "Step: 5593 -> Loss: 0.004466277547180653 -> Predictions: [[0.00370081]\n",
            " [0.9959986 ]\n",
            " [0.9959864 ]\n",
            " [0.00610768]]\n",
            "Step: 5594 -> Loss: 0.004466065671294928 -> Predictions: [[0.00370064]\n",
            " [0.99599886]\n",
            " [0.99598664]\n",
            " [0.0061074 ]]\n",
            "Step: 5595 -> Loss: 0.004465855658054352 -> Predictions: [[0.00370047]\n",
            " [0.9959991 ]\n",
            " [0.99598676]\n",
            " [0.0061071 ]]\n",
            "Step: 5596 -> Loss: 0.004465642385184765 -> Predictions: [[0.0037003]\n",
            " [0.9959992]\n",
            " [0.995987 ]\n",
            " [0.0061068]]\n",
            "Step: 5597 -> Loss: 0.004465433768928051 -> Predictions: [[0.00370014]\n",
            " [0.99599946]\n",
            " [0.99598724]\n",
            " [0.00610652]]\n",
            "Step: 5598 -> Loss: 0.004465221427381039 -> Predictions: [[0.00369997]\n",
            " [0.9959996 ]\n",
            " [0.99598736]\n",
            " [0.00610622]]\n",
            "Step: 5599 -> Loss: 0.00446501187980175 -> Predictions: [[0.00369979]\n",
            " [0.9959998 ]\n",
            " [0.9959876 ]\n",
            " [0.00610593]]\n",
            "Step: 5600 -> Loss: 0.004464799538254738 -> Predictions: [[0.00369963]\n",
            " [0.99599993]\n",
            " [0.9959877 ]\n",
            " [0.00610563]]\n",
            "Step: 5601 -> Loss: 0.004464590456336737 -> Predictions: [[0.00369946]\n",
            " [0.9960001 ]\n",
            " [0.99598795]\n",
            " [0.00610534]]\n",
            "Step: 5602 -> Loss: 0.004464377649128437 -> Predictions: [[0.00369929]\n",
            " [0.99600035]\n",
            " [0.9959882 ]\n",
            " [0.00610505]]\n",
            "Step: 5603 -> Loss: 0.004464165307581425 -> Predictions: [[0.00369912]\n",
            " [0.99600047]\n",
            " [0.9959883 ]\n",
            " [0.00610475]]\n",
            "Step: 5604 -> Loss: 0.004463954828679562 -> Predictions: [[0.00369895]\n",
            " [0.9960007 ]\n",
            " [0.99598855]\n",
            " [0.00610446]]\n",
            "Step: 5605 -> Loss: 0.004463745281100273 -> Predictions: [[0.00369878]\n",
            " [0.99600095]\n",
            " [0.99598867]\n",
            " [0.00610417]]\n",
            "Step: 5606 -> Loss: 0.00446353480219841 -> Predictions: [[0.00369861]\n",
            " [0.99600106]\n",
            " [0.9959889 ]\n",
            " [0.00610388]]\n",
            "Step: 5607 -> Loss: 0.00446332385763526 -> Predictions: [[0.00369844]\n",
            " [0.9960013 ]\n",
            " [0.995989  ]\n",
            " [0.00610359]]\n",
            "Step: 5608 -> Loss: 0.004463113844394684 -> Predictions: [[0.00369827]\n",
            " [0.9960014 ]\n",
            " [0.99598926]\n",
            " [0.0061033 ]]\n",
            "Step: 5609 -> Loss: 0.00446290010586381 -> Predictions: [[0.0036981 ]\n",
            " [0.99600166]\n",
            " [0.9959895 ]\n",
            " [0.00610299]]\n",
            "Step: 5610 -> Loss: 0.0044626896269619465 -> Predictions: [[0.00369793]\n",
            " [0.9960018 ]\n",
            " [0.9959896 ]\n",
            " [0.00610271]]\n",
            "Step: 5611 -> Loss: 0.004462478682398796 -> Predictions: [[0.00369776]\n",
            " [0.996002  ]\n",
            " [0.99598986]\n",
            " [0.00610242]]\n",
            "Step: 5612 -> Loss: 0.004462268203496933 -> Predictions: [[0.00369759]\n",
            " [0.99600226]\n",
            " [0.9959901 ]\n",
            " [0.00610212]]\n",
            "Step: 5613 -> Loss: 0.004462059587240219 -> Predictions: [[0.00369742]\n",
            " [0.9960024 ]\n",
            " [0.9959902 ]\n",
            " [0.00610184]]\n",
            "Step: 5614 -> Loss: 0.004461847711354494 -> Predictions: [[0.00369726]\n",
            " [0.9960026 ]\n",
            " [0.99599046]\n",
            " [0.00610155]]\n",
            "Step: 5615 -> Loss: 0.004461637698113918 -> Predictions: [[0.00369709]\n",
            " [0.99600285]\n",
            " [0.9959906 ]\n",
            " [0.00610126]]\n",
            "Step: 5616 -> Loss: 0.004461425822228193 -> Predictions: [[0.00369692]\n",
            " [0.996003  ]\n",
            " [0.9959908 ]\n",
            " [0.00610096]]\n",
            "Step: 5617 -> Loss: 0.0044612158089876175 -> Predictions: [[0.00369675]\n",
            " [0.9960032 ]\n",
            " [0.99599105]\n",
            " [0.00610067]]\n",
            "Step: 5618 -> Loss: 0.004461005795747042 -> Predictions: [[0.00369658]\n",
            " [0.9960033 ]\n",
            " [0.9959912 ]\n",
            " [0.00610038]]\n",
            "Step: 5619 -> Loss: 0.004460794385522604 -> Predictions: [[0.00369641]\n",
            " [0.99600357]\n",
            " [0.9959914 ]\n",
            " [0.00610009]]\n",
            "Step: 5620 -> Loss: 0.004460584372282028 -> Predictions: [[0.00369624]\n",
            " [0.9960037 ]\n",
            " [0.9959915 ]\n",
            " [0.0060998 ]]\n",
            "Step: 5621 -> Loss: 0.004460375290364027 -> Predictions: [[0.00369607]\n",
            " [0.9960039 ]\n",
            " [0.99599177]\n",
            " [0.00609951]]\n",
            "Step: 5622 -> Loss: 0.004460162948817015 -> Predictions: [[0.0036959 ]\n",
            " [0.99600416]\n",
            " [0.995992  ]\n",
            " [0.00609922]]\n",
            "Step: 5623 -> Loss: 0.004459952935576439 -> Predictions: [[0.00369573]\n",
            " [0.9960043 ]\n",
            " [0.9959921 ]\n",
            " [0.00609892]]\n",
            "Step: 5624 -> Loss: 0.004459740594029427 -> Predictions: [[0.00369557]\n",
            " [0.9960045 ]\n",
            " [0.99599236]\n",
            " [0.00609863]]\n",
            "Step: 5625 -> Loss: 0.0044595301151275635 -> Predictions: [[0.00369539]\n",
            " [0.99600464]\n",
            " [0.9959925 ]\n",
            " [0.00609834]]\n",
            "Step: 5626 -> Loss: 0.004459322430193424 -> Predictions: [[0.00369524]\n",
            " [0.9960049 ]\n",
            " [0.9959927 ]\n",
            " [0.00609805]]\n",
            "Step: 5627 -> Loss: 0.00445911381393671 -> Predictions: [[0.00369507]\n",
            " [0.9960051 ]\n",
            " [0.9959929 ]\n",
            " [0.00609777]]\n",
            "Step: 5628 -> Loss: 0.004458904266357422 -> Predictions: [[0.00369491]\n",
            " [0.99600524]\n",
            " [0.995993  ]\n",
            " [0.00609747]]\n",
            "Step: 5629 -> Loss: 0.004458693787455559 -> Predictions: [[0.00369474]\n",
            " [0.9960055 ]\n",
            " [0.99599326]\n",
            " [0.00609718]]\n",
            "Step: 5630 -> Loss: 0.0044584814459085464 -> Predictions: [[0.00369457]\n",
            " [0.9960056 ]\n",
            " [0.9959934 ]\n",
            " [0.00609689]]\n",
            "Step: 5631 -> Loss: 0.004458275157958269 -> Predictions: [[0.00369441]\n",
            " [0.99600583]\n",
            " [0.9959936 ]\n",
            " [0.0060966 ]]\n",
            "Step: 5632 -> Loss: 0.004458063282072544 -> Predictions: [[0.00369424]\n",
            " [0.9960061 ]\n",
            " [0.99599385]\n",
            " [0.00609631]]\n",
            "Step: 5633 -> Loss: 0.00445785466581583 -> Predictions: [[0.00369407]\n",
            " [0.9960062 ]\n",
            " [0.995994  ]\n",
            " [0.00609602]]\n",
            "Step: 5634 -> Loss: 0.004457646980881691 -> Predictions: [[0.00369391]\n",
            " [0.9960064 ]\n",
            " [0.9959942 ]\n",
            " [0.00609573]]\n",
            "Step: 5635 -> Loss: 0.004457433708012104 -> Predictions: [[0.00369374]\n",
            " [0.99600655]\n",
            " [0.9959943 ]\n",
            " [0.00609544]]\n",
            "Step: 5636 -> Loss: 0.0044572255574166775 -> Predictions: [[0.00369358]\n",
            " [0.9960068 ]\n",
            " [0.99599457]\n",
            " [0.00609514]]\n",
            "Step: 5637 -> Loss: 0.004457017872482538 -> Predictions: [[0.00369342]\n",
            " [0.996007  ]\n",
            " [0.9959948 ]\n",
            " [0.00609486]]\n",
            "Step: 5638 -> Loss: 0.004456805065274239 -> Predictions: [[0.00369325]\n",
            " [0.99600714]\n",
            " [0.9959949 ]\n",
            " [0.00609456]]\n",
            "Step: 5639 -> Loss: 0.004456596914678812 -> Predictions: [[0.00369308]\n",
            " [0.9960074 ]\n",
            " [0.99599516]\n",
            " [0.00609427]]\n",
            "Step: 5640 -> Loss: 0.004456386901438236 -> Predictions: [[0.00369292]\n",
            " [0.9960075 ]\n",
            " [0.9959954 ]\n",
            " [0.00609399]]\n",
            "Step: 5641 -> Loss: 0.004456178285181522 -> Predictions: [[0.00369275]\n",
            " [0.9960077 ]\n",
            " [0.9959955 ]\n",
            " [0.00609369]]\n",
            "Step: 5642 -> Loss: 0.004455968737602234 -> Predictions: [[0.00369258]\n",
            " [0.9960079 ]\n",
            " [0.99599576]\n",
            " [0.0060934 ]]\n",
            "Step: 5643 -> Loss: 0.004455758258700371 -> Predictions: [[0.00369242]\n",
            " [0.99600804]\n",
            " [0.9959959 ]\n",
            " [0.00609311]]\n",
            "Step: 5644 -> Loss: 0.004455549642443657 -> Predictions: [[0.00369226]\n",
            " [0.9960083 ]\n",
            " [0.9959961 ]\n",
            " [0.00609282]]\n",
            "Step: 5645 -> Loss: 0.004455341026186943 -> Predictions: [[0.00369209]\n",
            " [0.9960084 ]\n",
            " [0.99599624]\n",
            " [0.00609253]]\n",
            "Step: 5646 -> Loss: 0.004455127753317356 -> Predictions: [[0.00369192]\n",
            " [0.99600863]\n",
            " [0.9959965 ]\n",
            " [0.00609224]]\n",
            "Step: 5647 -> Loss: 0.004454921465367079 -> Predictions: [[0.00369176]\n",
            " [0.9960089 ]\n",
            " [0.9959967 ]\n",
            " [0.00609195]]\n",
            "Step: 5648 -> Loss: 0.004454711452126503 -> Predictions: [[0.00369159]\n",
            " [0.996009  ]\n",
            " [0.99599683]\n",
            " [0.00609166]]\n",
            "Step: 5649 -> Loss: 0.004454500041902065 -> Predictions: [[0.00369143]\n",
            " [0.99600923]\n",
            " [0.9959971 ]\n",
            " [0.00609137]]\n",
            "Step: 5650 -> Loss: 0.0044542900286614895 -> Predictions: [[0.00369126]\n",
            " [0.99600935]\n",
            " [0.9959973 ]\n",
            " [0.00609108]]\n",
            "Step: 5651 -> Loss: 0.004454080946743488 -> Predictions: [[0.0036911 ]\n",
            " [0.9960096 ]\n",
            " [0.9959974 ]\n",
            " [0.00609078]]\n",
            "Step: 5652 -> Loss: 0.004453871864825487 -> Predictions: [[0.00369093]\n",
            " [0.9960098 ]\n",
            " [0.99599767]\n",
            " [0.0060905 ]]\n",
            "Step: 5653 -> Loss: 0.004453664179891348 -> Predictions: [[0.00369077]\n",
            " [0.99600995]\n",
            " [0.9959978 ]\n",
            " [0.00609021]]\n",
            "Step: 5654 -> Loss: 0.00445345276966691 -> Predictions: [[0.0036906 ]\n",
            " [0.9960102 ]\n",
            " [0.995998  ]\n",
            " [0.00608992]]\n",
            "Step: 5655 -> Loss: 0.004453243687748909 -> Predictions: [[0.00369044]\n",
            " [0.9960103 ]\n",
            " [0.99599826]\n",
            " [0.00608963]]\n",
            "Step: 5656 -> Loss: 0.0044530341401696205 -> Predictions: [[0.00369027]\n",
            " [0.99601054]\n",
            " [0.9959984 ]\n",
            " [0.00608934]]\n",
            "Step: 5657 -> Loss: 0.0044528222642838955 -> Predictions: [[0.0036901 ]\n",
            " [0.99601066]\n",
            " [0.9959986 ]\n",
            " [0.00608904]]\n",
            "Step: 5658 -> Loss: 0.0044526150450110435 -> Predictions: [[0.00368994]\n",
            " [0.9960109 ]\n",
            " [0.99599874]\n",
            " [0.00608875]]\n",
            "Step: 5659 -> Loss: 0.004452405031770468 -> Predictions: [[0.00368977]\n",
            " [0.99601114]\n",
            " [0.995999  ]\n",
            " [0.00608846]]\n",
            "Step: 5660 -> Loss: 0.004452198278158903 -> Predictions: [[0.00368961]\n",
            " [0.99601126]\n",
            " [0.9959992 ]\n",
            " [0.00608817]]\n",
            "Step: 5661 -> Loss: 0.004451988264918327 -> Predictions: [[0.00368944]\n",
            " [0.9960115 ]\n",
            " [0.99599934]\n",
            " [0.00608788]]\n",
            "Step: 5662 -> Loss: 0.004451779183000326 -> Predictions: [[0.00368928]\n",
            " [0.9960116 ]\n",
            " [0.9959996 ]\n",
            " [0.00608758]]\n",
            "Step: 5663 -> Loss: 0.0044515710324049 -> Predictions: [[0.00368911]\n",
            " [0.99601185]\n",
            " [0.9959997 ]\n",
            " [0.00608729]]\n",
            "Step: 5664 -> Loss: 0.004451364278793335 -> Predictions: [[0.00368895]\n",
            " [0.996012  ]\n",
            " [0.99599993]\n",
            " [0.006087  ]]\n",
            "Step: 5665 -> Loss: 0.004451153799891472 -> Predictions: [[0.00368878]\n",
            " [0.9960122 ]\n",
            " [0.99600005]\n",
            " [0.0060867 ]]\n",
            "Step: 5666 -> Loss: 0.004450942389667034 -> Predictions: [[0.00368861]\n",
            " [0.99601245]\n",
            " [0.99600023]\n",
            " [0.00608641]]\n",
            "Step: 5667 -> Loss: 0.004450734704732895 -> Predictions: [[0.00368845]\n",
            " [0.99601257]\n",
            " [0.99600047]\n",
            " [0.00608611]]\n",
            "Step: 5668 -> Loss: 0.004450523294508457 -> Predictions: [[0.00368828]\n",
            " [0.9960128 ]\n",
            " [0.9960006 ]\n",
            " [0.00608582]]\n",
            "Step: 5669 -> Loss: 0.004450314678251743 -> Predictions: [[0.00368812]\n",
            " [0.9960129 ]\n",
            " [0.9960008 ]\n",
            " [0.00608553]]\n",
            "Step: 5670 -> Loss: 0.0044501060619950294 -> Predictions: [[0.00368795]\n",
            " [0.99601316]\n",
            " [0.99600095]\n",
            " [0.00608524]]\n",
            "Step: 5671 -> Loss: 0.004449896514415741 -> Predictions: [[0.00368779]\n",
            " [0.9960134 ]\n",
            " [0.9960012 ]\n",
            " [0.00608494]]\n",
            "Step: 5672 -> Loss: 0.004449689760804176 -> Predictions: [[0.00368762]\n",
            " [0.9960135 ]\n",
            " [0.9960014 ]\n",
            " [0.00608465]]\n",
            "Step: 5673 -> Loss: 0.0044494811445474625 -> Predictions: [[0.00368746]\n",
            " [0.99601376]\n",
            " [0.99600154]\n",
            " [0.00608435]]\n",
            "Step: 5674 -> Loss: 0.004449272062629461 -> Predictions: [[0.00368729]\n",
            " [0.9960139 ]\n",
            " [0.9960018 ]\n",
            " [0.00608406]]\n",
            "Step: 5675 -> Loss: 0.00444906298071146 -> Predictions: [[0.00368713]\n",
            " [0.9960141 ]\n",
            " [0.9960019 ]\n",
            " [0.00608376]]\n",
            "Step: 5676 -> Loss: 0.004448853433132172 -> Predictions: [[0.00368696]\n",
            " [0.99601424]\n",
            " [0.99600214]\n",
            " [0.00608347]]\n",
            "Step: 5677 -> Loss: 0.004448646679520607 -> Predictions: [[0.0036868 ]\n",
            " [0.9960145 ]\n",
            " [0.99600226]\n",
            " [0.00608318]]\n",
            "Step: 5678 -> Loss: 0.0044484371319413185 -> Predictions: [[0.00368663]\n",
            " [0.9960146 ]\n",
            " [0.9960025 ]\n",
            " [0.00608288]]\n",
            "Step: 5679 -> Loss: 0.004448224790394306 -> Predictions: [[0.00368646]\n",
            " [0.99601483]\n",
            " [0.99600273]\n",
            " [0.00608258]]\n",
            "Step: 5680 -> Loss: 0.004448017105460167 -> Predictions: [[0.0036863 ]\n",
            " [0.996015  ]\n",
            " [0.99600285]\n",
            " [0.00608229]]\n",
            "Step: 5681 -> Loss: 0.004447810351848602 -> Predictions: [[0.00368613]\n",
            " [0.99601513]\n",
            " [0.9960031 ]\n",
            " [0.006082  ]]\n",
            "Step: 5682 -> Loss: 0.004447599872946739 -> Predictions: [[0.00368597]\n",
            " [0.99601537]\n",
            " [0.9960032 ]\n",
            " [0.0060817 ]]\n",
            "Step: 5683 -> Loss: 0.0044473921880126 -> Predictions: [[0.0036858 ]\n",
            " [0.9960155 ]\n",
            " [0.99600345]\n",
            " [0.00608142]]\n",
            "Step: 5684 -> Loss: 0.004447184037417173 -> Predictions: [[0.00368564]\n",
            " [0.9960157 ]\n",
            " [0.99600357]\n",
            " [0.00608112]]\n",
            "Step: 5685 -> Loss: 0.0044469754211604595 -> Predictions: [[0.00368548]\n",
            " [0.99601585]\n",
            " [0.9960038 ]\n",
            " [0.00608082]]\n",
            "Step: 5686 -> Loss: 0.004446766804903746 -> Predictions: [[0.00368531]\n",
            " [0.9960161 ]\n",
            " [0.99600405]\n",
            " [0.00608053]]\n",
            "Step: 5687 -> Loss: 0.004446557257324457 -> Predictions: [[0.00368514]\n",
            " [0.9960163 ]\n",
            " [0.99600416]\n",
            " [0.00608024]]\n",
            "Step: 5688 -> Loss: 0.004446349106729031 -> Predictions: [[0.00368498]\n",
            " [0.99601644]\n",
            " [0.9960044 ]\n",
            " [0.00607994]]\n",
            "Step: 5689 -> Loss: 0.004446140490472317 -> Predictions: [[0.00368482]\n",
            " [0.9960167 ]\n",
            " [0.9960045 ]\n",
            " [0.00607965]]\n",
            "Step: 5690 -> Loss: 0.004445929080247879 -> Predictions: [[0.00368465]\n",
            " [0.9960168 ]\n",
            " [0.99600476]\n",
            " [0.00607935]]\n",
            "Step: 5691 -> Loss: 0.004445721860975027 -> Predictions: [[0.00368449]\n",
            " [0.99601704]\n",
            " [0.996005  ]\n",
            " [0.00607906]]\n",
            "Step: 5692 -> Loss: 0.0044455151073634624 -> Predictions: [[0.00368432]\n",
            " [0.99601716]\n",
            " [0.9960051 ]\n",
            " [0.00607877]]\n",
            "Step: 5693 -> Loss: 0.00444530276581645 -> Predictions: [[0.00368415]\n",
            " [0.9960174 ]\n",
            " [0.99600536]\n",
            " [0.00607847]]\n",
            "Step: 5694 -> Loss: 0.00444509694352746 -> Predictions: [[0.00368399]\n",
            " [0.99601763]\n",
            " [0.9960055 ]\n",
            " [0.00607818]]\n",
            "Step: 5695 -> Loss: 0.0044448887929320335 -> Predictions: [[0.00368382]\n",
            " [0.99601775]\n",
            " [0.9960057 ]\n",
            " [0.00607789]]\n",
            "Step: 5696 -> Loss: 0.004444677848368883 -> Predictions: [[0.00368366]\n",
            " [0.996018  ]\n",
            " [0.99600583]\n",
            " [0.00607759]]\n",
            "Step: 5697 -> Loss: 0.004444468766450882 -> Predictions: [[0.00368349]\n",
            " [0.9960181 ]\n",
            " [0.9960061 ]\n",
            " [0.0060773 ]]\n",
            "Step: 5698 -> Loss: 0.004444260615855455 -> Predictions: [[0.00368332]\n",
            " [0.99601835]\n",
            " [0.9960063 ]\n",
            " [0.00607701]]\n",
            "Step: 5699 -> Loss: 0.004444051533937454 -> Predictions: [[0.00368316]\n",
            " [0.99601847]\n",
            " [0.9960064 ]\n",
            " [0.00607671]]\n",
            "Step: 5700 -> Loss: 0.004443845711648464 -> Predictions: [[0.003683  ]\n",
            " [0.9960187 ]\n",
            " [0.99600667]\n",
            " [0.00607643]]\n",
            "Step: 5701 -> Loss: 0.004443635232746601 -> Predictions: [[0.00368284]\n",
            " [0.99601895]\n",
            " [0.9960068 ]\n",
            " [0.00607613]]\n",
            "Step: 5702 -> Loss: 0.004443425219506025 -> Predictions: [[0.00368267]\n",
            " [0.99601907]\n",
            " [0.996007  ]\n",
            " [0.00607583]]\n",
            "Step: 5703 -> Loss: 0.0044432152062654495 -> Predictions: [[0.0036825 ]\n",
            " [0.9960193 ]\n",
            " [0.99600726]\n",
            " [0.00607553]]\n",
            "Step: 5704 -> Loss: 0.004443010315299034 -> Predictions: [[0.00368234]\n",
            " [0.9960194 ]\n",
            " [0.9960074 ]\n",
            " [0.00607524]]\n",
            "Step: 5705 -> Loss: 0.00444280169904232 -> Predictions: [[0.00368217]\n",
            " [0.99601966]\n",
            " [0.99600756]\n",
            " [0.00607496]]\n",
            "Step: 5706 -> Loss: 0.004442593548446894 -> Predictions: [[0.00368201]\n",
            " [0.9960198 ]\n",
            " [0.9960077 ]\n",
            " [0.00607466]]\n",
            "Step: 5707 -> Loss: 0.004442387260496616 -> Predictions: [[0.00368185]\n",
            " [0.99602   ]\n",
            " [0.9960079 ]\n",
            " [0.00607437]]\n",
            "Step: 5708 -> Loss: 0.004442176781594753 -> Predictions: [[0.00368168]\n",
            " [0.99602026]\n",
            " [0.99600804]\n",
            " [0.00607408]]\n",
            "Step: 5709 -> Loss: 0.004441967234015465 -> Predictions: [[0.00368151]\n",
            " [0.9960204 ]\n",
            " [0.9960083 ]\n",
            " [0.00607378]]\n",
            "Step: 5710 -> Loss: 0.004441757686436176 -> Predictions: [[0.00368134]\n",
            " [0.9960206 ]\n",
            " [0.9960084 ]\n",
            " [0.00607349]]\n",
            "Step: 5711 -> Loss: 0.00444154953584075 -> Predictions: [[0.00368118]\n",
            " [0.99602073]\n",
            " [0.99600863]\n",
            " [0.00607319]]\n",
            "Step: 5712 -> Loss: 0.004441341385245323 -> Predictions: [[0.00368102]\n",
            " [0.996021  ]\n",
            " [0.9960089 ]\n",
            " [0.0060729 ]]\n",
            "Step: 5713 -> Loss: 0.004441132303327322 -> Predictions: [[0.00368085]\n",
            " [0.9960211 ]\n",
            " [0.996009  ]\n",
            " [0.00607261]]\n",
            "Step: 5714 -> Loss: 0.00444092508405447 -> Predictions: [[0.00368069]\n",
            " [0.99602133]\n",
            " [0.99600923]\n",
            " [0.00607231]]\n",
            "Step: 5715 -> Loss: 0.004440717399120331 -> Predictions: [[0.00368052]\n",
            " [0.99602145]\n",
            " [0.99600935]\n",
            " [0.00607202]]\n",
            "Step: 5716 -> Loss: 0.004440507385879755 -> Predictions: [[0.00368036]\n",
            " [0.9960217 ]\n",
            " [0.9960096 ]\n",
            " [0.00607173]]\n",
            "Step: 5717 -> Loss: 0.0044402978383004665 -> Predictions: [[0.00368019]\n",
            " [0.9960219 ]\n",
            " [0.9960098 ]\n",
            " [0.00607143]]\n",
            "Step: 5718 -> Loss: 0.004440092481672764 -> Predictions: [[0.00368003]\n",
            " [0.99602205]\n",
            " [0.99600995]\n",
            " [0.00607115]]\n",
            "Step: 5719 -> Loss: 0.0044398861937224865 -> Predictions: [[0.00367987]\n",
            " [0.9960223 ]\n",
            " [0.9960102 ]\n",
            " [0.00607086]]\n",
            "Step: 5720 -> Loss: 0.004439677577465773 -> Predictions: [[0.0036797 ]\n",
            " [0.9960224 ]\n",
            " [0.9960103 ]\n",
            " [0.00607057]]\n",
            "Step: 5721 -> Loss: 0.004439467564225197 -> Predictions: [[0.00367954]\n",
            " [0.9960226 ]\n",
            " [0.99601054]\n",
            " [0.00607028]]\n",
            "Step: 5722 -> Loss: 0.00443925941362977 -> Predictions: [[0.00367938]\n",
            " [0.9960228 ]\n",
            " [0.9960108 ]\n",
            " [0.00606999]]\n",
            "Step: 5723 -> Loss: 0.004439050331711769 -> Predictions: [[0.00367921]\n",
            " [0.99602294]\n",
            " [0.9960109 ]\n",
            " [0.0060697 ]]\n",
            "Step: 5724 -> Loss: 0.004438841715455055 -> Predictions: [[0.00367905]\n",
            " [0.9960232 ]\n",
            " [0.99601114]\n",
            " [0.00606941]]\n",
            "Step: 5725 -> Loss: 0.004438633099198341 -> Predictions: [[0.00367889]\n",
            " [0.9960233 ]\n",
            " [0.99601126]\n",
            " [0.00606911]]\n",
            "Step: 5726 -> Loss: 0.004438424948602915 -> Predictions: [[0.00367872]\n",
            " [0.99602354]\n",
            " [0.9960115 ]\n",
            " [0.00606882]]\n",
            "Step: 5727 -> Loss: 0.004438217729330063 -> Predictions: [[0.00367856]\n",
            " [0.99602365]\n",
            " [0.9960116 ]\n",
            " [0.00606853]]\n",
            "Step: 5728 -> Loss: 0.004438010044395924 -> Predictions: [[0.0036784 ]\n",
            " [0.9960239 ]\n",
            " [0.99601185]\n",
            " [0.00606825]]\n",
            "Step: 5729 -> Loss: 0.00443780142813921 -> Predictions: [[0.00367823]\n",
            " [0.99602413]\n",
            " [0.9960121 ]\n",
            " [0.00606796]]\n",
            "Step: 5730 -> Loss: 0.0044375937432050705 -> Predictions: [[0.00367807]\n",
            " [0.99602425]\n",
            " [0.9960122 ]\n",
            " [0.00606767]]\n",
            "Step: 5731 -> Loss: 0.004437382332980633 -> Predictions: [[0.0036779 ]\n",
            " [0.9960245 ]\n",
            " [0.99601245]\n",
            " [0.00606737]]\n",
            "Step: 5732 -> Loss: 0.004437178373336792 -> Predictions: [[0.00367775]\n",
            " [0.9960246 ]\n",
            " [0.99601257]\n",
            " [0.00606708]]\n",
            "Step: 5733 -> Loss: 0.004436970222741365 -> Predictions: [[0.00367758]\n",
            " [0.99602485]\n",
            " [0.9960128 ]\n",
            " [0.00606679]]\n",
            "Step: 5734 -> Loss: 0.004436761140823364 -> Predictions: [[0.00367742]\n",
            " [0.9960251 ]\n",
            " [0.99601305]\n",
            " [0.0060665 ]]\n",
            "Step: 5735 -> Loss: 0.004436556715518236 -> Predictions: [[0.00367726]\n",
            " [0.9960252 ]\n",
            " [0.99601316]\n",
            " [0.00606622]]\n",
            "Step: 5736 -> Loss: 0.0044363453052937984 -> Predictions: [[0.0036771 ]\n",
            " [0.99602544]\n",
            " [0.9960134 ]\n",
            " [0.00606592]]\n",
            "Step: 5737 -> Loss: 0.004436138551682234 -> Predictions: [[0.00367693]\n",
            " [0.99602556]\n",
            " [0.9960135 ]\n",
            " [0.00606564]]\n",
            "Step: 5738 -> Loss: 0.004435930401086807 -> Predictions: [[0.00367677]\n",
            " [0.9960258 ]\n",
            " [0.99601376]\n",
            " [0.00606534]]\n",
            "Step: 5739 -> Loss: 0.004435718059539795 -> Predictions: [[0.0036766 ]\n",
            " [0.9960259 ]\n",
            " [0.996014  ]\n",
            " [0.00606505]]\n",
            "Step: 5740 -> Loss: 0.004435512237250805 -> Predictions: [[0.00367644]\n",
            " [0.99602616]\n",
            " [0.9960141 ]\n",
            " [0.00606476]]\n",
            "Step: 5741 -> Loss: 0.004435306414961815 -> Predictions: [[0.00367628]\n",
            " [0.9960264 ]\n",
            " [0.99601436]\n",
            " [0.00606448]]\n",
            "Step: 5742 -> Loss: 0.004435097798705101 -> Predictions: [[0.00367612]\n",
            " [0.9960265 ]\n",
            " [0.9960145 ]\n",
            " [0.00606418]]\n",
            "Step: 5743 -> Loss: 0.004434889182448387 -> Predictions: [[0.00367595]\n",
            " [0.99602675]\n",
            " [0.9960147 ]\n",
            " [0.0060639 ]]\n",
            "Step: 5744 -> Loss: 0.004434681031852961 -> Predictions: [[0.00367578]\n",
            " [0.9960269 ]\n",
            " [0.99601495]\n",
            " [0.00606361]]\n",
            "Step: 5745 -> Loss: 0.004434471949934959 -> Predictions: [[0.00367562]\n",
            " [0.9960271 ]\n",
            " [0.996015  ]\n",
            " [0.00606331]]\n",
            "Step: 5746 -> Loss: 0.004434261936694384 -> Predictions: [[0.00367546]\n",
            " [0.99602735]\n",
            " [0.99601525]\n",
            " [0.00606301]]\n",
            "Step: 5747 -> Loss: 0.004434056114405394 -> Predictions: [[0.0036753 ]\n",
            " [0.99602747]\n",
            " [0.99601537]\n",
            " [0.00606273]]\n",
            "Step: 5748 -> Loss: 0.004433847963809967 -> Predictions: [[0.00367513]\n",
            " [0.9960277 ]\n",
            " [0.9960156 ]\n",
            " [0.00606244]]\n",
            "Step: 5749 -> Loss: 0.004433640278875828 -> Predictions: [[0.00367497]\n",
            " [0.9960278 ]\n",
            " [0.9960157 ]\n",
            " [0.00606215]]\n",
            "Step: 5750 -> Loss: 0.004433434456586838 -> Predictions: [[0.00367481]\n",
            " [0.99602807]\n",
            " [0.99601597]\n",
            " [0.00606186]]\n",
            "Step: 5751 -> Loss: 0.004433226305991411 -> Predictions: [[0.00367465]\n",
            " [0.9960282 ]\n",
            " [0.9960162 ]\n",
            " [0.00606158]]\n",
            "Step: 5752 -> Loss: 0.00443301722407341 -> Predictions: [[0.00367448]\n",
            " [0.9960284 ]\n",
            " [0.9960163 ]\n",
            " [0.00606129]]\n",
            "Step: 5753 -> Loss: 0.004432810470461845 -> Predictions: [[0.00367432]\n",
            " [0.99602866]\n",
            " [0.99601656]\n",
            " [0.00606099]]\n",
            "Step: 5754 -> Loss: 0.004432602319866419 -> Predictions: [[0.00367416]\n",
            " [0.9960288 ]\n",
            " [0.9960167 ]\n",
            " [0.0060607 ]]\n",
            "Step: 5755 -> Loss: 0.00443239277228713 -> Predictions: [[0.003674  ]\n",
            " [0.996029  ]\n",
            " [0.9960169 ]\n",
            " [0.00606041]]\n",
            "Step: 5756 -> Loss: 0.00443218694999814 -> Predictions: [[0.00367383]\n",
            " [0.99602914]\n",
            " [0.99601716]\n",
            " [0.00606012]]\n",
            "Step: 5757 -> Loss: 0.0044319769367575645 -> Predictions: [[0.00367367]\n",
            " [0.9960294 ]\n",
            " [0.9960173 ]\n",
            " [0.00605983]]\n",
            "Step: 5758 -> Loss: 0.004431769251823425 -> Predictions: [[0.00367351]\n",
            " [0.9960295 ]\n",
            " [0.9960175 ]\n",
            " [0.00605954]]\n",
            "Step: 5759 -> Loss: 0.004431561566889286 -> Predictions: [[0.00367334]\n",
            " [0.99602973]\n",
            " [0.99601763]\n",
            " [0.00605926]]\n",
            "Step: 5760 -> Loss: 0.004431354813277721 -> Predictions: [[0.00367318]\n",
            " [0.9960299 ]\n",
            " [0.9960179 ]\n",
            " [0.00605897]]\n",
            "Step: 5761 -> Loss: 0.0044311475940048695 -> Predictions: [[0.00367302]\n",
            " [0.99603003]\n",
            " [0.9960181 ]\n",
            " [0.00605868]]\n",
            "Step: 5762 -> Loss: 0.004430938046425581 -> Predictions: [[0.00367285]\n",
            " [0.9960303 ]\n",
            " [0.99601823]\n",
            " [0.00605839]]\n",
            "Step: 5763 -> Loss: 0.004430732689797878 -> Predictions: [[0.00367269]\n",
            " [0.9960304 ]\n",
            " [0.99601847]\n",
            " [0.0060581 ]]\n",
            "Step: 5764 -> Loss: 0.004430525004863739 -> Predictions: [[0.00367253]\n",
            " [0.9960306 ]\n",
            " [0.9960186 ]\n",
            " [0.00605781]]\n",
            "Step: 5765 -> Loss: 0.004430314060300589 -> Predictions: [[0.00367236]\n",
            " [0.99603087]\n",
            " [0.9960188 ]\n",
            " [0.00605751]]\n",
            "Step: 5766 -> Loss: 0.004430105909705162 -> Predictions: [[0.0036722 ]\n",
            " [0.996031  ]\n",
            " [0.99601895]\n",
            " [0.00605723]]\n",
            "Step: 5767 -> Loss: 0.00442989869043231 -> Predictions: [[0.00367204]\n",
            " [0.9960312 ]\n",
            " [0.9960192 ]\n",
            " [0.00605693]]\n",
            "Step: 5768 -> Loss: 0.0044296905398368835 -> Predictions: [[0.00367187]\n",
            " [0.99603134]\n",
            " [0.9960194 ]\n",
            " [0.00605665]]\n",
            "Step: 5769 -> Loss: 0.004429482854902744 -> Predictions: [[0.00367171]\n",
            " [0.9960316 ]\n",
            " [0.99601954]\n",
            " [0.00605636]]\n",
            "Step: 5770 -> Loss: 0.004429275169968605 -> Predictions: [[0.00367155]\n",
            " [0.9960317 ]\n",
            " [0.9960198 ]\n",
            " [0.00605606]]\n",
            "Step: 5771 -> Loss: 0.004429071210324764 -> Predictions: [[0.00367138]\n",
            " [0.99603194]\n",
            " [0.9960199 ]\n",
            " [0.00605578]]\n",
            "Step: 5772 -> Loss: 0.00442886259406805 -> Predictions: [[0.00367121]\n",
            " [0.99603206]\n",
            " [0.99602014]\n",
            " [0.00605549]]\n",
            "Step: 5773 -> Loss: 0.004428655840456486 -> Predictions: [[0.00367105]\n",
            " [0.9960323 ]\n",
            " [0.9960204 ]\n",
            " [0.0060552 ]]\n",
            "Step: 5774 -> Loss: 0.004428450018167496 -> Predictions: [[0.00367088]\n",
            " [0.99603254]\n",
            " [0.9960205 ]\n",
            " [0.0060549 ]]\n",
            "Step: 5775 -> Loss: 0.0044282423332333565 -> Predictions: [[0.00367072]\n",
            " [0.99603266]\n",
            " [0.99602073]\n",
            " [0.00605461]]\n",
            "Step: 5776 -> Loss: 0.004428034648299217 -> Predictions: [[0.00367055]\n",
            " [0.9960329 ]\n",
            " [0.99602085]\n",
            " [0.00605432]]\n",
            "Step: 5777 -> Loss: 0.004427830222994089 -> Predictions: [[0.00367038]\n",
            " [0.996033  ]\n",
            " [0.9960211 ]\n",
            " [0.00605404]]\n",
            "Step: 5778 -> Loss: 0.004427623003721237 -> Predictions: [[0.00367022]\n",
            " [0.99603325]\n",
            " [0.9960212 ]\n",
            " [0.00605375]]\n",
            "Step: 5779 -> Loss: 0.004427415318787098 -> Predictions: [[0.00367005]\n",
            " [0.9960334 ]\n",
            " [0.99602145]\n",
            " [0.00605346]]\n",
            "Step: 5780 -> Loss: 0.004427209496498108 -> Predictions: [[0.00366989]\n",
            " [0.9960336 ]\n",
            " [0.99602157]\n",
            " [0.00605317]]\n",
            "Step: 5781 -> Loss: 0.004427002742886543 -> Predictions: [[0.00366972]\n",
            " [0.9960337 ]\n",
            " [0.9960218 ]\n",
            " [0.00605288]]\n",
            "Step: 5782 -> Loss: 0.004426796454936266 -> Predictions: [[0.00366956]\n",
            " [0.99603397]\n",
            " [0.99602205]\n",
            " [0.00605259]]\n",
            "Step: 5783 -> Loss: 0.004426590166985989 -> Predictions: [[0.00366939]\n",
            " [0.9960342 ]\n",
            " [0.99602216]\n",
            " [0.0060523 ]]\n",
            "Step: 5784 -> Loss: 0.004426378756761551 -> Predictions: [[0.00366921]\n",
            " [0.9960343 ]\n",
            " [0.9960224 ]\n",
            " [0.00605201]]\n",
            "Step: 5785 -> Loss: 0.004426176194101572 -> Predictions: [[0.00366906]\n",
            " [0.99603456]\n",
            " [0.99602246]\n",
            " [0.00605172]]\n",
            "Step: 5786 -> Loss: 0.0044259680435061455 -> Predictions: [[0.00366889]\n",
            " [0.9960347 ]\n",
            " [0.9960227 ]\n",
            " [0.00605143]]\n",
            "Step: 5787 -> Loss: 0.004425760358572006 -> Predictions: [[0.00366872]\n",
            " [0.9960349 ]\n",
            " [0.9960228 ]\n",
            " [0.00605114]]\n",
            "Step: 5788 -> Loss: 0.004425554070621729 -> Predictions: [[0.00366855]\n",
            " [0.99603504]\n",
            " [0.99602306]\n",
            " [0.00605085]]\n",
            "Step: 5789 -> Loss: 0.0044253491796553135 -> Predictions: [[0.00366839]\n",
            " [0.9960353 ]\n",
            " [0.9960232 ]\n",
            " [0.00605056]]\n",
            "Step: 5790 -> Loss: 0.004425140097737312 -> Predictions: [[0.00366822]\n",
            " [0.9960354 ]\n",
            " [0.9960234 ]\n",
            " [0.00605027]]\n",
            "Step: 5791 -> Loss: 0.004424933344125748 -> Predictions: [[0.00366805]\n",
            " [0.99603564]\n",
            " [0.99602365]\n",
            " [0.00604998]]\n",
            "Step: 5792 -> Loss: 0.00442472705617547 -> Predictions: [[0.00366788]\n",
            " [0.99603575]\n",
            " [0.9960238 ]\n",
            " [0.00604969]]\n",
            "Step: 5793 -> Loss: 0.004424521699547768 -> Predictions: [[0.00366772]\n",
            " [0.996036  ]\n",
            " [0.996024  ]\n",
            " [0.00604941]]\n",
            "Step: 5794 -> Loss: 0.004424315877258778 -> Predictions: [[0.00366755]\n",
            " [0.9960361 ]\n",
            " [0.99602413]\n",
            " [0.00604911]]\n",
            "Step: 5795 -> Loss: 0.004424110986292362 -> Predictions: [[0.00366739]\n",
            " [0.99603635]\n",
            " [0.99602437]\n",
            " [0.00604882]]\n",
            "Step: 5796 -> Loss: 0.004423901438713074 -> Predictions: [[0.00366723]\n",
            " [0.9960366 ]\n",
            " [0.9960245 ]\n",
            " [0.00604853]]\n",
            "Step: 5797 -> Loss: 0.004423694685101509 -> Predictions: [[0.00366706]\n",
            " [0.9960367 ]\n",
            " [0.9960247 ]\n",
            " [0.00604824]]\n",
            "Step: 5798 -> Loss: 0.004423487465828657 -> Predictions: [[0.00366689]\n",
            " [0.99603695]\n",
            " [0.99602485]\n",
            " [0.00604795]]\n",
            "Step: 5799 -> Loss: 0.004423282574862242 -> Predictions: [[0.00366672]\n",
            " [0.99603707]\n",
            " [0.9960251 ]\n",
            " [0.00604767]]\n",
            "Step: 5800 -> Loss: 0.004423074424266815 -> Predictions: [[0.00366656]\n",
            " [0.9960373 ]\n",
            " [0.9960253 ]\n",
            " [0.00604737]]\n",
            "Step: 5801 -> Loss: 0.004422867204993963 -> Predictions: [[0.00366639]\n",
            " [0.99603736]\n",
            " [0.99602544]\n",
            " [0.00604708]]\n",
            "Step: 5802 -> Loss: 0.004422662779688835 -> Predictions: [[0.00366623]\n",
            " [0.9960376 ]\n",
            " [0.9960257 ]\n",
            " [0.0060468 ]]\n",
            "Step: 5803 -> Loss: 0.004422455094754696 -> Predictions: [[0.00366606]\n",
            " [0.9960377 ]\n",
            " [0.9960258 ]\n",
            " [0.00604651]]\n",
            "Step: 5804 -> Loss: 0.0044222502037882805 -> Predictions: [[0.0036659 ]\n",
            " [0.99603796]\n",
            " [0.99602604]\n",
            " [0.00604622]]\n",
            "Step: 5805 -> Loss: 0.004422040190547705 -> Predictions: [[0.00366572]\n",
            " [0.9960382 ]\n",
            " [0.99602616]\n",
            " [0.00604593]]\n",
            "Step: 5806 -> Loss: 0.004421836696565151 -> Predictions: [[0.00366556]\n",
            " [0.9960383 ]\n",
            " [0.9960264 ]\n",
            " [0.00604564]]\n",
            "Step: 5807 -> Loss: 0.004421629477292299 -> Predictions: [[0.00366539]\n",
            " [0.99603856]\n",
            " [0.9960265 ]\n",
            " [0.00604535]]\n",
            "Step: 5808 -> Loss: 0.004421423189342022 -> Predictions: [[0.00366523]\n",
            " [0.9960387 ]\n",
            " [0.99602675]\n",
            " [0.00604506]]\n",
            "Step: 5809 -> Loss: 0.00442121597006917 -> Predictions: [[0.00366506]\n",
            " [0.9960389 ]\n",
            " [0.9960269 ]\n",
            " [0.00604477]]\n",
            "Step: 5810 -> Loss: 0.004421008285135031 -> Predictions: [[0.0036649 ]\n",
            " [0.99603903]\n",
            " [0.9960271 ]\n",
            " [0.00604448]]\n",
            "Step: 5811 -> Loss: 0.004420801531523466 -> Predictions: [[0.00366473]\n",
            " [0.9960393 ]\n",
            " [0.99602735]\n",
            " [0.00604419]]\n",
            "Step: 5812 -> Loss: 0.004420597571879625 -> Predictions: [[0.00366457]\n",
            " [0.9960394 ]\n",
            " [0.99602747]\n",
            " [0.0060439 ]]\n",
            "Step: 5813 -> Loss: 0.004420389421284199 -> Predictions: [[0.0036644 ]\n",
            " [0.9960396 ]\n",
            " [0.9960277 ]\n",
            " [0.00604361]]\n",
            "Step: 5814 -> Loss: 0.004420182667672634 -> Predictions: [[0.00366424]\n",
            " [0.99603975]\n",
            " [0.9960278 ]\n",
            " [0.00604332]]\n",
            "Step: 5815 -> Loss: 0.004419978242367506 -> Predictions: [[0.00366407]\n",
            " [0.99604   ]\n",
            " [0.99602807]\n",
            " [0.00604303]]\n",
            "Step: 5816 -> Loss: 0.004419770557433367 -> Predictions: [[0.0036639 ]\n",
            " [0.9960402 ]\n",
            " [0.9960282 ]\n",
            " [0.00604274]]\n",
            "Step: 5817 -> Loss: 0.004419564735144377 -> Predictions: [[0.00366374]\n",
            " [0.99604034]\n",
            " [0.9960284 ]\n",
            " [0.00604245]]\n",
            "Step: 5818 -> Loss: 0.004419358912855387 -> Predictions: [[0.00366357]\n",
            " [0.9960406 ]\n",
            " [0.99602854]\n",
            " [0.00604216]]\n",
            "Step: 5819 -> Loss: 0.0044191512279212475 -> Predictions: [[0.0036634 ]\n",
            " [0.9960407 ]\n",
            " [0.9960288 ]\n",
            " [0.00604187]]\n",
            "Step: 5820 -> Loss: 0.004418946336954832 -> Predictions: [[0.00366324]\n",
            " [0.99604094]\n",
            " [0.996029  ]\n",
            " [0.00604159]]\n",
            "Step: 5821 -> Loss: 0.004418738652020693 -> Predictions: [[0.00366307]\n",
            " [0.99604106]\n",
            " [0.99602914]\n",
            " [0.0060413 ]]\n",
            "Step: 5822 -> Loss: 0.004418532829731703 -> Predictions: [[0.0036629 ]\n",
            " [0.9960413 ]\n",
            " [0.9960294 ]\n",
            " [0.00604101]]\n",
            "Step: 5823 -> Loss: 0.004418327473104 -> Predictions: [[0.00366274]\n",
            " [0.9960414 ]\n",
            " [0.9960295 ]\n",
            " [0.00604072]]\n",
            "Step: 5824 -> Loss: 0.004418120253831148 -> Predictions: [[0.00366257]\n",
            " [0.99604166]\n",
            " [0.99602973]\n",
            " [0.00604043]]\n",
            "Step: 5825 -> Loss: 0.0044179148972034454 -> Predictions: [[0.00366241]\n",
            " [0.9960418 ]\n",
            " [0.99602985]\n",
            " [0.00604014]]\n",
            "Step: 5826 -> Loss: 0.004417709074914455 -> Predictions: [[0.00366224]\n",
            " [0.996042  ]\n",
            " [0.99603003]\n",
            " [0.00603985]]\n",
            "Step: 5827 -> Loss: 0.004417499992996454 -> Predictions: [[0.00366207]\n",
            " [0.99604225]\n",
            " [0.99603015]\n",
            " [0.00603956]]\n",
            "Step: 5828 -> Loss: 0.004417295567691326 -> Predictions: [[0.00366191]\n",
            " [0.9960424 ]\n",
            " [0.9960304 ]\n",
            " [0.00603927]]\n",
            "Step: 5829 -> Loss: 0.004417090676724911 -> Predictions: [[0.00366175]\n",
            " [0.9960426 ]\n",
            " [0.9960306 ]\n",
            " [0.00603898]]\n",
            "Step: 5830 -> Loss: 0.004416885320097208 -> Predictions: [[0.00366158]\n",
            " [0.9960427 ]\n",
            " [0.99603075]\n",
            " [0.0060387 ]]\n",
            "Step: 5831 -> Loss: 0.004416675306856632 -> Predictions: [[0.00366141]\n",
            " [0.99604297]\n",
            " [0.996031  ]\n",
            " [0.0060384 ]]\n",
            "Step: 5832 -> Loss: 0.004416470415890217 -> Predictions: [[0.00366125]\n",
            " [0.9960431 ]\n",
            " [0.9960311 ]\n",
            " [0.00603812]]\n",
            "Step: 5833 -> Loss: 0.004416266456246376 -> Predictions: [[0.00366108]\n",
            " [0.9960433 ]\n",
            " [0.99603134]\n",
            " [0.00603782]]\n",
            "Step: 5834 -> Loss: 0.004416057839989662 -> Predictions: [[0.00366091]\n",
            " [0.99604344]\n",
            " [0.99603146]\n",
            " [0.00603753]]\n",
            "Step: 5835 -> Loss: 0.004415855742990971 -> Predictions: [[0.00366075]\n",
            " [0.9960437 ]\n",
            " [0.9960317 ]\n",
            " [0.00603725]]\n",
            "Step: 5836 -> Loss: 0.004415647592395544 -> Predictions: [[0.00366059]\n",
            " [0.9960438 ]\n",
            " [0.9960318 ]\n",
            " [0.00603696]]\n",
            "Step: 5837 -> Loss: 0.004415440373122692 -> Predictions: [[0.00366042]\n",
            " [0.99604404]\n",
            " [0.99603206]\n",
            " [0.00603667]]\n",
            "Step: 5838 -> Loss: 0.004415232688188553 -> Predictions: [[0.00366026]\n",
            " [0.9960443 ]\n",
            " [0.9960323 ]\n",
            " [0.00603637]]\n",
            "Step: 5839 -> Loss: 0.004415025934576988 -> Predictions: [[0.00366008]\n",
            " [0.9960444 ]\n",
            " [0.9960324 ]\n",
            " [0.00603609]]\n",
            "Step: 5840 -> Loss: 0.004414820112287998 -> Predictions: [[0.00365992]\n",
            " [0.99604464]\n",
            " [0.99603266]\n",
            " [0.0060358 ]]\n",
            "Step: 5841 -> Loss: 0.004414616152644157 -> Predictions: [[0.00365976]\n",
            " [0.99604475]\n",
            " [0.9960328 ]\n",
            " [0.00603551]]\n",
            "Step: 5842 -> Loss: 0.004414408467710018 -> Predictions: [[0.00365959]\n",
            " [0.99604493]\n",
            " [0.996033  ]\n",
            " [0.00603522]]\n",
            "Step: 5843 -> Loss: 0.004414201248437166 -> Predictions: [[0.00365942]\n",
            " [0.99604505]\n",
            " [0.99603313]\n",
            " [0.00603493]]\n",
            "Step: 5844 -> Loss: 0.004413997754454613 -> Predictions: [[0.00365926]\n",
            " [0.9960453 ]\n",
            " [0.9960334 ]\n",
            " [0.00603465]]\n",
            "Step: 5845 -> Loss: 0.004413791466504335 -> Predictions: [[0.00365909]\n",
            " [0.9960454 ]\n",
            " [0.9960335 ]\n",
            " [0.00603436]]\n",
            "Step: 5846 -> Loss: 0.004413585178554058 -> Predictions: [[0.00365892]\n",
            " [0.99604565]\n",
            " [0.9960337 ]\n",
            " [0.00603407]]\n",
            "Step: 5847 -> Loss: 0.004413377493619919 -> Predictions: [[0.00365876]\n",
            " [0.99604577]\n",
            " [0.99603385]\n",
            " [0.00603378]]\n",
            "Step: 5848 -> Loss: 0.00441316980868578 -> Predictions: [[0.00365859]\n",
            " [0.996046  ]\n",
            " [0.9960341 ]\n",
            " [0.00603349]]\n",
            "Step: 5849 -> Loss: 0.004412965849041939 -> Predictions: [[0.00365843]\n",
            " [0.9960461 ]\n",
            " [0.9960343 ]\n",
            " [0.0060332 ]]\n",
            "Step: 5850 -> Loss: 0.004412760026752949 -> Predictions: [[0.00365826]\n",
            " [0.99604636]\n",
            " [0.99603444]\n",
            " [0.00603292]]\n",
            "Step: 5851 -> Loss: 0.004412555601447821 -> Predictions: [[0.0036581 ]\n",
            " [0.9960466 ]\n",
            " [0.9960347 ]\n",
            " [0.00603263]]\n",
            "Step: 5852 -> Loss: 0.004412347916513681 -> Predictions: [[0.00365793]\n",
            " [0.9960467 ]\n",
            " [0.9960348 ]\n",
            " [0.00603234]]\n",
            "Step: 5853 -> Loss: 0.004412142094224691 -> Predictions: [[0.00365777]\n",
            " [0.99604696]\n",
            " [0.99603504]\n",
            " [0.00603205]]\n",
            "Step: 5854 -> Loss: 0.004411937668919563 -> Predictions: [[0.0036576 ]\n",
            " [0.9960471 ]\n",
            " [0.99603516]\n",
            " [0.00603176]]\n",
            "Step: 5855 -> Loss: 0.004411732312291861 -> Predictions: [[0.00365744]\n",
            " [0.9960473 ]\n",
            " [0.9960354 ]\n",
            " [0.00603147]]\n",
            "Step: 5856 -> Loss: 0.004411525093019009 -> Predictions: [[0.00365727]\n",
            " [0.99604744]\n",
            " [0.9960355 ]\n",
            " [0.00603118]]\n",
            "Step: 5857 -> Loss: 0.004411316942423582 -> Predictions: [[0.0036571 ]\n",
            " [0.9960477 ]\n",
            " [0.99603575]\n",
            " [0.00603089]]\n",
            "Step: 5858 -> Loss: 0.00441110972315073 -> Predictions: [[0.00365693]\n",
            " [0.9960478 ]\n",
            " [0.996036  ]\n",
            " [0.0060306 ]]\n",
            "Step: 5859 -> Loss: 0.004410907160490751 -> Predictions: [[0.00365677]\n",
            " [0.99604803]\n",
            " [0.9960361 ]\n",
            " [0.00603032]]\n",
            "Step: 5860 -> Loss: 0.004410699941217899 -> Predictions: [[0.0036566 ]\n",
            " [0.99604815]\n",
            " [0.99603635]\n",
            " [0.00603003]]\n",
            "Step: 5861 -> Loss: 0.004410494584590197 -> Predictions: [[0.00365644]\n",
            " [0.9960484 ]\n",
            " [0.99603647]\n",
            " [0.00602974]]\n",
            "Step: 5862 -> Loss: 0.004410287365317345 -> Predictions: [[0.00365627]\n",
            " [0.9960486 ]\n",
            " [0.9960367 ]\n",
            " [0.00602945]]\n",
            "Step: 5863 -> Loss: 0.004410082474350929 -> Predictions: [[0.00365611]\n",
            " [0.99604875]\n",
            " [0.9960368 ]\n",
            " [0.00602916]]\n",
            "Step: 5864 -> Loss: 0.004409877583384514 -> Predictions: [[0.00365594]\n",
            " [0.996049  ]\n",
            " [0.99603707]\n",
            " [0.00602887]]\n",
            "Step: 5865 -> Loss: 0.004409670829772949 -> Predictions: [[0.00365578]\n",
            " [0.9960491 ]\n",
            " [0.9960372 ]\n",
            " [0.00602858]]\n",
            "Step: 5866 -> Loss: 0.004409464076161385 -> Predictions: [[0.00365561]\n",
            " [0.99604934]\n",
            " [0.99603736]\n",
            " [0.0060283 ]]\n",
            "Step: 5867 -> Loss: 0.0044092582538723946 -> Predictions: [[0.00365545]\n",
            " [0.99604946]\n",
            " [0.9960375 ]\n",
            " [0.006028  ]]\n",
            "Step: 5868 -> Loss: 0.004409054759889841 -> Predictions: [[0.00365528]\n",
            " [0.9960497 ]\n",
            " [0.9960377 ]\n",
            " [0.00602772]]\n",
            "Step: 5869 -> Loss: 0.004408846143633127 -> Predictions: [[0.00365511]\n",
            " [0.9960498 ]\n",
            " [0.99603796]\n",
            " [0.00602743]]\n",
            "Step: 5870 -> Loss: 0.004408642183989286 -> Predictions: [[0.00365495]\n",
            " [0.99605006]\n",
            " [0.9960381 ]\n",
            " [0.00602713]]\n",
            "Step: 5871 -> Loss: 0.00440843403339386 -> Predictions: [[0.00365478]\n",
            " [0.9960502 ]\n",
            " [0.9960383 ]\n",
            " [0.00602685]]\n",
            "Step: 5872 -> Loss: 0.0044082291424274445 -> Predictions: [[0.00365462]\n",
            " [0.9960504 ]\n",
            " [0.99603844]\n",
            " [0.00602656]]\n",
            "Step: 5873 -> Loss: 0.004408021457493305 -> Predictions: [[0.00365445]\n",
            " [0.99605066]\n",
            " [0.9960387 ]\n",
            " [0.00602627]]\n",
            "Step: 5874 -> Loss: 0.004407818429172039 -> Predictions: [[0.00365429]\n",
            " [0.9960508 ]\n",
            " [0.9960388 ]\n",
            " [0.00602599]]\n",
            "Step: 5875 -> Loss: 0.004407613538205624 -> Predictions: [[0.00365412]\n",
            " [0.996051  ]\n",
            " [0.99603903]\n",
            " [0.0060257 ]]\n",
            "Step: 5876 -> Loss: 0.004407405853271484 -> Predictions: [[0.00365396]\n",
            " [0.99605113]\n",
            " [0.99603915]\n",
            " [0.00602541]]\n",
            "Step: 5877 -> Loss: 0.004407200030982494 -> Predictions: [[0.00365379]\n",
            " [0.9960514 ]\n",
            " [0.9960394 ]\n",
            " [0.00602512]]\n",
            "Step: 5878 -> Loss: 0.004406994208693504 -> Predictions: [[0.00365363]\n",
            " [0.9960515 ]\n",
            " [0.9960395 ]\n",
            " [0.00602483]]\n",
            "Step: 5879 -> Loss: 0.0044067916460335255 -> Predictions: [[0.00365346]\n",
            " [0.9960517 ]\n",
            " [0.99603975]\n",
            " [0.00602455]]\n",
            "Step: 5880 -> Loss: 0.004406581167131662 -> Predictions: [[0.00365329]\n",
            " [0.99605185]\n",
            " [0.99604   ]\n",
            " [0.00602425]]\n",
            "Step: 5881 -> Loss: 0.004406377673149109 -> Predictions: [[0.00365313]\n",
            " [0.9960521 ]\n",
            " [0.9960401 ]\n",
            " [0.00602396]]\n",
            "Step: 5882 -> Loss: 0.00440617511048913 -> Predictions: [[0.00365297]\n",
            " [0.9960522 ]\n",
            " [0.99604034]\n",
            " [0.00602369]]\n",
            "Step: 5883 -> Loss: 0.004405964631587267 -> Predictions: [[0.00365281]\n",
            " [0.9960524 ]\n",
            " [0.99604046]\n",
            " [0.00602339]]\n",
            "Step: 5884 -> Loss: 0.004405763000249863 -> Predictions: [[0.00365265]\n",
            " [0.9960526 ]\n",
            " [0.9960407 ]\n",
            " [0.00602311]]\n",
            "Step: 5885 -> Loss: 0.004405559506267309 -> Predictions: [[0.00365249]\n",
            " [0.99605274]\n",
            " [0.9960408 ]\n",
            " [0.00602282]]\n",
            "Step: 5886 -> Loss: 0.00440535694360733 -> Predictions: [[0.00365233]\n",
            " [0.996053  ]\n",
            " [0.99604106]\n",
            " [0.00602254]]\n",
            "Step: 5887 -> Loss: 0.004405148793011904 -> Predictions: [[0.00365216]\n",
            " [0.9960531 ]\n",
            " [0.9960412 ]\n",
            " [0.00602225]]\n",
            "Step: 5888 -> Loss: 0.004404946696013212 -> Predictions: [[0.003652  ]\n",
            " [0.99605334]\n",
            " [0.9960414 ]\n",
            " [0.00602196]]\n",
            "Step: 5889 -> Loss: 0.0044047413393855095 -> Predictions: [[0.00365184]\n",
            " [0.99605346]\n",
            " [0.99604154]\n",
            " [0.00602167]]\n",
            "Step: 5890 -> Loss: 0.004404535982757807 -> Predictions: [[0.00365167]\n",
            " [0.9960537 ]\n",
            " [0.9960418 ]\n",
            " [0.00602139]]\n",
            "Step: 5891 -> Loss: 0.004404330626130104 -> Predictions: [[0.00365151]\n",
            " [0.9960538 ]\n",
            " [0.996042  ]\n",
            " [0.0060211 ]]\n",
            "Step: 5892 -> Loss: 0.0044041285291314125 -> Predictions: [[0.00365136]\n",
            " [0.99605405]\n",
            " [0.99604213]\n",
            " [0.00602081]]\n",
            "Step: 5893 -> Loss: 0.004403921775519848 -> Predictions: [[0.00365119]\n",
            " [0.9960542 ]\n",
            " [0.9960424 ]\n",
            " [0.00602052]]\n",
            "Step: 5894 -> Loss: 0.00440371735021472 -> Predictions: [[0.00365103]\n",
            " [0.9960544 ]\n",
            " [0.9960425 ]\n",
            " [0.00602024]]\n",
            "Step: 5895 -> Loss: 0.004403514787554741 -> Predictions: [[0.00365086]\n",
            " [0.99605465]\n",
            " [0.9960427 ]\n",
            " [0.00601996]]\n",
            "Step: 5896 -> Loss: 0.004403308033943176 -> Predictions: [[0.0036507 ]\n",
            " [0.99605477]\n",
            " [0.99604285]\n",
            " [0.00601967]]\n",
            "Step: 5897 -> Loss: 0.004403101745992899 -> Predictions: [[0.00365054]\n",
            " [0.996055  ]\n",
            " [0.9960431 ]\n",
            " [0.00601938]]\n",
            "Step: 5898 -> Loss: 0.004402897786349058 -> Predictions: [[0.00365038]\n",
            " [0.9960551 ]\n",
            " [0.9960432 ]\n",
            " [0.00601909]]\n",
            "Step: 5899 -> Loss: 0.004402695223689079 -> Predictions: [[0.00365022]\n",
            " [0.99605536]\n",
            " [0.99604344]\n",
            " [0.00601881]]\n",
            "Step: 5900 -> Loss: 0.004402488470077515 -> Predictions: [[0.00365005]\n",
            " [0.9960555 ]\n",
            " [0.9960437 ]\n",
            " [0.00601852]]\n",
            "Step: 5901 -> Loss: 0.004402283579111099 -> Predictions: [[0.00364989]\n",
            " [0.9960557 ]\n",
            " [0.9960438 ]\n",
            " [0.00601824]]\n",
            "Step: 5902 -> Loss: 0.004402082413434982 -> Predictions: [[0.00364973]\n",
            " [0.99605584]\n",
            " [0.99604404]\n",
            " [0.00601795]]\n",
            "Step: 5903 -> Loss: 0.004401874728500843 -> Predictions: [[0.00364957]\n",
            " [0.9960561 ]\n",
            " [0.99604416]\n",
            " [0.00601766]]\n",
            "Step: 5904 -> Loss: 0.004401667974889278 -> Predictions: [[0.0036494 ]\n",
            " [0.9960562 ]\n",
            " [0.9960444 ]\n",
            " [0.00601738]]\n",
            "Step: 5905 -> Loss: 0.004401464480906725 -> Predictions: [[0.00364924]\n",
            " [0.99605644]\n",
            " [0.9960445 ]\n",
            " [0.00601709]]\n",
            "Step: 5906 -> Loss: 0.004401262849569321 -> Predictions: [[0.00364909]\n",
            " [0.9960567 ]\n",
            " [0.99604475]\n",
            " [0.00601681]]\n",
            "Step: 5907 -> Loss: 0.004401057492941618 -> Predictions: [[0.00364892]\n",
            " [0.9960568 ]\n",
            " [0.9960448 ]\n",
            " [0.00601652]]\n",
            "Step: 5908 -> Loss: 0.00440085306763649 -> Predictions: [[0.00364876]\n",
            " [0.99605703]\n",
            " [0.99604505]\n",
            " [0.00601623]]\n",
            "Step: 5909 -> Loss: 0.004400646314024925 -> Predictions: [[0.0036486 ]\n",
            " [0.99605715]\n",
            " [0.9960452 ]\n",
            " [0.00601594]]\n",
            "Step: 5910 -> Loss: 0.004400444682687521 -> Predictions: [[0.00364844]\n",
            " [0.9960574 ]\n",
            " [0.9960454 ]\n",
            " [0.00601566]]\n",
            "Step: 5911 -> Loss: 0.004400238394737244 -> Predictions: [[0.00364827]\n",
            " [0.9960575 ]\n",
            " [0.99604565]\n",
            " [0.00601538]]\n",
            "Step: 5912 -> Loss: 0.004400033038109541 -> Predictions: [[0.00364811]\n",
            " [0.99605775]\n",
            " [0.99604577]\n",
            " [0.00601509]]\n",
            "Step: 5913 -> Loss: 0.004399830941110849 -> Predictions: [[0.00364795]\n",
            " [0.99605787]\n",
            " [0.996046  ]\n",
            " [0.00601481]]\n",
            "Step: 5914 -> Loss: 0.00439962325617671 -> Predictions: [[0.00364778]\n",
            " [0.9960581 ]\n",
            " [0.9960461 ]\n",
            " [0.00601451]]\n",
            "Step: 5915 -> Loss: 0.004399420693516731 -> Predictions: [[0.00364762]\n",
            " [0.99605834]\n",
            " [0.99604636]\n",
            " [0.00601423]]\n",
            "Step: 5916 -> Loss: 0.004399218130856752 -> Predictions: [[0.00364746]\n",
            " [0.99605846]\n",
            " [0.9960465 ]\n",
            " [0.00601395]]\n",
            "Step: 5917 -> Loss: 0.00439901277422905 -> Predictions: [[0.0036473 ]\n",
            " [0.9960587 ]\n",
            " [0.9960467 ]\n",
            " [0.00601365]]\n",
            "Step: 5918 -> Loss: 0.004398807883262634 -> Predictions: [[0.00364714]\n",
            " [0.9960588 ]\n",
            " [0.99604684]\n",
            " [0.00601337]]\n",
            "Step: 5919 -> Loss: 0.004398603457957506 -> Predictions: [[0.00364698]\n",
            " [0.99605906]\n",
            " [0.9960471 ]\n",
            " [0.00601309]]\n",
            "Step: 5920 -> Loss: 0.004398397170007229 -> Predictions: [[0.00364681]\n",
            " [0.9960592 ]\n",
            " [0.9960472 ]\n",
            " [0.0060128 ]]\n",
            "Step: 5921 -> Loss: 0.004398193210363388 -> Predictions: [[0.00364665]\n",
            " [0.9960594 ]\n",
            " [0.99604744]\n",
            " [0.00601251]]\n",
            "Step: 5922 -> Loss: 0.00439798878505826 -> Predictions: [[0.00364649]\n",
            " [0.99605954]\n",
            " [0.9960477 ]\n",
            " [0.00601223]]\n",
            "Step: 5923 -> Loss: 0.00439778808504343 -> Predictions: [[0.00364634]\n",
            " [0.9960598 ]\n",
            " [0.9960478 ]\n",
            " [0.00601194]]\n",
            "Step: 5924 -> Loss: 0.004397581331431866 -> Predictions: [[0.00364617]\n",
            " [0.99605983]\n",
            " [0.99604803]\n",
            " [0.00601165]]\n",
            "Step: 5925 -> Loss: 0.004397374112159014 -> Predictions: [[0.00364601]\n",
            " [0.9960601 ]\n",
            " [0.99604815]\n",
            " [0.00601136]]\n",
            "Step: 5926 -> Loss: 0.004397171549499035 -> Predictions: [[0.00364585]\n",
            " [0.9960603 ]\n",
            " [0.9960484 ]\n",
            " [0.00601108]]\n",
            "Step: 5927 -> Loss: 0.004396968521177769 -> Predictions: [[0.00364569]\n",
            " [0.99606043]\n",
            " [0.9960485 ]\n",
            " [0.0060108 ]]\n",
            "Step: 5928 -> Loss: 0.0043967608362436295 -> Predictions: [[0.00364552]\n",
            " [0.99606067]\n",
            " [0.99604875]\n",
            " [0.00601051]]\n",
            "Step: 5929 -> Loss: 0.004396557807922363 -> Predictions: [[0.00364536]\n",
            " [0.9960608 ]\n",
            " [0.99604887]\n",
            " [0.00601022]]\n",
            "Step: 5930 -> Loss: 0.0043963538482785225 -> Predictions: [[0.0036452 ]\n",
            " [0.996061  ]\n",
            " [0.9960491 ]\n",
            " [0.00600994]]\n",
            "Step: 5931 -> Loss: 0.004396148957312107 -> Predictions: [[0.00364504]\n",
            " [0.99606115]\n",
            " [0.9960492 ]\n",
            " [0.00600965]]\n",
            "Step: 5932 -> Loss: 0.004395943135023117 -> Predictions: [[0.00364488]\n",
            " [0.9960614 ]\n",
            " [0.99604946]\n",
            " [0.00600936]]\n",
            "Step: 5933 -> Loss: 0.004395742435008287 -> Predictions: [[0.00364472]\n",
            " [0.9960615 ]\n",
            " [0.9960497 ]\n",
            " [0.00600908]]\n",
            "Step: 5934 -> Loss: 0.0043955352157354355 -> Predictions: [[0.00364455]\n",
            " [0.99606174]\n",
            " [0.9960498 ]\n",
            " [0.00600879]]\n",
            "Step: 5935 -> Loss: 0.004395334515720606 -> Predictions: [[0.0036444 ]\n",
            " [0.996062  ]\n",
            " [0.99605006]\n",
            " [0.00600851]]\n",
            "Step: 5936 -> Loss: 0.004395126830786467 -> Predictions: [[0.00364423]\n",
            " [0.9960621 ]\n",
            " [0.9960502 ]\n",
            " [0.00600822]]\n",
            "Step: 5937 -> Loss: 0.0043949238024652 -> Predictions: [[0.00364407]\n",
            " [0.99606234]\n",
            " [0.9960504 ]\n",
            " [0.00600794]]\n",
            "Step: 5938 -> Loss: 0.004394719377160072 -> Predictions: [[0.00364391]\n",
            " [0.99606246]\n",
            " [0.99605054]\n",
            " [0.00600766]]\n",
            "Step: 5939 -> Loss: 0.004394517280161381 -> Predictions: [[0.00364375]\n",
            " [0.9960627 ]\n",
            " [0.9960508 ]\n",
            " [0.00600738]]\n",
            "Step: 5940 -> Loss: 0.004394312389194965 -> Predictions: [[0.00364359]\n",
            " [0.9960628 ]\n",
            " [0.9960509 ]\n",
            " [0.00600709]]\n",
            "Step: 5941 -> Loss: 0.004394108429551125 -> Predictions: [[0.00364343]\n",
            " [0.99606305]\n",
            " [0.99605113]\n",
            " [0.00600681]]\n",
            "Step: 5942 -> Loss: 0.004393902141600847 -> Predictions: [[0.00364326]\n",
            " [0.9960632 ]\n",
            " [0.9960514 ]\n",
            " [0.00600652]]\n",
            "Step: 5943 -> Loss: 0.004393697716295719 -> Predictions: [[0.0036431 ]\n",
            " [0.9960634 ]\n",
            " [0.9960515 ]\n",
            " [0.00600623]]\n",
            "Step: 5944 -> Loss: 0.00439349515363574 -> Predictions: [[0.00364294]\n",
            " [0.99606365]\n",
            " [0.9960517 ]\n",
            " [0.00600595]]\n",
            "Step: 5945 -> Loss: 0.004393290262669325 -> Predictions: [[0.00364278]\n",
            " [0.99606377]\n",
            " [0.99605185]\n",
            " [0.00600568]]\n",
            "Step: 5946 -> Loss: 0.004393087700009346 -> Predictions: [[0.00364262]\n",
            " [0.996064  ]\n",
            " [0.9960521 ]\n",
            " [0.0060054 ]]\n",
            "Step: 5947 -> Loss: 0.004392882343381643 -> Predictions: [[0.00364246]\n",
            " [0.9960641 ]\n",
            " [0.9960522 ]\n",
            " [0.00600512]]\n",
            "Step: 5948 -> Loss: 0.004392682574689388 -> Predictions: [[0.00364231]\n",
            " [0.99606436]\n",
            " [0.9960524 ]\n",
            " [0.00600484]]\n",
            "Step: 5949 -> Loss: 0.004392473958432674 -> Predictions: [[0.00364215]\n",
            " [0.9960645 ]\n",
            " [0.9960526 ]\n",
            " [0.00600455]]\n",
            "Step: 5950 -> Loss: 0.0043922727927565575 -> Predictions: [[0.00364199]\n",
            " [0.9960647 ]\n",
            " [0.99605274]\n",
            " [0.00600427]]\n",
            "Step: 5951 -> Loss: 0.004392067901790142 -> Predictions: [[0.00364182]\n",
            " [0.99606484]\n",
            " [0.996053  ]\n",
            " [0.00600399]]\n",
            "Step: 5952 -> Loss: 0.004391866736114025 -> Predictions: [[0.00364167]\n",
            " [0.9960651 ]\n",
            " [0.9960531 ]\n",
            " [0.00600371]]\n",
            "Step: 5953 -> Loss: 0.00439166184514761 -> Predictions: [[0.00364151]\n",
            " [0.9960653 ]\n",
            " [0.99605334]\n",
            " [0.00600343]]\n",
            "Step: 5954 -> Loss: 0.004391456954181194 -> Predictions: [[0.00364135]\n",
            " [0.99606544]\n",
            " [0.99605346]\n",
            " [0.00600315]]\n",
            "Step: 5955 -> Loss: 0.004391255788505077 -> Predictions: [[0.00364119]\n",
            " [0.9960657 ]\n",
            " [0.9960537 ]\n",
            " [0.00600287]]\n",
            "Step: 5956 -> Loss: 0.004391048569232225 -> Predictions: [[0.00364103]\n",
            " [0.9960658 ]\n",
            " [0.99605393]\n",
            " [0.00600259]]\n",
            "Step: 5957 -> Loss: 0.00439084880053997 -> Predictions: [[0.00364087]\n",
            " [0.99606603]\n",
            " [0.99605405]\n",
            " [0.00600231]]\n",
            "Step: 5958 -> Loss: 0.004390643909573555 -> Predictions: [[0.00364071]\n",
            " [0.99606615]\n",
            " [0.9960543 ]\n",
            " [0.00600202]]\n",
            "Step: 5959 -> Loss: 0.004390439949929714 -> Predictions: [[0.00364055]\n",
            " [0.9960664 ]\n",
            " [0.9960544 ]\n",
            " [0.00600174]]\n",
            "Step: 5960 -> Loss: 0.004390235058963299 -> Predictions: [[0.00364039]\n",
            " [0.99606663]\n",
            " [0.99605465]\n",
            " [0.00600146]]\n",
            "Step: 5961 -> Loss: 0.004390031564980745 -> Predictions: [[0.00364023]\n",
            " [0.99606675]\n",
            " [0.99605477]\n",
            " [0.00600118]]\n",
            "Step: 5962 -> Loss: 0.004389827139675617 -> Predictions: [[0.00364007]\n",
            " [0.996067  ]\n",
            " [0.996055  ]\n",
            " [0.0060009 ]]\n",
            "Step: 5963 -> Loss: 0.004389623180031776 -> Predictions: [[0.00363991]\n",
            " [0.9960671 ]\n",
            " [0.99605525]\n",
            " [0.00600062]]\n",
            "Step: 5964 -> Loss: 0.00438942015171051 -> Predictions: [[0.00363975]\n",
            " [0.99606735]\n",
            " [0.99605536]\n",
            " [0.00600034]]\n",
            "Step: 5965 -> Loss: 0.00438921432942152 -> Predictions: [[0.00363959]\n",
            " [0.9960674 ]\n",
            " [0.9960556 ]\n",
            " [0.00600005]]\n",
            "Step: 5966 -> Loss: 0.004389012232422829 -> Predictions: [[0.00363943]\n",
            " [0.99606764]\n",
            " [0.9960557 ]\n",
            " [0.00599978]]\n",
            "Step: 5967 -> Loss: 0.0043888092041015625 -> Predictions: [[0.00363927]\n",
            " [0.99606776]\n",
            " [0.99605596]\n",
            " [0.0059995 ]]\n",
            "Step: 5968 -> Loss: 0.004388606641441584 -> Predictions: [[0.00363912]\n",
            " [0.996068  ]\n",
            " [0.9960561 ]\n",
            " [0.00599922]]\n",
            "Step: 5969 -> Loss: 0.004388401284813881 -> Predictions: [[0.00363895]\n",
            " [0.99606824]\n",
            " [0.9960563 ]\n",
            " [0.00599893]]\n",
            "Step: 5970 -> Loss: 0.004388196859508753 -> Predictions: [[0.0036388 ]\n",
            " [0.99606836]\n",
            " [0.99605656]\n",
            " [0.00599865]]\n",
            "Step: 5971 -> Loss: 0.004387993365526199 -> Predictions: [[0.00363864]\n",
            " [0.9960686 ]\n",
            " [0.9960567 ]\n",
            " [0.00599837]]\n",
            "Step: 5972 -> Loss: 0.004387792199850082 -> Predictions: [[0.00363848]\n",
            " [0.9960687 ]\n",
            " [0.9960569 ]\n",
            " [0.0059981 ]]\n",
            "Step: 5973 -> Loss: 0.00438758684322238 -> Predictions: [[0.00363832]\n",
            " [0.99606895]\n",
            " [0.99605703]\n",
            " [0.00599781]]\n",
            "Step: 5974 -> Loss: 0.004387384746223688 -> Predictions: [[0.00363816]\n",
            " [0.9960691 ]\n",
            " [0.9960573 ]\n",
            " [0.00599753]]\n",
            "Step: 5975 -> Loss: 0.00438718032091856 -> Predictions: [[0.003638  ]\n",
            " [0.9960693 ]\n",
            " [0.9960574 ]\n",
            " [0.00599725]]\n",
            "Step: 5976 -> Loss: 0.004386975429952145 -> Predictions: [[0.00363784]\n",
            " [0.99606955]\n",
            " [0.9960576 ]\n",
            " [0.00599697]]\n",
            "Step: 5977 -> Loss: 0.004386770538985729 -> Predictions: [[0.00363768]\n",
            " [0.99606967]\n",
            " [0.99605787]\n",
            " [0.00599669]]\n",
            "Step: 5978 -> Loss: 0.004386569373309612 -> Predictions: [[0.00363752]\n",
            " [0.9960699 ]\n",
            " [0.996058  ]\n",
            " [0.00599641]]\n",
            "Step: 5979 -> Loss: 0.004386366810649633 -> Predictions: [[0.00363736]\n",
            " [0.99607   ]\n",
            " [0.9960582 ]\n",
            " [0.00599613]]\n",
            "Step: 5980 -> Loss: 0.004386161454021931 -> Predictions: [[0.0036372 ]\n",
            " [0.99607027]\n",
            " [0.99605834]\n",
            " [0.00599585]]\n",
            "Step: 5981 -> Loss: 0.004385961685329676 -> Predictions: [[0.00363705]\n",
            " [0.9960704 ]\n",
            " [0.9960586 ]\n",
            " [0.00599557]]\n",
            "Step: 5982 -> Loss: 0.004385754466056824 -> Predictions: [[0.00363689]\n",
            " [0.9960706 ]\n",
            " [0.9960587 ]\n",
            " [0.00599529]]\n",
            "Step: 5983 -> Loss: 0.004385555163025856 -> Predictions: [[0.00363673]\n",
            " [0.99607086]\n",
            " [0.99605894]\n",
            " [0.00599501]]\n",
            "Step: 5984 -> Loss: 0.004385346546769142 -> Predictions: [[0.00363657]\n",
            " [0.996071  ]\n",
            " [0.9960592 ]\n",
            " [0.00599472]]\n",
            "Step: 5985 -> Loss: 0.0043851463124156 -> Predictions: [[0.00363641]\n",
            " [0.9960712 ]\n",
            " [0.9960593 ]\n",
            " [0.00599445]]\n",
            "Step: 5986 -> Loss: 0.004384942818433046 -> Predictions: [[0.00363625]\n",
            " [0.99607134]\n",
            " [0.99605954]\n",
            " [0.00599416]]\n",
            "Step: 5987 -> Loss: 0.004384737461805344 -> Predictions: [[0.00363609]\n",
            " [0.9960716 ]\n",
            " [0.99605966]\n",
            " [0.00599388]]\n",
            "Step: 5988 -> Loss: 0.0043845344334840775 -> Predictions: [[0.00363593]\n",
            " [0.9960717 ]\n",
            " [0.99605983]\n",
            " [0.0059936 ]]\n",
            "Step: 5989 -> Loss: 0.004384332336485386 -> Predictions: [[0.00363577]\n",
            " [0.99607193]\n",
            " [0.99605995]\n",
            " [0.00599332]]\n",
            "Step: 5990 -> Loss: 0.004384128376841545 -> Predictions: [[0.00363561]\n",
            " [0.99607205]\n",
            " [0.9960602 ]\n",
            " [0.00599304]]\n",
            "Step: 5991 -> Loss: 0.00438392348587513 -> Predictions: [[0.00363545]\n",
            " [0.9960723 ]\n",
            " [0.99606043]\n",
            " [0.00599276]]\n",
            "Step: 5992 -> Loss: 0.004383721388876438 -> Predictions: [[0.00363529]\n",
            " [0.99607253]\n",
            " [0.99606055]\n",
            " [0.00599248]]\n",
            "Step: 5993 -> Loss: 0.004383517894893885 -> Predictions: [[0.00363513]\n",
            " [0.99607265]\n",
            " [0.9960608 ]\n",
            " [0.0059922 ]]\n",
            "Step: 5994 -> Loss: 0.0043833134695887566 -> Predictions: [[0.00363497]\n",
            " [0.9960729 ]\n",
            " [0.9960609 ]\n",
            " [0.00599192]]\n",
            "Step: 5995 -> Loss: 0.004383113235235214 -> Predictions: [[0.00363482]\n",
            " [0.996073  ]\n",
            " [0.99606115]\n",
            " [0.00599164]]\n",
            "Step: 5996 -> Loss: 0.004382908809930086 -> Predictions: [[0.00363466]\n",
            " [0.99607325]\n",
            " [0.99606127]\n",
            " [0.00599136]]\n",
            "Step: 5997 -> Loss: 0.004382703453302383 -> Predictions: [[0.0036345 ]\n",
            " [0.99607337]\n",
            " [0.9960615 ]\n",
            " [0.00599108]]\n",
            "Step: 5998 -> Loss: 0.004382498096674681 -> Predictions: [[0.00363433]\n",
            " [0.9960736 ]\n",
            " [0.99606174]\n",
            " [0.0059908 ]]\n",
            "Step: 5999 -> Loss: 0.0043822964653372765 -> Predictions: [[0.00363418]\n",
            " [0.99607384]\n",
            " [0.99606186]\n",
            " [0.00599051]]\n",
            "Step: 6001 -> Loss: 0.004382074810564518 -> Predictions: [[0.003634  ]\n",
            " [0.99607396]\n",
            " [0.9960621 ]\n",
            " [0.00599021]]\n",
            "Step: 6002 -> Loss: 0.004382053390145302 -> Predictions: [[0.00363398]\n",
            " [0.99607396]\n",
            " [0.9960621 ]\n",
            " [0.00599018]]\n",
            "Step: 6003 -> Loss: 0.004382031969726086 -> Predictions: [[0.00363397]\n",
            " [0.99607396]\n",
            " [0.9960621 ]\n",
            " [0.00599015]]\n",
            "Step: 6004 -> Loss: 0.004382013808935881 -> Predictions: [[0.00363395]\n",
            " [0.9960741 ]\n",
            " [0.9960621 ]\n",
            " [0.00599012]]\n",
            "Step: 6005 -> Loss: 0.00438199145719409 -> Predictions: [[0.00363394]\n",
            " [0.9960741 ]\n",
            " [0.9960621 ]\n",
            " [0.00599009]]\n",
            "Step: 6006 -> Loss: 0.004381970968097448 -> Predictions: [[0.00363392]\n",
            " [0.9960741 ]\n",
            " [0.9960622 ]\n",
            " [0.00599005]]\n",
            "Step: 6007 -> Loss: 0.004381952807307243 -> Predictions: [[0.0036339 ]\n",
            " [0.9960741 ]\n",
            " [0.9960622 ]\n",
            " [0.00599003]]\n",
            "Step: 6008 -> Loss: 0.004381929058581591 -> Predictions: [[0.00363389]\n",
            " [0.9960741 ]\n",
            " [0.9960622 ]\n",
            " [0.00598999]]\n",
            "Step: 6009 -> Loss: 0.004381909966468811 -> Predictions: [[0.00363387]\n",
            " [0.9960741 ]\n",
            " [0.9960622 ]\n",
            " [0.00598997]]\n",
            "Step: 6010 -> Loss: 0.004381886683404446 -> Predictions: [[0.00363385]\n",
            " [0.9960742 ]\n",
            " [0.9960622 ]\n",
            " [0.00598993]]\n",
            "Step: 6011 -> Loss: 0.004381869453936815 -> Predictions: [[0.00363384]\n",
            " [0.9960742 ]\n",
            " [0.9960622 ]\n",
            " [0.00598991]]\n",
            "Step: 6012 -> Loss: 0.004381849430501461 -> Predictions: [[0.00363382]\n",
            " [0.9960742 ]\n",
            " [0.9960622 ]\n",
            " [0.00598988]]\n",
            "Step: 6013 -> Loss: 0.004381829872727394 -> Predictions: [[0.00363381]\n",
            " [0.9960742 ]\n",
            " [0.99606234]\n",
            " [0.00598985]]\n",
            "Step: 6014 -> Loss: 0.0043818093836307526 -> Predictions: [[0.00363379]\n",
            " [0.9960742 ]\n",
            " [0.99606234]\n",
            " [0.00598982]]\n",
            "Step: 6015 -> Loss: 0.004381788894534111 -> Predictions: [[0.00363378]\n",
            " [0.9960742 ]\n",
            " [0.99606234]\n",
            " [0.00598979]]\n",
            "Step: 6016 -> Loss: 0.004381765611469746 -> Predictions: [[0.00363376]\n",
            " [0.9960742 ]\n",
            " [0.99606234]\n",
            " [0.00598976]]\n",
            "Step: 6017 -> Loss: 0.004381747450679541 -> Predictions: [[0.00363374]\n",
            " [0.9960743 ]\n",
            " [0.99606234]\n",
            " [0.00598973]]\n",
            "Step: 6018 -> Loss: 0.004381728358566761 -> Predictions: [[0.00363373]\n",
            " [0.9960743 ]\n",
            " [0.99606234]\n",
            " [0.0059897 ]]\n",
            "Step: 6019 -> Loss: 0.004381704144179821 -> Predictions: [[0.00363371]\n",
            " [0.9960743 ]\n",
            " [0.99606234]\n",
            " [0.00598967]]\n",
            "Step: 6020 -> Loss: 0.004381685517728329 -> Predictions: [[0.00363369]\n",
            " [0.9960743 ]\n",
            " [0.99606246]\n",
            " [0.00598964]]\n",
            "Step: 6021 -> Loss: 0.0043816654942929745 -> Predictions: [[0.00363368]\n",
            " [0.9960743 ]\n",
            " [0.99606246]\n",
            " [0.0059896 ]]\n",
            "Step: 6022 -> Loss: 0.0043816473335027695 -> Predictions: [[0.00363366]\n",
            " [0.9960743 ]\n",
            " [0.99606246]\n",
            " [0.00598958]]\n",
            "Step: 6023 -> Loss: 0.004381624981760979 -> Predictions: [[0.00363364]\n",
            " [0.9960743 ]\n",
            " [0.99606246]\n",
            " [0.00598955]]\n",
            "Step: 6024 -> Loss: 0.00438160402700305 -> Predictions: [[0.00363363]\n",
            " [0.99607444]\n",
            " [0.99606246]\n",
            " [0.00598952]]\n",
            "Step: 6025 -> Loss: 0.004381582140922546 -> Predictions: [[0.00363361]\n",
            " [0.99607444]\n",
            " [0.99606246]\n",
            " [0.00598948]]\n",
            "Step: 6026 -> Loss: 0.004381563980132341 -> Predictions: [[0.0036336 ]\n",
            " [0.99607444]\n",
            " [0.99606246]\n",
            " [0.00598946]]\n",
            "Step: 6027 -> Loss: 0.004381545819342136 -> Predictions: [[0.00363357]\n",
            " [0.99607444]\n",
            " [0.9960626 ]\n",
            " [0.00598943]]\n",
            "Step: 6028 -> Loss: 0.00438151927664876 -> Predictions: [[0.00363356]\n",
            " [0.99607444]\n",
            " [0.9960626 ]\n",
            " [0.00598939]]\n",
            "Step: 6029 -> Loss: 0.004381505306810141 -> Predictions: [[0.00363355]\n",
            " [0.99607444]\n",
            " [0.9960626 ]\n",
            " [0.00598937]]\n",
            "Step: 6030 -> Loss: 0.004381483420729637 -> Predictions: [[0.00363353]\n",
            " [0.99607444]\n",
            " [0.9960626 ]\n",
            " [0.00598934]]\n",
            "Step: 6031 -> Loss: 0.004381460137665272 -> Predictions: [[0.00363351]\n",
            " [0.99607456]\n",
            " [0.9960626 ]\n",
            " [0.00598931]]\n",
            "Step: 6032 -> Loss: 0.004381439182907343 -> Predictions: [[0.00363349]\n",
            " [0.99607456]\n",
            " [0.9960626 ]\n",
            " [0.00598927]]\n",
            "Step: 6033 -> Loss: 0.004381420090794563 -> Predictions: [[0.00363348]\n",
            " [0.99607456]\n",
            " [0.9960627 ]\n",
            " [0.00598925]]\n",
            "Step: 6034 -> Loss: 0.004381400067359209 -> Predictions: [[0.00363346]\n",
            " [0.99607456]\n",
            " [0.9960627 ]\n",
            " [0.00598922]]\n",
            "Step: 6035 -> Loss: 0.0043813795782625675 -> Predictions: [[0.00363344]\n",
            " [0.99607456]\n",
            " [0.9960627 ]\n",
            " [0.00598919]]\n",
            "Step: 6036 -> Loss: 0.004381360486149788 -> Predictions: [[0.00363343]\n",
            " [0.99607456]\n",
            " [0.9960627 ]\n",
            " [0.00598916]]\n",
            "Step: 6037 -> Loss: 0.004381340928375721 -> Predictions: [[0.00363341]\n",
            " [0.9960747 ]\n",
            " [0.9960627 ]\n",
            " [0.00598913]]\n",
            "Step: 6038 -> Loss: 0.004381316713988781 -> Predictions: [[0.00363339]\n",
            " [0.9960747 ]\n",
            " [0.9960627 ]\n",
            " [0.00598909]]\n",
            "Step: 6039 -> Loss: 0.004381299018859863 -> Predictions: [[0.00363338]\n",
            " [0.9960747 ]\n",
            " [0.9960627 ]\n",
            " [0.00598907]]\n",
            "Step: 6040 -> Loss: 0.004381279926747084 -> Predictions: [[0.00363336]\n",
            " [0.9960747 ]\n",
            " [0.9960628 ]\n",
            " [0.00598904]]\n",
            "Step: 6041 -> Loss: 0.004381257575005293 -> Predictions: [[0.00363335]\n",
            " [0.9960747 ]\n",
            " [0.9960628 ]\n",
            " [0.00598901]]\n",
            "Step: 6042 -> Loss: 0.004381236620247364 -> Predictions: [[0.00363333]\n",
            " [0.9960747 ]\n",
            " [0.9960628 ]\n",
            " [0.00598898]]\n",
            "Step: 6043 -> Loss: 0.004381218925118446 -> Predictions: [[0.00363332]\n",
            " [0.9960747 ]\n",
            " [0.9960628 ]\n",
            " [0.00598895]]\n",
            "Step: 6044 -> Loss: 0.004381195642054081 -> Predictions: [[0.00363329]\n",
            " [0.9960748 ]\n",
            " [0.9960628 ]\n",
            " [0.00598892]]\n",
            "Step: 6045 -> Loss: 0.004381175618618727 -> Predictions: [[0.00363328]\n",
            " [0.9960748 ]\n",
            " [0.9960628 ]\n",
            " [0.00598889]]\n",
            "Step: 6046 -> Loss: 0.004381157457828522 -> Predictions: [[0.00363327]\n",
            " [0.9960748 ]\n",
            " [0.9960628 ]\n",
            " [0.00598886]]\n",
            "Step: 6047 -> Loss: 0.004381136503070593 -> Predictions: [[0.00363325]\n",
            " [0.9960748 ]\n",
            " [0.99606293]\n",
            " [0.00598883]]\n",
            "Step: 6048 -> Loss: 0.004381116479635239 -> Predictions: [[0.00363323]\n",
            " [0.9960748 ]\n",
            " [0.99606293]\n",
            " [0.0059888 ]]\n",
            "Step: 6049 -> Loss: 0.004381091799587011 -> Predictions: [[0.00363321]\n",
            " [0.9960748 ]\n",
            " [0.99606293]\n",
            " [0.00598876]]\n",
            "Step: 6050 -> Loss: 0.004381073638796806 -> Predictions: [[0.0036332 ]\n",
            " [0.9960748 ]\n",
            " [0.99606293]\n",
            " [0.00598874]]\n",
            "Step: 6051 -> Loss: 0.00438105221837759 -> Predictions: [[0.00363318]\n",
            " [0.99607486]\n",
            " [0.99606293]\n",
            " [0.00598871]]\n",
            "Step: 6052 -> Loss: 0.004381033591926098 -> Predictions: [[0.00363317]\n",
            " [0.99607486]\n",
            " [0.99606293]\n",
            " [0.00598868]]\n",
            "Step: 6053 -> Loss: 0.004381012171506882 -> Predictions: [[0.00363315]\n",
            " [0.99607486]\n",
            " [0.99606293]\n",
            " [0.00598865]]\n",
            "Step: 6054 -> Loss: 0.004380992613732815 -> Predictions: [[0.00363313]\n",
            " [0.99607486]\n",
            " [0.99606305]\n",
            " [0.00598862]]\n",
            "Step: 6055 -> Loss: 0.004380972124636173 -> Predictions: [[0.00363312]\n",
            " [0.99607486]\n",
            " [0.99606305]\n",
            " [0.00598858]]\n",
            "Step: 6056 -> Loss: 0.004380953498184681 -> Predictions: [[0.0036331 ]\n",
            " [0.99607486]\n",
            " [0.99606305]\n",
            " [0.00598856]]\n",
            "Step: 6057 -> Loss: 0.004380933009088039 -> Predictions: [[0.00363309]\n",
            " [0.99607486]\n",
            " [0.99606305]\n",
            " [0.00598853]]\n",
            "Step: 6058 -> Loss: 0.004380910191684961 -> Predictions: [[0.00363307]\n",
            " [0.996075  ]\n",
            " [0.99606305]\n",
            " [0.0059885 ]]\n",
            "Step: 6059 -> Loss: 0.004380890168249607 -> Predictions: [[0.00363305]\n",
            " [0.996075  ]\n",
            " [0.99606305]\n",
            " [0.00598847]]\n",
            "Step: 6060 -> Loss: 0.004380870144814253 -> Predictions: [[0.00363303]\n",
            " [0.996075  ]\n",
            " [0.99606305]\n",
            " [0.00598844]]\n",
            "Step: 6061 -> Loss: 0.004380850587040186 -> Predictions: [[0.00363302]\n",
            " [0.996075  ]\n",
            " [0.9960632 ]\n",
            " [0.00598841]]\n",
            "Step: 6062 -> Loss: 0.004380830097943544 -> Predictions: [[0.003633  ]\n",
            " [0.996075  ]\n",
            " [0.9960632 ]\n",
            " [0.00598838]]\n",
            "Step: 6063 -> Loss: 0.004380808677524328 -> Predictions: [[0.00363299]\n",
            " [0.996075  ]\n",
            " [0.9960632 ]\n",
            " [0.00598835]]\n",
            "Step: 6064 -> Loss: 0.004380787257105112 -> Predictions: [[0.00363297]\n",
            " [0.996075  ]\n",
            " [0.9960632 ]\n",
            " [0.00598831]]\n",
            "Step: 6065 -> Loss: 0.004380769096314907 -> Predictions: [[0.00363295]\n",
            " [0.9960751 ]\n",
            " [0.9960632 ]\n",
            " [0.00598829]]\n",
            "Step: 6066 -> Loss: 0.0043807486072182655 -> Predictions: [[0.00363294]\n",
            " [0.9960751 ]\n",
            " [0.9960632 ]\n",
            " [0.00598826]]\n",
            "Step: 6067 -> Loss: 0.004380727652460337 -> Predictions: [[0.00363292]\n",
            " [0.9960751 ]\n",
            " [0.9960632 ]\n",
            " [0.00598823]]\n",
            "Step: 6068 -> Loss: 0.004380705766379833 -> Predictions: [[0.0036329 ]\n",
            " [0.9960751 ]\n",
            " [0.9960633 ]\n",
            " [0.00598819]]\n",
            "Step: 6069 -> Loss: 0.004380686208605766 -> Predictions: [[0.00363289]\n",
            " [0.9960751 ]\n",
            " [0.9960633 ]\n",
            " [0.00598817]]\n",
            "Step: 6070 -> Loss: 0.004380665719509125 -> Predictions: [[0.00363287]\n",
            " [0.9960751 ]\n",
            " [0.9960633 ]\n",
            " [0.00598814]]\n",
            "Step: 6071 -> Loss: 0.004380644299089909 -> Predictions: [[0.00363285]\n",
            " [0.9960752 ]\n",
            " [0.9960633 ]\n",
            " [0.00598811]]\n",
            "Step: 6072 -> Loss: 0.004380626603960991 -> Predictions: [[0.00363284]\n",
            " [0.9960752 ]\n",
            " [0.9960633 ]\n",
            " [0.00598808]]\n",
            "Step: 6073 -> Loss: 0.004380603786557913 -> Predictions: [[0.00363282]\n",
            " [0.9960752 ]\n",
            " [0.9960633 ]\n",
            " [0.00598804]]\n",
            "Step: 6074 -> Loss: 0.0043805805034935474 -> Predictions: [[0.0036328 ]\n",
            " [0.9960752 ]\n",
            " [0.9960634 ]\n",
            " [0.00598801]]\n",
            "Step: 6075 -> Loss: 0.004380561877042055 -> Predictions: [[0.00363279]\n",
            " [0.9960752 ]\n",
            " [0.9960634 ]\n",
            " [0.00598799]]\n",
            "Step: 6076 -> Loss: 0.004380541853606701 -> Predictions: [[0.00363277]\n",
            " [0.9960752 ]\n",
            " [0.9960634 ]\n",
            " [0.00598795]]\n",
            "Step: 6077 -> Loss: 0.004380524158477783 -> Predictions: [[0.00363275]\n",
            " [0.9960752 ]\n",
            " [0.9960634 ]\n",
            " [0.00598793]]\n",
            "Step: 6078 -> Loss: 0.004380503203719854 -> Predictions: [[0.00363274]\n",
            " [0.99607533]\n",
            " [0.9960634 ]\n",
            " [0.0059879 ]]\n",
            "Step: 6079 -> Loss: 0.0043804822489619255 -> Predictions: [[0.00363272]\n",
            " [0.99607533]\n",
            " [0.9960634 ]\n",
            " [0.00598787]]\n",
            "Step: 6080 -> Loss: 0.004380462691187859 -> Predictions: [[0.00363271]\n",
            " [0.99607533]\n",
            " [0.9960634 ]\n",
            " [0.00598784]]\n",
            "Step: 6081 -> Loss: 0.004380440339446068 -> Predictions: [[0.00363269]\n",
            " [0.99607533]\n",
            " [0.99606353]\n",
            " [0.00598781]]\n",
            "Step: 6082 -> Loss: 0.00438042264431715 -> Predictions: [[0.00363267]\n",
            " [0.99607533]\n",
            " [0.99606353]\n",
            " [0.00598778]]\n",
            "Step: 6083 -> Loss: 0.004380402155220509 -> Predictions: [[0.00363266]\n",
            " [0.99607533]\n",
            " [0.99606353]\n",
            " [0.00598775]]\n",
            "Step: 6084 -> Loss: 0.004380377940833569 -> Predictions: [[0.00363264]\n",
            " [0.99607533]\n",
            " [0.99606353]\n",
            " [0.00598772]]\n",
            "Step: 6085 -> Loss: 0.004380361642688513 -> Predictions: [[0.00363262]\n",
            " [0.99607545]\n",
            " [0.99606353]\n",
            " [0.0059877 ]]\n",
            "Step: 6086 -> Loss: 0.004380338359624147 -> Predictions: [[0.00363261]\n",
            " [0.99607545]\n",
            " [0.99606353]\n",
            " [0.00598765]]\n",
            "Step: 6087 -> Loss: 0.0043803188018500805 -> Predictions: [[0.00363259]\n",
            " [0.99607545]\n",
            " [0.99606353]\n",
            " [0.00598763]]\n",
            "Step: 6088 -> Loss: 0.004380295518785715 -> Predictions: [[0.00363257]\n",
            " [0.99607545]\n",
            " [0.99606365]\n",
            " [0.00598759]]\n",
            "Step: 6089 -> Loss: 0.004380280151963234 -> Predictions: [[0.00363256]\n",
            " [0.99607545]\n",
            " [0.99606365]\n",
            " [0.00598757]]\n",
            "Step: 6090 -> Loss: 0.004380257800221443 -> Predictions: [[0.00363254]\n",
            " [0.99607545]\n",
            " [0.99606365]\n",
            " [0.00598754]]\n",
            "Step: 6091 -> Loss: 0.004380234982818365 -> Predictions: [[0.00363252]\n",
            " [0.99607545]\n",
            " [0.99606365]\n",
            " [0.0059875 ]]\n",
            "Step: 6092 -> Loss: 0.004380217753350735 -> Predictions: [[0.00363251]\n",
            " [0.9960756 ]\n",
            " [0.99606365]\n",
            " [0.00598748]]\n",
            "Step: 6093 -> Loss: 0.004380197264254093 -> Predictions: [[0.00363249]\n",
            " [0.9960756 ]\n",
            " [0.99606365]\n",
            " [0.00598745]]\n",
            "Step: 6094 -> Loss: 0.004380176309496164 -> Predictions: [[0.00363247]\n",
            " [0.9960756 ]\n",
            " [0.99606365]\n",
            " [0.00598742]]\n",
            "Step: 6095 -> Loss: 0.0043801553547382355 -> Predictions: [[0.00363246]\n",
            " [0.9960756 ]\n",
            " [0.99606377]\n",
            " [0.00598739]]\n",
            "Step: 6096 -> Loss: 0.004380134865641594 -> Predictions: [[0.00363244]\n",
            " [0.9960756 ]\n",
            " [0.99606377]\n",
            " [0.00598736]]\n",
            "Step: 6097 -> Loss: 0.004380113910883665 -> Predictions: [[0.00363243]\n",
            " [0.9960756 ]\n",
            " [0.99606377]\n",
            " [0.00598733]]\n",
            "Step: 6098 -> Loss: 0.00438009575009346 -> Predictions: [[0.00363241]\n",
            " [0.9960756 ]\n",
            " [0.99606377]\n",
            " [0.0059873 ]]\n",
            "Step: 6099 -> Loss: 0.004380072001367807 -> Predictions: [[0.00363239]\n",
            " [0.9960757 ]\n",
            " [0.99606377]\n",
            " [0.00598727]]\n",
            "Step: 6100 -> Loss: 0.0043800524435937405 -> Predictions: [[0.00363238]\n",
            " [0.9960757 ]\n",
            " [0.99606377]\n",
            " [0.00598723]]\n",
            "Step: 6101 -> Loss: 0.004380033351480961 -> Predictions: [[0.00363236]\n",
            " [0.9960757 ]\n",
            " [0.9960639 ]\n",
            " [0.00598721]]\n",
            "Step: 6102 -> Loss: 0.004380013328045607 -> Predictions: [[0.00363234]\n",
            " [0.9960757 ]\n",
            " [0.9960639 ]\n",
            " [0.00598718]]\n",
            "Step: 6103 -> Loss: 0.004379992373287678 -> Predictions: [[0.00363232]\n",
            " [0.9960757 ]\n",
            " [0.9960639 ]\n",
            " [0.00598715]]\n",
            "Step: 6104 -> Loss: 0.004379970487207174 -> Predictions: [[0.00363231]\n",
            " [0.9960757 ]\n",
            " [0.9960639 ]\n",
            " [0.00598711]]\n",
            "Step: 6105 -> Loss: 0.004379949066787958 -> Predictions: [[0.00363229]\n",
            " [0.9960758 ]\n",
            " [0.9960639 ]\n",
            " [0.00598709]]\n",
            "Step: 6106 -> Loss: 0.004379933699965477 -> Predictions: [[0.00363228]\n",
            " [0.9960758 ]\n",
            " [0.9960639 ]\n",
            " [0.00598706]]\n",
            "Step: 6107 -> Loss: 0.004379911348223686 -> Predictions: [[0.00363226]\n",
            " [0.9960758 ]\n",
            " [0.9960639 ]\n",
            " [0.00598703]]\n",
            "Step: 6108 -> Loss: 0.004379890393465757 -> Predictions: [[0.00363224]\n",
            " [0.9960758 ]\n",
            " [0.996064  ]\n",
            " [0.005987  ]]\n",
            "Step: 6109 -> Loss: 0.004379872232675552 -> Predictions: [[0.00363223]\n",
            " [0.9960758 ]\n",
            " [0.996064  ]\n",
            " [0.00598697]]\n",
            "Step: 6110 -> Loss: 0.004379849880933762 -> Predictions: [[0.00363222]\n",
            " [0.9960758 ]\n",
            " [0.996064  ]\n",
            " [0.00598693]]\n",
            "Step: 6111 -> Loss: 0.00437982939183712 -> Predictions: [[0.0036322 ]\n",
            " [0.9960758 ]\n",
            " [0.996064  ]\n",
            " [0.00598691]]\n",
            "Step: 6112 -> Loss: 0.0043798089027404785 -> Predictions: [[0.00363218]\n",
            " [0.9960759 ]\n",
            " [0.996064  ]\n",
            " [0.00598688]]\n",
            "Step: 6113 -> Loss: 0.004379787016659975 -> Predictions: [[0.00363216]\n",
            " [0.9960759 ]\n",
            " [0.996064  ]\n",
            " [0.00598685]]\n",
            "Step: 6114 -> Loss: 0.004379765596240759 -> Predictions: [[0.00363214]\n",
            " [0.9960759 ]\n",
            " [0.996064  ]\n",
            " [0.00598681]]\n",
            "Step: 6115 -> Loss: 0.004379746504127979 -> Predictions: [[0.00363213]\n",
            " [0.9960759 ]\n",
            " [0.9960641 ]\n",
            " [0.00598678]]\n",
            "Step: 6116 -> Loss: 0.004379726946353912 -> Predictions: [[0.00363212]\n",
            " [0.9960759 ]\n",
            " [0.9960641 ]\n",
            " [0.00598675]]\n",
            "Step: 6117 -> Loss: 0.004379707388579845 -> Predictions: [[0.0036321 ]\n",
            " [0.9960759 ]\n",
            " [0.9960641 ]\n",
            " [0.00598673]]\n",
            "Step: 6118 -> Loss: 0.004379686899483204 -> Predictions: [[0.00363208]\n",
            " [0.9960759 ]\n",
            " [0.9960641 ]\n",
            " [0.0059867 ]]\n",
            "Step: 6119 -> Loss: 0.004379663150757551 -> Predictions: [[0.00363206]\n",
            " [0.99607605]\n",
            " [0.9960641 ]\n",
            " [0.00598667]]\n",
            "Step: 6120 -> Loss: 0.00437964778393507 -> Predictions: [[0.00363205]\n",
            " [0.99607605]\n",
            " [0.9960641 ]\n",
            " [0.00598664]]\n",
            "Step: 6121 -> Loss: 0.004379624966531992 -> Predictions: [[0.00363203]\n",
            " [0.99607605]\n",
            " [0.9960641 ]\n",
            " [0.00598661]]\n",
            "Step: 6122 -> Loss: 0.004379605408757925 -> Predictions: [[0.00363202]\n",
            " [0.99607605]\n",
            " [0.99606425]\n",
            " [0.00598658]]\n",
            "Step: 6123 -> Loss: 0.004379585385322571 -> Predictions: [[0.003632  ]\n",
            " [0.99607605]\n",
            " [0.99606425]\n",
            " [0.00598655]]\n",
            "Step: 6124 -> Loss: 0.00437956303358078 -> Predictions: [[0.00363198]\n",
            " [0.99607605]\n",
            " [0.99606425]\n",
            " [0.00598651]]\n",
            "Step: 6125 -> Loss: 0.004379543010145426 -> Predictions: [[0.00363196]\n",
            " [0.99607605]\n",
            " [0.99606425]\n",
            " [0.00598649]]\n",
            "Step: 6126 -> Loss: 0.0043795229867100716 -> Predictions: [[0.00363195]\n",
            " [0.99607617]\n",
            " [0.99606425]\n",
            " [0.00598646]]\n",
            "Step: 6127 -> Loss: 0.004379501566290855 -> Predictions: [[0.00363193]\n",
            " [0.99607617]\n",
            " [0.99606425]\n",
            " [0.00598643]]\n",
            "Step: 6128 -> Loss: 0.0043794820085167885 -> Predictions: [[0.00363192]\n",
            " [0.99607617]\n",
            " [0.99606425]\n",
            " [0.0059864 ]]\n",
            "Step: 6129 -> Loss: 0.004379462916404009 -> Predictions: [[0.0036319 ]\n",
            " [0.99607617]\n",
            " [0.99606436]\n",
            " [0.00598637]]\n",
            "Step: 6130 -> Loss: 0.004379443824291229 -> Predictions: [[0.00363188]\n",
            " [0.99607617]\n",
            " [0.99606436]\n",
            " [0.00598634]]\n",
            "Step: 6131 -> Loss: 0.004379419609904289 -> Predictions: [[0.00363187]\n",
            " [0.99607617]\n",
            " [0.99606436]\n",
            " [0.0059863 ]]\n",
            "Step: 6132 -> Loss: 0.004379399586468935 -> Predictions: [[0.00363185]\n",
            " [0.99607617]\n",
            " [0.99606436]\n",
            " [0.00598628]]\n",
            "Step: 6133 -> Loss: 0.004379380494356155 -> Predictions: [[0.00363184]\n",
            " [0.9960763 ]\n",
            " [0.99606436]\n",
            " [0.00598624]]\n",
            "Step: 6134 -> Loss: 0.004379359073936939 -> Predictions: [[0.00363182]\n",
            " [0.9960763 ]\n",
            " [0.99606436]\n",
            " [0.00598621]]\n",
            "Step: 6135 -> Loss: 0.004379338584840298 -> Predictions: [[0.0036318 ]\n",
            " [0.9960763 ]\n",
            " [0.9960645 ]\n",
            " [0.00598618]]\n",
            "Step: 6136 -> Loss: 0.004379318095743656 -> Predictions: [[0.00363178]\n",
            " [0.9960763 ]\n",
            " [0.9960645 ]\n",
            " [0.00598616]]\n",
            "Step: 6137 -> Loss: 0.004379299934953451 -> Predictions: [[0.00363177]\n",
            " [0.9960763 ]\n",
            " [0.9960645 ]\n",
            " [0.00598613]]\n",
            "Step: 6138 -> Loss: 0.004379278980195522 -> Predictions: [[0.00363176]\n",
            " [0.9960763 ]\n",
            " [0.9960645 ]\n",
            " [0.00598609]]\n",
            "Step: 6139 -> Loss: 0.004379259422421455 -> Predictions: [[0.00363174]\n",
            " [0.9960763 ]\n",
            " [0.9960645 ]\n",
            " [0.00598607]]\n",
            "Step: 6140 -> Loss: 0.00437923613935709 -> Predictions: [[0.00363172]\n",
            " [0.9960764 ]\n",
            " [0.9960645 ]\n",
            " [0.00598603]]\n",
            "Step: 6141 -> Loss: 0.004379216581583023 -> Predictions: [[0.00363171]\n",
            " [0.9960764 ]\n",
            " [0.9960645 ]\n",
            " [0.005986  ]]\n",
            "Step: 6142 -> Loss: 0.0043791960924863815 -> Predictions: [[0.00363169]\n",
            " [0.9960764 ]\n",
            " [0.9960646 ]\n",
            " [0.00598598]]\n",
            "Step: 6143 -> Loss: 0.004379176534712315 -> Predictions: [[0.00363167]\n",
            " [0.9960764 ]\n",
            " [0.9960646 ]\n",
            " [0.00598595]]\n",
            "Step: 6144 -> Loss: 0.004379156045615673 -> Predictions: [[0.00363165]\n",
            " [0.9960764 ]\n",
            " [0.9960646 ]\n",
            " [0.00598592]]\n",
            "Step: 6145 -> Loss: 0.004379137884825468 -> Predictions: [[0.00363164]\n",
            " [0.9960764 ]\n",
            " [0.9960646 ]\n",
            " [0.00598589]]\n",
            "Step: 6146 -> Loss: 0.004379116464406252 -> Predictions: [[0.00363162]\n",
            " [0.9960764 ]\n",
            " [0.9960646 ]\n",
            " [0.00598586]]\n",
            "Step: 6147 -> Loss: 0.004379095509648323 -> Predictions: [[0.00363161]\n",
            " [0.9960765 ]\n",
            " [0.9960646 ]\n",
            " [0.00598583]]\n",
            "Step: 6148 -> Loss: 0.004379074089229107 -> Predictions: [[0.00363159]\n",
            " [0.9960765 ]\n",
            " [0.9960646 ]\n",
            " [0.0059858 ]]\n",
            "Step: 6149 -> Loss: 0.004379054065793753 -> Predictions: [[0.00363157]\n",
            " [0.9960765 ]\n",
            " [0.9960647 ]\n",
            " [0.00598577]]\n",
            "Step: 6150 -> Loss: 0.004379033111035824 -> Predictions: [[0.00363155]\n",
            " [0.9960765 ]\n",
            " [0.9960647 ]\n",
            " [0.00598573]]\n",
            "Step: 6151 -> Loss: 0.004379012621939182 -> Predictions: [[0.00363154]\n",
            " [0.9960765 ]\n",
            " [0.9960647 ]\n",
            " [0.00598571]]\n",
            "Step: 6152 -> Loss: 0.004378993064165115 -> Predictions: [[0.00363153]\n",
            " [0.9960765 ]\n",
            " [0.9960647 ]\n",
            " [0.00598568]]\n",
            "Step: 6153 -> Loss: 0.004378972575068474 -> Predictions: [[0.00363151]\n",
            " [0.99607664]\n",
            " [0.9960647 ]\n",
            " [0.00598564]]\n",
            "Step: 6154 -> Loss: 0.004378950223326683 -> Predictions: [[0.00363149]\n",
            " [0.99607664]\n",
            " [0.9960647 ]\n",
            " [0.00598561]]\n",
            "Step: 6155 -> Loss: 0.00437893345952034 -> Predictions: [[0.00363148]\n",
            " [0.99607664]\n",
            " [0.9960647 ]\n",
            " [0.00598559]]\n",
            "Step: 6156 -> Loss: 0.004378911107778549 -> Predictions: [[0.00363145]\n",
            " [0.99607664]\n",
            " [0.99606484]\n",
            " [0.00598556]]\n",
            "Step: 6157 -> Loss: 0.004378891084343195 -> Predictions: [[0.00363144]\n",
            " [0.99607664]\n",
            " [0.99606484]\n",
            " [0.00598553]]\n",
            "Step: 6158 -> Loss: 0.004378870595246553 -> Predictions: [[0.00363143]\n",
            " [0.99607664]\n",
            " [0.99606484]\n",
            " [0.0059855 ]]\n",
            "Step: 6159 -> Loss: 0.004378849640488625 -> Predictions: [[0.00363141]\n",
            " [0.99607664]\n",
            " [0.99606484]\n",
            " [0.00598547]]\n",
            "Step: 6160 -> Loss: 0.004378828685730696 -> Predictions: [[0.00363139]\n",
            " [0.99607676]\n",
            " [0.99606484]\n",
            " [0.00598543]]\n",
            "Step: 6161 -> Loss: 0.004378809127956629 -> Predictions: [[0.00363138]\n",
            " [0.99607676]\n",
            " [0.99606484]\n",
            " [0.0059854 ]]\n",
            "Step: 6162 -> Loss: 0.0043787905015051365 -> Predictions: [[0.00363136]\n",
            " [0.99607676]\n",
            " [0.99606484]\n",
            " [0.00598538]]\n",
            "Step: 6163 -> Loss: 0.004378768615424633 -> Predictions: [[0.00363134]\n",
            " [0.99607676]\n",
            " [0.99606496]\n",
            " [0.00598535]]\n",
            "Step: 6164 -> Loss: 0.004378746263682842 -> Predictions: [[0.00363132]\n",
            " [0.99607676]\n",
            " [0.99606496]\n",
            " [0.00598532]]\n",
            "Step: 6165 -> Loss: 0.00437872763723135 -> Predictions: [[0.00363131]\n",
            " [0.99607676]\n",
            " [0.99606496]\n",
            " [0.00598529]]\n",
            "Step: 6166 -> Loss: 0.004378708079457283 -> Predictions: [[0.00363129]\n",
            " [0.99607676]\n",
            " [0.99606496]\n",
            " [0.00598526]]\n",
            "Step: 6167 -> Loss: 0.004378685727715492 -> Predictions: [[0.00363128]\n",
            " [0.9960769 ]\n",
            " [0.99606496]\n",
            " [0.00598522]]\n",
            "Step: 6168 -> Loss: 0.004378666169941425 -> Predictions: [[0.00363127]\n",
            " [0.9960769 ]\n",
            " [0.99606496]\n",
            " [0.0059852 ]]\n",
            "Step: 6169 -> Loss: 0.0043786452151834965 -> Predictions: [[0.00363124]\n",
            " [0.9960769 ]\n",
            " [0.9960651 ]\n",
            " [0.00598517]]\n",
            "Step: 6170 -> Loss: 0.004378625191748142 -> Predictions: [[0.00363123]\n",
            " [0.9960769 ]\n",
            " [0.9960651 ]\n",
            " [0.00598513]]\n",
            "Step: 6171 -> Loss: 0.004378605633974075 -> Predictions: [[0.00363121]\n",
            " [0.9960769 ]\n",
            " [0.9960651 ]\n",
            " [0.00598511]]\n",
            "Step: 6172 -> Loss: 0.004378587007522583 -> Predictions: [[0.00363119]\n",
            " [0.9960769 ]\n",
            " [0.9960651 ]\n",
            " [0.00598508]]\n",
            "Step: 6173 -> Loss: 0.004378563724458218 -> Predictions: [[0.00363118]\n",
            " [0.9960769 ]\n",
            " [0.9960651 ]\n",
            " [0.00598505]]\n",
            "Step: 6174 -> Loss: 0.004378544166684151 -> Predictions: [[0.00363117]\n",
            " [0.996077  ]\n",
            " [0.9960651 ]\n",
            " [0.00598501]]\n",
            "Step: 6175 -> Loss: 0.0043785227462649345 -> Predictions: [[0.00363114]\n",
            " [0.996077  ]\n",
            " [0.9960651 ]\n",
            " [0.00598499]]\n",
            "Step: 6176 -> Loss: 0.004378503654152155 -> Predictions: [[0.00363113]\n",
            " [0.996077  ]\n",
            " [0.9960652 ]\n",
            " [0.00598496]]\n",
            "Step: 6177 -> Loss: 0.004378481302410364 -> Predictions: [[0.00363111]\n",
            " [0.996077  ]\n",
            " [0.9960652 ]\n",
            " [0.00598492]]\n",
            "Step: 6178 -> Loss: 0.004378463141620159 -> Predictions: [[0.0036311]\n",
            " [0.996077 ]\n",
            " [0.9960652]\n",
            " [0.0059849]]\n",
            "Step: 6179 -> Loss: 0.004378442652523518 -> Predictions: [[0.00363108]\n",
            " [0.996077  ]\n",
            " [0.9960652 ]\n",
            " [0.00598487]]\n",
            "Step: 6180 -> Loss: 0.004378420766443014 -> Predictions: [[0.00363106]\n",
            " [0.9960771 ]\n",
            " [0.9960652 ]\n",
            " [0.00598484]]\n",
            "Step: 6181 -> Loss: 0.004378402139991522 -> Predictions: [[0.00363104]\n",
            " [0.9960771 ]\n",
            " [0.9960652 ]\n",
            " [0.00598481]]\n",
            "Step: 6182 -> Loss: 0.004378378391265869 -> Predictions: [[0.00363103]\n",
            " [0.9960771 ]\n",
            " [0.9960652 ]\n",
            " [0.00598478]]\n",
            "Step: 6183 -> Loss: 0.004378362093120813 -> Predictions: [[0.00363101]\n",
            " [0.9960771 ]\n",
            " [0.9960653 ]\n",
            " [0.00598475]]\n",
            "Step: 6184 -> Loss: 0.004378337878733873 -> Predictions: [[0.00363099]\n",
            " [0.9960771 ]\n",
            " [0.9960653 ]\n",
            " [0.00598471]]\n",
            "Step: 6185 -> Loss: 0.00437832111492753 -> Predictions: [[0.00363098]\n",
            " [0.9960771 ]\n",
            " [0.9960653 ]\n",
            " [0.00598469]]\n",
            "Step: 6186 -> Loss: 0.004378301557153463 -> Predictions: [[0.00363097]\n",
            " [0.9960771 ]\n",
            " [0.9960653 ]\n",
            " [0.00598466]]\n",
            "Step: 6187 -> Loss: 0.004378278739750385 -> Predictions: [[0.00363094]\n",
            " [0.99607724]\n",
            " [0.9960653 ]\n",
            " [0.00598463]]\n",
            "Step: 6188 -> Loss: 0.0043782563880085945 -> Predictions: [[0.00363093]\n",
            " [0.99607724]\n",
            " [0.9960653 ]\n",
            " [0.0059846 ]]\n",
            "Step: 6189 -> Loss: 0.0043782396242022514 -> Predictions: [[0.00363092]\n",
            " [0.99607724]\n",
            " [0.9960653 ]\n",
            " [0.00598456]]\n",
            "Step: 6190 -> Loss: 0.0043782200664281845 -> Predictions: [[0.0036309 ]\n",
            " [0.99607724]\n",
            " [0.99606544]\n",
            " [0.00598454]]\n",
            "Step: 6191 -> Loss: 0.004378196783363819 -> Predictions: [[0.00363088]\n",
            " [0.99607724]\n",
            " [0.99606544]\n",
            " [0.0059845 ]]\n",
            "Step: 6192 -> Loss: 0.004378178622573614 -> Predictions: [[0.00363087]\n",
            " [0.99607724]\n",
            " [0.99606544]\n",
            " [0.00598448]]\n",
            "Step: 6193 -> Loss: 0.004378156736493111 -> Predictions: [[0.00363085]\n",
            " [0.99607724]\n",
            " [0.99606544]\n",
            " [0.00598444]]\n",
            "Step: 6194 -> Loss: 0.004378133919090033 -> Predictions: [[0.00363083]\n",
            " [0.99607736]\n",
            " [0.99606544]\n",
            " [0.00598441]]\n",
            "Step: 6195 -> Loss: 0.004378114826977253 -> Predictions: [[0.00363082]\n",
            " [0.99607736]\n",
            " [0.99606544]\n",
            " [0.00598439]]\n",
            "Step: 6196 -> Loss: 0.004378093406558037 -> Predictions: [[0.0036308 ]\n",
            " [0.99607736]\n",
            " [0.99606544]\n",
            " [0.00598435]]\n",
            "Step: 6197 -> Loss: 0.004378072917461395 -> Predictions: [[0.00363078]\n",
            " [0.99607736]\n",
            " [0.99606556]\n",
            " [0.00598433]]\n",
            "Step: 6198 -> Loss: 0.004378055222332478 -> Predictions: [[0.00363077]\n",
            " [0.99607736]\n",
            " [0.99606556]\n",
            " [0.00598429]]\n",
            "Step: 6199 -> Loss: 0.004378033801913261 -> Predictions: [[0.00363076]\n",
            " [0.99607736]\n",
            " [0.99606556]\n",
            " [0.00598426]]\n",
            "Step: 6200 -> Loss: 0.004378014709800482 -> Predictions: [[0.00363074]\n",
            " [0.99607736]\n",
            " [0.99606556]\n",
            " [0.00598423]]\n",
            "Step: 6201 -> Loss: 0.004377993289381266 -> Predictions: [[0.00363072]\n",
            " [0.9960775 ]\n",
            " [0.99606556]\n",
            " [0.00598421]]\n",
            "Step: 6202 -> Loss: 0.004377973265945911 -> Predictions: [[0.00363071]\n",
            " [0.9960775 ]\n",
            " [0.99606556]\n",
            " [0.00598418]]\n",
            "Step: 6203 -> Loss: 0.004377955570816994 -> Predictions: [[0.00363069]\n",
            " [0.9960775 ]\n",
            " [0.9960657 ]\n",
            " [0.00598415]]\n",
            "Step: 6204 -> Loss: 0.0043779341503977776 -> Predictions: [[0.00363067]\n",
            " [0.9960775 ]\n",
            " [0.9960657 ]\n",
            " [0.00598411]]\n",
            "Step: 6205 -> Loss: 0.004377913195639849 -> Predictions: [[0.00363066]\n",
            " [0.9960775 ]\n",
            " [0.9960657 ]\n",
            " [0.00598409]]\n",
            "Step: 6206 -> Loss: 0.00437789224088192 -> Predictions: [[0.00363064]\n",
            " [0.9960775 ]\n",
            " [0.9960657 ]\n",
            " [0.00598406]]\n",
            "Step: 6207 -> Loss: 0.004377871751785278 -> Predictions: [[0.00363062]\n",
            " [0.9960775 ]\n",
            " [0.9960657 ]\n",
            " [0.00598402]]\n",
            "Step: 6208 -> Loss: 0.004377851728349924 -> Predictions: [[0.00363061]\n",
            " [0.9960776 ]\n",
            " [0.9960657 ]\n",
            " [0.005984  ]]\n",
            "Step: 6209 -> Loss: 0.0043778312392532825 -> Predictions: [[0.00363059]\n",
            " [0.9960776 ]\n",
            " [0.9960657 ]\n",
            " [0.00598397]]\n",
            "Step: 6210 -> Loss: 0.004377809353172779 -> Predictions: [[0.00363057]\n",
            " [0.9960776 ]\n",
            " [0.9960658 ]\n",
            " [0.00598394]]\n",
            "Step: 6211 -> Loss: 0.0043777888640761375 -> Predictions: [[0.00363055]\n",
            " [0.9960776 ]\n",
            " [0.9960658 ]\n",
            " [0.00598391]]\n",
            "Step: 6212 -> Loss: 0.004377769306302071 -> Predictions: [[0.00363054]\n",
            " [0.9960776 ]\n",
            " [0.9960658 ]\n",
            " [0.00598388]]\n",
            "Step: 6213 -> Loss: 0.004377748351544142 -> Predictions: [[0.00363052]\n",
            " [0.9960776 ]\n",
            " [0.9960658 ]\n",
            " [0.00598385]]\n",
            "Step: 6214 -> Loss: 0.0043777283281087875 -> Predictions: [[0.0036305 ]\n",
            " [0.9960776 ]\n",
            " [0.9960658 ]\n",
            " [0.00598382]]\n",
            "Step: 6215 -> Loss: 0.004377709235996008 -> Predictions: [[0.00363049]\n",
            " [0.9960777 ]\n",
            " [0.9960658 ]\n",
            " [0.00598379]]\n",
            "Step: 6216 -> Loss: 0.004377688281238079 -> Predictions: [[0.00363048]\n",
            " [0.9960777 ]\n",
            " [0.9960658 ]\n",
            " [0.00598375]]\n",
            "Step: 6217 -> Loss: 0.004377666860818863 -> Predictions: [[0.00363046]\n",
            " [0.9960777 ]\n",
            " [0.9960659 ]\n",
            " [0.00598373]]\n",
            "Step: 6218 -> Loss: 0.004377645906060934 -> Predictions: [[0.00363044]\n",
            " [0.9960777 ]\n",
            " [0.9960659 ]\n",
            " [0.00598369]]\n",
            "Step: 6219 -> Loss: 0.004377626348286867 -> Predictions: [[0.00363043]\n",
            " [0.9960777 ]\n",
            " [0.9960659 ]\n",
            " [0.00598366]]\n",
            "Step: 6220 -> Loss: 0.004377609118819237 -> Predictions: [[0.00363041]\n",
            " [0.9960777 ]\n",
            " [0.9960659 ]\n",
            " [0.00598364]]\n",
            "Step: 6221 -> Loss: 0.004377586301416159 -> Predictions: [[0.00363039]\n",
            " [0.99607784]\n",
            " [0.9960659 ]\n",
            " [0.00598361]]\n",
            "Step: 6222 -> Loss: 0.0043775648809969425 -> Predictions: [[0.00363038]\n",
            " [0.99607784]\n",
            " [0.9960659 ]\n",
            " [0.00598357]]\n",
            "Step: 6223 -> Loss: 0.0043775420635938644 -> Predictions: [[0.00363035]\n",
            " [0.99607784]\n",
            " [0.9960659 ]\n",
            " [0.00598355]]\n",
            "Step: 6224 -> Loss: 0.004377525765448809 -> Predictions: [[0.00363034]\n",
            " [0.99607784]\n",
            " [0.99606603]\n",
            " [0.00598352]]\n",
            "Step: 6225 -> Loss: 0.0043775043450295925 -> Predictions: [[0.00363033]\n",
            " [0.99607784]\n",
            " [0.99606603]\n",
            " [0.00598349]]\n",
            "Step: 6226 -> Loss: 0.004377483855932951 -> Predictions: [[0.00363031]\n",
            " [0.99607784]\n",
            " [0.99606603]\n",
            " [0.00598346]]\n",
            "Step: 6227 -> Loss: 0.004377464763820171 -> Predictions: [[0.00363029]\n",
            " [0.99607784]\n",
            " [0.99606603]\n",
            " [0.00598343]]\n",
            "Step: 6228 -> Loss: 0.00437744427472353 -> Predictions: [[0.00363028]\n",
            " [0.99607795]\n",
            " [0.99606603]\n",
            " [0.0059834 ]]\n",
            "Step: 6229 -> Loss: 0.004377422388643026 -> Predictions: [[0.00363026]\n",
            " [0.99607795]\n",
            " [0.99606603]\n",
            " [0.00598336]]\n",
            "Step: 6230 -> Loss: 0.004377402830868959 -> Predictions: [[0.00363025]\n",
            " [0.99607795]\n",
            " [0.99606615]\n",
            " [0.00598334]]\n",
            "Step: 6231 -> Loss: 0.004377382807433605 -> Predictions: [[0.00363022]\n",
            " [0.99607795]\n",
            " [0.99606615]\n",
            " [0.00598331]]\n",
            "Step: 6232 -> Loss: 0.004377361387014389 -> Predictions: [[0.00363021]\n",
            " [0.99607795]\n",
            " [0.99606615]\n",
            " [0.00598327]]\n",
            "Step: 6233 -> Loss: 0.004377341363579035 -> Predictions: [[0.00363019]\n",
            " [0.99607795]\n",
            " [0.99606615]\n",
            " [0.00598325]]\n",
            "Step: 6234 -> Loss: 0.004377320408821106 -> Predictions: [[0.00363018]\n",
            " [0.99607795]\n",
            " [0.99606615]\n",
            " [0.00598322]]\n",
            "Step: 6235 -> Loss: 0.004377302248030901 -> Predictions: [[0.00363017]\n",
            " [0.9960781 ]\n",
            " [0.99606615]\n",
            " [0.00598319]]\n",
            "Step: 6236 -> Loss: 0.004377279430627823 -> Predictions: [[0.00363014]\n",
            " [0.9960781 ]\n",
            " [0.99606615]\n",
            " [0.00598315]]\n",
            "Step: 6237 -> Loss: 0.004377261269837618 -> Predictions: [[0.00363013]\n",
            " [0.9960781 ]\n",
            " [0.9960663 ]\n",
            " [0.00598313]]\n",
            "Step: 6238 -> Loss: 0.00437723845243454 -> Predictions: [[0.00363011]\n",
            " [0.9960781 ]\n",
            " [0.9960663 ]\n",
            " [0.0059831 ]]\n",
            "Step: 6239 -> Loss: 0.004377218894660473 -> Predictions: [[0.0036301 ]\n",
            " [0.9960781 ]\n",
            " [0.9960663 ]\n",
            " [0.00598306]]\n",
            "Step: 6240 -> Loss: 0.004377198405563831 -> Predictions: [[0.00363008]\n",
            " [0.9960781 ]\n",
            " [0.9960663 ]\n",
            " [0.00598304]]\n",
            "Step: 6241 -> Loss: 0.004377176985144615 -> Predictions: [[0.00363006]\n",
            " [0.9960781 ]\n",
            " [0.9960663 ]\n",
            " [0.005983  ]]\n",
            "Step: 6242 -> Loss: 0.004377155564725399 -> Predictions: [[0.00363005]\n",
            " [0.9960782 ]\n",
            " [0.9960663 ]\n",
            " [0.00598297]]\n",
            "Step: 6243 -> Loss: 0.004377136006951332 -> Predictions: [[0.00363003]\n",
            " [0.9960782 ]\n",
            " [0.9960663 ]\n",
            " [0.00598295]]\n",
            "Step: 6244 -> Loss: 0.004377120640128851 -> Predictions: [[0.00363002]\n",
            " [0.9960782 ]\n",
            " [0.9960664 ]\n",
            " [0.00598292]]\n",
            "Step: 6245 -> Loss: 0.004377095494419336 -> Predictions: [[0.00362999]\n",
            " [0.9960782 ]\n",
            " [0.9960664 ]\n",
            " [0.00598288]]\n",
            "Step: 6246 -> Loss: 0.004377076402306557 -> Predictions: [[0.00362998]\n",
            " [0.9960782 ]\n",
            " [0.9960664 ]\n",
            " [0.00598286]]\n",
            "Step: 6247 -> Loss: 0.0043770549818873405 -> Predictions: [[0.00362997]\n",
            " [0.9960782 ]\n",
            " [0.9960664 ]\n",
            " [0.00598282]]\n",
            "Step: 6248 -> Loss: 0.0043770368210971355 -> Predictions: [[0.00362995]\n",
            " [0.9960782 ]\n",
            " [0.9960664 ]\n",
            " [0.0059828 ]]\n",
            "Step: 6249 -> Loss: 0.004377014935016632 -> Predictions: [[0.00362993]\n",
            " [0.9960783 ]\n",
            " [0.9960664 ]\n",
            " [0.00598276]]\n",
            "Step: 6250 -> Loss: 0.004376994911581278 -> Predictions: [[0.00362991]\n",
            " [0.9960783 ]\n",
            " [0.9960664 ]\n",
            " [0.00598274]]\n",
            "Step: 6251 -> Loss: 0.004376974422484636 -> Predictions: [[0.0036299 ]\n",
            " [0.9960783 ]\n",
            " [0.9960665 ]\n",
            " [0.00598271]]\n",
            "Step: 6252 -> Loss: 0.004376952536404133 -> Predictions: [[0.00362988]\n",
            " [0.9960783 ]\n",
            " [0.9960665 ]\n",
            " [0.00598267]]\n",
            "Step: 6253 -> Loss: 0.004376930184662342 -> Predictions: [[0.00362986]\n",
            " [0.9960783 ]\n",
            " [0.9960665 ]\n",
            " [0.00598264]]\n",
            "Step: 6254 -> Loss: 0.0043769110925495625 -> Predictions: [[0.00362985]\n",
            " [0.9960783 ]\n",
            " [0.9960665 ]\n",
            " [0.00598262]]\n",
            "Step: 6255 -> Loss: 0.0043768915347754955 -> Predictions: [[0.00362983]\n",
            " [0.99607843]\n",
            " [0.9960665 ]\n",
            " [0.00598259]]\n",
            "Step: 6256 -> Loss: 0.004376871511340141 -> Predictions: [[0.00362982]\n",
            " [0.99607843]\n",
            " [0.9960665 ]\n",
            " [0.00598256]]\n",
            "Step: 6257 -> Loss: 0.004376851487904787 -> Predictions: [[0.0036298 ]\n",
            " [0.99607843]\n",
            " [0.9960665 ]\n",
            " [0.00598253]]\n",
            "Step: 6258 -> Loss: 0.0043768323957920074 -> Predictions: [[0.00362978]\n",
            " [0.99607843]\n",
            " [0.99606663]\n",
            " [0.00598249]]\n",
            "Step: 6259 -> Loss: 0.004376811906695366 -> Predictions: [[0.00362977]\n",
            " [0.99607843]\n",
            " [0.99606663]\n",
            " [0.00598247]]\n",
            "Step: 6260 -> Loss: 0.004376789554953575 -> Predictions: [[0.00362975]\n",
            " [0.99607843]\n",
            " [0.99606663]\n",
            " [0.00598244]]\n",
            "Step: 6261 -> Loss: 0.004376773722469807 -> Predictions: [[0.00362974]\n",
            " [0.99607843]\n",
            " [0.99606663]\n",
            " [0.00598241]]\n",
            "Step: 6262 -> Loss: 0.004376748576760292 -> Predictions: [[0.00362972]\n",
            " [0.99607855]\n",
            " [0.99606663]\n",
            " [0.00598238]]\n",
            "Step: 6263 -> Loss: 0.004376731812953949 -> Predictions: [[0.0036297 ]\n",
            " [0.99607855]\n",
            " [0.99606663]\n",
            " [0.00598235]]\n",
            "Step: 6264 -> Loss: 0.004376710392534733 -> Predictions: [[0.00362969]\n",
            " [0.99607855]\n",
            " [0.99606663]\n",
            " [0.00598232]]\n",
            "Step: 6265 -> Loss: 0.004376688040792942 -> Predictions: [[0.00362967]\n",
            " [0.99607855]\n",
            " [0.99606675]\n",
            " [0.00598228]]\n",
            "Step: 6266 -> Loss: 0.004376668017357588 -> Predictions: [[0.00362965]\n",
            " [0.99607855]\n",
            " [0.99606675]\n",
            " [0.00598226]]\n",
            "Step: 6267 -> Loss: 0.004376647062599659 -> Predictions: [[0.00362963]\n",
            " [0.99607855]\n",
            " [0.99606675]\n",
            " [0.00598222]]\n",
            "Step: 6268 -> Loss: 0.004376628901809454 -> Predictions: [[0.00362963]\n",
            " [0.99607855]\n",
            " [0.99606675]\n",
            " [0.0059822 ]]\n",
            "Step: 6269 -> Loss: 0.0043766070157289505 -> Predictions: [[0.0036296 ]\n",
            " [0.99607867]\n",
            " [0.99606675]\n",
            " [0.00598217]]\n",
            "Step: 6270 -> Loss: 0.0043765888549387455 -> Predictions: [[0.00362959]\n",
            " [0.99607867]\n",
            " [0.99606675]\n",
            " [0.00598214]]\n",
            "Step: 6271 -> Loss: 0.004376569297164679 -> Predictions: [[0.00362958]\n",
            " [0.99607867]\n",
            " [0.99606687]\n",
            " [0.00598211]]\n",
            "Step: 6272 -> Loss: 0.004376544151455164 -> Predictions: [[0.00362955]\n",
            " [0.99607867]\n",
            " [0.99606687]\n",
            " [0.00598207]]\n",
            "Step: 6273 -> Loss: 0.004376523196697235 -> Predictions: [[0.00362954]\n",
            " [0.99607867]\n",
            " [0.99606687]\n",
            " [0.00598205]]\n",
            "Step: 6274 -> Loss: 0.004376507829874754 -> Predictions: [[0.00362952]\n",
            " [0.99607867]\n",
            " [0.99606687]\n",
            " [0.00598202]]\n",
            "Step: 6275 -> Loss: 0.004376485478132963 -> Predictions: [[0.0036295 ]\n",
            " [0.99607867]\n",
            " [0.99606687]\n",
            " [0.00598199]]\n",
            "Step: 6276 -> Loss: 0.004376464523375034 -> Predictions: [[0.00362949]\n",
            " [0.9960788 ]\n",
            " [0.99606687]\n",
            " [0.00598196]]\n",
            "Step: 6277 -> Loss: 0.004376443102955818 -> Predictions: [[0.00362947]\n",
            " [0.9960788 ]\n",
            " [0.99606687]\n",
            " [0.00598192]]\n",
            "Step: 6278 -> Loss: 0.004376425873488188 -> Predictions: [[0.00362946]\n",
            " [0.9960788 ]\n",
            " [0.996067  ]\n",
            " [0.00598189]]\n",
            "Step: 6279 -> Loss: 0.004376407712697983 -> Predictions: [[0.00362944]\n",
            " [0.9960788 ]\n",
            " [0.996067  ]\n",
            " [0.00598187]]\n",
            "Step: 6280 -> Loss: 0.004376382101327181 -> Predictions: [[0.00362942]\n",
            " [0.9960788 ]\n",
            " [0.996067  ]\n",
            " [0.00598183]]\n",
            "Step: 6281 -> Loss: 0.004376361612230539 -> Predictions: [[0.0036294 ]\n",
            " [0.9960788 ]\n",
            " [0.996067  ]\n",
            " [0.00598181]]\n",
            "Step: 6282 -> Loss: 0.004376343451440334 -> Predictions: [[0.00362939]\n",
            " [0.9960788 ]\n",
            " [0.996067  ]\n",
            " [0.00598178]]\n",
            "Step: 6283 -> Loss: 0.004376320168375969 -> Predictions: [[0.00362937]\n",
            " [0.9960789 ]\n",
            " [0.996067  ]\n",
            " [0.00598174]]\n",
            "Step: 6284 -> Loss: 0.004376299679279327 -> Predictions: [[0.00362935]\n",
            " [0.9960789 ]\n",
            " [0.996067  ]\n",
            " [0.00598171]]\n",
            "Step: 6285 -> Loss: 0.004376279190182686 -> Predictions: [[0.00362934]\n",
            " [0.9960789 ]\n",
            " [0.9960671 ]\n",
            " [0.00598169]]\n",
            "Step: 6286 -> Loss: 0.004376264754682779 -> Predictions: [[0.00362933]\n",
            " [0.9960789 ]\n",
            " [0.9960671 ]\n",
            " [0.00598166]]\n",
            "Step: 6287 -> Loss: 0.004376241005957127 -> Predictions: [[0.00362931]\n",
            " [0.9960789 ]\n",
            " [0.9960671 ]\n",
            " [0.00598163]]\n",
            "Step: 6288 -> Loss: 0.004376220516860485 -> Predictions: [[0.00362929]\n",
            " [0.9960789 ]\n",
            " [0.9960671 ]\n",
            " [0.0059816 ]]\n",
            "Step: 6289 -> Loss: 0.004376198165118694 -> Predictions: [[0.00362927]\n",
            " [0.996079  ]\n",
            " [0.9960671 ]\n",
            " [0.00598157]]\n",
            "Step: 6290 -> Loss: 0.004376180004328489 -> Predictions: [[0.00362926]\n",
            " [0.996079  ]\n",
            " [0.9960671 ]\n",
            " [0.00598154]]\n",
            "Step: 6291 -> Loss: 0.004376158583909273 -> Predictions: [[0.00362924]\n",
            " [0.996079  ]\n",
            " [0.9960672 ]\n",
            " [0.00598151]]\n",
            "Step: 6292 -> Loss: 0.0043761394917964935 -> Predictions: [[0.00362923]\n",
            " [0.996079  ]\n",
            " [0.9960672 ]\n",
            " [0.00598148]]\n",
            "Step: 6293 -> Loss: 0.004376119002699852 -> Predictions: [[0.00362921]\n",
            " [0.996079  ]\n",
            " [0.9960672 ]\n",
            " [0.00598145]]\n",
            "Step: 6294 -> Loss: 0.004376097582280636 -> Predictions: [[0.0036292 ]\n",
            " [0.996079  ]\n",
            " [0.9960672 ]\n",
            " [0.00598141]]\n",
            "Step: 6295 -> Loss: 0.004376077093183994 -> Predictions: [[0.00362918]\n",
            " [0.996079  ]\n",
            " [0.9960672 ]\n",
            " [0.00598138]]\n",
            "Step: 6296 -> Loss: 0.004376057535409927 -> Predictions: [[0.00362916]\n",
            " [0.99607915]\n",
            " [0.9960672 ]\n",
            " [0.00598136]]\n",
            "Step: 6297 -> Loss: 0.0043760365806519985 -> Predictions: [[0.00362914]\n",
            " [0.99607915]\n",
            " [0.9960672 ]\n",
            " [0.00598133]]\n",
            "Step: 6298 -> Loss: 0.004376016557216644 -> Predictions: [[0.00362913]\n",
            " [0.99607915]\n",
            " [0.99606735]\n",
            " [0.0059813 ]]\n",
            "Step: 6299 -> Loss: 0.004375996999442577 -> Predictions: [[0.00362912]\n",
            " [0.99607915]\n",
            " [0.99606735]\n",
            " [0.00598127]]\n",
            "Step: 6300 -> Loss: 0.004375975579023361 -> Predictions: [[0.0036291 ]\n",
            " [0.99607915]\n",
            " [0.99606735]\n",
            " [0.00598123]]\n",
            "Step: 6301 -> Loss: 0.004375954624265432 -> Predictions: [[0.00362908]\n",
            " [0.99607915]\n",
            " [0.99606735]\n",
            " [0.00598121]]\n",
            "Step: 6302 -> Loss: 0.004375934135168791 -> Predictions: [[0.00362907]\n",
            " [0.99607915]\n",
            " [0.99606735]\n",
            " [0.00598117]]\n",
            "Step: 6303 -> Loss: 0.004375914111733437 -> Predictions: [[0.00362905]\n",
            " [0.99607927]\n",
            " [0.99606735]\n",
            " [0.00598115]]\n",
            "Step: 6304 -> Loss: 0.004375896416604519 -> Predictions: [[0.00362904]\n",
            " [0.99607927]\n",
            " [0.99606735]\n",
            " [0.00598112]]\n",
            "Step: 6305 -> Loss: 0.004375872667878866 -> Predictions: [[0.00362901]\n",
            " [0.99607927]\n",
            " [0.9960674 ]\n",
            " [0.00598108]]\n",
            "Step: 6306 -> Loss: 0.004375852644443512 -> Predictions: [[0.003629  ]\n",
            " [0.99607927]\n",
            " [0.9960674 ]\n",
            " [0.00598106]]\n",
            "Step: 6307 -> Loss: 0.0043758307583630085 -> Predictions: [[0.00362898]\n",
            " [0.99607927]\n",
            " [0.9960674 ]\n",
            " [0.00598102]]\n",
            "Step: 6308 -> Loss: 0.004375812131911516 -> Predictions: [[0.00362896]\n",
            " [0.99607927]\n",
            " [0.9960674 ]\n",
            " [0.005981  ]]\n",
            "Step: 6309 -> Loss: 0.004375792574137449 -> Predictions: [[0.00362895]\n",
            " [0.99607927]\n",
            " [0.9960674 ]\n",
            " [0.00598097]]\n",
            "Step: 6310 -> Loss: 0.004375770688056946 -> Predictions: [[0.00362893]\n",
            " [0.9960794 ]\n",
            " [0.9960674 ]\n",
            " [0.00598094]]\n",
            "Step: 6311 -> Loss: 0.004375753924250603 -> Predictions: [[0.00362892]\n",
            " [0.9960794 ]\n",
            " [0.9960674 ]\n",
            " [0.00598091]]\n",
            "Step: 6312 -> Loss: 0.004375731106847525 -> Predictions: [[0.0036289 ]\n",
            " [0.9960794 ]\n",
            " [0.9960675 ]\n",
            " [0.00598088]]\n",
            "Step: 6313 -> Loss: 0.004375712014734745 -> Predictions: [[0.00362888]\n",
            " [0.9960794 ]\n",
            " [0.9960675 ]\n",
            " [0.00598085]]\n",
            "Step: 6314 -> Loss: 0.004375690594315529 -> Predictions: [[0.00362887]\n",
            " [0.9960794 ]\n",
            " [0.9960675 ]\n",
            " [0.00598081]]\n",
            "Step: 6315 -> Loss: 0.004375670105218887 -> Predictions: [[0.00362885]\n",
            " [0.9960794 ]\n",
            " [0.9960675 ]\n",
            " [0.00598079]]\n",
            "Step: 6316 -> Loss: 0.00437565054744482 -> Predictions: [[0.00362883]\n",
            " [0.9960794 ]\n",
            " [0.9960675 ]\n",
            " [0.00598076]]\n",
            "Step: 6317 -> Loss: 0.004375629127025604 -> Predictions: [[0.00362882]\n",
            " [0.9960795 ]\n",
            " [0.9960675 ]\n",
            " [0.00598073]]\n",
            "Step: 6318 -> Loss: 0.004375610500574112 -> Predictions: [[0.0036288]\n",
            " [0.9960795]\n",
            " [0.9960675]\n",
            " [0.0059807]]\n",
            "Step: 6319 -> Loss: 0.00437559001147747 -> Predictions: [[0.00362879]\n",
            " [0.9960795 ]\n",
            " [0.99606764]\n",
            " [0.00598067]]\n",
            "Step: 6320 -> Loss: 0.004375567194074392 -> Predictions: [[0.00362877]\n",
            " [0.9960795 ]\n",
            " [0.99606764]\n",
            " [0.00598063]]\n",
            "Step: 6321 -> Loss: 0.004375549033284187 -> Predictions: [[0.00362875]\n",
            " [0.9960795 ]\n",
            " [0.99606764]\n",
            " [0.00598061]]\n",
            "Step: 6322 -> Loss: 0.004375527612864971 -> Predictions: [[0.00362874]\n",
            " [0.9960795 ]\n",
            " [0.99606764]\n",
            " [0.00598058]]\n",
            "Step: 6323 -> Loss: 0.004375504795461893 -> Predictions: [[0.00362872]\n",
            " [0.9960796 ]\n",
            " [0.99606764]\n",
            " [0.00598054]]\n",
            "Step: 6324 -> Loss: 0.004375483375042677 -> Predictions: [[0.0036287 ]\n",
            " [0.9960796 ]\n",
            " [0.99606764]\n",
            " [0.00598051]]\n",
            "Step: 6325 -> Loss: 0.004375468473881483 -> Predictions: [[0.00362869]\n",
            " [0.9960796 ]\n",
            " [0.99606764]\n",
            " [0.00598048]]\n",
            "Step: 6326 -> Loss: 0.004375446122139692 -> Predictions: [[0.00362867]\n",
            " [0.9960796 ]\n",
            " [0.99606776]\n",
            " [0.00598046]]\n",
            "Step: 6327 -> Loss: 0.004375425633043051 -> Predictions: [[0.00362865]\n",
            " [0.9960796 ]\n",
            " [0.99606776]\n",
            " [0.00598043]]\n",
            "Step: 6328 -> Loss: 0.004375406540930271 -> Predictions: [[0.00362864]\n",
            " [0.9960796 ]\n",
            " [0.99606776]\n",
            " [0.0059804 ]]\n",
            "Step: 6329 -> Loss: 0.00437538418918848 -> Predictions: [[0.00362863]\n",
            " [0.9960796 ]\n",
            " [0.99606776]\n",
            " [0.00598037]]\n",
            "Step: 6330 -> Loss: 0.004375366494059563 -> Predictions: [[0.00362861]\n",
            " [0.99607974]\n",
            " [0.99606776]\n",
            " [0.00598034]]\n",
            "Step: 6331 -> Loss: 0.004375346004962921 -> Predictions: [[0.00362859]\n",
            " [0.99607974]\n",
            " [0.99606776]\n",
            " [0.00598031]]\n",
            "Step: 6332 -> Loss: 0.004375322721898556 -> Predictions: [[0.00362857]\n",
            " [0.99607974]\n",
            " [0.9960679 ]\n",
            " [0.00598028]]\n",
            "Step: 6333 -> Loss: 0.0043753040954470634 -> Predictions: [[0.00362855]\n",
            " [0.99607974]\n",
            " [0.9960679 ]\n",
            " [0.00598025]]\n",
            "Step: 6334 -> Loss: 0.004375285468995571 -> Predictions: [[0.00362854]\n",
            " [0.99607974]\n",
            " [0.9960679 ]\n",
            " [0.00598022]]\n",
            "Step: 6335 -> Loss: 0.004375261254608631 -> Predictions: [[0.00362852]\n",
            " [0.99607974]\n",
            " [0.9960679 ]\n",
            " [0.00598019]]\n",
            "Step: 6336 -> Loss: 0.004375242628157139 -> Predictions: [[0.00362851]\n",
            " [0.99607974]\n",
            " [0.9960679 ]\n",
            " [0.00598016]]\n",
            "Step: 6337 -> Loss: 0.004375221207737923 -> Predictions: [[0.00362849]\n",
            " [0.99607986]\n",
            " [0.9960679 ]\n",
            " [0.00598013]]\n",
            "Step: 6338 -> Loss: 0.004375200718641281 -> Predictions: [[0.00362847]\n",
            " [0.99607986]\n",
            " [0.9960679 ]\n",
            " [0.00598009]]\n",
            "Step: 6339 -> Loss: 0.004375182092189789 -> Predictions: [[0.00362846]\n",
            " [0.99607986]\n",
            " [0.996068  ]\n",
            " [0.00598007]]\n",
            "Step: 6340 -> Loss: 0.004375160671770573 -> Predictions: [[0.00362844]\n",
            " [0.99607986]\n",
            " [0.996068  ]\n",
            " [0.00598004]]\n",
            "Step: 6341 -> Loss: 0.004375140648335218 -> Predictions: [[0.00362842]\n",
            " [0.99607986]\n",
            " [0.996068  ]\n",
            " [0.00598001]]\n",
            "Step: 6342 -> Loss: 0.004375122021883726 -> Predictions: [[0.00362841]\n",
            " [0.99607986]\n",
            " [0.996068  ]\n",
            " [0.00597998]]\n",
            "Step: 6343 -> Loss: 0.004375099204480648 -> Predictions: [[0.0036284 ]\n",
            " [0.99607986]\n",
            " [0.996068  ]\n",
            " [0.00597994]]\n",
            "Step: 6344 -> Loss: 0.004375078249722719 -> Predictions: [[0.00362837]\n",
            " [0.99608   ]\n",
            " [0.996068  ]\n",
            " [0.00597992]]\n",
            "Step: 6345 -> Loss: 0.004375059623271227 -> Predictions: [[0.00362836]\n",
            " [0.99608   ]\n",
            " [0.996068  ]\n",
            " [0.00597989]]\n",
            "Step: 6346 -> Loss: 0.004375040531158447 -> Predictions: [[0.00362834]\n",
            " [0.99608   ]\n",
            " [0.9960681 ]\n",
            " [0.00597986]]\n",
            "Step: 6347 -> Loss: 0.0043750181794166565 -> Predictions: [[0.00362833]\n",
            " [0.99608   ]\n",
            " [0.9960681 ]\n",
            " [0.00597983]]\n",
            "Step: 6348 -> Loss: 0.004374997690320015 -> Predictions: [[0.00362831]\n",
            " [0.99608   ]\n",
            " [0.9960681 ]\n",
            " [0.00597979]]\n",
            "Step: 6349 -> Loss: 0.004374976269900799 -> Predictions: [[0.00362829]\n",
            " [0.99608   ]\n",
            " [0.9960681 ]\n",
            " [0.00597977]]\n",
            "Step: 6350 -> Loss: 0.00437495531514287 -> Predictions: [[0.00362827]\n",
            " [0.99608   ]\n",
            " [0.9960681 ]\n",
            " [0.00597974]]\n",
            "Step: 6351 -> Loss: 0.004374937620013952 -> Predictions: [[0.00362826]\n",
            " [0.9960801 ]\n",
            " [0.9960681 ]\n",
            " [0.00597971]]\n",
            "Step: 6352 -> Loss: 0.004374916199594736 -> Predictions: [[0.00362825]\n",
            " [0.9960801 ]\n",
            " [0.99606824]\n",
            " [0.00597968]]\n",
            "Step: 6353 -> Loss: 0.004374895244836807 -> Predictions: [[0.00362822]\n",
            " [0.9960801 ]\n",
            " [0.99606824]\n",
            " [0.00597965]]\n",
            "Step: 6354 -> Loss: 0.004374875221401453 -> Predictions: [[0.00362821]\n",
            " [0.9960801 ]\n",
            " [0.99606824]\n",
            " [0.00597962]]\n",
            "Step: 6355 -> Loss: 0.004374856129288673 -> Predictions: [[0.0036282 ]\n",
            " [0.9960801 ]\n",
            " [0.99606824]\n",
            " [0.00597959]]\n",
            "Step: 6356 -> Loss: 0.004374833777546883 -> Predictions: [[0.00362818]\n",
            " [0.9960801 ]\n",
            " [0.99606824]\n",
            " [0.00597956]]\n",
            "Step: 6357 -> Loss: 0.004374814685434103 -> Predictions: [[0.00362816]\n",
            " [0.9960801 ]\n",
            " [0.99606824]\n",
            " [0.00597953]]\n",
            "Step: 6358 -> Loss: 0.004374794661998749 -> Predictions: [[0.00362814]\n",
            " [0.9960802 ]\n",
            " [0.99606824]\n",
            " [0.0059795 ]]\n",
            "Step: 6359 -> Loss: 0.0043747746385633945 -> Predictions: [[0.00362813]\n",
            " [0.9960802 ]\n",
            " [0.99606824]\n",
            " [0.00597947]]\n",
            "Step: 6360 -> Loss: 0.004374755546450615 -> Predictions: [[0.00362812]\n",
            " [0.9960802 ]\n",
            " [0.99606836]\n",
            " [0.00597944]]\n",
            "Step: 6361 -> Loss: 0.0043747322633862495 -> Predictions: [[0.0036281 ]\n",
            " [0.9960802 ]\n",
            " [0.99606836]\n",
            " [0.00597941]]\n",
            "Step: 6362 -> Loss: 0.00437471317127347 -> Predictions: [[0.00362808]\n",
            " [0.9960802 ]\n",
            " [0.99606836]\n",
            " [0.00597938]]\n",
            "Step: 6363 -> Loss: 0.0043746912851929665 -> Predictions: [[0.00362806]\n",
            " [0.9960802 ]\n",
            " [0.99606836]\n",
            " [0.00597934]]\n",
            "Step: 6364 -> Loss: 0.0043746731244027615 -> Predictions: [[0.00362805]\n",
            " [0.99608034]\n",
            " [0.99606836]\n",
            " [0.00597933]]\n",
            "Step: 6365 -> Loss: 0.004374650306999683 -> Predictions: [[0.00362803]\n",
            " [0.99608034]\n",
            " [0.99606836]\n",
            " [0.00597929]]\n",
            "Step: 6366 -> Loss: 0.00437462842091918 -> Predictions: [[0.00362801]\n",
            " [0.99608034]\n",
            " [0.9960685 ]\n",
            " [0.00597925]]\n",
            "Step: 6367 -> Loss: 0.0043746111914515495 -> Predictions: [[0.003628  ]\n",
            " [0.99608034]\n",
            " [0.9960685 ]\n",
            " [0.00597923]]\n",
            "Step: 6368 -> Loss: 0.004374588839709759 -> Predictions: [[0.00362798]\n",
            " [0.99608034]\n",
            " [0.9960685 ]\n",
            " [0.0059792 ]]\n",
            "Step: 6369 -> Loss: 0.0043745702132582664 -> Predictions: [[0.00362797]\n",
            " [0.99608034]\n",
            " [0.9960685 ]\n",
            " [0.00597917]]\n",
            "Step: 6370 -> Loss: 0.004374550189822912 -> Predictions: [[0.00362795]\n",
            " [0.99608034]\n",
            " [0.9960685 ]\n",
            " [0.00597914]]\n",
            "Step: 6371 -> Loss: 0.004374530166387558 -> Predictions: [[0.00362793]\n",
            " [0.99608046]\n",
            " [0.9960685 ]\n",
            " [0.00597911]]\n",
            "Step: 6372 -> Loss: 0.004374508745968342 -> Predictions: [[0.00362792]\n",
            " [0.99608046]\n",
            " [0.9960685 ]\n",
            " [0.00597907]]\n",
            "Step: 6373 -> Loss: 0.0043744882568717 -> Predictions: [[0.0036279 ]\n",
            " [0.99608046]\n",
            " [0.9960686 ]\n",
            " [0.00597905]]\n",
            "Step: 6374 -> Loss: 0.0043744673021137714 -> Predictions: [[0.00362789]\n",
            " [0.99608046]\n",
            " [0.9960686 ]\n",
            " [0.00597902]]\n",
            "Step: 6375 -> Loss: 0.00437444681301713 -> Predictions: [[0.00362786]\n",
            " [0.99608046]\n",
            " [0.9960686 ]\n",
            " [0.00597899]]\n",
            "Step: 6376 -> Loss: 0.004374429117888212 -> Predictions: [[0.00362785]\n",
            " [0.99608046]\n",
            " [0.9960686 ]\n",
            " [0.00597896]]\n",
            "Step: 6377 -> Loss: 0.004374405834823847 -> Predictions: [[0.00362783]\n",
            " [0.99608046]\n",
            " [0.9960686 ]\n",
            " [0.00597893]]\n",
            "Step: 6378 -> Loss: 0.004374384414404631 -> Predictions: [[0.00362782]\n",
            " [0.9960806 ]\n",
            " [0.9960686 ]\n",
            " [0.00597889]]\n",
            "Step: 6379 -> Loss: 0.004374364856630564 -> Predictions: [[0.0036278 ]\n",
            " [0.9960806 ]\n",
            " [0.9960686 ]\n",
            " [0.00597887]]\n",
            "Step: 6380 -> Loss: 0.0043743448331952095 -> Predictions: [[0.00362778]\n",
            " [0.9960806 ]\n",
            " [0.9960687 ]\n",
            " [0.00597884]]\n",
            "Step: 6381 -> Loss: 0.004374325275421143 -> Predictions: [[0.00362777]\n",
            " [0.9960806 ]\n",
            " [0.9960687 ]\n",
            " [0.00597881]]\n",
            "Step: 6382 -> Loss: 0.004374307114630938 -> Predictions: [[0.00362775]\n",
            " [0.9960806 ]\n",
            " [0.9960687 ]\n",
            " [0.00597878]]\n",
            "Step: 6383 -> Loss: 0.004374283365905285 -> Predictions: [[0.00362774]\n",
            " [0.9960806 ]\n",
            " [0.9960687 ]\n",
            " [0.00597875]]\n",
            "Step: 6384 -> Loss: 0.004374264273792505 -> Predictions: [[0.00362772]\n",
            " [0.9960806 ]\n",
            " [0.9960687 ]\n",
            " [0.00597871]]\n",
            "Step: 6385 -> Loss: 0.004374242387712002 -> Predictions: [[0.0036277 ]\n",
            " [0.9960807 ]\n",
            " [0.9960687 ]\n",
            " [0.00597869]]\n",
            "Step: 6386 -> Loss: 0.004374223295599222 -> Predictions: [[0.00362769]\n",
            " [0.9960807 ]\n",
            " [0.9960687 ]\n",
            " [0.00597866]]\n",
            "Step: 6387 -> Loss: 0.004374203272163868 -> Predictions: [[0.00362767]\n",
            " [0.9960807 ]\n",
            " [0.99606884]\n",
            " [0.00597863]]\n",
            "Step: 6388 -> Loss: 0.004374181851744652 -> Predictions: [[0.00362765]\n",
            " [0.9960807 ]\n",
            " [0.99606884]\n",
            " [0.0059786 ]]\n",
            "Step: 6389 -> Loss: 0.004374162293970585 -> Predictions: [[0.00362764]\n",
            " [0.9960807 ]\n",
            " [0.99606884]\n",
            " [0.00597857]]\n",
            "Step: 6390 -> Loss: 0.004374141804873943 -> Predictions: [[0.00362762]\n",
            " [0.9960807 ]\n",
            " [0.99606884]\n",
            " [0.00597854]]\n",
            "Step: 6391 -> Loss: 0.004374120384454727 -> Predictions: [[0.00362761]\n",
            " [0.9960807 ]\n",
            " [0.99606884]\n",
            " [0.00597851]]\n",
            "Step: 6392 -> Loss: 0.00437410082668066 -> Predictions: [[0.00362759]\n",
            " [0.9960808 ]\n",
            " [0.99606884]\n",
            " [0.00597848]]\n",
            "Step: 6393 -> Loss: 0.004374080337584019 -> Predictions: [[0.00362757]\n",
            " [0.9960808 ]\n",
            " [0.99606884]\n",
            " [0.00597845]]\n",
            "Step: 6394 -> Loss: 0.004374061245471239 -> Predictions: [[0.00362756]\n",
            " [0.9960808 ]\n",
            " [0.99606895]\n",
            " [0.00597842]]\n",
            "Step: 6395 -> Loss: 0.004374039825052023 -> Predictions: [[0.00362754]\n",
            " [0.9960808 ]\n",
            " [0.99606895]\n",
            " [0.00597839]]\n",
            "Step: 6396 -> Loss: 0.004374020267277956 -> Predictions: [[0.00362752]\n",
            " [0.9960808 ]\n",
            " [0.99606895]\n",
            " [0.00597836]]\n",
            "Step: 6397 -> Loss: 0.004373997915536165 -> Predictions: [[0.0036275 ]\n",
            " [0.9960808 ]\n",
            " [0.99606895]\n",
            " [0.00597833]]\n",
            "Step: 6398 -> Loss: 0.00437397975474596 -> Predictions: [[0.00362749]\n",
            " [0.9960808 ]\n",
            " [0.99606895]\n",
            " [0.0059783 ]]\n",
            "Step: 6399 -> Loss: 0.004373959731310606 -> Predictions: [[0.00362747]\n",
            " [0.99608094]\n",
            " [0.99606895]\n",
            " [0.00597827]]\n",
            "Step: 6400 -> Loss: 0.004373938776552677 -> Predictions: [[0.00362746]\n",
            " [0.99608094]\n",
            " [0.9960691 ]\n",
            " [0.00597824]]\n",
            "Step: 6401 -> Loss: 0.004373916890472174 -> Predictions: [[0.00362744]\n",
            " [0.99608094]\n",
            " [0.9960691 ]\n",
            " [0.0059782 ]]\n",
            "Step: 6402 -> Loss: 0.004373898264020681 -> Predictions: [[0.00362742]\n",
            " [0.99608094]\n",
            " [0.9960691 ]\n",
            " [0.00597818]]\n",
            "Step: 6403 -> Loss: 0.004373878240585327 -> Predictions: [[0.00362741]\n",
            " [0.99608094]\n",
            " [0.9960691 ]\n",
            " [0.00597815]]\n",
            "Step: 6404 -> Loss: 0.004373857285827398 -> Predictions: [[0.00362739]\n",
            " [0.99608094]\n",
            " [0.9960691 ]\n",
            " [0.00597812]]\n",
            "Step: 6405 -> Loss: 0.004373835865408182 -> Predictions: [[0.00362738]\n",
            " [0.99608105]\n",
            " [0.9960691 ]\n",
            " [0.00597809]]\n",
            "Step: 6406 -> Loss: 0.004373815841972828 -> Predictions: [[0.00362735]\n",
            " [0.99608105]\n",
            " [0.9960691 ]\n",
            " [0.00597806]]\n",
            "Step: 6407 -> Loss: 0.004373796749860048 -> Predictions: [[0.00362734]\n",
            " [0.99608105]\n",
            " [0.9960692 ]\n",
            " [0.00597803]]\n",
            "Step: 6408 -> Loss: 0.004373776726424694 -> Predictions: [[0.00362733]\n",
            " [0.99608105]\n",
            " [0.9960692 ]\n",
            " [0.00597799]]\n",
            "Step: 6409 -> Loss: 0.004373755306005478 -> Predictions: [[0.00362731]\n",
            " [0.99608105]\n",
            " [0.9960692 ]\n",
            " [0.00597797]]\n",
            "Step: 6410 -> Loss: 0.004373735282570124 -> Predictions: [[0.00362729]\n",
            " [0.99608105]\n",
            " [0.9960692 ]\n",
            " [0.00597794]]\n",
            "Step: 6411 -> Loss: 0.0043737152591347694 -> Predictions: [[0.00362727]\n",
            " [0.99608105]\n",
            " [0.9960692 ]\n",
            " [0.00597791]]\n",
            "Step: 6412 -> Loss: 0.004373692907392979 -> Predictions: [[0.00362726]\n",
            " [0.9960812 ]\n",
            " [0.9960692 ]\n",
            " [0.00597788]]\n",
            "Step: 6413 -> Loss: 0.004373675677925348 -> Predictions: [[0.00362725]\n",
            " [0.9960812 ]\n",
            " [0.9960692 ]\n",
            " [0.00597785]]\n",
            "Step: 6414 -> Loss: 0.00437365286052227 -> Predictions: [[0.00362723]\n",
            " [0.9960812 ]\n",
            " [0.9960693 ]\n",
            " [0.00597782]]\n",
            "Step: 6415 -> Loss: 0.004373634234070778 -> Predictions: [[0.00362721]\n",
            " [0.9960812 ]\n",
            " [0.9960693 ]\n",
            " [0.00597779]]\n",
            "Step: 6416 -> Loss: 0.004373611882328987 -> Predictions: [[0.00362719]\n",
            " [0.9960812 ]\n",
            " [0.9960693 ]\n",
            " [0.00597776]]\n",
            "Step: 6417 -> Loss: 0.00437359232455492 -> Predictions: [[0.00362718]\n",
            " [0.9960812 ]\n",
            " [0.9960693 ]\n",
            " [0.00597773]]\n",
            "Step: 6418 -> Loss: 0.004373573232442141 -> Predictions: [[0.00362716]\n",
            " [0.9960812 ]\n",
            " [0.9960693 ]\n",
            " [0.0059777 ]]\n",
            "Step: 6419 -> Loss: 0.004373551346361637 -> Predictions: [[0.00362714]\n",
            " [0.9960813 ]\n",
            " [0.9960693 ]\n",
            " [0.00597767]]\n",
            "Step: 6420 -> Loss: 0.004373530857264996 -> Predictions: [[0.00362713]\n",
            " [0.9960813 ]\n",
            " [0.9960693 ]\n",
            " [0.00597764]]\n",
            "Step: 6421 -> Loss: 0.004373506642878056 -> Predictions: [[0.00362711]\n",
            " [0.9960813 ]\n",
            " [0.99606943]\n",
            " [0.0059776 ]]\n",
            "Step: 6422 -> Loss: 0.004373491741716862 -> Predictions: [[0.0036271 ]\n",
            " [0.9960813 ]\n",
            " [0.99606943]\n",
            " [0.00597758]]\n",
            "Step: 6423 -> Loss: 0.004373470321297646 -> Predictions: [[0.00362708]\n",
            " [0.9960813 ]\n",
            " [0.99606943]\n",
            " [0.00597755]]\n",
            "Step: 6424 -> Loss: 0.004373450763523579 -> Predictions: [[0.00362706]\n",
            " [0.9960813 ]\n",
            " [0.99606943]\n",
            " [0.00597752]]\n",
            "Step: 6425 -> Loss: 0.004373432137072086 -> Predictions: [[0.00362705]\n",
            " [0.9960813 ]\n",
            " [0.99606943]\n",
            " [0.0059775 ]]\n",
            "Step: 6426 -> Loss: 0.004373408854007721 -> Predictions: [[0.00362703]\n",
            " [0.9960814 ]\n",
            " [0.99606943]\n",
            " [0.00597746]]\n",
            "Step: 6427 -> Loss: 0.004373390693217516 -> Predictions: [[0.00362701]\n",
            " [0.9960814 ]\n",
            " [0.99606943]\n",
            " [0.00597743]]\n",
            "Step: 6428 -> Loss: 0.004373368341475725 -> Predictions: [[0.003627  ]\n",
            " [0.9960814 ]\n",
            " [0.99606955]\n",
            " [0.0059774 ]]\n",
            "Step: 6429 -> Loss: 0.004373349715024233 -> Predictions: [[0.00362698]\n",
            " [0.9960814 ]\n",
            " [0.99606955]\n",
            " [0.00597737]]\n",
            "Step: 6430 -> Loss: 0.004373328294605017 -> Predictions: [[0.00362697]\n",
            " [0.9960814 ]\n",
            " [0.99606955]\n",
            " [0.00597734]]\n",
            "Step: 6431 -> Loss: 0.0043733068741858006 -> Predictions: [[0.00362695]\n",
            " [0.9960814 ]\n",
            " [0.99606955]\n",
            " [0.00597731]]\n",
            "Step: 6432 -> Loss: 0.004373285919427872 -> Predictions: [[0.00362694]\n",
            " [0.9960814 ]\n",
            " [0.99606955]\n",
            " [0.00597728]]\n",
            "Step: 6433 -> Loss: 0.004373266827315092 -> Predictions: [[0.00362692]\n",
            " [0.99608153]\n",
            " [0.99606955]\n",
            " [0.00597725]]\n",
            "Step: 6434 -> Loss: 0.004373245872557163 -> Predictions: [[0.0036269 ]\n",
            " [0.99608153]\n",
            " [0.99606955]\n",
            " [0.00597722]]\n",
            "Step: 6435 -> Loss: 0.004373226314783096 -> Predictions: [[0.00362689]\n",
            " [0.99608153]\n",
            " [0.99606967]\n",
            " [0.00597719]]\n",
            "Step: 6436 -> Loss: 0.00437320489436388 -> Predictions: [[0.00362687]\n",
            " [0.99608153]\n",
            " [0.99606967]\n",
            " [0.00597716]]\n",
            "Step: 6437 -> Loss: 0.004373184405267239 -> Predictions: [[0.00362685]\n",
            " [0.99608153]\n",
            " [0.99606967]\n",
            " [0.00597713]]\n",
            "Step: 6438 -> Loss: 0.004373164381831884 -> Predictions: [[0.00362683]\n",
            " [0.99608153]\n",
            " [0.99606967]\n",
            " [0.0059771 ]]\n",
            "Step: 6439 -> Loss: 0.004373142961412668 -> Predictions: [[0.00362682]\n",
            " [0.99608153]\n",
            " [0.99606967]\n",
            " [0.00597707]]\n",
            "Step: 6440 -> Loss: 0.004373123403638601 -> Predictions: [[0.0036268 ]\n",
            " [0.99608165]\n",
            " [0.99606967]\n",
            " [0.00597704]]\n",
            "Step: 6441 -> Loss: 0.004373104311525822 -> Predictions: [[0.00362679]\n",
            " [0.99608165]\n",
            " [0.9960698 ]\n",
            " [0.00597701]]\n",
            "Step: 6442 -> Loss: 0.00437308382242918 -> Predictions: [[0.00362677]\n",
            " [0.99608165]\n",
            " [0.9960698 ]\n",
            " [0.00597698]]\n",
            "Step: 6443 -> Loss: 0.004373062402009964 -> Predictions: [[0.00362675]\n",
            " [0.99608165]\n",
            " [0.9960698 ]\n",
            " [0.00597695]]\n",
            "Step: 6444 -> Loss: 0.004373043775558472 -> Predictions: [[0.00362674]\n",
            " [0.99608165]\n",
            " [0.9960698 ]\n",
            " [0.00597692]]\n",
            "Step: 6445 -> Loss: 0.004373021423816681 -> Predictions: [[0.00362672]\n",
            " [0.99608165]\n",
            " [0.9960698 ]\n",
            " [0.00597689]]\n",
            "Step: 6446 -> Loss: 0.004373002331703901 -> Predictions: [[0.0036267 ]\n",
            " [0.99608177]\n",
            " [0.9960698 ]\n",
            " [0.00597686]]\n",
            "Step: 6447 -> Loss: 0.004372982308268547 -> Predictions: [[0.00362669]\n",
            " [0.99608177]\n",
            " [0.9960698 ]\n",
            " [0.00597683]]\n",
            "Step: 6448 -> Loss: 0.0043729632161557674 -> Predictions: [[0.00362667]\n",
            " [0.99608177]\n",
            " [0.9960699 ]\n",
            " [0.0059768 ]]\n",
            "Step: 6449 -> Loss: 0.004372941330075264 -> Predictions: [[0.00362666]\n",
            " [0.99608177]\n",
            " [0.9960699 ]\n",
            " [0.00597677]]\n",
            "Step: 6450 -> Loss: 0.0043729208409786224 -> Predictions: [[0.00362664]\n",
            " [0.99608177]\n",
            " [0.9960699 ]\n",
            " [0.00597674]]\n",
            "Step: 6451 -> Loss: 0.0043729012832045555 -> Predictions: [[0.00362662]\n",
            " [0.99608177]\n",
            " [0.9960699 ]\n",
            " [0.00597671]]\n",
            "Step: 6452 -> Loss: 0.00437287800014019 -> Predictions: [[0.0036266 ]\n",
            " [0.99608177]\n",
            " [0.9960699 ]\n",
            " [0.00597668]]\n",
            "Step: 6453 -> Loss: 0.004372861236333847 -> Predictions: [[0.00362659]\n",
            " [0.9960819 ]\n",
            " [0.9960699 ]\n",
            " [0.00597665]]\n",
            "Step: 6454 -> Loss: 0.004372838884592056 -> Predictions: [[0.00362657]\n",
            " [0.9960819 ]\n",
            " [0.9960699 ]\n",
            " [0.00597662]]\n",
            "Step: 6455 -> Loss: 0.004372818861156702 -> Predictions: [[0.00362656]\n",
            " [0.9960819 ]\n",
            " [0.99607   ]\n",
            " [0.00597659]]\n",
            "Step: 6456 -> Loss: 0.004372796509414911 -> Predictions: [[0.00362653]\n",
            " [0.9960819 ]\n",
            " [0.99607   ]\n",
            " [0.00597656]]\n",
            "Step: 6457 -> Loss: 0.004372777417302132 -> Predictions: [[0.00362652]\n",
            " [0.9960819 ]\n",
            " [0.99607   ]\n",
            " [0.00597653]]\n",
            "Step: 6458 -> Loss: 0.0043727559968829155 -> Predictions: [[0.0036265]\n",
            " [0.9960819]\n",
            " [0.99607  ]\n",
            " [0.0059765]]\n",
            "Step: 6459 -> Loss: 0.004372734576463699 -> Predictions: [[0.00362649]\n",
            " [0.9960819 ]\n",
            " [0.99607   ]\n",
            " [0.00597647]]\n",
            "Step: 6460 -> Loss: 0.004372715018689632 -> Predictions: [[0.00362647]\n",
            " [0.996082  ]\n",
            " [0.99607   ]\n",
            " [0.00597644]]\n",
            "Step: 6461 -> Loss: 0.00437269639223814 -> Predictions: [[0.00362646]\n",
            " [0.996082  ]\n",
            " [0.99607015]\n",
            " [0.00597641]]\n",
            "Step: 6462 -> Loss: 0.004372674971818924 -> Predictions: [[0.00362644]\n",
            " [0.996082  ]\n",
            " [0.99607015]\n",
            " [0.00597638]]\n",
            "Step: 6463 -> Loss: 0.004372655414044857 -> Predictions: [[0.00362643]\n",
            " [0.996082  ]\n",
            " [0.99607015]\n",
            " [0.00597635]]\n",
            "Step: 6464 -> Loss: 0.004372636787593365 -> Predictions: [[0.00362641]\n",
            " [0.996082  ]\n",
            " [0.99607015]\n",
            " [0.00597632]]\n",
            "Step: 6465 -> Loss: 0.004372616298496723 -> Predictions: [[0.00362639]\n",
            " [0.996082  ]\n",
            " [0.99607015]\n",
            " [0.00597629]]\n",
            "Step: 6466 -> Loss: 0.004372594878077507 -> Predictions: [[0.00362638]\n",
            " [0.996082  ]\n",
            " [0.99607015]\n",
            " [0.00597626]]\n",
            "Step: 6467 -> Loss: 0.004372571595013142 -> Predictions: [[0.00362636]\n",
            " [0.9960821 ]\n",
            " [0.99607015]\n",
            " [0.00597623]]\n",
            "Step: 6468 -> Loss: 0.004372552502900362 -> Predictions: [[0.00362634]\n",
            " [0.9960821 ]\n",
            " [0.99607027]\n",
            " [0.0059762 ]]\n",
            "Step: 6469 -> Loss: 0.00437253387644887 -> Predictions: [[0.00362633]\n",
            " [0.9960821 ]\n",
            " [0.99607027]\n",
            " [0.00597617]]\n",
            "Step: 6470 -> Loss: 0.0043725138530135155 -> Predictions: [[0.00362631]\n",
            " [0.9960821 ]\n",
            " [0.99607027]\n",
            " [0.00597614]]\n",
            "Step: 6471 -> Loss: 0.004372491966933012 -> Predictions: [[0.0036263 ]\n",
            " [0.9960821 ]\n",
            " [0.99607027]\n",
            " [0.00597611]]\n",
            "Step: 6472 -> Loss: 0.004372472874820232 -> Predictions: [[0.00362628]\n",
            " [0.9960821 ]\n",
            " [0.99607027]\n",
            " [0.00597609]]\n",
            "Step: 6473 -> Loss: 0.004372448660433292 -> Predictions: [[0.00362626]\n",
            " [0.99608225]\n",
            " [0.99607027]\n",
            " [0.00597605]]\n",
            "Step: 6474 -> Loss: 0.004372432362288237 -> Predictions: [[0.00362625]\n",
            " [0.99608225]\n",
            " [0.99607027]\n",
            " [0.00597602]]\n",
            "Step: 6475 -> Loss: 0.004372410476207733 -> Predictions: [[0.00362623]\n",
            " [0.99608225]\n",
            " [0.9960704 ]\n",
            " [0.00597599]]\n",
            "Step: 6476 -> Loss: 0.004372390918433666 -> Predictions: [[0.00362622]\n",
            " [0.99608225]\n",
            " [0.9960704 ]\n",
            " [0.00597596]]\n",
            "Step: 6477 -> Loss: 0.004372371360659599 -> Predictions: [[0.00362619]\n",
            " [0.99608225]\n",
            " [0.9960704 ]\n",
            " [0.00597593]]\n",
            "Step: 6478 -> Loss: 0.004372350871562958 -> Predictions: [[0.00362618]\n",
            " [0.99608225]\n",
            " [0.9960704 ]\n",
            " [0.0059759 ]]\n",
            "Step: 6479 -> Loss: 0.004372329451143742 -> Predictions: [[0.00362616]\n",
            " [0.99608225]\n",
            " [0.9960704 ]\n",
            " [0.00597587]]\n",
            "Step: 6480 -> Loss: 0.004372309427708387 -> Predictions: [[0.00362615]\n",
            " [0.99608237]\n",
            " [0.9960704 ]\n",
            " [0.00597584]]\n",
            "Step: 6481 -> Loss: 0.004372286610305309 -> Predictions: [[0.00362613]\n",
            " [0.99608237]\n",
            " [0.9960704 ]\n",
            " [0.00597581]]\n",
            "Step: 6482 -> Loss: 0.004372269846498966 -> Predictions: [[0.00362611]\n",
            " [0.99608237]\n",
            " [0.9960705 ]\n",
            " [0.00597579]]\n",
            "Step: 6483 -> Loss: 0.004372248891741037 -> Predictions: [[0.00362609]\n",
            " [0.99608237]\n",
            " [0.9960705 ]\n",
            " [0.00597575]]\n",
            "Step: 6484 -> Loss: 0.004372228402644396 -> Predictions: [[0.00362608]\n",
            " [0.99608237]\n",
            " [0.9960705 ]\n",
            " [0.00597573]]\n",
            "Step: 6485 -> Loss: 0.004372206050902605 -> Predictions: [[0.00362607]\n",
            " [0.99608237]\n",
            " [0.9960705 ]\n",
            " [0.00597569]]\n",
            "Step: 6486 -> Loss: 0.004372187424451113 -> Predictions: [[0.00362605]\n",
            " [0.99608237]\n",
            " [0.9960705 ]\n",
            " [0.00597566]]\n",
            "Step: 6487 -> Loss: 0.004372166935354471 -> Predictions: [[0.00362603]\n",
            " [0.9960824 ]\n",
            " [0.9960705 ]\n",
            " [0.00597563]]\n",
            "Step: 6488 -> Loss: 0.004372146911919117 -> Predictions: [[0.00362602]\n",
            " [0.9960824 ]\n",
            " [0.9960705 ]\n",
            " [0.0059756 ]]\n",
            "Step: 6489 -> Loss: 0.00437212735414505 -> Predictions: [[0.003626  ]\n",
            " [0.9960824 ]\n",
            " [0.9960706 ]\n",
            " [0.00597558]]\n",
            "Step: 6490 -> Loss: 0.004372104071080685 -> Predictions: [[0.00362598]\n",
            " [0.9960824 ]\n",
            " [0.9960706 ]\n",
            " [0.00597554]]\n",
            "Step: 6491 -> Loss: 0.004372085444629192 -> Predictions: [[0.00362597]\n",
            " [0.9960824 ]\n",
            " [0.9960706 ]\n",
            " [0.00597551]]\n",
            "Step: 6492 -> Loss: 0.004372062627226114 -> Predictions: [[0.00362595]\n",
            " [0.9960824 ]\n",
            " [0.9960706 ]\n",
            " [0.00597548]]\n",
            "Step: 6493 -> Loss: 0.004372045397758484 -> Predictions: [[0.00362594]\n",
            " [0.9960824 ]\n",
            " [0.9960706 ]\n",
            " [0.00597545]]\n",
            "Step: 6494 -> Loss: 0.00437202537432313 -> Predictions: [[0.00362592]\n",
            " [0.99608254]\n",
            " [0.9960706 ]\n",
            " [0.00597543]]\n",
            "Step: 6495 -> Loss: 0.004372004419565201 -> Predictions: [[0.0036259 ]\n",
            " [0.99608254]\n",
            " [0.9960706 ]\n",
            " [0.00597539]]\n",
            "Step: 6496 -> Loss: 0.004371985327452421 -> Predictions: [[0.00362589]\n",
            " [0.99608254]\n",
            " [0.99607074]\n",
            " [0.00597537]]\n",
            "Step: 6497 -> Loss: 0.0043719615787267685 -> Predictions: [[0.00362587]\n",
            " [0.99608254]\n",
            " [0.99607074]\n",
            " [0.00597533]]\n",
            "Step: 6498 -> Loss: 0.004371942020952702 -> Predictions: [[0.00362585]\n",
            " [0.99608254]\n",
            " [0.99607074]\n",
            " [0.0059753 ]]\n",
            "Step: 6499 -> Loss: 0.004371920134872198 -> Predictions: [[0.00362583]\n",
            " [0.99608254]\n",
            " [0.99607074]\n",
            " [0.00597526]]\n",
            "Step: 6501 -> Loss: 0.00437188008800149 -> Predictions: [[0.0036258 ]\n",
            " [0.99608266]\n",
            " [0.99607074]\n",
            " [0.00597521]]\n",
            "Step: 6502 -> Loss: 0.004371860530227423 -> Predictions: [[0.00362578]\n",
            " [0.99608266]\n",
            " [0.99607086]\n",
            " [0.00597518]]\n",
            "Step: 6503 -> Loss: 0.004371840041130781 -> Predictions: [[0.00362577]\n",
            " [0.99608266]\n",
            " [0.99607086]\n",
            " [0.00597515]]\n",
            "Step: 6504 -> Loss: 0.004371819086372852 -> Predictions: [[0.00362575]\n",
            " [0.99608266]\n",
            " [0.99607086]\n",
            " [0.00597512]]\n",
            "Step: 6505 -> Loss: 0.004371800925582647 -> Predictions: [[0.00362573]\n",
            " [0.99608266]\n",
            " [0.99607086]\n",
            " [0.0059751 ]]\n",
            "Step: 6506 -> Loss: 0.004371778108179569 -> Predictions: [[0.00362572]\n",
            " [0.99608266]\n",
            " [0.99607086]\n",
            " [0.00597506]]\n",
            "Step: 6507 -> Loss: 0.004371761344373226 -> Predictions: [[0.00362571]\n",
            " [0.99608266]\n",
            " [0.99607086]\n",
            " [0.00597504]]\n",
            "Step: 6508 -> Loss: 0.004371738061308861 -> Predictions: [[0.00362568]\n",
            " [0.9960828 ]\n",
            " [0.99607086]\n",
            " [0.005975  ]]\n",
            "Step: 6509 -> Loss: 0.004371717572212219 -> Predictions: [[0.00362567]\n",
            " [0.9960828 ]\n",
            " [0.996071  ]\n",
            " [0.00597497]]\n",
            "Step: 6510 -> Loss: 0.004371696151793003 -> Predictions: [[0.00362565]\n",
            " [0.9960828 ]\n",
            " [0.996071  ]\n",
            " [0.00597494]]\n",
            "Step: 6511 -> Loss: 0.004371678456664085 -> Predictions: [[0.00362564]\n",
            " [0.9960828 ]\n",
            " [0.996071  ]\n",
            " [0.00597491]]\n",
            "Step: 6512 -> Loss: 0.004371657967567444 -> Predictions: [[0.00362562]\n",
            " [0.9960828 ]\n",
            " [0.996071  ]\n",
            " [0.00597489]]\n",
            "Step: 6513 -> Loss: 0.004371637478470802 -> Predictions: [[0.0036256 ]\n",
            " [0.9960828 ]\n",
            " [0.996071  ]\n",
            " [0.00597486]]\n",
            "Step: 6514 -> Loss: 0.004371618386358023 -> Predictions: [[0.00362559]\n",
            " [0.9960828 ]\n",
            " [0.996071  ]\n",
            " [0.00597482]]\n",
            "Step: 6515 -> Loss: 0.004371595568954945 -> Predictions: [[0.00362557]\n",
            " [0.9960829 ]\n",
            " [0.996071  ]\n",
            " [0.0059748 ]]\n",
            "Step: 6516 -> Loss: 0.004371576011180878 -> Predictions: [[0.00362556]\n",
            " [0.9960829 ]\n",
            " [0.9960711 ]\n",
            " [0.00597477]]\n",
            "Step: 6517 -> Loss: 0.004371556453406811 -> Predictions: [[0.00362554]\n",
            " [0.9960829 ]\n",
            " [0.9960711 ]\n",
            " [0.00597473]]\n",
            "Step: 6518 -> Loss: 0.004371535964310169 -> Predictions: [[0.00362552]\n",
            " [0.9960829 ]\n",
            " [0.9960711 ]\n",
            " [0.0059747 ]]\n",
            "Step: 6519 -> Loss: 0.004371516406536102 -> Predictions: [[0.00362551]\n",
            " [0.9960829 ]\n",
            " [0.9960711 ]\n",
            " [0.00597468]]\n",
            "Step: 6520 -> Loss: 0.0043714940547943115 -> Predictions: [[0.00362549]\n",
            " [0.9960829 ]\n",
            " [0.9960711 ]\n",
            " [0.00597465]]\n",
            "Step: 6521 -> Loss: 0.00437147356569767 -> Predictions: [[0.00362547]\n",
            " [0.9960829 ]\n",
            " [0.9960711 ]\n",
            " [0.00597461]]\n",
            "Step: 6522 -> Loss: 0.004371454007923603 -> Predictions: [[0.00362546]\n",
            " [0.996083  ]\n",
            " [0.9960711 ]\n",
            " [0.00597459]]\n",
            "Step: 6523 -> Loss: 0.004371436312794685 -> Predictions: [[0.00362544]\n",
            " [0.996083  ]\n",
            " [0.9960712 ]\n",
            " [0.00597456]]\n",
            "Step: 6524 -> Loss: 0.004371413495391607 -> Predictions: [[0.00362543]\n",
            " [0.996083  ]\n",
            " [0.9960712 ]\n",
            " [0.00597452]]\n",
            "Step: 6525 -> Loss: 0.004371391609311104 -> Predictions: [[0.00362541]\n",
            " [0.996083  ]\n",
            " [0.9960712 ]\n",
            " [0.0059745 ]]\n",
            "Step: 6526 -> Loss: 0.004371370188891888 -> Predictions: [[0.00362539]\n",
            " [0.996083  ]\n",
            " [0.9960712 ]\n",
            " [0.00597447]]\n",
            "Step: 6527 -> Loss: 0.004371352028101683 -> Predictions: [[0.00362538]\n",
            " [0.996083  ]\n",
            " [0.9960712 ]\n",
            " [0.00597443]]\n",
            "Step: 6528 -> Loss: 0.00437133340165019 -> Predictions: [[0.00362536]\n",
            " [0.99608314]\n",
            " [0.9960712 ]\n",
            " [0.00597441]]\n",
            "Step: 6529 -> Loss: 0.004371310584247112 -> Predictions: [[0.00362534]\n",
            " [0.99608314]\n",
            " [0.9960712 ]\n",
            " [0.00597437]]\n",
            "Step: 6530 -> Loss: 0.004371291492134333 -> Predictions: [[0.00362532]\n",
            " [0.99608314]\n",
            " [0.99607134]\n",
            " [0.00597434]]\n",
            "Step: 6531 -> Loss: 0.004371268674731255 -> Predictions: [[0.00362531]\n",
            " [0.99608314]\n",
            " [0.99607134]\n",
            " [0.00597431]]\n",
            "Step: 6532 -> Loss: 0.004371249582618475 -> Predictions: [[0.00362529]\n",
            " [0.99608314]\n",
            " [0.99607134]\n",
            " [0.00597428]]\n",
            "Step: 6533 -> Loss: 0.004371229093521833 -> Predictions: [[0.00362528]\n",
            " [0.99608314]\n",
            " [0.99607134]\n",
            " [0.00597425]]\n",
            "Step: 6534 -> Loss: 0.004371208138763905 -> Predictions: [[0.00362526]\n",
            " [0.99608314]\n",
            " [0.99607134]\n",
            " [0.00597422]]\n",
            "Step: 6535 -> Loss: 0.004371187649667263 -> Predictions: [[0.00362524]\n",
            " [0.99608326]\n",
            " [0.99607134]\n",
            " [0.00597419]]\n",
            "Step: 6536 -> Loss: 0.004371167626231909 -> Predictions: [[0.00362523]\n",
            " [0.99608326]\n",
            " [0.99607146]\n",
            " [0.00597416]]\n",
            "Step: 6537 -> Loss: 0.0043711476027965546 -> Predictions: [[0.00362521]\n",
            " [0.99608326]\n",
            " [0.99607146]\n",
            " [0.00597414]]\n",
            "Step: 6538 -> Loss: 0.0043711294420063496 -> Predictions: [[0.0036252 ]\n",
            " [0.99608326]\n",
            " [0.99607146]\n",
            " [0.00597411]]\n",
            "Step: 6539 -> Loss: 0.004371108487248421 -> Predictions: [[0.00362518]\n",
            " [0.99608326]\n",
            " [0.99607146]\n",
            " [0.00597407]]\n",
            "Step: 6540 -> Loss: 0.00437108613550663 -> Predictions: [[0.00362516]\n",
            " [0.99608326]\n",
            " [0.99607146]\n",
            " [0.00597404]]\n",
            "Step: 6541 -> Loss: 0.00437106704339385 -> Predictions: [[0.00362515]\n",
            " [0.99608326]\n",
            " [0.99607146]\n",
            " [0.00597401]]\n",
            "Step: 6542 -> Loss: 0.004371046554297209 -> Predictions: [[0.00362513]\n",
            " [0.9960834 ]\n",
            " [0.99607146]\n",
            " [0.00597399]]\n",
            "Step: 6543 -> Loss: 0.004371029790490866 -> Predictions: [[0.00362511]\n",
            " [0.9960834 ]\n",
            " [0.9960716 ]\n",
            " [0.00597396]]\n",
            "Step: 6544 -> Loss: 0.004371004179120064 -> Predictions: [[0.0036251 ]\n",
            " [0.9960834 ]\n",
            " [0.9960716 ]\n",
            " [0.00597392]]\n",
            "Step: 6545 -> Loss: 0.004370986483991146 -> Predictions: [[0.00362508]\n",
            " [0.9960834 ]\n",
            " [0.9960716 ]\n",
            " [0.0059739 ]]\n",
            "Step: 6546 -> Loss: 0.004370963200926781 -> Predictions: [[0.00362507]\n",
            " [0.9960834 ]\n",
            " [0.9960716 ]\n",
            " [0.00597386]]\n",
            "Step: 6547 -> Loss: 0.0043709431774914265 -> Predictions: [[0.00362505]\n",
            " [0.9960834 ]\n",
            " [0.9960716 ]\n",
            " [0.00597383]]\n",
            "Step: 6548 -> Loss: 0.004370924551039934 -> Predictions: [[0.00362504]\n",
            " [0.9960834 ]\n",
            " [0.9960716 ]\n",
            " [0.0059738 ]]\n",
            "Step: 6549 -> Loss: 0.00437090452760458 -> Predictions: [[0.00362502]\n",
            " [0.9960835 ]\n",
            " [0.9960716 ]\n",
            " [0.00597377]]\n",
            "Step: 6550 -> Loss: 0.004370883107185364 -> Predictions: [[0.003625  ]\n",
            " [0.9960835 ]\n",
            " [0.9960717 ]\n",
            " [0.00597374]]\n",
            "Step: 6551 -> Loss: 0.0043708630837500095 -> Predictions: [[0.00362498]\n",
            " [0.9960835 ]\n",
            " [0.9960717 ]\n",
            " [0.00597372]]\n",
            "Step: 6552 -> Loss: 0.004370843060314655 -> Predictions: [[0.00362496]\n",
            " [0.9960835 ]\n",
            " [0.9960717 ]\n",
            " [0.00597369]]\n",
            "Step: 6553 -> Loss: 0.0043708207085728645 -> Predictions: [[0.00362495]\n",
            " [0.9960835 ]\n",
            " [0.9960717 ]\n",
            " [0.00597365]]\n",
            "Step: 6554 -> Loss: 0.004370802082121372 -> Predictions: [[0.00362493]\n",
            " [0.9960835 ]\n",
            " [0.9960717 ]\n",
            " [0.00597363]]\n",
            "Step: 6555 -> Loss: 0.004370782524347305 -> Predictions: [[0.00362492]\n",
            " [0.9960835 ]\n",
            " [0.9960717 ]\n",
            " [0.0059736 ]]\n",
            "Step: 6556 -> Loss: 0.004370762035250664 -> Predictions: [[0.0036249 ]\n",
            " [0.9960836 ]\n",
            " [0.9960717 ]\n",
            " [0.00597357]]\n",
            "Step: 6557 -> Loss: 0.004370740614831448 -> Predictions: [[0.00362488]\n",
            " [0.9960836 ]\n",
            " [0.9960718 ]\n",
            " [0.00597353]]\n",
            "Step: 6558 -> Loss: 0.004370721522718668 -> Predictions: [[0.00362487]\n",
            " [0.9960836 ]\n",
            " [0.9960718 ]\n",
            " [0.00597351]]\n",
            "Step: 6559 -> Loss: 0.004370700567960739 -> Predictions: [[0.00362485]\n",
            " [0.9960836 ]\n",
            " [0.9960718 ]\n",
            " [0.00597347]]\n",
            "Step: 6560 -> Loss: 0.004370679147541523 -> Predictions: [[0.00362484]\n",
            " [0.9960836 ]\n",
            " [0.9960718 ]\n",
            " [0.00597344]]\n",
            "Step: 6561 -> Loss: 0.004370660055428743 -> Predictions: [[0.00362482]\n",
            " [0.9960836 ]\n",
            " [0.9960718 ]\n",
            " [0.00597342]]\n",
            "Step: 6562 -> Loss: 0.0043706391006708145 -> Predictions: [[0.0036248 ]\n",
            " [0.99608374]\n",
            " [0.9960718 ]\n",
            " [0.00597338]]\n",
            "Step: 6563 -> Loss: 0.004370618611574173 -> Predictions: [[0.00362479]\n",
            " [0.99608374]\n",
            " [0.99607193]\n",
            " [0.00597336]]\n",
            "Step: 6564 -> Loss: 0.004370598122477531 -> Predictions: [[0.00362477]\n",
            " [0.99608374]\n",
            " [0.99607193]\n",
            " [0.00597332]]\n",
            "Step: 6565 -> Loss: 0.004370579496026039 -> Predictions: [[0.00362476]\n",
            " [0.99608374]\n",
            " [0.99607193]\n",
            " [0.0059733 ]]\n",
            "Step: 6566 -> Loss: 0.0043705604039132595 -> Predictions: [[0.00362474]\n",
            " [0.99608374]\n",
            " [0.99607193]\n",
            " [0.00597327]]\n",
            "Step: 6567 -> Loss: 0.004370537120848894 -> Predictions: [[0.00362472]\n",
            " [0.99608374]\n",
            " [0.99607193]\n",
            " [0.00597324]]\n",
            "Step: 6568 -> Loss: 0.00437051709741354 -> Predictions: [[0.0036247 ]\n",
            " [0.99608374]\n",
            " [0.99607193]\n",
            " [0.00597321]]\n",
            "Step: 6569 -> Loss: 0.00437049800530076 -> Predictions: [[0.00362469]\n",
            " [0.99608386]\n",
            " [0.99607193]\n",
            " [0.00597317]]\n",
            "Step: 6570 -> Loss: 0.004370477050542831 -> Predictions: [[0.00362467]\n",
            " [0.99608386]\n",
            " [0.99607205]\n",
            " [0.00597315]]\n",
            "Step: 6571 -> Loss: 0.00437045656144619 -> Predictions: [[0.00362466]\n",
            " [0.99608386]\n",
            " [0.99607205]\n",
            " [0.00597312]]\n",
            "Step: 6572 -> Loss: 0.004370435606688261 -> Predictions: [[0.00362464]\n",
            " [0.99608386]\n",
            " [0.99607205]\n",
            " [0.00597309]]\n",
            "Step: 6573 -> Loss: 0.0043704151175916195 -> Predictions: [[0.00362462]\n",
            " [0.99608386]\n",
            " [0.99607205]\n",
            " [0.00597306]]\n",
            "Step: 6574 -> Loss: 0.004370394162833691 -> Predictions: [[0.00362461]\n",
            " [0.99608386]\n",
            " [0.99607205]\n",
            " [0.00597302]]\n",
            "Step: 6575 -> Loss: 0.004370376467704773 -> Predictions: [[0.00362459]\n",
            " [0.99608386]\n",
            " [0.99607205]\n",
            " [0.005973  ]]\n",
            "Step: 6576 -> Loss: 0.0043703531846404076 -> Predictions: [[0.00362457]\n",
            " [0.996084  ]\n",
            " [0.99607205]\n",
            " [0.00597296]]\n",
            "Step: 6577 -> Loss: 0.004370334092527628 -> Predictions: [[0.00362456]\n",
            " [0.996084  ]\n",
            " [0.9960722 ]\n",
            " [0.00597294]]\n",
            "Step: 6578 -> Loss: 0.004370315466076136 -> Predictions: [[0.00362454]\n",
            " [0.996084  ]\n",
            " [0.9960722 ]\n",
            " [0.00597291]]\n",
            "Step: 6579 -> Loss: 0.004370294511318207 -> Predictions: [[0.00362453]\n",
            " [0.996084  ]\n",
            " [0.9960722 ]\n",
            " [0.00597288]]\n",
            "Step: 6580 -> Loss: 0.004370271693915129 -> Predictions: [[0.00362451]\n",
            " [0.996084  ]\n",
            " [0.9960722 ]\n",
            " [0.00597284]]\n",
            "Step: 6581 -> Loss: 0.004370252601802349 -> Predictions: [[0.00362449]\n",
            " [0.996084  ]\n",
            " [0.9960722 ]\n",
            " [0.00597282]]\n",
            "Step: 6582 -> Loss: 0.004370232578366995 -> Predictions: [[0.00362447]\n",
            " [0.996084  ]\n",
            " [0.9960722 ]\n",
            " [0.00597278]]\n",
            "Step: 6583 -> Loss: 0.004370211623609066 -> Predictions: [[0.00362446]\n",
            " [0.9960841 ]\n",
            " [0.9960722 ]\n",
            " [0.00597276]]\n",
            "Step: 6584 -> Loss: 0.0043701911345124245 -> Predictions: [[0.00362444]\n",
            " [0.9960841 ]\n",
            " [0.9960723 ]\n",
            " [0.00597273]]\n",
            "Step: 6585 -> Loss: 0.004370170645415783 -> Predictions: [[0.00362443]\n",
            " [0.9960841 ]\n",
            " [0.9960723 ]\n",
            " [0.0059727 ]]\n",
            "Step: 6586 -> Loss: 0.004370151087641716 -> Predictions: [[0.00362441]\n",
            " [0.9960841 ]\n",
            " [0.9960723 ]\n",
            " [0.00597267]]\n",
            "Step: 6587 -> Loss: 0.0043701292015612125 -> Predictions: [[0.00362439]\n",
            " [0.9960841 ]\n",
            " [0.9960723 ]\n",
            " [0.00597263]]\n",
            "Step: 6588 -> Loss: 0.004370108712464571 -> Predictions: [[0.00362438]\n",
            " [0.9960841 ]\n",
            " [0.9960723 ]\n",
            " [0.00597261]]\n",
            "Step: 6589 -> Loss: 0.004370091482996941 -> Predictions: [[0.00362436]\n",
            " [0.9960841 ]\n",
            " [0.9960723 ]\n",
            " [0.00597258]]\n",
            "Step: 6590 -> Loss: 0.004370070993900299 -> Predictions: [[0.00362435]\n",
            " [0.9960842 ]\n",
            " [0.9960723 ]\n",
            " [0.00597255]]\n",
            "Step: 6591 -> Loss: 0.004370051436126232 -> Predictions: [[0.00362433]\n",
            " [0.9960842 ]\n",
            " [0.9960724 ]\n",
            " [0.00597252]]\n",
            "Step: 6592 -> Loss: 0.004370029084384441 -> Predictions: [[0.00362431]\n",
            " [0.9960842 ]\n",
            " [0.9960724 ]\n",
            " [0.00597249]]\n",
            "Step: 6593 -> Loss: 0.004370007198303938 -> Predictions: [[0.00362429]\n",
            " [0.9960842 ]\n",
            " [0.9960724 ]\n",
            " [0.00597246]]\n",
            "Step: 6594 -> Loss: 0.004369988106191158 -> Predictions: [[0.00362428]\n",
            " [0.9960842 ]\n",
            " [0.9960724 ]\n",
            " [0.00597243]]\n",
            "Step: 6595 -> Loss: 0.004369967617094517 -> Predictions: [[0.00362426]\n",
            " [0.9960842 ]\n",
            " [0.9960724 ]\n",
            " [0.0059724 ]]\n",
            "Step: 6596 -> Loss: 0.004369946662336588 -> Predictions: [[0.00362424]\n",
            " [0.99608433]\n",
            " [0.9960724 ]\n",
            " [0.00597237]]\n",
            "Step: 6597 -> Loss: 0.00436992896720767 -> Predictions: [[0.00362423]\n",
            " [0.99608433]\n",
            " [0.9960724 ]\n",
            " [0.00597234]]\n",
            "Step: 6598 -> Loss: 0.004369906149804592 -> Predictions: [[0.00362421]\n",
            " [0.99608433]\n",
            " [0.99607253]\n",
            " [0.0059723 ]]\n",
            "Step: 6599 -> Loss: 0.0043698875233531 -> Predictions: [[0.0036242 ]\n",
            " [0.99608433]\n",
            " [0.99607253]\n",
            " [0.00597227]]\n",
            "Step: 6600 -> Loss: 0.0043698642402887344 -> Predictions: [[0.00362418]\n",
            " [0.99608433]\n",
            " [0.99607253]\n",
            " [0.00597224]]\n",
            "Step: 6601 -> Loss: 0.004369847010821104 -> Predictions: [[0.00362417]\n",
            " [0.99608433]\n",
            " [0.99607253]\n",
            " [0.00597222]]\n",
            "Step: 6602 -> Loss: 0.0043698265217244625 -> Predictions: [[0.00362415]\n",
            " [0.99608433]\n",
            " [0.99607253]\n",
            " [0.00597219]]\n",
            "Step: 6603 -> Loss: 0.004369805566966534 -> Predictions: [[0.00362413]\n",
            " [0.99608445]\n",
            " [0.99607253]\n",
            " [0.00597216]]\n",
            "Step: 6604 -> Loss: 0.004369785077869892 -> Predictions: [[0.00362411]\n",
            " [0.99608445]\n",
            " [0.99607265]\n",
            " [0.00597213]]\n",
            "Step: 6605 -> Loss: 0.004369762726128101 -> Predictions: [[0.0036241 ]\n",
            " [0.99608445]\n",
            " [0.99607265]\n",
            " [0.0059721 ]]\n",
            "Step: 6606 -> Loss: 0.004369743168354034 -> Predictions: [[0.00362408]\n",
            " [0.99608445]\n",
            " [0.99607265]\n",
            " [0.00597206]]\n",
            "Step: 6607 -> Loss: 0.004369724541902542 -> Predictions: [[0.00362407]\n",
            " [0.99608445]\n",
            " [0.99607265]\n",
            " [0.00597204]]\n",
            "Step: 6608 -> Loss: 0.004369703121483326 -> Predictions: [[0.00362405]\n",
            " [0.99608445]\n",
            " [0.99607265]\n",
            " [0.00597201]]\n",
            "Step: 6609 -> Loss: 0.004369682632386684 -> Predictions: [[0.00362403]\n",
            " [0.99608445]\n",
            " [0.99607265]\n",
            " [0.00597198]]\n",
            "Step: 6610 -> Loss: 0.004369661211967468 -> Predictions: [[0.00362401]\n",
            " [0.9960846 ]\n",
            " [0.99607265]\n",
            " [0.00597195]]\n",
            "Step: 6611 -> Loss: 0.004369643516838551 -> Predictions: [[0.003624  ]\n",
            " [0.9960846 ]\n",
            " [0.99607277]\n",
            " [0.00597192]]\n",
            "Step: 6612 -> Loss: 0.004369622096419334 -> Predictions: [[0.00362398]\n",
            " [0.9960846 ]\n",
            " [0.99607277]\n",
            " [0.00597189]]\n",
            "Step: 6613 -> Loss: 0.0043696011416614056 -> Predictions: [[0.00362397]\n",
            " [0.9960846 ]\n",
            " [0.99607277]\n",
            " [0.00597186]]\n",
            "Step: 6614 -> Loss: 0.004369580652564764 -> Predictions: [[0.00362395]\n",
            " [0.9960846 ]\n",
            " [0.99607277]\n",
            " [0.00597183]]\n",
            "Step: 6615 -> Loss: 0.0043695601634681225 -> Predictions: [[0.00362393]\n",
            " [0.9960846 ]\n",
            " [0.99607277]\n",
            " [0.0059718 ]]\n",
            "Step: 6616 -> Loss: 0.004369539674371481 -> Predictions: [[0.00362392]\n",
            " [0.9960846 ]\n",
            " [0.99607277]\n",
            " [0.00597177]]\n",
            "Step: 6617 -> Loss: 0.0043695224449038506 -> Predictions: [[0.0036239 ]\n",
            " [0.9960847 ]\n",
            " [0.99607277]\n",
            " [0.00597174]]\n",
            "Step: 6618 -> Loss: 0.004369498696178198 -> Predictions: [[0.00362389]\n",
            " [0.9960847 ]\n",
            " [0.9960729 ]\n",
            " [0.00597171]]\n",
            "Step: 6619 -> Loss: 0.004369478672742844 -> Predictions: [[0.00362387]\n",
            " [0.9960847 ]\n",
            " [0.9960729 ]\n",
            " [0.00597168]]\n",
            "Step: 6620 -> Loss: 0.004369459580630064 -> Predictions: [[0.00362385]\n",
            " [0.9960847 ]\n",
            " [0.9960729 ]\n",
            " [0.00597165]]\n",
            "Step: 6621 -> Loss: 0.0043694390915334225 -> Predictions: [[0.00362383]\n",
            " [0.9960847 ]\n",
            " [0.9960729 ]\n",
            " [0.00597162]]\n",
            "Step: 6622 -> Loss: 0.004369418602436781 -> Predictions: [[0.00362382]\n",
            " [0.9960847 ]\n",
            " [0.9960729 ]\n",
            " [0.00597159]]\n",
            "Step: 6623 -> Loss: 0.004369399510324001 -> Predictions: [[0.00362381]\n",
            " [0.9960847 ]\n",
            " [0.9960729 ]\n",
            " [0.00597156]]\n",
            "Step: 6624 -> Loss: 0.0043693785555660725 -> Predictions: [[0.00362379]\n",
            " [0.9960848 ]\n",
            " [0.9960729 ]\n",
            " [0.00597153]]\n",
            "Step: 6625 -> Loss: 0.004369357600808144 -> Predictions: [[0.00362377]\n",
            " [0.9960848 ]\n",
            " [0.996073  ]\n",
            " [0.0059715 ]]\n",
            "Step: 6626 -> Loss: 0.004369336646050215 -> Predictions: [[0.00362375]\n",
            " [0.9960848 ]\n",
            " [0.996073  ]\n",
            " [0.00597146]]\n",
            "Step: 6627 -> Loss: 0.004369318950921297 -> Predictions: [[0.00362374]\n",
            " [0.9960848 ]\n",
            " [0.996073  ]\n",
            " [0.00597144]]\n",
            "Step: 6628 -> Loss: 0.004369297064840794 -> Predictions: [[0.00362372]\n",
            " [0.9960848 ]\n",
            " [0.996073  ]\n",
            " [0.00597141]]\n",
            "Step: 6629 -> Loss: 0.004369276575744152 -> Predictions: [[0.0036237 ]\n",
            " [0.9960848 ]\n",
            " [0.996073  ]\n",
            " [0.00597139]]\n",
            "Step: 6630 -> Loss: 0.004369255620986223 -> Predictions: [[0.00362369]\n",
            " [0.9960849 ]\n",
            " [0.996073  ]\n",
            " [0.00597135]]\n",
            "Step: 6631 -> Loss: 0.00436923373490572 -> Predictions: [[0.00362367]\n",
            " [0.9960849 ]\n",
            " [0.9960731 ]\n",
            " [0.00597132]]\n",
            "Step: 6632 -> Loss: 0.004369216971099377 -> Predictions: [[0.00362366]\n",
            " [0.9960849 ]\n",
            " [0.9960731 ]\n",
            " [0.00597129]]\n",
            "Step: 6633 -> Loss: 0.004369193222373724 -> Predictions: [[0.00362364]\n",
            " [0.9960849 ]\n",
            " [0.9960731 ]\n",
            " [0.00597126]]\n",
            "Step: 6634 -> Loss: 0.004369174130260944 -> Predictions: [[0.00362362]\n",
            " [0.9960849 ]\n",
            " [0.9960731 ]\n",
            " [0.00597123]]\n",
            "Step: 6635 -> Loss: 0.004369151778519154 -> Predictions: [[0.00362361]\n",
            " [0.9960849 ]\n",
            " [0.9960731 ]\n",
            " [0.0059712 ]]\n",
            "Step: 6636 -> Loss: 0.004369131289422512 -> Predictions: [[0.00362359]\n",
            " [0.9960849 ]\n",
            " [0.9960731 ]\n",
            " [0.00597117]]\n",
            "Step: 6637 -> Loss: 0.004369114525616169 -> Predictions: [[0.00362358]\n",
            " [0.99608505]\n",
            " [0.9960731 ]\n",
            " [0.00597114]]\n",
            "Step: 6638 -> Loss: 0.004369093105196953 -> Predictions: [[0.00362356]\n",
            " [0.99608505]\n",
            " [0.99607325]\n",
            " [0.00597111]]\n",
            "Step: 6639 -> Loss: 0.004369072616100311 -> Predictions: [[0.00362354]\n",
            " [0.99608505]\n",
            " [0.99607325]\n",
            " [0.00597108]]\n",
            "Step: 6640 -> Loss: 0.004369050730019808 -> Predictions: [[0.00362352]\n",
            " [0.99608505]\n",
            " [0.99607325]\n",
            " [0.00597105]]\n",
            "Step: 6641 -> Loss: 0.004369033500552177 -> Predictions: [[0.00362351]\n",
            " [0.99608505]\n",
            " [0.99607325]\n",
            " [0.00597102]]\n",
            "Step: 6642 -> Loss: 0.004369009751826525 -> Predictions: [[0.00362349]\n",
            " [0.99608505]\n",
            " [0.99607325]\n",
            " [0.00597099]]\n",
            "Step: 6643 -> Loss: 0.00436899159103632 -> Predictions: [[0.00362347]\n",
            " [0.99608505]\n",
            " [0.99607325]\n",
            " [0.00597096]]\n",
            "Step: 6644 -> Loss: 0.004368968307971954 -> Predictions: [[0.00362346]\n",
            " [0.99608517]\n",
            " [0.99607325]\n",
            " [0.00597093]]\n",
            "Step: 6645 -> Loss: 0.0043689482845366 -> Predictions: [[0.00362344]\n",
            " [0.99608517]\n",
            " [0.99607337]\n",
            " [0.0059709 ]]\n",
            "Step: 6646 -> Loss: 0.004368930589407682 -> Predictions: [[0.00362343]\n",
            " [0.99608517]\n",
            " [0.99607337]\n",
            " [0.00597087]]\n",
            "Step: 6647 -> Loss: 0.004368909634649754 -> Predictions: [[0.00362341]\n",
            " [0.99608517]\n",
            " [0.99607337]\n",
            " [0.00597084]]\n",
            "Step: 6648 -> Loss: 0.004368889145553112 -> Predictions: [[0.00362339]\n",
            " [0.99608517]\n",
            " [0.99607337]\n",
            " [0.00597081]]\n",
            "Step: 6649 -> Loss: 0.004368867725133896 -> Predictions: [[0.00362338]\n",
            " [0.99608517]\n",
            " [0.99607337]\n",
            " [0.00597078]]\n",
            "Step: 6650 -> Loss: 0.0043688490986824036 -> Predictions: [[0.00362336]\n",
            " [0.99608517]\n",
            " [0.99607337]\n",
            " [0.00597075]]\n",
            "Step: 6651 -> Loss: 0.004368827678263187 -> Predictions: [[0.00362334]\n",
            " [0.9960853 ]\n",
            " [0.99607337]\n",
            " [0.00597072]]\n",
            "Step: 6652 -> Loss: 0.004368809051811695 -> Predictions: [[0.00362332]\n",
            " [0.9960853 ]\n",
            " [0.9960735 ]\n",
            " [0.0059707 ]]\n",
            "Step: 6653 -> Loss: 0.004368786234408617 -> Predictions: [[0.00362331]\n",
            " [0.9960853 ]\n",
            " [0.9960735 ]\n",
            " [0.00597066]]\n",
            "Step: 6654 -> Loss: 0.004368766210973263 -> Predictions: [[0.00362329]\n",
            " [0.9960853 ]\n",
            " [0.9960735 ]\n",
            " [0.00597063]]\n",
            "Step: 6655 -> Loss: 0.004368748515844345 -> Predictions: [[0.00362328]\n",
            " [0.9960853 ]\n",
            " [0.9960735 ]\n",
            " [0.00597061]]\n",
            "Step: 6656 -> Loss: 0.004368726164102554 -> Predictions: [[0.00362326]\n",
            " [0.9960853 ]\n",
            " [0.9960735 ]\n",
            " [0.00597057]]\n",
            "Step: 6657 -> Loss: 0.004368704743683338 -> Predictions: [[0.00362324]\n",
            " [0.9960853 ]\n",
            " [0.9960735 ]\n",
            " [0.00597054]]\n",
            "Step: 6658 -> Loss: 0.004368686582893133 -> Predictions: [[0.00362323]\n",
            " [0.9960854 ]\n",
            " [0.9960735 ]\n",
            " [0.00597051]]\n",
            "Step: 6659 -> Loss: 0.004368665628135204 -> Predictions: [[0.00362322]\n",
            " [0.9960854 ]\n",
            " [0.9960736 ]\n",
            " [0.00597049]]\n",
            "Step: 6660 -> Loss: 0.004368643742054701 -> Predictions: [[0.00362319]\n",
            " [0.9960854 ]\n",
            " [0.9960736 ]\n",
            " [0.00597045]]\n",
            "Step: 6661 -> Loss: 0.004368624184280634 -> Predictions: [[0.00362318]\n",
            " [0.9960854 ]\n",
            " [0.9960736 ]\n",
            " [0.00597042]]\n",
            "Step: 6662 -> Loss: 0.004368605092167854 -> Predictions: [[0.00362317]\n",
            " [0.9960854 ]\n",
            " [0.9960736 ]\n",
            " [0.00597039]]\n",
            "Step: 6663 -> Loss: 0.0043685850687325 -> Predictions: [[0.00362315]\n",
            " [0.9960854 ]\n",
            " [0.9960736 ]\n",
            " [0.00597036]]\n",
            "Step: 6664 -> Loss: 0.004368562251329422 -> Predictions: [[0.00362313]\n",
            " [0.9960855 ]\n",
            " [0.9960736 ]\n",
            " [0.00597033]]\n",
            "Step: 6665 -> Loss: 0.00436854362487793 -> Predictions: [[0.00362312]\n",
            " [0.9960855 ]\n",
            " [0.9960736 ]\n",
            " [0.0059703 ]]\n",
            "Step: 6666 -> Loss: 0.004368523135781288 -> Predictions: [[0.0036231 ]\n",
            " [0.9960855 ]\n",
            " [0.9960737 ]\n",
            " [0.00597027]]\n",
            "Step: 6667 -> Loss: 0.004368502646684647 -> Predictions: [[0.00362308]\n",
            " [0.9960855 ]\n",
            " [0.9960737 ]\n",
            " [0.00597024]]\n",
            "Step: 6668 -> Loss: 0.0043684812262654305 -> Predictions: [[0.00362306]\n",
            " [0.9960855 ]\n",
            " [0.9960737 ]\n",
            " [0.00597021]]\n",
            "Step: 6669 -> Loss: 0.004368460737168789 -> Predictions: [[0.00362305]\n",
            " [0.9960855 ]\n",
            " [0.9960737 ]\n",
            " [0.00597018]]\n",
            "Step: 6670 -> Loss: 0.004368442110717297 -> Predictions: [[0.00362303]\n",
            " [0.9960855 ]\n",
            " [0.9960737 ]\n",
            " [0.00597016]]\n",
            "Step: 6671 -> Loss: 0.0043684192933142185 -> Predictions: [[0.00362301]\n",
            " [0.9960855 ]\n",
            " [0.9960737 ]\n",
            " [0.00597012]]\n",
            "Step: 6672 -> Loss: 0.004368402063846588 -> Predictions: [[0.003623  ]\n",
            " [0.99608564]\n",
            " [0.99607384]\n",
            " [0.00597009]]\n",
            "Step: 6673 -> Loss: 0.004368381109088659 -> Predictions: [[0.00362298]\n",
            " [0.99608564]\n",
            " [0.99607384]\n",
            " [0.00597007]]\n",
            "Step: 6674 -> Loss: 0.004368358291685581 -> Predictions: [[0.00362296]\n",
            " [0.99608564]\n",
            " [0.99607384]\n",
            " [0.00597003]]\n",
            "Step: 6675 -> Loss: 0.0043683405965566635 -> Predictions: [[0.00362296]\n",
            " [0.99608564]\n",
            " [0.99607384]\n",
            " [0.00597   ]]\n",
            "Step: 6676 -> Loss: 0.004368321970105171 -> Predictions: [[0.00362294]\n",
            " [0.99608564]\n",
            " [0.99607384]\n",
            " [0.00596997]]\n",
            "Step: 6677 -> Loss: 0.004368297755718231 -> Predictions: [[0.00362292]\n",
            " [0.99608564]\n",
            " [0.99607384]\n",
            " [0.00596994]]\n",
            "Step: 6678 -> Loss: 0.004368279129266739 -> Predictions: [[0.00362291]\n",
            " [0.99608576]\n",
            " [0.99607384]\n",
            " [0.00596991]]\n",
            "Step: 6679 -> Loss: 0.004368257243186235 -> Predictions: [[0.00362289]\n",
            " [0.99608576]\n",
            " [0.99607396]\n",
            " [0.00596988]]\n",
            "Step: 6680 -> Loss: 0.00436823908239603 -> Predictions: [[0.00362287]\n",
            " [0.99608576]\n",
            " [0.99607396]\n",
            " [0.00596986]]\n",
            "Step: 6681 -> Loss: 0.004368218593299389 -> Predictions: [[0.00362285]\n",
            " [0.99608576]\n",
            " [0.99607396]\n",
            " [0.00596983]]\n",
            "Step: 6682 -> Loss: 0.004368198104202747 -> Predictions: [[0.00362284]\n",
            " [0.99608576]\n",
            " [0.99607396]\n",
            " [0.00596979]]\n",
            "Step: 6683 -> Loss: 0.004368176683783531 -> Predictions: [[0.00362282]\n",
            " [0.99608576]\n",
            " [0.99607396]\n",
            " [0.00596977]]\n",
            "Step: 6684 -> Loss: 0.004368156660348177 -> Predictions: [[0.00362281]\n",
            " [0.99608576]\n",
            " [0.99607396]\n",
            " [0.00596973]]\n",
            "Step: 6685 -> Loss: 0.004368139896541834 -> Predictions: [[0.00362279]\n",
            " [0.9960859 ]\n",
            " [0.99607396]\n",
            " [0.00596971]]\n",
            "Step: 6686 -> Loss: 0.004368116147816181 -> Predictions: [[0.00362277]\n",
            " [0.9960859 ]\n",
            " [0.9960741 ]\n",
            " [0.00596968]]\n",
            "Step: 6687 -> Loss: 0.004368097521364689 -> Predictions: [[0.00362276]\n",
            " [0.9960859 ]\n",
            " [0.9960741 ]\n",
            " [0.00596964]]\n",
            "Step: 6688 -> Loss: 0.004368077497929335 -> Predictions: [[0.00362274]\n",
            " [0.9960859 ]\n",
            " [0.9960741 ]\n",
            " [0.00596962]]\n",
            "Step: 6689 -> Loss: 0.0043680546805262566 -> Predictions: [[0.00362273]\n",
            " [0.9960859 ]\n",
            " [0.9960741 ]\n",
            " [0.00596958]]\n",
            "Step: 6690 -> Loss: 0.004368036054074764 -> Predictions: [[0.00362271]\n",
            " [0.9960859 ]\n",
            " [0.9960741 ]\n",
            " [0.00596956]]\n",
            "Step: 6691 -> Loss: 0.004368016961961985 -> Predictions: [[0.0036227 ]\n",
            " [0.9960859 ]\n",
            " [0.9960741 ]\n",
            " [0.00596952]]\n",
            "Step: 6692 -> Loss: 0.004367996007204056 -> Predictions: [[0.00362268]\n",
            " [0.996086  ]\n",
            " [0.9960741 ]\n",
            " [0.00596949]]\n",
            "Step: 6693 -> Loss: 0.00436797458678484 -> Predictions: [[0.00362266]\n",
            " [0.996086  ]\n",
            " [0.9960742 ]\n",
            " [0.00596946]]\n",
            "Step: 6694 -> Loss: 0.0043679531663656235 -> Predictions: [[0.00362265]\n",
            " [0.996086  ]\n",
            " [0.9960742 ]\n",
            " [0.00596943]]\n",
            "Step: 6695 -> Loss: 0.004367934074252844 -> Predictions: [[0.00362263]\n",
            " [0.996086  ]\n",
            " [0.9960742 ]\n",
            " [0.0059694 ]]\n",
            "Step: 6696 -> Loss: 0.004367913585156202 -> Predictions: [[0.00362261]\n",
            " [0.996086  ]\n",
            " [0.9960742 ]\n",
            " [0.00596938]]\n",
            "Step: 6697 -> Loss: 0.004367894027382135 -> Predictions: [[0.0036226 ]\n",
            " [0.996086  ]\n",
            " [0.9960742 ]\n",
            " [0.00596934]]\n",
            "Step: 6698 -> Loss: 0.0043678730726242065 -> Predictions: [[0.00362258]\n",
            " [0.996086  ]\n",
            " [0.9960742 ]\n",
            " [0.00596932]]\n",
            "Step: 6699 -> Loss: 0.004367850720882416 -> Predictions: [[0.00362256]\n",
            " [0.9960861 ]\n",
            " [0.9960742 ]\n",
            " [0.00596928]]\n",
            "Step: 6700 -> Loss: 0.004367831628769636 -> Predictions: [[0.00362255]\n",
            " [0.9960861 ]\n",
            " [0.9960743 ]\n",
            " [0.00596925]]\n",
            "Step: 6701 -> Loss: 0.004367813002318144 -> Predictions: [[0.00362253]\n",
            " [0.9960861 ]\n",
            " [0.9960743 ]\n",
            " [0.00596923]]\n",
            "Step: 6702 -> Loss: 0.004367793910205364 -> Predictions: [[0.00362252]\n",
            " [0.9960861 ]\n",
            " [0.9960743 ]\n",
            " [0.0059692 ]]\n",
            "Step: 6703 -> Loss: 0.00436776876449585 -> Predictions: [[0.0036225 ]\n",
            " [0.9960861 ]\n",
            " [0.9960743 ]\n",
            " [0.00596916]]\n",
            "Step: 6704 -> Loss: 0.004367749206721783 -> Predictions: [[0.00362248]\n",
            " [0.9960861 ]\n",
            " [0.9960743 ]\n",
            " [0.00596913]]\n",
            "Step: 6705 -> Loss: 0.0043677291832864285 -> Predictions: [[0.00362246]\n",
            " [0.99608624]\n",
            " [0.9960743 ]\n",
            " [0.00596911]]\n",
            "Step: 6706 -> Loss: 0.004367710091173649 -> Predictions: [[0.00362245]\n",
            " [0.99608624]\n",
            " [0.99607444]\n",
            " [0.00596908]]\n",
            "Step: 6707 -> Loss: 0.004367688205093145 -> Predictions: [[0.00362243]\n",
            " [0.99608624]\n",
            " [0.99607444]\n",
            " [0.00596904]]\n",
            "Step: 6708 -> Loss: 0.004367670975625515 -> Predictions: [[0.00362242]\n",
            " [0.99608624]\n",
            " [0.99607444]\n",
            " [0.00596902]]\n",
            "Step: 6709 -> Loss: 0.004367650020867586 -> Predictions: [[0.0036224 ]\n",
            " [0.99608624]\n",
            " [0.99607444]\n",
            " [0.00596899]]\n",
            "Step: 6710 -> Loss: 0.004367625806480646 -> Predictions: [[0.00362237]\n",
            " [0.99608624]\n",
            " [0.99607444]\n",
            " [0.00596895]]\n",
            "Step: 6711 -> Loss: 0.004367608577013016 -> Predictions: [[0.00362237]\n",
            " [0.99608624]\n",
            " [0.99607444]\n",
            " [0.00596893]]\n",
            "Step: 6712 -> Loss: 0.004367587622255087 -> Predictions: [[0.00362235]\n",
            " [0.99608636]\n",
            " [0.99607444]\n",
            " [0.0059689 ]]\n",
            "Step: 6713 -> Loss: 0.00436756806448102 -> Predictions: [[0.00362233]\n",
            " [0.99608636]\n",
            " [0.99607444]\n",
            " [0.00596886]]\n",
            "Step: 6714 -> Loss: 0.004367545712739229 -> Predictions: [[0.00362232]\n",
            " [0.99608636]\n",
            " [0.99607456]\n",
            " [0.00596884]]\n",
            "Step: 6715 -> Loss: 0.004367525223642588 -> Predictions: [[0.0036223 ]\n",
            " [0.99608636]\n",
            " [0.99607456]\n",
            " [0.0059688 ]]\n",
            "Step: 6716 -> Loss: 0.004367506597191095 -> Predictions: [[0.00362228]\n",
            " [0.99608636]\n",
            " [0.99607456]\n",
            " [0.00596878]]\n",
            "Step: 6717 -> Loss: 0.0043674856424331665 -> Predictions: [[0.00362227]\n",
            " [0.99608636]\n",
            " [0.99607456]\n",
            " [0.00596874]]\n",
            "Step: 6718 -> Loss: 0.0043674660846591 -> Predictions: [[0.00362225]\n",
            " [0.99608636]\n",
            " [0.99607456]\n",
            " [0.00596872]]\n",
            "Step: 6719 -> Loss: 0.004367445595562458 -> Predictions: [[0.00362223]\n",
            " [0.9960865 ]\n",
            " [0.99607456]\n",
            " [0.00596869]]\n",
            "Step: 6720 -> Loss: 0.004367424175143242 -> Predictions: [[0.00362222]\n",
            " [0.9960865 ]\n",
            " [0.9960747 ]\n",
            " [0.00596865]]\n",
            "Step: 6721 -> Loss: 0.00436740554869175 -> Predictions: [[0.0036222 ]\n",
            " [0.9960865 ]\n",
            " [0.9960747 ]\n",
            " [0.00596863]]\n",
            "Step: 6722 -> Loss: 0.004367385059595108 -> Predictions: [[0.00362219]\n",
            " [0.9960865 ]\n",
            " [0.9960747 ]\n",
            " [0.0059686 ]]\n",
            "Step: 6723 -> Loss: 0.004367362707853317 -> Predictions: [[0.00362217]\n",
            " [0.9960865 ]\n",
            " [0.9960747 ]\n",
            " [0.00596857]]\n",
            "Step: 6724 -> Loss: 0.00436734315007925 -> Predictions: [[0.00362215]\n",
            " [0.9960865 ]\n",
            " [0.9960747 ]\n",
            " [0.00596854]]\n",
            "Step: 6725 -> Loss: 0.004367322660982609 -> Predictions: [[0.00362213]\n",
            " [0.9960865 ]\n",
            " [0.9960747 ]\n",
            " [0.00596851]]\n",
            "Step: 6726 -> Loss: 0.0043673026375472546 -> Predictions: [[0.00362212]\n",
            " [0.9960866 ]\n",
            " [0.9960747 ]\n",
            " [0.00596847]]\n",
            "Step: 6727 -> Loss: 0.004367281682789326 -> Predictions: [[0.0036221 ]\n",
            " [0.9960866 ]\n",
            " [0.9960748 ]\n",
            " [0.00596845]]\n",
            "Step: 6728 -> Loss: 0.004367262125015259 -> Predictions: [[0.00362209]\n",
            " [0.9960866 ]\n",
            " [0.9960748 ]\n",
            " [0.00596841]]\n",
            "Step: 6729 -> Loss: 0.004367241635918617 -> Predictions: [[0.00362206]\n",
            " [0.9960866 ]\n",
            " [0.9960748 ]\n",
            " [0.00596839]]\n",
            "Step: 6730 -> Loss: 0.004367220215499401 -> Predictions: [[0.00362205]\n",
            " [0.9960866 ]\n",
            " [0.9960748 ]\n",
            " [0.00596835]]\n",
            "Step: 6731 -> Loss: 0.004367199260741472 -> Predictions: [[0.00362204]\n",
            " [0.9960866 ]\n",
            " [0.9960748 ]\n",
            " [0.00596832]]\n",
            "Step: 6732 -> Loss: 0.004367180168628693 -> Predictions: [[0.00362202]\n",
            " [0.9960866 ]\n",
            " [0.9960748 ]\n",
            " [0.0059683 ]]\n",
            "Step: 6733 -> Loss: 0.0043671573512256145 -> Predictions: [[0.003622  ]\n",
            " [0.9960867 ]\n",
            " [0.9960748 ]\n",
            " [0.00596826]]\n",
            "Step: 6734 -> Loss: 0.004367140121757984 -> Predictions: [[0.00362198]\n",
            " [0.9960867 ]\n",
            " [0.99607486]\n",
            " [0.00596824]]\n",
            "Step: 6735 -> Loss: 0.004367119632661343 -> Predictions: [[0.00362197]\n",
            " [0.9960867 ]\n",
            " [0.99607486]\n",
            " [0.0059682 ]]\n",
            "Step: 6736 -> Loss: 0.0043670982122421265 -> Predictions: [[0.00362195]\n",
            " [0.9960867 ]\n",
            " [0.99607486]\n",
            " [0.00596818]]\n",
            "Step: 6737 -> Loss: 0.004367078188806772 -> Predictions: [[0.00362193]\n",
            " [0.9960867 ]\n",
            " [0.99607486]\n",
            " [0.00596815]]\n",
            "Step: 6738 -> Loss: 0.0043670558370649815 -> Predictions: [[0.00362192]\n",
            " [0.9960867 ]\n",
            " [0.99607486]\n",
            " [0.00596811]]\n",
            "Step: 6739 -> Loss: 0.004367036744952202 -> Predictions: [[0.0036219 ]\n",
            " [0.9960867 ]\n",
            " [0.99607486]\n",
            " [0.00596809]]\n",
            "Step: 6740 -> Loss: 0.00436701625585556 -> Predictions: [[0.00362189]\n",
            " [0.99608684]\n",
            " [0.996075  ]\n",
            " [0.00596806]]\n",
            "Step: 6741 -> Loss: 0.004366996698081493 -> Predictions: [[0.00362187]\n",
            " [0.99608684]\n",
            " [0.996075  ]\n",
            " [0.00596803]]\n",
            "Step: 6742 -> Loss: 0.0043669771403074265 -> Predictions: [[0.00362185]\n",
            " [0.99608684]\n",
            " [0.996075  ]\n",
            " [0.005968  ]]\n",
            "Step: 6743 -> Loss: 0.004366956651210785 -> Predictions: [[0.00362184]\n",
            " [0.99608684]\n",
            " [0.996075  ]\n",
            " [0.00596797]]\n",
            "Step: 6744 -> Loss: 0.004366933833807707 -> Predictions: [[0.00362182]\n",
            " [0.99608684]\n",
            " [0.996075  ]\n",
            " [0.00596793]]\n",
            "Step: 6745 -> Loss: 0.004366916138678789 -> Predictions: [[0.00362181]\n",
            " [0.99608684]\n",
            " [0.996075  ]\n",
            " [0.00596791]]\n",
            "Step: 6746 -> Loss: 0.004366896115243435 -> Predictions: [[0.00362179]\n",
            " [0.99608684]\n",
            " [0.996075  ]\n",
            " [0.00596788]]\n",
            "Step: 6747 -> Loss: 0.004366875626146793 -> Predictions: [[0.00362177]\n",
            " [0.99608696]\n",
            " [0.9960751 ]\n",
            " [0.00596785]]\n",
            "Step: 6748 -> Loss: 0.004366854205727577 -> Predictions: [[0.00362176]\n",
            " [0.99608696]\n",
            " [0.9960751 ]\n",
            " [0.00596782]]\n",
            "Step: 6749 -> Loss: 0.004366834182292223 -> Predictions: [[0.00362174]\n",
            " [0.99608696]\n",
            " [0.9960751 ]\n",
            " [0.00596779]]\n",
            "Step: 6750 -> Loss: 0.0043668136931955814 -> Predictions: [[0.00362172]\n",
            " [0.99608696]\n",
            " [0.9960751 ]\n",
            " [0.00596775]]\n",
            "Step: 6751 -> Loss: 0.004366792738437653 -> Predictions: [[0.0036217 ]\n",
            " [0.99608696]\n",
            " [0.9960751 ]\n",
            " [0.00596773]]\n",
            "Step: 6752 -> Loss: 0.00436677411198616 -> Predictions: [[0.00362169]\n",
            " [0.99608696]\n",
            " [0.9960751 ]\n",
            " [0.0059677 ]]\n",
            "Step: 6753 -> Loss: 0.0043667517602443695 -> Predictions: [[0.00362167]\n",
            " [0.9960871 ]\n",
            " [0.9960751 ]\n",
            " [0.00596766]]\n",
            "Step: 6754 -> Loss: 0.004366732202470303 -> Predictions: [[0.00362166]\n",
            " [0.9960871 ]\n",
            " [0.9960752 ]\n",
            " [0.00596764]]\n",
            "Step: 6755 -> Loss: 0.004366710782051086 -> Predictions: [[0.00362164]\n",
            " [0.9960871 ]\n",
            " [0.9960752 ]\n",
            " [0.0059676 ]]\n",
            "Step: 6756 -> Loss: 0.004366692155599594 -> Predictions: [[0.00362162]\n",
            " [0.9960871 ]\n",
            " [0.9960752 ]\n",
            " [0.00596758]]\n",
            "Step: 6757 -> Loss: 0.004366669338196516 -> Predictions: [[0.00362161]\n",
            " [0.9960871 ]\n",
            " [0.9960752 ]\n",
            " [0.00596755]]\n",
            "Step: 6758 -> Loss: 0.004366652108728886 -> Predictions: [[0.00362159]\n",
            " [0.9960871 ]\n",
            " [0.9960752 ]\n",
            " [0.00596752]]\n",
            "Step: 6759 -> Loss: 0.004366633947938681 -> Predictions: [[0.00362158]\n",
            " [0.9960871 ]\n",
            " [0.9960752 ]\n",
            " [0.0059675 ]]\n",
            "Step: 6760 -> Loss: 0.004366610199213028 -> Predictions: [[0.00362156]\n",
            " [0.9960872 ]\n",
            " [0.9960752 ]\n",
            " [0.00596746]]\n",
            "Step: 6761 -> Loss: 0.004366589710116386 -> Predictions: [[0.00362154]\n",
            " [0.9960872 ]\n",
            " [0.99607533]\n",
            " [0.00596743]]\n",
            "Step: 6762 -> Loss: 0.0043665687553584576 -> Predictions: [[0.00362153]\n",
            " [0.9960872 ]\n",
            " [0.99607533]\n",
            " [0.0059674 ]]\n",
            "Step: 6763 -> Loss: 0.004366549197584391 -> Predictions: [[0.00362151]\n",
            " [0.9960872 ]\n",
            " [0.99607533]\n",
            " [0.00596737]]\n",
            "Step: 6764 -> Loss: 0.0043665277771651745 -> Predictions: [[0.00362149]\n",
            " [0.9960872 ]\n",
            " [0.99607533]\n",
            " [0.00596734]]\n",
            "Step: 6765 -> Loss: 0.004366509150713682 -> Predictions: [[0.00362148]\n",
            " [0.9960872 ]\n",
            " [0.99607533]\n",
            " [0.00596731]]\n",
            "Step: 6766 -> Loss: 0.004366490989923477 -> Predictions: [[0.00362146]\n",
            " [0.9960872 ]\n",
            " [0.99607533]\n",
            " [0.00596728]]\n",
            "Step: 6767 -> Loss: 0.0043664672411978245 -> Predictions: [[0.00362144]\n",
            " [0.9960873 ]\n",
            " [0.99607533]\n",
            " [0.00596725]]\n",
            "Step: 6768 -> Loss: 0.0043664490804076195 -> Predictions: [[0.00362143]\n",
            " [0.9960873 ]\n",
            " [0.99607545]\n",
            " [0.00596722]]\n",
            "Step: 6769 -> Loss: 0.004366427194327116 -> Predictions: [[0.00362141]\n",
            " [0.9960873 ]\n",
            " [0.99607545]\n",
            " [0.00596719]]\n",
            "Step: 6770 -> Loss: 0.004366409033536911 -> Predictions: [[0.00362139]\n",
            " [0.9960873 ]\n",
            " [0.99607545]\n",
            " [0.00596717]]\n",
            "Step: 6771 -> Loss: 0.00436638668179512 -> Predictions: [[0.00362138]\n",
            " [0.9960873 ]\n",
            " [0.99607545]\n",
            " [0.00596713]]\n",
            "Step: 6772 -> Loss: 0.004366369917988777 -> Predictions: [[0.00362136]\n",
            " [0.9960873 ]\n",
            " [0.99607545]\n",
            " [0.00596711]]\n",
            "Step: 6773 -> Loss: 0.0043663461692631245 -> Predictions: [[0.00362134]\n",
            " [0.9960873 ]\n",
            " [0.99607545]\n",
            " [0.00596707]]\n",
            "Step: 6774 -> Loss: 0.004366324748843908 -> Predictions: [[0.00362133]\n",
            " [0.99608743]\n",
            " [0.9960756 ]\n",
            " [0.00596704]]\n",
            "Step: 6775 -> Loss: 0.004366305656731129 -> Predictions: [[0.00362131]\n",
            " [0.99608743]\n",
            " [0.9960756 ]\n",
            " [0.00596701]]\n",
            "Step: 6776 -> Loss: 0.0043662856332957745 -> Predictions: [[0.0036213 ]\n",
            " [0.99608743]\n",
            " [0.9960756 ]\n",
            " [0.00596698]]\n",
            "Step: 6777 -> Loss: 0.004366264678537846 -> Predictions: [[0.00362128]\n",
            " [0.99608743]\n",
            " [0.9960756 ]\n",
            " [0.00596695]]\n",
            "Step: 6778 -> Loss: 0.004366243723779917 -> Predictions: [[0.00362126]\n",
            " [0.99608743]\n",
            " [0.9960756 ]\n",
            " [0.00596692]]\n",
            "Step: 6779 -> Loss: 0.004366222769021988 -> Predictions: [[0.00362125]\n",
            " [0.99608743]\n",
            " [0.9960756 ]\n",
            " [0.00596689]]\n",
            "Step: 6780 -> Loss: 0.004366202279925346 -> Predictions: [[0.00362123]\n",
            " [0.99608743]\n",
            " [0.9960756 ]\n",
            " [0.00596686]]\n",
            "Step: 6781 -> Loss: 0.004366183187812567 -> Predictions: [[0.00362122]\n",
            " [0.99608755]\n",
            " [0.9960757 ]\n",
            " [0.00596683]]\n",
            "Step: 6782 -> Loss: 0.004366164095699787 -> Predictions: [[0.00362121]\n",
            " [0.99608755]\n",
            " [0.9960757 ]\n",
            " [0.0059668 ]]\n",
            "Step: 6783 -> Loss: 0.00436614453792572 -> Predictions: [[0.00362118]\n",
            " [0.99608755]\n",
            " [0.9960757 ]\n",
            " [0.00596677]]\n",
            "Step: 6784 -> Loss: 0.004366124514490366 -> Predictions: [[0.00362117]\n",
            " [0.99608755]\n",
            " [0.9960757 ]\n",
            " [0.00596674]]\n",
            "Step: 6785 -> Loss: 0.00436610309407115 -> Predictions: [[0.00362115]\n",
            " [0.99608755]\n",
            " [0.9960757 ]\n",
            " [0.00596671]]\n",
            "Step: 6786 -> Loss: 0.004366079345345497 -> Predictions: [[0.00362113]\n",
            " [0.99608755]\n",
            " [0.9960757 ]\n",
            " [0.00596668]]\n",
            "Step: 6787 -> Loss: 0.004366063978523016 -> Predictions: [[0.00362112]\n",
            " [0.99608755]\n",
            " [0.9960757 ]\n",
            " [0.00596665]]\n",
            "Step: 6788 -> Loss: 0.004366040229797363 -> Predictions: [[0.0036211 ]\n",
            " [0.9960877 ]\n",
            " [0.9960758 ]\n",
            " [0.00596662]]\n",
            "Step: 6789 -> Loss: 0.004366025328636169 -> Predictions: [[0.00362109]\n",
            " [0.9960877 ]\n",
            " [0.9960758 ]\n",
            " [0.00596659]]\n",
            "Step: 6790 -> Loss: 0.004366000182926655 -> Predictions: [[0.00362107]\n",
            " [0.9960877 ]\n",
            " [0.9960758 ]\n",
            " [0.00596656]]\n",
            "Step: 6791 -> Loss: 0.004365978762507439 -> Predictions: [[0.00362105]\n",
            " [0.9960877 ]\n",
            " [0.9960758 ]\n",
            " [0.00596652]]\n",
            "Step: 6792 -> Loss: 0.004365961998701096 -> Predictions: [[0.00362104]\n",
            " [0.9960877 ]\n",
            " [0.9960758 ]\n",
            " [0.0059665 ]]\n",
            "Step: 6793 -> Loss: 0.004365938249975443 -> Predictions: [[0.00362102]\n",
            " [0.9960877 ]\n",
            " [0.9960758 ]\n",
            " [0.00596647]]\n",
            "Step: 6794 -> Loss: 0.004365919157862663 -> Predictions: [[0.003621  ]\n",
            " [0.9960878 ]\n",
            " [0.9960758 ]\n",
            " [0.00596644]]\n",
            "Step: 6795 -> Loss: 0.004365900997072458 -> Predictions: [[0.00362099]\n",
            " [0.9960878 ]\n",
            " [0.9960759 ]\n",
            " [0.00596642]]\n",
            "Step: 6796 -> Loss: 0.004365879110991955 -> Predictions: [[0.00362097]\n",
            " [0.9960878 ]\n",
            " [0.9960759 ]\n",
            " [0.00596638]]\n",
            "Step: 6797 -> Loss: 0.004365856759250164 -> Predictions: [[0.00362095]\n",
            " [0.9960878 ]\n",
            " [0.9960759 ]\n",
            " [0.00596635]]\n",
            "Step: 6798 -> Loss: 0.004365837667137384 -> Predictions: [[0.00362094]\n",
            " [0.9960878 ]\n",
            " [0.9960759 ]\n",
            " [0.00596632]]\n",
            "Step: 6799 -> Loss: 0.0043658181093633175 -> Predictions: [[0.00362093]\n",
            " [0.9960878 ]\n",
            " [0.9960759 ]\n",
            " [0.0059663 ]]\n",
            "Step: 6800 -> Loss: 0.004365799017250538 -> Predictions: [[0.00362091]\n",
            " [0.9960878 ]\n",
            " [0.9960759 ]\n",
            " [0.00596626]]\n",
            "Step: 6801 -> Loss: 0.004365778062492609 -> Predictions: [[0.00362089]\n",
            " [0.9960879 ]\n",
            " [0.9960759 ]\n",
            " [0.00596623]]\n",
            "Step: 6802 -> Loss: 0.004365758970379829 -> Predictions: [[0.00362088]\n",
            " [0.9960879 ]\n",
            " [0.99607605]\n",
            " [0.00596621]]\n",
            "Step: 6803 -> Loss: 0.004365735221654177 -> Predictions: [[0.00362085]\n",
            " [0.9960879 ]\n",
            " [0.99607605]\n",
            " [0.00596617]]\n",
            "Step: 6804 -> Loss: 0.004365716129541397 -> Predictions: [[0.00362084]\n",
            " [0.9960879 ]\n",
            " [0.99607605]\n",
            " [0.00596614]]\n",
            "Step: 6805 -> Loss: 0.004365699365735054 -> Predictions: [[0.00362083]\n",
            " [0.9960879 ]\n",
            " [0.99607605]\n",
            " [0.00596612]]\n",
            "Step: 6806 -> Loss: 0.004365676548331976 -> Predictions: [[0.00362081]\n",
            " [0.9960879 ]\n",
            " [0.99607605]\n",
            " [0.00596608]]\n",
            "Step: 6807 -> Loss: 0.004365655593574047 -> Predictions: [[0.00362079]\n",
            " [0.9960879 ]\n",
            " [0.99607605]\n",
            " [0.00596606]]\n",
            "Step: 6808 -> Loss: 0.004365634638816118 -> Predictions: [[0.00362078]\n",
            " [0.996088  ]\n",
            " [0.99607617]\n",
            " [0.00596602]]\n",
            "Step: 6809 -> Loss: 0.004365614615380764 -> Predictions: [[0.00362076]\n",
            " [0.996088  ]\n",
            " [0.99607617]\n",
            " [0.00596599]]\n",
            "Step: 6810 -> Loss: 0.004365595988929272 -> Predictions: [[0.00362075]\n",
            " [0.996088  ]\n",
            " [0.99607617]\n",
            " [0.00596596]]\n",
            "Step: 6811 -> Loss: 0.004365573637187481 -> Predictions: [[0.00362072]\n",
            " [0.996088  ]\n",
            " [0.99607617]\n",
            " [0.00596594]]\n",
            "Step: 6812 -> Loss: 0.004365555010735989 -> Predictions: [[0.00362071]\n",
            " [0.996088  ]\n",
            " [0.99607617]\n",
            " [0.0059659 ]]\n",
            "Step: 6813 -> Loss: 0.004365533124655485 -> Predictions: [[0.00362069]\n",
            " [0.996088  ]\n",
            " [0.99607617]\n",
            " [0.00596587]]\n",
            "Step: 6814 -> Loss: 0.004365510307252407 -> Predictions: [[0.00362068]\n",
            " [0.996088  ]\n",
            " [0.99607617]\n",
            " [0.00596584]]\n",
            "Step: 6815 -> Loss: 0.0043654898181557655 -> Predictions: [[0.00362066]\n",
            " [0.99608815]\n",
            " [0.9960763 ]\n",
            " [0.00596581]]\n",
            "Step: 6816 -> Loss: 0.004365472123026848 -> Predictions: [[0.00362065]\n",
            " [0.99608815]\n",
            " [0.9960763 ]\n",
            " [0.00596578]]\n",
            "Step: 6817 -> Loss: 0.004365451633930206 -> Predictions: [[0.00362063]\n",
            " [0.99608815]\n",
            " [0.9960763 ]\n",
            " [0.00596575]]\n",
            "Step: 6818 -> Loss: 0.004365432076156139 -> Predictions: [[0.00362061]\n",
            " [0.99608815]\n",
            " [0.9960763 ]\n",
            " [0.00596572]]\n",
            "Step: 6819 -> Loss: 0.0043654125183820724 -> Predictions: [[0.0036206 ]\n",
            " [0.99608815]\n",
            " [0.9960763 ]\n",
            " [0.0059657 ]]\n",
            "Step: 6820 -> Loss: 0.004365390632301569 -> Predictions: [[0.00362058]\n",
            " [0.99608815]\n",
            " [0.9960763 ]\n",
            " [0.00596566]]\n",
            "Step: 6821 -> Loss: 0.00436536967754364 -> Predictions: [[0.00362056]\n",
            " [0.99608815]\n",
            " [0.9960763 ]\n",
            " [0.00596563]]\n",
            "Step: 6822 -> Loss: 0.00436535244807601 -> Predictions: [[0.00362055]\n",
            " [0.99608827]\n",
            " [0.9960764 ]\n",
            " [0.00596561]]\n",
            "Step: 6823 -> Loss: 0.004365328699350357 -> Predictions: [[0.00362053]\n",
            " [0.99608827]\n",
            " [0.9960764 ]\n",
            " [0.00596557]]\n",
            "Step: 6824 -> Loss: 0.004365310072898865 -> Predictions: [[0.00362051]\n",
            " [0.99608827]\n",
            " [0.9960764 ]\n",
            " [0.00596555]]\n",
            "Step: 6825 -> Loss: 0.004365289118140936 -> Predictions: [[0.0036205 ]\n",
            " [0.99608827]\n",
            " [0.9960764 ]\n",
            " [0.00596551]]\n",
            "Step: 6826 -> Loss: 0.004365269560366869 -> Predictions: [[0.00362048]\n",
            " [0.99608827]\n",
            " [0.9960764 ]\n",
            " [0.00596548]]\n",
            "Step: 6827 -> Loss: 0.004365249536931515 -> Predictions: [[0.00362047]\n",
            " [0.99608827]\n",
            " [0.9960764 ]\n",
            " [0.00596546]]\n",
            "Step: 6828 -> Loss: 0.004365226253867149 -> Predictions: [[0.00362045]\n",
            " [0.9960884 ]\n",
            " [0.9960764 ]\n",
            " [0.00596542]]\n",
            "Step: 6829 -> Loss: 0.004365206696093082 -> Predictions: [[0.00362043]\n",
            " [0.9960884 ]\n",
            " [0.9960765 ]\n",
            " [0.00596539]]\n",
            "Step: 6830 -> Loss: 0.00436518806964159 -> Predictions: [[0.00362041]\n",
            " [0.9960884 ]\n",
            " [0.9960765 ]\n",
            " [0.00596537]]\n",
            "Step: 6831 -> Loss: 0.004365168511867523 -> Predictions: [[0.0036204 ]\n",
            " [0.9960884 ]\n",
            " [0.9960765 ]\n",
            " [0.00596534]]\n",
            "Step: 6832 -> Loss: 0.004365146160125732 -> Predictions: [[0.00362038]\n",
            " [0.9960884 ]\n",
            " [0.9960765 ]\n",
            " [0.00596531]]\n",
            "Step: 6833 -> Loss: 0.0043651266023516655 -> Predictions: [[0.00362036]\n",
            " [0.9960884 ]\n",
            " [0.9960765 ]\n",
            " [0.00596528]]\n",
            "Step: 6834 -> Loss: 0.004365104250609875 -> Predictions: [[0.00362035]\n",
            " [0.9960884 ]\n",
            " [0.9960765 ]\n",
            " [0.00596525]]\n",
            "Step: 6835 -> Loss: 0.004365086555480957 -> Predictions: [[0.00362033]\n",
            " [0.9960885 ]\n",
            " [0.9960765 ]\n",
            " [0.00596522]]\n",
            "Step: 6836 -> Loss: 0.004365065135061741 -> Predictions: [[0.00362032]\n",
            " [0.9960885 ]\n",
            " [0.99607664]\n",
            " [0.00596518]]\n",
            "Step: 6837 -> Loss: 0.004365048371255398 -> Predictions: [[0.00362031]\n",
            " [0.9960885 ]\n",
            " [0.99607664]\n",
            " [0.00596516]]\n",
            "Step: 6838 -> Loss: 0.004365026485174894 -> Predictions: [[0.00362029]\n",
            " [0.9960885 ]\n",
            " [0.99607664]\n",
            " [0.00596513]]\n",
            "Step: 6839 -> Loss: 0.0043650041334331036 -> Predictions: [[0.00362027]\n",
            " [0.9960885 ]\n",
            " [0.99607664]\n",
            " [0.00596509]]\n",
            "Step: 6840 -> Loss: 0.004364985041320324 -> Predictions: [[0.00362025]\n",
            " [0.9960885 ]\n",
            " [0.99607664]\n",
            " [0.00596507]]\n",
            "Step: 6841 -> Loss: 0.004364964552223682 -> Predictions: [[0.00362024]\n",
            " [0.9960885 ]\n",
            " [0.99607664]\n",
            " [0.00596504]]\n",
            "Step: 6842 -> Loss: 0.004364942200481892 -> Predictions: [[0.00362022]\n",
            " [0.9960886 ]\n",
            " [0.99607664]\n",
            " [0.005965  ]]\n",
            "Step: 6843 -> Loss: 0.004364923574030399 -> Predictions: [[0.0036202 ]\n",
            " [0.9960886 ]\n",
            " [0.99607676]\n",
            " [0.00596498]]\n",
            "Step: 6844 -> Loss: 0.004364904016256332 -> Predictions: [[0.00362019]\n",
            " [0.9960886 ]\n",
            " [0.99607676]\n",
            " [0.00596495]]\n",
            "Step: 6845 -> Loss: 0.004364879801869392 -> Predictions: [[0.00362017]\n",
            " [0.9960886 ]\n",
            " [0.99607676]\n",
            " [0.00596491]]\n",
            "Step: 6846 -> Loss: 0.004364860709756613 -> Predictions: [[0.00362015]\n",
            " [0.9960886 ]\n",
            " [0.99607676]\n",
            " [0.00596488]]\n",
            "Step: 6847 -> Loss: 0.004364843480288982 -> Predictions: [[0.00362014]\n",
            " [0.9960886 ]\n",
            " [0.99607676]\n",
            " [0.00596486]]\n",
            "Step: 6848 -> Loss: 0.004364821128547192 -> Predictions: [[0.00362012]\n",
            " [0.9960886 ]\n",
            " [0.99607676]\n",
            " [0.00596483]]\n",
            "Step: 6849 -> Loss: 0.004364798776805401 -> Predictions: [[0.0036201 ]\n",
            " [0.99608874]\n",
            " [0.9960769 ]\n",
            " [0.00596479]]\n",
            "Step: 6850 -> Loss: 0.0043647815473377705 -> Predictions: [[0.00362008]\n",
            " [0.99608874]\n",
            " [0.9960769 ]\n",
            " [0.00596477]]\n",
            "Step: 6851 -> Loss: 0.00436475919559598 -> Predictions: [[0.00362007]\n",
            " [0.99608874]\n",
            " [0.9960769 ]\n",
            " [0.00596473]]\n",
            "Step: 6852 -> Loss: 0.004364741966128349 -> Predictions: [[0.00362006]\n",
            " [0.99608874]\n",
            " [0.9960769 ]\n",
            " [0.00596471]]\n",
            "Step: 6853 -> Loss: 0.0043647196143865585 -> Predictions: [[0.00362004]\n",
            " [0.99608874]\n",
            " [0.9960769 ]\n",
            " [0.00596467]]\n",
            "Step: 6854 -> Loss: 0.004364702384918928 -> Predictions: [[0.00362003]\n",
            " [0.99608874]\n",
            " [0.9960769 ]\n",
            " [0.00596465]]\n",
            "Step: 6855 -> Loss: 0.004364680498838425 -> Predictions: [[0.00362001]\n",
            " [0.99608874]\n",
            " [0.9960769 ]\n",
            " [0.00596462]]\n",
            "Step: 6856 -> Loss: 0.0043646604754030704 -> Predictions: [[0.00361999]\n",
            " [0.99608886]\n",
            " [0.996077  ]\n",
            " [0.00596459]]\n",
            "Step: 6857 -> Loss: 0.004364638589322567 -> Predictions: [[0.00361997]\n",
            " [0.99608886]\n",
            " [0.996077  ]\n",
            " [0.00596456]]\n",
            "Step: 6858 -> Loss: 0.004364618565887213 -> Predictions: [[0.00361996]\n",
            " [0.99608886]\n",
            " [0.996077  ]\n",
            " [0.00596453]]\n",
            "Step: 6859 -> Loss: 0.004364599473774433 -> Predictions: [[0.00361994]\n",
            " [0.99608886]\n",
            " [0.996077  ]\n",
            " [0.0059645 ]]\n",
            "Step: 6860 -> Loss: 0.004364576190710068 -> Predictions: [[0.00361992]\n",
            " [0.99608886]\n",
            " [0.996077  ]\n",
            " [0.00596447]]\n",
            "Step: 6861 -> Loss: 0.004364556632936001 -> Predictions: [[0.0036199 ]\n",
            " [0.99608886]\n",
            " [0.996077  ]\n",
            " [0.00596444]]\n",
            "Step: 6862 -> Loss: 0.004364536609500647 -> Predictions: [[0.00361989]\n",
            " [0.99608886]\n",
            " [0.996077  ]\n",
            " [0.00596441]]\n",
            "Step: 6863 -> Loss: 0.004364517517387867 -> Predictions: [[0.00361988]\n",
            " [0.996089  ]\n",
            " [0.9960771 ]\n",
            " [0.00596438]]\n",
            "Step: 6864 -> Loss: 0.004364496562629938 -> Predictions: [[0.00361986]\n",
            " [0.996089  ]\n",
            " [0.9960771 ]\n",
            " [0.00596434]]\n",
            "Step: 6865 -> Loss: 0.004364476539194584 -> Predictions: [[0.00361984]\n",
            " [0.996089  ]\n",
            " [0.9960771 ]\n",
            " [0.00596432]]\n",
            "Step: 6866 -> Loss: 0.004364456050097942 -> Predictions: [[0.00361983]\n",
            " [0.996089  ]\n",
            " [0.9960771 ]\n",
            " [0.00596429]]\n",
            "Step: 6867 -> Loss: 0.004364435561001301 -> Predictions: [[0.00361981]\n",
            " [0.996089  ]\n",
            " [0.9960771 ]\n",
            " [0.00596426]]\n",
            "Step: 6868 -> Loss: 0.004364416003227234 -> Predictions: [[0.0036198 ]\n",
            " [0.996089  ]\n",
            " [0.9960771 ]\n",
            " [0.00596423]]\n",
            "Step: 6869 -> Loss: 0.004364394582808018 -> Predictions: [[0.00361978]\n",
            " [0.9960891 ]\n",
            " [0.9960771 ]\n",
            " [0.0059642 ]]\n",
            "Step: 6870 -> Loss: 0.004364373628050089 -> Predictions: [[0.00361976]\n",
            " [0.9960891 ]\n",
            " [0.99607724]\n",
            " [0.00596417]]\n",
            "Step: 6871 -> Loss: 0.004364353138953447 -> Predictions: [[0.00361974]\n",
            " [0.9960891 ]\n",
            " [0.99607724]\n",
            " [0.00596414]]\n",
            "Step: 6872 -> Loss: 0.004364336840808392 -> Predictions: [[0.00361973]\n",
            " [0.9960891 ]\n",
            " [0.99607724]\n",
            " [0.00596412]]\n",
            "Step: 6873 -> Loss: 0.004364315886050463 -> Predictions: [[0.00361972]\n",
            " [0.9960891 ]\n",
            " [0.99607724]\n",
            " [0.00596408]]\n",
            "Step: 6874 -> Loss: 0.004364293068647385 -> Predictions: [[0.0036197 ]\n",
            " [0.9960891 ]\n",
            " [0.99607724]\n",
            " [0.00596405]]\n",
            "Step: 6875 -> Loss: 0.004364270716905594 -> Predictions: [[0.00361968]\n",
            " [0.9960891 ]\n",
            " [0.99607724]\n",
            " [0.00596401]]\n",
            "Step: 6876 -> Loss: 0.004364253021776676 -> Predictions: [[0.00361966]\n",
            " [0.9960892 ]\n",
            " [0.99607724]\n",
            " [0.00596399]]\n",
            "Step: 6877 -> Loss: 0.0043642339296638966 -> Predictions: [[0.00361965]\n",
            " [0.9960892 ]\n",
            " [0.99607736]\n",
            " [0.00596396]]\n",
            "Step: 6878 -> Loss: 0.00436421250924468 -> Predictions: [[0.00361963]\n",
            " [0.9960892 ]\n",
            " [0.99607736]\n",
            " [0.00596393]]\n",
            "Step: 6879 -> Loss: 0.004364191088825464 -> Predictions: [[0.00361961]\n",
            " [0.9960892 ]\n",
            " [0.99607736]\n",
            " [0.0059639 ]]\n",
            "Step: 6880 -> Loss: 0.004364169668406248 -> Predictions: [[0.0036196 ]\n",
            " [0.9960892 ]\n",
            " [0.99607736]\n",
            " [0.00596387]]\n",
            "Step: 6881 -> Loss: 0.004364151507616043 -> Predictions: [[0.00361958]\n",
            " [0.9960892 ]\n",
            " [0.99607736]\n",
            " [0.00596384]]\n",
            "Step: 6882 -> Loss: 0.004364128224551678 -> Predictions: [[0.00361956]\n",
            " [0.9960892 ]\n",
            " [0.99607736]\n",
            " [0.00596381]]\n",
            "Step: 6883 -> Loss: 0.00436411052942276 -> Predictions: [[0.00361955]\n",
            " [0.99608934]\n",
            " [0.99607736]\n",
            " [0.00596378]]\n",
            "Step: 6884 -> Loss: 0.0043640900403261185 -> Predictions: [[0.00361954]\n",
            " [0.99608934]\n",
            " [0.9960775 ]\n",
            " [0.00596375]]\n",
            "Step: 6885 -> Loss: 0.004364068619906902 -> Predictions: [[0.00361951]\n",
            " [0.99608934]\n",
            " [0.9960775 ]\n",
            " [0.00596372]]\n",
            "Step: 6886 -> Loss: 0.004364048130810261 -> Predictions: [[0.0036195 ]\n",
            " [0.99608934]\n",
            " [0.9960775 ]\n",
            " [0.00596369]]\n",
            "Step: 6887 -> Loss: 0.004364027641713619 -> Predictions: [[0.00361948]\n",
            " [0.99608934]\n",
            " [0.9960775 ]\n",
            " [0.00596366]]\n",
            "Step: 6888 -> Loss: 0.00436400668695569 -> Predictions: [[0.00361946]\n",
            " [0.99608934]\n",
            " [0.9960775 ]\n",
            " [0.00596363]]\n",
            "Step: 6889 -> Loss: 0.004363988060504198 -> Predictions: [[0.00361945]\n",
            " [0.99608934]\n",
            " [0.9960775 ]\n",
            " [0.0059636 ]]\n",
            "Step: 6890 -> Loss: 0.004363967105746269 -> Predictions: [[0.00361943]\n",
            " [0.99608946]\n",
            " [0.9960776 ]\n",
            " [0.00596357]]\n",
            "Step: 6891 -> Loss: 0.004363947547972202 -> Predictions: [[0.00361942]\n",
            " [0.99608946]\n",
            " [0.9960776 ]\n",
            " [0.00596354]]\n",
            "Step: 6892 -> Loss: 0.004363924264907837 -> Predictions: [[0.0036194 ]\n",
            " [0.99608946]\n",
            " [0.9960776 ]\n",
            " [0.00596351]]\n",
            "Step: 6893 -> Loss: 0.0043639084324240685 -> Predictions: [[0.00361938]\n",
            " [0.99608946]\n",
            " [0.9960776 ]\n",
            " [0.00596349]]\n",
            "Step: 6894 -> Loss: 0.0043638888746500015 -> Predictions: [[0.00361937]\n",
            " [0.99608946]\n",
            " [0.9960776 ]\n",
            " [0.00596345]]\n",
            "Step: 6895 -> Loss: 0.0043638646602630615 -> Predictions: [[0.00361935]\n",
            " [0.99608946]\n",
            " [0.9960776 ]\n",
            " [0.00596342]]\n",
            "Step: 6896 -> Loss: 0.004363845568150282 -> Predictions: [[0.00361934]\n",
            " [0.99608946]\n",
            " [0.9960776 ]\n",
            " [0.00596339]]\n",
            "Step: 6897 -> Loss: 0.004363825544714928 -> Predictions: [[0.00361932]\n",
            " [0.9960896 ]\n",
            " [0.9960777 ]\n",
            " [0.00596336]]\n",
            "Step: 6898 -> Loss: 0.0043638055212795734 -> Predictions: [[0.0036193 ]\n",
            " [0.9960896 ]\n",
            " [0.9960777 ]\n",
            " [0.00596333]]\n",
            "Step: 6899 -> Loss: 0.004363786894828081 -> Predictions: [[0.00361929]\n",
            " [0.9960896 ]\n",
            " [0.9960777 ]\n",
            " [0.00596331]]\n",
            "Step: 6900 -> Loss: 0.004363765940070152 -> Predictions: [[0.00361927]\n",
            " [0.9960896 ]\n",
            " [0.9960777 ]\n",
            " [0.00596328]]\n",
            "Step: 6901 -> Loss: 0.004363742657005787 -> Predictions: [[0.00361925]\n",
            " [0.9960896 ]\n",
            " [0.9960777 ]\n",
            " [0.00596324]]\n",
            "Step: 6902 -> Loss: 0.004363724961876869 -> Predictions: [[0.00361923]\n",
            " [0.9960896 ]\n",
            " [0.9960777 ]\n",
            " [0.00596321]]\n",
            "Step: 6903 -> Loss: 0.004363703541457653 -> Predictions: [[0.00361922]\n",
            " [0.9960896 ]\n",
            " [0.9960777 ]\n",
            " [0.00596318]]\n",
            "Step: 6904 -> Loss: 0.004363682121038437 -> Predictions: [[0.0036192 ]\n",
            " [0.9960897 ]\n",
            " [0.99607784]\n",
            " [0.00596316]]\n",
            "Step: 6905 -> Loss: 0.00436366256326437 -> Predictions: [[0.00361919]\n",
            " [0.9960897 ]\n",
            " [0.99607784]\n",
            " [0.00596312]]\n",
            "Step: 6906 -> Loss: 0.004363642539829016 -> Predictions: [[0.00361917]\n",
            " [0.9960897 ]\n",
            " [0.99607784]\n",
            " [0.00596309]]\n",
            "Step: 6907 -> Loss: 0.004363620653748512 -> Predictions: [[0.00361916]\n",
            " [0.9960897 ]\n",
            " [0.99607784]\n",
            " [0.00596306]]\n",
            "Step: 6908 -> Loss: 0.00436360202729702 -> Predictions: [[0.00361914]\n",
            " [0.9960897 ]\n",
            " [0.99607784]\n",
            " [0.00596304]]\n",
            "Step: 6909 -> Loss: 0.004363581538200378 -> Predictions: [[0.00361912]\n",
            " [0.9960897 ]\n",
            " [0.99607784]\n",
            " [0.00596301]]\n",
            "Step: 6910 -> Loss: 0.004363559652119875 -> Predictions: [[0.00361911]\n",
            " [0.9960898 ]\n",
            " [0.99607784]\n",
            " [0.00596297]]\n",
            "Step: 6911 -> Loss: 0.004363540560007095 -> Predictions: [[0.00361909]\n",
            " [0.9960898 ]\n",
            " [0.99607795]\n",
            " [0.00596294]]\n",
            "Step: 6912 -> Loss: 0.004363520536571741 -> Predictions: [[0.00361907]\n",
            " [0.9960898 ]\n",
            " [0.99607795]\n",
            " [0.00596292]]\n",
            "Step: 6913 -> Loss: 0.004363499116152525 -> Predictions: [[0.00361906]\n",
            " [0.9960898 ]\n",
            " [0.99607795]\n",
            " [0.00596288]]\n",
            "Step: 6914 -> Loss: 0.004363480024039745 -> Predictions: [[0.00361904]\n",
            " [0.9960898 ]\n",
            " [0.99607795]\n",
            " [0.00596285]]\n",
            "Step: 6915 -> Loss: 0.004363459534943104 -> Predictions: [[0.00361902]\n",
            " [0.9960898 ]\n",
            " [0.99607795]\n",
            " [0.00596283]]\n",
            "Step: 6916 -> Loss: 0.004363439045846462 -> Predictions: [[0.00361901]\n",
            " [0.9960898 ]\n",
            " [0.99607795]\n",
            " [0.0059628 ]]\n",
            "Step: 6917 -> Loss: 0.004363418091088533 -> Predictions: [[0.00361899]\n",
            " [0.99608994]\n",
            " [0.99607795]\n",
            " [0.00596276]]\n",
            "Step: 6918 -> Loss: 0.004363398067653179 -> Predictions: [[0.00361898]\n",
            " [0.99608994]\n",
            " [0.9960781 ]\n",
            " [0.00596273]]\n",
            "Step: 6919 -> Loss: 0.004363379441201687 -> Predictions: [[0.00361896]\n",
            " [0.99608994]\n",
            " [0.9960781 ]\n",
            " [0.0059627 ]]\n",
            "Step: 6920 -> Loss: 0.004363357089459896 -> Predictions: [[0.00361894]\n",
            " [0.99608994]\n",
            " [0.9960781 ]\n",
            " [0.00596267]]\n",
            "Step: 6921 -> Loss: 0.004363338463008404 -> Predictions: [[0.00361893]\n",
            " [0.99608994]\n",
            " [0.9960781 ]\n",
            " [0.00596265]]\n",
            "Step: 6922 -> Loss: 0.0043633165769279 -> Predictions: [[0.00361891]\n",
            " [0.99608994]\n",
            " [0.9960781 ]\n",
            " [0.00596261]]\n",
            "Step: 6923 -> Loss: 0.004363297484815121 -> Predictions: [[0.0036189 ]\n",
            " [0.99608994]\n",
            " [0.9960781 ]\n",
            " [0.00596258]]\n",
            "Step: 6924 -> Loss: 0.004363276995718479 -> Predictions: [[0.00361888]\n",
            " [0.99609   ]\n",
            " [0.9960781 ]\n",
            " [0.00596255]]\n",
            "Step: 6925 -> Loss: 0.004363258369266987 -> Predictions: [[0.00361887]\n",
            " [0.99609   ]\n",
            " [0.9960782 ]\n",
            " [0.00596253]]\n",
            "Step: 6926 -> Loss: 0.004363236948847771 -> Predictions: [[0.00361885]\n",
            " [0.99609   ]\n",
            " [0.9960782 ]\n",
            " [0.0059625 ]]\n",
            "Step: 6927 -> Loss: 0.004363215994089842 -> Predictions: [[0.00361883]\n",
            " [0.99609   ]\n",
            " [0.9960782 ]\n",
            " [0.00596246]]\n",
            "Step: 6928 -> Loss: 0.004363196436315775 -> Predictions: [[0.00361881]\n",
            " [0.99609   ]\n",
            " [0.9960782 ]\n",
            " [0.00596244]]\n",
            "Step: 6929 -> Loss: 0.004363172687590122 -> Predictions: [[0.00361879]\n",
            " [0.99609   ]\n",
            " [0.9960782 ]\n",
            " [0.0059624 ]]\n",
            "Step: 6930 -> Loss: 0.004363154526799917 -> Predictions: [[0.00361878]\n",
            " [0.99609   ]\n",
            " [0.9960782 ]\n",
            " [0.00596237]]\n",
            "Step: 6931 -> Loss: 0.00436313496902585 -> Predictions: [[0.00361876]\n",
            " [0.9960901 ]\n",
            " [0.9960783 ]\n",
            " [0.00596234]]\n",
            "Step: 6932 -> Loss: 0.004363114945590496 -> Predictions: [[0.00361875]\n",
            " [0.9960901 ]\n",
            " [0.9960783 ]\n",
            " [0.00596232]]\n",
            "Step: 6933 -> Loss: 0.0043630944564938545 -> Predictions: [[0.00361873]\n",
            " [0.9960901 ]\n",
            " [0.9960783 ]\n",
            " [0.00596229]]\n",
            "Step: 6934 -> Loss: 0.004363072570413351 -> Predictions: [[0.00361871]\n",
            " [0.9960901 ]\n",
            " [0.9960783 ]\n",
            " [0.00596226]]\n",
            "Step: 6935 -> Loss: 0.0043630534783005714 -> Predictions: [[0.00361869]\n",
            " [0.9960901 ]\n",
            " [0.9960783 ]\n",
            " [0.00596223]]\n",
            "Step: 6936 -> Loss: 0.004363034851849079 -> Predictions: [[0.00361868]\n",
            " [0.9960901 ]\n",
            " [0.9960783 ]\n",
            " [0.0059622 ]]\n",
            "Step: 6937 -> Loss: 0.004363013431429863 -> Predictions: [[0.00361867]\n",
            " [0.9960901 ]\n",
            " [0.9960783 ]\n",
            " [0.00596217]]\n",
            "Step: 6938 -> Loss: 0.004362992011010647 -> Predictions: [[0.00361865]\n",
            " [0.99609023]\n",
            " [0.99607843]\n",
            " [0.00596214]]\n",
            "Step: 6939 -> Loss: 0.0043629747815430164 -> Predictions: [[0.00361863]\n",
            " [0.99609023]\n",
            " [0.99607843]\n",
            " [0.00596211]]\n",
            "Step: 6940 -> Loss: 0.0043629491701722145 -> Predictions: [[0.00361861]\n",
            " [0.99609023]\n",
            " [0.99607843]\n",
            " [0.00596207]]\n",
            "Step: 6941 -> Loss: 0.004362933803349733 -> Predictions: [[0.0036186 ]\n",
            " [0.99609023]\n",
            " [0.99607843]\n",
            " [0.00596206]]\n",
            "Step: 6942 -> Loss: 0.004362910985946655 -> Predictions: [[0.00361858]\n",
            " [0.99609023]\n",
            " [0.99607843]\n",
            " [0.00596202]]\n",
            "Step: 6943 -> Loss: 0.004362889099866152 -> Predictions: [[0.00361857]\n",
            " [0.99609023]\n",
            " [0.99607843]\n",
            " [0.00596199]]\n",
            "Step: 6944 -> Loss: 0.004362871404737234 -> Predictions: [[0.00361855]\n",
            " [0.99609023]\n",
            " [0.99607843]\n",
            " [0.00596196]]\n",
            "Step: 6945 -> Loss: 0.0043628523126244545 -> Predictions: [[0.00361853]\n",
            " [0.99609035]\n",
            " [0.99607855]\n",
            " [0.00596193]]\n",
            "Step: 6946 -> Loss: 0.004362829495221376 -> Predictions: [[0.00361852]\n",
            " [0.99609035]\n",
            " [0.99607855]\n",
            " [0.0059619 ]]\n",
            "Step: 6947 -> Loss: 0.004362807609140873 -> Predictions: [[0.0036185 ]\n",
            " [0.99609035]\n",
            " [0.99607855]\n",
            " [0.00596187]]\n",
            "Step: 6948 -> Loss: 0.004362789448350668 -> Predictions: [[0.00361849]\n",
            " [0.99609035]\n",
            " [0.99607855]\n",
            " [0.00596183]]\n",
            "Step: 6949 -> Loss: 0.004362770356237888 -> Predictions: [[0.00361847]\n",
            " [0.99609035]\n",
            " [0.99607855]\n",
            " [0.00596181]]\n",
            "Step: 6950 -> Loss: 0.004362747073173523 -> Predictions: [[0.00361845]\n",
            " [0.99609035]\n",
            " [0.99607855]\n",
            " [0.00596178]]\n",
            "Step: 6951 -> Loss: 0.004362727515399456 -> Predictions: [[0.00361844]\n",
            " [0.9960905 ]\n",
            " [0.99607867]\n",
            " [0.00596175]]\n",
            "Step: 6952 -> Loss: 0.004362707491964102 -> Predictions: [[0.00361842]\n",
            " [0.9960905 ]\n",
            " [0.99607867]\n",
            " [0.00596172]]\n",
            "Step: 6953 -> Loss: 0.0043626874685287476 -> Predictions: [[0.0036184 ]\n",
            " [0.9960905 ]\n",
            " [0.99607867]\n",
            " [0.00596169]]\n",
            "Step: 6954 -> Loss: 0.004362666979432106 -> Predictions: [[0.00361839]\n",
            " [0.9960905 ]\n",
            " [0.99607867]\n",
            " [0.00596166]]\n",
            "Step: 6955 -> Loss: 0.0043626464903354645 -> Predictions: [[0.00361837]\n",
            " [0.9960905 ]\n",
            " [0.99607867]\n",
            " [0.00596163]]\n",
            "Step: 6956 -> Loss: 0.004362625069916248 -> Predictions: [[0.00361835]\n",
            " [0.9960905 ]\n",
            " [0.99607867]\n",
            " [0.0059616 ]]\n",
            "Step: 6957 -> Loss: 0.004362608306109905 -> Predictions: [[0.00361834]\n",
            " [0.9960905 ]\n",
            " [0.99607867]\n",
            " [0.00596157]]\n",
            "Step: 6958 -> Loss: 0.004362587817013264 -> Predictions: [[0.00361832]\n",
            " [0.9960906 ]\n",
            " [0.99607867]\n",
            " [0.00596154]]\n",
            "Step: 6959 -> Loss: 0.004362563602626324 -> Predictions: [[0.0036183 ]\n",
            " [0.9960906 ]\n",
            " [0.9960788 ]\n",
            " [0.00596151]]\n",
            "Step: 6960 -> Loss: 0.004362543113529682 -> Predictions: [[0.00361829]\n",
            " [0.9960906 ]\n",
            " [0.9960788 ]\n",
            " [0.00596148]]\n",
            "Step: 6961 -> Loss: 0.004362525884062052 -> Predictions: [[0.00361827]\n",
            " [0.9960906 ]\n",
            " [0.9960788 ]\n",
            " [0.00596145]]\n",
            "Step: 6962 -> Loss: 0.004362504929304123 -> Predictions: [[0.00361826]\n",
            " [0.9960906 ]\n",
            " [0.9960788 ]\n",
            " [0.00596142]]\n",
            "Step: 6963 -> Loss: 0.004362485837191343 -> Predictions: [[0.00361824]\n",
            " [0.9960906 ]\n",
            " [0.9960788 ]\n",
            " [0.00596139]]\n",
            "Step: 6964 -> Loss: 0.004362461157143116 -> Predictions: [[0.00361822]\n",
            " [0.9960906 ]\n",
            " [0.9960788 ]\n",
            " [0.00596136]]\n",
            "Step: 6965 -> Loss: 0.004362443462014198 -> Predictions: [[0.00361821]\n",
            " [0.9960907 ]\n",
            " [0.9960789 ]\n",
            " [0.00596133]]\n",
            "Step: 6966 -> Loss: 0.0043624225072562695 -> Predictions: [[0.00361819]\n",
            " [0.9960907 ]\n",
            " [0.9960789 ]\n",
            " [0.0059613 ]]\n",
            "Step: 6967 -> Loss: 0.0043624029494822025 -> Predictions: [[0.00361818]\n",
            " [0.9960907 ]\n",
            " [0.9960789 ]\n",
            " [0.00596127]]\n",
            "Step: 6968 -> Loss: 0.004362381063401699 -> Predictions: [[0.00361815]\n",
            " [0.9960907 ]\n",
            " [0.9960789 ]\n",
            " [0.00596124]]\n",
            "Step: 6969 -> Loss: 0.004362362436950207 -> Predictions: [[0.00361814]\n",
            " [0.9960907 ]\n",
            " [0.9960789 ]\n",
            " [0.00596121]]\n",
            "Step: 6970 -> Loss: 0.00436234287917614 -> Predictions: [[0.00361813]\n",
            " [0.9960907 ]\n",
            " [0.9960789 ]\n",
            " [0.00596118]]\n",
            "Step: 6971 -> Loss: 0.004362320527434349 -> Predictions: [[0.00361811]\n",
            " [0.9960907 ]\n",
            " [0.9960789 ]\n",
            " [0.00596114]]\n",
            "Step: 6972 -> Loss: 0.004362301900982857 -> Predictions: [[0.00361809]\n",
            " [0.9960908 ]\n",
            " [0.996079  ]\n",
            " [0.00596112]]\n",
            "Step: 6973 -> Loss: 0.0043622832745313644 -> Predictions: [[0.00361808]\n",
            " [0.9960908 ]\n",
            " [0.996079  ]\n",
            " [0.0059611 ]]\n",
            "Step: 6974 -> Loss: 0.004362260922789574 -> Predictions: [[0.00361806]\n",
            " [0.9960908 ]\n",
            " [0.996079  ]\n",
            " [0.00596106]]\n",
            "Step: 6975 -> Loss: 0.004362243227660656 -> Predictions: [[0.00361804]\n",
            " [0.9960908 ]\n",
            " [0.996079  ]\n",
            " [0.00596103]]\n",
            "Step: 6976 -> Loss: 0.004362219944596291 -> Predictions: [[0.00361803]\n",
            " [0.9960908 ]\n",
            " [0.996079  ]\n",
            " [0.005961  ]]\n",
            "Step: 6977 -> Loss: 0.004362200852483511 -> Predictions: [[0.00361802]\n",
            " [0.9960908 ]\n",
            " [0.996079  ]\n",
            " [0.00596097]]\n",
            "Step: 6978 -> Loss: 0.004362182226032019 -> Predictions: [[0.003618  ]\n",
            " [0.9960908 ]\n",
            " [0.996079  ]\n",
            " [0.00596094]]\n",
            "Step: 6979 -> Loss: 0.004362158942967653 -> Predictions: [[0.00361798]\n",
            " [0.99609095]\n",
            " [0.99607915]\n",
            " [0.00596091]]\n",
            "Step: 6980 -> Loss: 0.004362139850854874 -> Predictions: [[0.00361797]\n",
            " [0.99609095]\n",
            " [0.99607915]\n",
            " [0.00596088]]\n",
            "Step: 6981 -> Loss: 0.0043621184304356575 -> Predictions: [[0.00361795]\n",
            " [0.99609095]\n",
            " [0.99607915]\n",
            " [0.00596085]]\n",
            "Step: 6982 -> Loss: 0.004362101200968027 -> Predictions: [[0.00361793]\n",
            " [0.99609095]\n",
            " [0.99607915]\n",
            " [0.00596082]]\n",
            "Step: 6983 -> Loss: 0.004362081177532673 -> Predictions: [[0.00361792]\n",
            " [0.99609095]\n",
            " [0.99607915]\n",
            " [0.00596079]]\n",
            "Step: 6984 -> Loss: 0.004362056963145733 -> Predictions: [[0.0036179 ]\n",
            " [0.99609095]\n",
            " [0.99607915]\n",
            " [0.00596076]]\n",
            "Step: 6985 -> Loss: 0.004362038336694241 -> Predictions: [[0.00361789]\n",
            " [0.99609095]\n",
            " [0.99607915]\n",
            " [0.00596073]]\n",
            "Step: 6986 -> Loss: 0.004362016450613737 -> Predictions: [[0.00361786]\n",
            " [0.99609107]\n",
            " [0.99607927]\n",
            " [0.0059607 ]]\n",
            "Step: 6987 -> Loss: 0.0043619973585009575 -> Predictions: [[0.00361785]\n",
            " [0.99609107]\n",
            " [0.99607927]\n",
            " [0.00596067]]\n",
            "Step: 6988 -> Loss: 0.0043619778007268906 -> Predictions: [[0.00361783]\n",
            " [0.99609107]\n",
            " [0.99607927]\n",
            " [0.00596064]]\n",
            "Step: 6989 -> Loss: 0.004361954517662525 -> Predictions: [[0.00361782]\n",
            " [0.99609107]\n",
            " [0.99607927]\n",
            " [0.00596061]]\n",
            "Step: 6990 -> Loss: 0.0043619368225336075 -> Predictions: [[0.0036178 ]\n",
            " [0.99609107]\n",
            " [0.99607927]\n",
            " [0.00596058]]\n",
            "Step: 6991 -> Loss: 0.0043619172647595406 -> Predictions: [[0.00361778]\n",
            " [0.99609107]\n",
            " [0.99607927]\n",
            " [0.00596055]]\n",
            "Step: 6992 -> Loss: 0.0043618930503726006 -> Predictions: [[0.00361776]\n",
            " [0.9960912 ]\n",
            " [0.9960794 ]\n",
            " [0.00596052]]\n",
            "Step: 6993 -> Loss: 0.004361874423921108 -> Predictions: [[0.00361775]\n",
            " [0.9960912 ]\n",
            " [0.9960794 ]\n",
            " [0.00596049]]\n",
            "Step: 6994 -> Loss: 0.004361855331808329 -> Predictions: [[0.00361773]\n",
            " [0.9960912 ]\n",
            " [0.9960794 ]\n",
            " [0.00596047]]\n",
            "Step: 6995 -> Loss: 0.0043618339113891125 -> Predictions: [[0.00361772]\n",
            " [0.9960912 ]\n",
            " [0.9960794 ]\n",
            " [0.00596043]]\n",
            "Step: 6996 -> Loss: 0.004361812025308609 -> Predictions: [[0.0036177]\n",
            " [0.9960912]\n",
            " [0.9960794]\n",
            " [0.0059604]]\n",
            "Step: 6997 -> Loss: 0.0043617961928248405 -> Predictions: [[0.00361768]\n",
            " [0.9960912 ]\n",
            " [0.9960794 ]\n",
            " [0.00596038]]\n",
            "Step: 6998 -> Loss: 0.004361772909760475 -> Predictions: [[0.00361767]\n",
            " [0.9960912 ]\n",
            " [0.9960794 ]\n",
            " [0.00596035]]\n",
            "Step: 6999 -> Loss: 0.004361752886325121 -> Predictions: [[0.00361765]\n",
            " [0.9960913 ]\n",
            " [0.9960794 ]\n",
            " [0.00596032]]\n",
            "Step: 7001 -> Loss: 0.0043617114424705505 -> Predictions: [[0.00361762]\n",
            " [0.9960913 ]\n",
            " [0.9960795 ]\n",
            " [0.00596025]]\n",
            "Step: 7002 -> Loss: 0.004361690953373909 -> Predictions: [[0.0036176 ]\n",
            " [0.9960913 ]\n",
            " [0.9960795 ]\n",
            " [0.00596022]]\n",
            "Step: 7003 -> Loss: 0.004361672326922417 -> Predictions: [[0.00361759]\n",
            " [0.9960913 ]\n",
            " [0.9960795 ]\n",
            " [0.00596019]]\n",
            "Step: 7004 -> Loss: 0.00436165276914835 -> Predictions: [[0.00361757]\n",
            " [0.9960913 ]\n",
            " [0.9960795 ]\n",
            " [0.00596017]]\n",
            "Step: 7005 -> Loss: 0.004361631348729134 -> Predictions: [[0.00361755]\n",
            " [0.9960913 ]\n",
            " [0.9960795 ]\n",
            " [0.00596014]]\n",
            "Step: 7006 -> Loss: 0.0043616099283099174 -> Predictions: [[0.00361753]\n",
            " [0.9960914 ]\n",
            " [0.9960796 ]\n",
            " [0.0059601 ]]\n",
            "Step: 7007 -> Loss: 0.004361589439213276 -> Predictions: [[0.00361752]\n",
            " [0.9960914 ]\n",
            " [0.9960796 ]\n",
            " [0.00596007]]\n",
            "Step: 7008 -> Loss: 0.004361571744084358 -> Predictions: [[0.00361751]\n",
            " [0.9960914 ]\n",
            " [0.9960796 ]\n",
            " [0.00596004]]\n",
            "Step: 7009 -> Loss: 0.0043615493923425674 -> Predictions: [[0.00361749]\n",
            " [0.9960914 ]\n",
            " [0.9960796 ]\n",
            " [0.00596001]]\n",
            "Step: 7010 -> Loss: 0.004361528437584639 -> Predictions: [[0.00361747]\n",
            " [0.9960914 ]\n",
            " [0.9960796 ]\n",
            " [0.00595999]]\n",
            "Step: 7011 -> Loss: 0.004361508414149284 -> Predictions: [[0.00361745]\n",
            " [0.9960914 ]\n",
            " [0.9960796 ]\n",
            " [0.00595995]]\n",
            "Step: 7012 -> Loss: 0.004361490253359079 -> Predictions: [[0.00361744]\n",
            " [0.9960914 ]\n",
            " [0.9960796 ]\n",
            " [0.00595993]]\n",
            "Step: 7013 -> Loss: 0.004361467901617289 -> Predictions: [[0.00361742]\n",
            " [0.99609154]\n",
            " [0.99607974]\n",
            " [0.0059599 ]]\n",
            "Step: 7014 -> Loss: 0.004361449740827084 -> Predictions: [[0.00361741]\n",
            " [0.99609154]\n",
            " [0.99607974]\n",
            " [0.00595987]]\n",
            "Step: 7015 -> Loss: 0.0043614269234240055 -> Predictions: [[0.00361739]\n",
            " [0.99609154]\n",
            " [0.99607974]\n",
            " [0.00595983]]\n",
            "Step: 7016 -> Loss: 0.004361405968666077 -> Predictions: [[0.00361737]\n",
            " [0.99609154]\n",
            " [0.99607974]\n",
            " [0.00595981]]\n",
            "Step: 7017 -> Loss: 0.004361388739198446 -> Predictions: [[0.00361736]\n",
            " [0.99609154]\n",
            " [0.99607974]\n",
            " [0.00595978]]\n",
            "Step: 7018 -> Loss: 0.004361366853117943 -> Predictions: [[0.00361734]\n",
            " [0.99609154]\n",
            " [0.99607974]\n",
            " [0.00595975]]\n",
            "Step: 7019 -> Loss: 0.004361346364021301 -> Predictions: [[0.00361732]\n",
            " [0.99609154]\n",
            " [0.99607974]\n",
            " [0.00595972]]\n",
            "Step: 7020 -> Loss: 0.004361326806247234 -> Predictions: [[0.00361731]\n",
            " [0.99609166]\n",
            " [0.99607986]\n",
            " [0.00595968]]\n",
            "Step: 7021 -> Loss: 0.004361304454505444 -> Predictions: [[0.00361729]\n",
            " [0.99609166]\n",
            " [0.99607986]\n",
            " [0.00595966]]\n",
            "Step: 7022 -> Loss: 0.004361284896731377 -> Predictions: [[0.00361728]\n",
            " [0.99609166]\n",
            " [0.99607986]\n",
            " [0.00595962]]\n",
            "Step: 7023 -> Loss: 0.004361265804618597 -> Predictions: [[0.00361726]\n",
            " [0.99609166]\n",
            " [0.99607986]\n",
            " [0.0059596 ]]\n",
            "Step: 7024 -> Loss: 0.004361243452876806 -> Predictions: [[0.00361724]\n",
            " [0.99609166]\n",
            " [0.99607986]\n",
            " [0.00595956]]\n",
            "Step: 7025 -> Loss: 0.004361225292086601 -> Predictions: [[0.00361723]\n",
            " [0.99609166]\n",
            " [0.99607986]\n",
            " [0.00595954]]\n",
            "Step: 7026 -> Loss: 0.004361204337328672 -> Predictions: [[0.00361721]\n",
            " [0.99609166]\n",
            " [0.99608   ]\n",
            " [0.00595951]]\n",
            "Step: 7027 -> Loss: 0.0043611847795546055 -> Predictions: [[0.0036172 ]\n",
            " [0.9960918 ]\n",
            " [0.99608   ]\n",
            " [0.00595948]]\n",
            "Step: 7028 -> Loss: 0.004361164756119251 -> Predictions: [[0.00361717]\n",
            " [0.9960918 ]\n",
            " [0.99608   ]\n",
            " [0.00595945]]\n",
            "Step: 7029 -> Loss: 0.004361145198345184 -> Predictions: [[0.00361716]\n",
            " [0.9960918 ]\n",
            " [0.99608   ]\n",
            " [0.00595942]]\n",
            "Step: 7030 -> Loss: 0.004361125640571117 -> Predictions: [[0.00361715]\n",
            " [0.9960918 ]\n",
            " [0.99608   ]\n",
            " [0.00595939]]\n",
            "Step: 7031 -> Loss: 0.004361102357506752 -> Predictions: [[0.00361713]\n",
            " [0.9960918 ]\n",
            " [0.99608   ]\n",
            " [0.00595936]]\n",
            "Step: 7032 -> Loss: 0.004361083265393972 -> Predictions: [[0.00361711]\n",
            " [0.9960918 ]\n",
            " [0.99608   ]\n",
            " [0.00595933]]\n",
            "Step: 7033 -> Loss: 0.004361060447990894 -> Predictions: [[0.00361709]\n",
            " [0.9960919 ]\n",
            " [0.9960801 ]\n",
            " [0.00595929]]\n",
            "Step: 7034 -> Loss: 0.004361042752861977 -> Predictions: [[0.00361708]\n",
            " [0.9960919 ]\n",
            " [0.9960801 ]\n",
            " [0.00595927]]\n",
            "Step: 7035 -> Loss: 0.004361022263765335 -> Predictions: [[0.00361706]\n",
            " [0.9960919 ]\n",
            " [0.9960801 ]\n",
            " [0.00595924]]\n",
            "Step: 7036 -> Loss: 0.004361001309007406 -> Predictions: [[0.00361705]\n",
            " [0.9960919 ]\n",
            " [0.9960801 ]\n",
            " [0.00595921]]\n",
            "Step: 7037 -> Loss: 0.0043609836138784885 -> Predictions: [[0.00361703]\n",
            " [0.9960919 ]\n",
            " [0.9960801 ]\n",
            " [0.00595918]]\n",
            "Step: 7038 -> Loss: 0.0043609607964754105 -> Predictions: [[0.00361701]\n",
            " [0.9960919 ]\n",
            " [0.9960801 ]\n",
            " [0.00595915]]\n",
            "Step: 7039 -> Loss: 0.004360938910394907 -> Predictions: [[0.003617  ]\n",
            " [0.9960919 ]\n",
            " [0.9960801 ]\n",
            " [0.00595912]]\n",
            "Step: 7040 -> Loss: 0.00436091935262084 -> Predictions: [[0.00361698]\n",
            " [0.996092  ]\n",
            " [0.9960802 ]\n",
            " [0.00595909]]\n",
            "Step: 7041 -> Loss: 0.0043608988635241985 -> Predictions: [[0.00361696]\n",
            " [0.996092  ]\n",
            " [0.9960802 ]\n",
            " [0.00595906]]\n",
            "Step: 7042 -> Loss: 0.004360879771411419 -> Predictions: [[0.00361695]\n",
            " [0.996092  ]\n",
            " [0.9960802 ]\n",
            " [0.00595903]]\n",
            "Step: 7043 -> Loss: 0.004360860679298639 -> Predictions: [[0.00361693]\n",
            " [0.996092  ]\n",
            " [0.9960802 ]\n",
            " [0.005959  ]]\n",
            "Step: 7044 -> Loss: 0.004360838793218136 -> Predictions: [[0.00361692]\n",
            " [0.996092  ]\n",
            " [0.9960802 ]\n",
            " [0.00595897]]\n",
            "Step: 7045 -> Loss: 0.00436081737279892 -> Predictions: [[0.0036169 ]\n",
            " [0.996092  ]\n",
            " [0.9960802 ]\n",
            " [0.00595894]]\n",
            "Step: 7046 -> Loss: 0.004360799677670002 -> Predictions: [[0.00361689]\n",
            " [0.996092  ]\n",
            " [0.9960802 ]\n",
            " [0.00595891]]\n",
            "Step: 7047 -> Loss: 0.004360778257250786 -> Predictions: [[0.00361687]\n",
            " [0.99609214]\n",
            " [0.99608034]\n",
            " [0.00595888]]\n",
            "Step: 7048 -> Loss: 0.004360757302492857 -> Predictions: [[0.00361685]\n",
            " [0.99609214]\n",
            " [0.99608034]\n",
            " [0.00595885]]\n",
            "Step: 7049 -> Loss: 0.0043607368133962154 -> Predictions: [[0.00361683]\n",
            " [0.99609214]\n",
            " [0.99608034]\n",
            " [0.00595882]]\n",
            "Step: 7050 -> Loss: 0.004360716789960861 -> Predictions: [[0.00361682]\n",
            " [0.99609214]\n",
            " [0.99608034]\n",
            " [0.00595879]]\n",
            "Step: 7051 -> Loss: 0.004360698163509369 -> Predictions: [[0.0036168 ]\n",
            " [0.99609214]\n",
            " [0.99608034]\n",
            " [0.00595876]]\n",
            "Step: 7052 -> Loss: 0.004360676743090153 -> Predictions: [[0.00361678]\n",
            " [0.99609214]\n",
            " [0.99608034]\n",
            " [0.00595873]]\n",
            "Step: 7053 -> Loss: 0.004360656253993511 -> Predictions: [[0.00361677]\n",
            " [0.99609214]\n",
            " [0.99608034]\n",
            " [0.0059587 ]]\n",
            "Step: 7054 -> Loss: 0.004360638093203306 -> Predictions: [[0.00361675]\n",
            " [0.99609226]\n",
            " [0.99608046]\n",
            " [0.00595868]]\n",
            "Step: 7055 -> Loss: 0.0043606143444776535 -> Predictions: [[0.00361674]\n",
            " [0.99609226]\n",
            " [0.99608046]\n",
            " [0.00595864]]\n",
            "Step: 7056 -> Loss: 0.004360596649348736 -> Predictions: [[0.00361672]\n",
            " [0.99609226]\n",
            " [0.99608046]\n",
            " [0.00595861]]\n",
            "Step: 7057 -> Loss: 0.004360576160252094 -> Predictions: [[0.0036167 ]\n",
            " [0.99609226]\n",
            " [0.99608046]\n",
            " [0.00595858]]\n",
            "Step: 7058 -> Loss: 0.004360557068139315 -> Predictions: [[0.00361669]\n",
            " [0.99609226]\n",
            " [0.99608046]\n",
            " [0.00595855]]\n",
            "Step: 7059 -> Loss: 0.004360532388091087 -> Predictions: [[0.00361667]\n",
            " [0.99609226]\n",
            " [0.99608046]\n",
            " [0.00595852]]\n",
            "Step: 7060 -> Loss: 0.004360515624284744 -> Predictions: [[0.00361666]\n",
            " [0.99609226]\n",
            " [0.99608046]\n",
            " [0.00595849]]\n",
            "Step: 7061 -> Loss: 0.0043604932725429535 -> Predictions: [[0.00361664]\n",
            " [0.9960924 ]\n",
            " [0.9960806 ]\n",
            " [0.00595846]]\n",
            "Step: 7062 -> Loss: 0.004360471852123737 -> Predictions: [[0.00361662]\n",
            " [0.9960924 ]\n",
            " [0.9960806 ]\n",
            " [0.00595843]]\n",
            "Step: 7063 -> Loss: 0.004360455088317394 -> Predictions: [[0.00361661]\n",
            " [0.9960924 ]\n",
            " [0.9960806 ]\n",
            " [0.0059584 ]]\n",
            "Step: 7064 -> Loss: 0.0043604327365756035 -> Predictions: [[0.00361659]\n",
            " [0.9960924 ]\n",
            " [0.9960806 ]\n",
            " [0.00595837]]\n",
            "Step: 7065 -> Loss: 0.004360411781817675 -> Predictions: [[0.00361657]\n",
            " [0.9960924 ]\n",
            " [0.9960806 ]\n",
            " [0.00595835]]\n",
            "Step: 7066 -> Loss: 0.00436039175838232 -> Predictions: [[0.00361655]\n",
            " [0.9960924 ]\n",
            " [0.9960806 ]\n",
            " [0.00595831]]\n",
            "Step: 7067 -> Loss: 0.004360374063253403 -> Predictions: [[0.00361654]\n",
            " [0.9960924 ]\n",
            " [0.9960806 ]\n",
            " [0.00595829]]\n",
            "Step: 7068 -> Loss: 0.0043603526428341866 -> Predictions: [[0.00361652]\n",
            " [0.9960925 ]\n",
            " [0.9960807 ]\n",
            " [0.00595826]]\n",
            "Step: 7069 -> Loss: 0.004360332619398832 -> Predictions: [[0.00361651]\n",
            " [0.9960925 ]\n",
            " [0.9960807 ]\n",
            " [0.00595822]]\n",
            "Step: 7070 -> Loss: 0.004360308405011892 -> Predictions: [[0.00361649]\n",
            " [0.9960925 ]\n",
            " [0.9960807 ]\n",
            " [0.00595819]]\n",
            "Step: 7071 -> Loss: 0.004360291641205549 -> Predictions: [[0.00361647]\n",
            " [0.9960925 ]\n",
            " [0.9960807 ]\n",
            " [0.00595817]]\n",
            "Step: 7072 -> Loss: 0.004360268358141184 -> Predictions: [[0.00361646]\n",
            " [0.9960925 ]\n",
            " [0.9960807 ]\n",
            " [0.00595813]]\n",
            "Step: 7073 -> Loss: 0.00436024833470583 -> Predictions: [[0.00361644]\n",
            " [0.9960925 ]\n",
            " [0.9960807 ]\n",
            " [0.0059581 ]]\n",
            "Step: 7074 -> Loss: 0.0043602315708994865 -> Predictions: [[0.00361643]\n",
            " [0.9960925 ]\n",
            " [0.9960807 ]\n",
            " [0.00595807]]\n",
            "Step: 7075 -> Loss: 0.004360209219157696 -> Predictions: [[0.00361641]\n",
            " [0.9960926 ]\n",
            " [0.9960808 ]\n",
            " [0.00595804]]\n",
            "Step: 7076 -> Loss: 0.00436018779873848 -> Predictions: [[0.00361639]\n",
            " [0.9960926 ]\n",
            " [0.9960808 ]\n",
            " [0.00595801]]\n",
            "Step: 7077 -> Loss: 0.004360169172286987 -> Predictions: [[0.00361638]\n",
            " [0.9960926 ]\n",
            " [0.9960808 ]\n",
            " [0.00595798]]\n",
            "Step: 7078 -> Loss: 0.004360149148851633 -> Predictions: [[0.00361636]\n",
            " [0.9960926 ]\n",
            " [0.9960808 ]\n",
            " [0.00595796]]\n",
            "Step: 7079 -> Loss: 0.0043601286597549915 -> Predictions: [[0.00361634]\n",
            " [0.9960926 ]\n",
            " [0.9960808 ]\n",
            " [0.00595792]]\n",
            "Step: 7080 -> Loss: 0.004360108636319637 -> Predictions: [[0.00361633]\n",
            " [0.9960926 ]\n",
            " [0.9960808 ]\n",
            " [0.0059579 ]]\n",
            "Step: 7081 -> Loss: 0.004360084887593985 -> Predictions: [[0.00361631]\n",
            " [0.99609274]\n",
            " [0.99608094]\n",
            " [0.00595786]]\n",
            "Step: 7082 -> Loss: 0.004360068589448929 -> Predictions: [[0.0036163 ]\n",
            " [0.99609274]\n",
            " [0.99608094]\n",
            " [0.00595783]]\n",
            "Step: 7083 -> Loss: 0.004360046237707138 -> Predictions: [[0.00361628]\n",
            " [0.99609274]\n",
            " [0.99608094]\n",
            " [0.00595781]]\n",
            "Step: 7084 -> Loss: 0.004360026679933071 -> Predictions: [[0.00361626]\n",
            " [0.99609274]\n",
            " [0.99608094]\n",
            " [0.00595777]]\n",
            "Step: 7085 -> Loss: 0.004360005259513855 -> Predictions: [[0.00361625]\n",
            " [0.99609274]\n",
            " [0.99608094]\n",
            " [0.00595774]]\n",
            "Step: 7086 -> Loss: 0.0043599847704172134 -> Predictions: [[0.00361623]\n",
            " [0.99609274]\n",
            " [0.99608094]\n",
            " [0.00595771]]\n",
            "Step: 7087 -> Loss: 0.004359966143965721 -> Predictions: [[0.00361621]\n",
            " [0.99609274]\n",
            " [0.99608094]\n",
            " [0.00595769]]\n",
            "Step: 7088 -> Loss: 0.004359945189207792 -> Predictions: [[0.0036162 ]\n",
            " [0.99609286]\n",
            " [0.99608105]\n",
            " [0.00595766]]\n",
            "Step: 7089 -> Loss: 0.004359924700111151 -> Predictions: [[0.00361618]\n",
            " [0.99609286]\n",
            " [0.99608105]\n",
            " [0.00595763]]\n",
            "Step: 7090 -> Loss: 0.004359905142337084 -> Predictions: [[0.00361616]\n",
            " [0.99609286]\n",
            " [0.99608105]\n",
            " [0.0059576 ]]\n",
            "Step: 7091 -> Loss: 0.004359885584563017 -> Predictions: [[0.00361615]\n",
            " [0.99609286]\n",
            " [0.99608105]\n",
            " [0.00595757]]\n",
            "Step: 7092 -> Loss: 0.004359863698482513 -> Predictions: [[0.00361613]\n",
            " [0.99609286]\n",
            " [0.99608105]\n",
            " [0.00595754]]\n",
            "Step: 7093 -> Loss: 0.004359845537692308 -> Predictions: [[0.00361612]\n",
            " [0.99609286]\n",
            " [0.99608105]\n",
            " [0.00595751]]\n",
            "Step: 7094 -> Loss: 0.00435982272028923 -> Predictions: [[0.0036161 ]\n",
            " [0.99609286]\n",
            " [0.99608105]\n",
            " [0.00595748]]\n",
            "Step: 7095 -> Loss: 0.004359803628176451 -> Predictions: [[0.00361608]\n",
            " [0.996093  ]\n",
            " [0.9960812 ]\n",
            " [0.00595744]]\n",
            "Step: 7096 -> Loss: 0.004359785467386246 -> Predictions: [[0.00361607]\n",
            " [0.996093  ]\n",
            " [0.9960812 ]\n",
            " [0.00595742]]\n",
            "Step: 7097 -> Loss: 0.00435976404696703 -> Predictions: [[0.00361605]\n",
            " [0.996093  ]\n",
            " [0.9960812 ]\n",
            " [0.00595739]]\n",
            "Step: 7098 -> Loss: 0.0043597412295639515 -> Predictions: [[0.00361603]\n",
            " [0.996093  ]\n",
            " [0.9960812 ]\n",
            " [0.00595735]]\n",
            "Step: 7099 -> Loss: 0.004359721671789885 -> Predictions: [[0.00361602]\n",
            " [0.996093  ]\n",
            " [0.9960812 ]\n",
            " [0.00595733]]\n",
            "Step: 7100 -> Loss: 0.004359702579677105 -> Predictions: [[0.003616  ]\n",
            " [0.996093  ]\n",
            " [0.9960812 ]\n",
            " [0.00595729]]\n",
            "Step: 7101 -> Loss: 0.0043596792966127396 -> Predictions: [[0.00361598]\n",
            " [0.996093  ]\n",
            " [0.9960813 ]\n",
            " [0.00595727]]\n",
            "Step: 7102 -> Loss: 0.004359657410532236 -> Predictions: [[0.00361597]\n",
            " [0.9960931 ]\n",
            " [0.9960813 ]\n",
            " [0.00595723]]\n",
            "Step: 7103 -> Loss: 0.004359641578048468 -> Predictions: [[0.00361595]\n",
            " [0.9960931 ]\n",
            " [0.9960813 ]\n",
            " [0.00595721]]\n",
            "Step: 7104 -> Loss: 0.004359621554613113 -> Predictions: [[0.00361593]\n",
            " [0.9960931 ]\n",
            " [0.9960813 ]\n",
            " [0.00595718]]\n",
            "Step: 7105 -> Loss: 0.004359600134193897 -> Predictions: [[0.00361592]\n",
            " [0.9960931 ]\n",
            " [0.9960813 ]\n",
            " [0.00595714]]\n",
            "Step: 7106 -> Loss: 0.004359578713774681 -> Predictions: [[0.0036159 ]\n",
            " [0.9960931 ]\n",
            " [0.9960813 ]\n",
            " [0.00595712]]\n",
            "Step: 7107 -> Loss: 0.004359557759016752 -> Predictions: [[0.00361588]\n",
            " [0.9960931 ]\n",
            " [0.9960813 ]\n",
            " [0.00595709]]\n",
            "Step: 7108 -> Loss: 0.004359539598226547 -> Predictions: [[0.00361587]\n",
            " [0.9960931 ]\n",
            " [0.9960813 ]\n",
            " [0.00595706]]\n",
            "Step: 7109 -> Loss: 0.004359518177807331 -> Predictions: [[0.00361586]\n",
            " [0.9960932 ]\n",
            " [0.9960814 ]\n",
            " [0.00595702]]\n",
            "Step: 7110 -> Loss: 0.004359495360404253 -> Predictions: [[0.00361584]\n",
            " [0.9960932 ]\n",
            " [0.9960814 ]\n",
            " [0.00595699]]\n",
            "Step: 7111 -> Loss: 0.004359479062259197 -> Predictions: [[0.00361582]\n",
            " [0.9960932 ]\n",
            " [0.9960814 ]\n",
            " [0.00595697]]\n",
            "Step: 7112 -> Loss: 0.004359457176178694 -> Predictions: [[0.00361581]\n",
            " [0.9960932 ]\n",
            " [0.9960814 ]\n",
            " [0.00595693]]\n",
            "Step: 7113 -> Loss: 0.004359436687082052 -> Predictions: [[0.00361579]\n",
            " [0.9960932 ]\n",
            " [0.9960814 ]\n",
            " [0.00595691]]\n",
            "Step: 7114 -> Loss: 0.004359417129307985 -> Predictions: [[0.00361577]\n",
            " [0.9960932 ]\n",
            " [0.9960814 ]\n",
            " [0.00595688]]\n",
            "Step: 7115 -> Loss: 0.0043593961745500565 -> Predictions: [[0.00361575]\n",
            " [0.99609333]\n",
            " [0.99608153]\n",
            " [0.00595685]]\n",
            "Step: 7116 -> Loss: 0.004359375219792128 -> Predictions: [[0.00361574]\n",
            " [0.99609333]\n",
            " [0.99608153]\n",
            " [0.00595682]]\n",
            "Step: 7117 -> Loss: 0.004359355196356773 -> Predictions: [[0.00361572]\n",
            " [0.99609333]\n",
            " [0.99608153]\n",
            " [0.00595678]]\n",
            "Step: 7118 -> Loss: 0.0043593342415988445 -> Predictions: [[0.0036157 ]\n",
            " [0.99609333]\n",
            " [0.99608153]\n",
            " [0.00595676]]\n",
            "Step: 7119 -> Loss: 0.0043593160808086395 -> Predictions: [[0.00361569]\n",
            " [0.99609333]\n",
            " [0.99608153]\n",
            " [0.00595673]]\n",
            "Step: 7120 -> Loss: 0.004359296523034573 -> Predictions: [[0.00361567]\n",
            " [0.99609333]\n",
            " [0.99608153]\n",
            " [0.0059567 ]]\n",
            "Step: 7121 -> Loss: 0.004359276499599218 -> Predictions: [[0.00361566]\n",
            " [0.99609333]\n",
            " [0.99608153]\n",
            " [0.00595667]]\n",
            "Step: 7122 -> Loss: 0.004359252750873566 -> Predictions: [[0.00361564]\n",
            " [0.99609345]\n",
            " [0.99608165]\n",
            " [0.00595664]]\n",
            "Step: 7123 -> Loss: 0.004359235055744648 -> Predictions: [[0.00361562]\n",
            " [0.99609345]\n",
            " [0.99608165]\n",
            " [0.00595661]]\n",
            "Step: 7124 -> Loss: 0.004359211772680283 -> Predictions: [[0.00361561]\n",
            " [0.99609345]\n",
            " [0.99608165]\n",
            " [0.00595657]]\n",
            "Step: 7125 -> Loss: 0.004359194077551365 -> Predictions: [[0.00361559]\n",
            " [0.99609345]\n",
            " [0.99608165]\n",
            " [0.00595655]]\n",
            "Step: 7126 -> Loss: 0.004359174054116011 -> Predictions: [[0.00361558]\n",
            " [0.99609345]\n",
            " [0.99608165]\n",
            " [0.00595652]]\n",
            "Step: 7127 -> Loss: 0.0043591526336967945 -> Predictions: [[0.00361556]\n",
            " [0.99609345]\n",
            " [0.99608165]\n",
            " [0.00595649]]\n",
            "Step: 7128 -> Loss: 0.004359135404229164 -> Predictions: [[0.00361554]\n",
            " [0.99609345]\n",
            " [0.99608165]\n",
            " [0.00595646]]\n",
            "Step: 7129 -> Loss: 0.004359113052487373 -> Predictions: [[0.00361552]\n",
            " [0.9960936 ]\n",
            " [0.99608177]\n",
            " [0.00595643]]\n",
            "Step: 7130 -> Loss: 0.004359092563390732 -> Predictions: [[0.00361551]\n",
            " [0.9960936 ]\n",
            " [0.99608177]\n",
            " [0.0059564 ]]\n",
            "Step: 7131 -> Loss: 0.004359070677310228 -> Predictions: [[0.0036155 ]\n",
            " [0.9960936 ]\n",
            " [0.99608177]\n",
            " [0.00595637]]\n",
            "Step: 7132 -> Loss: 0.004359053447842598 -> Predictions: [[0.00361548]\n",
            " [0.9960936 ]\n",
            " [0.99608177]\n",
            " [0.00595635]]\n",
            "Step: 7133 -> Loss: 0.004359032958745956 -> Predictions: [[0.00361546]\n",
            " [0.9960936 ]\n",
            " [0.99608177]\n",
            " [0.00595631]]\n",
            "Step: 7134 -> Loss: 0.004359009675681591 -> Predictions: [[0.00361544]\n",
            " [0.9960936 ]\n",
            " [0.99608177]\n",
            " [0.00595628]]\n",
            "Step: 7135 -> Loss: 0.004358992911875248 -> Predictions: [[0.00361543]\n",
            " [0.9960936 ]\n",
            " [0.99608177]\n",
            " [0.00595625]]\n",
            "Step: 7136 -> Loss: 0.004358969628810883 -> Predictions: [[0.00361541]\n",
            " [0.9960937 ]\n",
            " [0.9960819 ]\n",
            " [0.00595622]]\n",
            "Step: 7137 -> Loss: 0.00435895100235939 -> Predictions: [[0.0036154 ]\n",
            " [0.9960937 ]\n",
            " [0.9960819 ]\n",
            " [0.00595619]]\n",
            "Step: 7138 -> Loss: 0.004358929581940174 -> Predictions: [[0.00361538]\n",
            " [0.9960937 ]\n",
            " [0.9960819 ]\n",
            " [0.00595616]]\n",
            "Step: 7139 -> Loss: 0.004358907695859671 -> Predictions: [[0.00361536]\n",
            " [0.9960937 ]\n",
            " [0.9960819 ]\n",
            " [0.00595613]]\n",
            "Step: 7140 -> Loss: 0.00435889046639204 -> Predictions: [[0.00361535]\n",
            " [0.9960937 ]\n",
            " [0.9960819 ]\n",
            " [0.0059561 ]]\n",
            "Step: 7141 -> Loss: 0.004358870908617973 -> Predictions: [[0.00361533]\n",
            " [0.9960937 ]\n",
            " [0.9960819 ]\n",
            " [0.00595608]]\n",
            "Step: 7142 -> Loss: 0.004358848091214895 -> Predictions: [[0.00361531]\n",
            " [0.9960937 ]\n",
            " [0.996082  ]\n",
            " [0.00595604]]\n",
            "Step: 7143 -> Loss: 0.004358828067779541 -> Predictions: [[0.0036153 ]\n",
            " [0.9960938 ]\n",
            " [0.996082  ]\n",
            " [0.00595601]]\n",
            "Step: 7144 -> Loss: 0.004358809441328049 -> Predictions: [[0.00361528]\n",
            " [0.9960938 ]\n",
            " [0.996082  ]\n",
            " [0.00595598]]\n",
            "Step: 7145 -> Loss: 0.0043587880209088326 -> Predictions: [[0.00361527]\n",
            " [0.9960938 ]\n",
            " [0.996082  ]\n",
            " [0.00595595]]\n",
            "Step: 7146 -> Loss: 0.004358768463134766 -> Predictions: [[0.00361525]\n",
            " [0.9960938 ]\n",
            " [0.996082  ]\n",
            " [0.00595592]]\n",
            "Step: 7147 -> Loss: 0.004358746111392975 -> Predictions: [[0.00361524]\n",
            " [0.9960938 ]\n",
            " [0.996082  ]\n",
            " [0.00595589]]\n",
            "Step: 7148 -> Loss: 0.0043587274849414825 -> Predictions: [[0.00361522]\n",
            " [0.9960938 ]\n",
            " [0.996082  ]\n",
            " [0.00595586]]\n",
            "Step: 7149 -> Loss: 0.004358707927167416 -> Predictions: [[0.0036152 ]\n",
            " [0.9960938 ]\n",
            " [0.996082  ]\n",
            " [0.00595583]]\n",
            "Step: 7150 -> Loss: 0.004358689300715923 -> Predictions: [[0.00361519]\n",
            " [0.9960939 ]\n",
            " [0.9960821 ]\n",
            " [0.00595581]]\n",
            "Step: 7151 -> Loss: 0.0043586669489741325 -> Predictions: [[0.00361517]\n",
            " [0.9960939 ]\n",
            " [0.9960821 ]\n",
            " [0.00595578]]\n",
            "Step: 7152 -> Loss: 0.004358646925538778 -> Predictions: [[0.00361515]\n",
            " [0.9960939 ]\n",
            " [0.9960821 ]\n",
            " [0.00595574]]\n",
            "Step: 7153 -> Loss: 0.004358625039458275 -> Predictions: [[0.00361513]\n",
            " [0.9960939 ]\n",
            " [0.9960821 ]\n",
            " [0.00595571]]\n",
            "Step: 7154 -> Loss: 0.004358604550361633 -> Predictions: [[0.00361512]\n",
            " [0.9960939 ]\n",
            " [0.9960821 ]\n",
            " [0.00595569]]\n",
            "Step: 7155 -> Loss: 0.004358584526926279 -> Predictions: [[0.0036151 ]\n",
            " [0.9960939 ]\n",
            " [0.9960821 ]\n",
            " [0.00595565]]\n",
            "Step: 7156 -> Loss: 0.0043585654348134995 -> Predictions: [[0.00361508]\n",
            " [0.9960939 ]\n",
            " [0.99608225]\n",
            " [0.00595563]]\n",
            "Step: 7157 -> Loss: 0.004358544014394283 -> Predictions: [[0.00361507]\n",
            " [0.99609405]\n",
            " [0.99608225]\n",
            " [0.00595559]]\n",
            "Step: 7158 -> Loss: 0.004358523525297642 -> Predictions: [[0.00361505]\n",
            " [0.99609405]\n",
            " [0.99608225]\n",
            " [0.00595556]]\n",
            "Step: 7159 -> Loss: 0.004358502104878426 -> Predictions: [[0.00361504]\n",
            " [0.99609405]\n",
            " [0.99608225]\n",
            " [0.00595553]]\n",
            "Step: 7160 -> Loss: 0.004358482547104359 -> Predictions: [[0.00361502]\n",
            " [0.99609405]\n",
            " [0.99608225]\n",
            " [0.0059555 ]]\n",
            "Step: 7161 -> Loss: 0.004358463454991579 -> Predictions: [[0.003615  ]\n",
            " [0.99609405]\n",
            " [0.99608225]\n",
            " [0.00595548]]\n",
            "Step: 7162 -> Loss: 0.004358442034572363 -> Predictions: [[0.00361499]\n",
            " [0.99609405]\n",
            " [0.99608225]\n",
            " [0.00595544]]\n",
            "Step: 7163 -> Loss: 0.004358422011137009 -> Predictions: [[0.00361497]\n",
            " [0.99609417]\n",
            " [0.99608237]\n",
            " [0.00595541]]\n",
            "Step: 7164 -> Loss: 0.00435840105637908 -> Predictions: [[0.00361495]\n",
            " [0.99609417]\n",
            " [0.99608237]\n",
            " [0.00595538]]\n",
            "Step: 7165 -> Loss: 0.004358381498605013 -> Predictions: [[0.00361493]\n",
            " [0.99609417]\n",
            " [0.99608237]\n",
            " [0.00595536]]\n",
            "Step: 7166 -> Loss: 0.004358361940830946 -> Predictions: [[0.00361492]\n",
            " [0.99609417]\n",
            " [0.99608237]\n",
            " [0.00595533]]\n",
            "Step: 7167 -> Loss: 0.004358343780040741 -> Predictions: [[0.00361491]\n",
            " [0.99609417]\n",
            " [0.99608237]\n",
            " [0.0059553 ]]\n",
            "Step: 7168 -> Loss: 0.004358323290944099 -> Predictions: [[0.00361489]\n",
            " [0.99609417]\n",
            " [0.99608237]\n",
            " [0.00595527]]\n",
            "Step: 7169 -> Loss: 0.004358301870524883 -> Predictions: [[0.00361488]\n",
            " [0.99609417]\n",
            " [0.99608237]\n",
            " [0.00595523]]\n",
            "Step: 7170 -> Loss: 0.004358282312750816 -> Predictions: [[0.00361486]\n",
            " [0.9960943 ]\n",
            " [0.9960824 ]\n",
            " [0.00595521]]\n",
            "Step: 7171 -> Loss: 0.0043582613579928875 -> Predictions: [[0.00361484]\n",
            " [0.9960943 ]\n",
            " [0.9960824 ]\n",
            " [0.00595518]]\n",
            "Step: 7172 -> Loss: 0.004358239937573671 -> Predictions: [[0.00361482]\n",
            " [0.9960943 ]\n",
            " [0.9960824 ]\n",
            " [0.00595515]]\n",
            "Step: 7173 -> Loss: 0.004358220379799604 -> Predictions: [[0.00361481]\n",
            " [0.9960943 ]\n",
            " [0.9960824 ]\n",
            " [0.00595512]]\n",
            "Step: 7174 -> Loss: 0.004358201287686825 -> Predictions: [[0.0036148 ]\n",
            " [0.9960943 ]\n",
            " [0.9960824 ]\n",
            " [0.00595509]]\n",
            "Step: 7175 -> Loss: 0.004358181729912758 -> Predictions: [[0.00361478]\n",
            " [0.9960943 ]\n",
            " [0.9960824 ]\n",
            " [0.00595506]]\n",
            "Step: 7176 -> Loss: 0.004358160309493542 -> Predictions: [[0.00361476]\n",
            " [0.9960943 ]\n",
            " [0.9960824 ]\n",
            " [0.00595503]]\n",
            "Step: 7177 -> Loss: 0.0043581398203969 -> Predictions: [[0.00361475]\n",
            " [0.9960944 ]\n",
            " [0.99608254]\n",
            " [0.005955  ]]\n",
            "Step: 7178 -> Loss: 0.004358117468655109 -> Predictions: [[0.00361472]\n",
            " [0.9960944 ]\n",
            " [0.99608254]\n",
            " [0.00595497]]\n",
            "Step: 7179 -> Loss: 0.004358096048235893 -> Predictions: [[0.00361471]\n",
            " [0.9960944 ]\n",
            " [0.99608254]\n",
            " [0.00595493]]\n",
            "Step: 7180 -> Loss: 0.004358074627816677 -> Predictions: [[0.00361469]\n",
            " [0.9960944 ]\n",
            " [0.99608254]\n",
            " [0.0059549 ]]\n",
            "Step: 7181 -> Loss: 0.0043580555357038975 -> Predictions: [[0.00361467]\n",
            " [0.9960944 ]\n",
            " [0.99608254]\n",
            " [0.00595488]]\n",
            "Step: 7182 -> Loss: 0.004358036909252405 -> Predictions: [[0.00361466]\n",
            " [0.9960944 ]\n",
            " [0.99608254]\n",
            " [0.00595485]]\n",
            "Step: 7183 -> Loss: 0.004358015954494476 -> Predictions: [[0.00361464]\n",
            " [0.9960944 ]\n",
            " [0.99608266]\n",
            " [0.00595482]]\n",
            "Step: 7184 -> Loss: 0.004357996862381697 -> Predictions: [[0.00361463]\n",
            " [0.9960945 ]\n",
            " [0.99608266]\n",
            " [0.00595479]]\n",
            "Step: 7185 -> Loss: 0.0043579754419624805 -> Predictions: [[0.00361461]\n",
            " [0.9960945 ]\n",
            " [0.99608266]\n",
            " [0.00595476]]\n",
            "Step: 7186 -> Loss: 0.004357953555881977 -> Predictions: [[0.00361459]\n",
            " [0.9960945 ]\n",
            " [0.99608266]\n",
            " [0.00595473]]\n",
            "Step: 7187 -> Loss: 0.004357938189059496 -> Predictions: [[0.00361458]\n",
            " [0.9960945 ]\n",
            " [0.99608266]\n",
            " [0.0059547 ]]\n",
            "Step: 7188 -> Loss: 0.004357915371656418 -> Predictions: [[0.00361456]\n",
            " [0.9960945 ]\n",
            " [0.99608266]\n",
            " [0.00595468]]\n",
            "Step: 7189 -> Loss: 0.004357893951237202 -> Predictions: [[0.00361455]\n",
            " [0.9960945 ]\n",
            " [0.99608266]\n",
            " [0.00595464]]\n",
            "Step: 7190 -> Loss: 0.00435787346214056 -> Predictions: [[0.00361453]\n",
            " [0.9960945 ]\n",
            " [0.9960828 ]\n",
            " [0.00595461]]\n",
            "Step: 7191 -> Loss: 0.004357852973043919 -> Predictions: [[0.00361451]\n",
            " [0.99609464]\n",
            " [0.9960828 ]\n",
            " [0.00595458]]\n",
            "Step: 7192 -> Loss: 0.004357835743576288 -> Predictions: [[0.0036145 ]\n",
            " [0.99609464]\n",
            " [0.9960828 ]\n",
            " [0.00595456]]\n",
            "Step: 7193 -> Loss: 0.00435781292617321 -> Predictions: [[0.00361448]\n",
            " [0.99609464]\n",
            " [0.9960828 ]\n",
            " [0.00595452]]\n",
            "Step: 7194 -> Loss: 0.004357794299721718 -> Predictions: [[0.00361447]\n",
            " [0.99609464]\n",
            " [0.9960828 ]\n",
            " [0.00595449]]\n",
            "Step: 7195 -> Loss: 0.004357772879302502 -> Predictions: [[0.00361445]\n",
            " [0.99609464]\n",
            " [0.9960828 ]\n",
            " [0.00595446]]\n",
            "Step: 7196 -> Loss: 0.004357750527560711 -> Predictions: [[0.00361443]\n",
            " [0.99609464]\n",
            " [0.9960828 ]\n",
            " [0.00595443]]\n",
            "Step: 7197 -> Loss: 0.004357734229415655 -> Predictions: [[0.00361442]\n",
            " [0.99609464]\n",
            " [0.9960829 ]\n",
            " [0.0059544 ]]\n",
            "Step: 7198 -> Loss: 0.004357711412012577 -> Predictions: [[0.0036144 ]\n",
            " [0.99609476]\n",
            " [0.9960829 ]\n",
            " [0.00595437]]\n",
            "Step: 7199 -> Loss: 0.004357691388577223 -> Predictions: [[0.00361438]\n",
            " [0.99609476]\n",
            " [0.9960829 ]\n",
            " [0.00595434]]\n",
            "Step: 7200 -> Loss: 0.004357671830803156 -> Predictions: [[0.00361436]\n",
            " [0.99609476]\n",
            " [0.9960829 ]\n",
            " [0.00595431]]\n",
            "Step: 7201 -> Loss: 0.004357651341706514 -> Predictions: [[0.00361435]\n",
            " [0.99609476]\n",
            " [0.9960829 ]\n",
            " [0.00595428]]\n",
            "Step: 7202 -> Loss: 0.004357627127319574 -> Predictions: [[0.00361433]\n",
            " [0.99609476]\n",
            " [0.9960829 ]\n",
            " [0.00595424]]\n",
            "Step: 7203 -> Loss: 0.004357609897851944 -> Predictions: [[0.00361432]\n",
            " [0.99609476]\n",
            " [0.9960829 ]\n",
            " [0.00595422]]\n",
            "Step: 7204 -> Loss: 0.004357592202723026 -> Predictions: [[0.00361431]\n",
            " [0.99609476]\n",
            " [0.996083  ]\n",
            " [0.00595419]]\n",
            "Step: 7205 -> Loss: 0.004357572644948959 -> Predictions: [[0.00361429]\n",
            " [0.9960949 ]\n",
            " [0.996083  ]\n",
            " [0.00595416]]\n",
            "Step: 7206 -> Loss: 0.004357549827545881 -> Predictions: [[0.00361427]\n",
            " [0.9960949 ]\n",
            " [0.996083  ]\n",
            " [0.00595413]]\n",
            "Step: 7207 -> Loss: 0.004357529804110527 -> Predictions: [[0.00361426]\n",
            " [0.9960949 ]\n",
            " [0.996083  ]\n",
            " [0.0059541 ]]\n",
            "Step: 7208 -> Loss: 0.00435751024633646 -> Predictions: [[0.00361424]\n",
            " [0.9960949 ]\n",
            " [0.996083  ]\n",
            " [0.00595407]]\n",
            "Step: 7209 -> Loss: 0.004357490222901106 -> Predictions: [[0.00361422]\n",
            " [0.9960949 ]\n",
            " [0.996083  ]\n",
            " [0.00595405]]\n",
            "Step: 7210 -> Loss: 0.004357472062110901 -> Predictions: [[0.00361421]\n",
            " [0.9960949 ]\n",
            " [0.996083  ]\n",
            " [0.00595402]]\n",
            "Step: 7211 -> Loss: 0.004357446916401386 -> Predictions: [[0.00361418]\n",
            " [0.996095  ]\n",
            " [0.99608314]\n",
            " [0.00595398]]\n",
            "Step: 7212 -> Loss: 0.004357428289949894 -> Predictions: [[0.00361417]\n",
            " [0.996095  ]\n",
            " [0.99608314]\n",
            " [0.00595395]]\n",
            "Step: 7213 -> Loss: 0.004357410594820976 -> Predictions: [[0.00361415]\n",
            " [0.996095  ]\n",
            " [0.99608314]\n",
            " [0.00595392]]\n",
            "Step: 7214 -> Loss: 0.004357389640063047 -> Predictions: [[0.00361414]\n",
            " [0.996095  ]\n",
            " [0.99608314]\n",
            " [0.0059539 ]]\n",
            "Step: 7215 -> Loss: 0.004357367753982544 -> Predictions: [[0.00361412]\n",
            " [0.996095  ]\n",
            " [0.99608314]\n",
            " [0.00595386]]\n",
            "Step: 7216 -> Loss: 0.004357346799224615 -> Predictions: [[0.00361411]\n",
            " [0.996095  ]\n",
            " [0.99608314]\n",
            " [0.00595383]]\n",
            "Step: 7217 -> Loss: 0.004357326775789261 -> Predictions: [[0.00361409]\n",
            " [0.996095  ]\n",
            " [0.99608314]\n",
            " [0.0059538 ]]\n",
            "Step: 7218 -> Loss: 0.004357307218015194 -> Predictions: [[0.00361407]\n",
            " [0.9960951 ]\n",
            " [0.99608326]\n",
            " [0.00595378]]\n",
            "Step: 7219 -> Loss: 0.004357285797595978 -> Predictions: [[0.00361406]\n",
            " [0.9960951 ]\n",
            " [0.99608326]\n",
            " [0.00595374]]\n",
            "Step: 7220 -> Loss: 0.004357264377176762 -> Predictions: [[0.00361404]\n",
            " [0.9960951 ]\n",
            " [0.99608326]\n",
            " [0.00595372]]\n",
            "Step: 7221 -> Loss: 0.004357246682047844 -> Predictions: [[0.00361403]\n",
            " [0.9960951 ]\n",
            " [0.99608326]\n",
            " [0.00595368]]\n",
            "Step: 7222 -> Loss: 0.004357225727289915 -> Predictions: [[0.00361401]\n",
            " [0.9960951 ]\n",
            " [0.99608326]\n",
            " [0.00595365]]\n",
            "Step: 7223 -> Loss: 0.004357205703854561 -> Predictions: [[0.00361399]\n",
            " [0.9960951 ]\n",
            " [0.99608326]\n",
            " [0.00595363]]\n",
            "Step: 7224 -> Loss: 0.004357186611741781 -> Predictions: [[0.00361398]\n",
            " [0.9960951 ]\n",
            " [0.99608326]\n",
            " [0.0059536 ]]\n",
            "Step: 7225 -> Loss: 0.004357163794338703 -> Predictions: [[0.00361396]\n",
            " [0.99609524]\n",
            " [0.9960834 ]\n",
            " [0.00595356]]\n",
            "Step: 7226 -> Loss: 0.004357144236564636 -> Predictions: [[0.00361395]\n",
            " [0.99609524]\n",
            " [0.9960834 ]\n",
            " [0.00595353]]\n",
            "Step: 7227 -> Loss: 0.004357124678790569 -> Predictions: [[0.00361393]\n",
            " [0.99609524]\n",
            " [0.9960834 ]\n",
            " [0.00595351]]\n",
            "Step: 7228 -> Loss: 0.00435710558667779 -> Predictions: [[0.00361391]\n",
            " [0.99609524]\n",
            " [0.9960834 ]\n",
            " [0.00595348]]\n",
            "Step: 7229 -> Loss: 0.004357082769274712 -> Predictions: [[0.0036139 ]\n",
            " [0.99609524]\n",
            " [0.9960834 ]\n",
            " [0.00595345]]\n",
            "Step: 7230 -> Loss: 0.004357063677161932 -> Predictions: [[0.00361387]\n",
            " [0.99609524]\n",
            " [0.9960834 ]\n",
            " [0.00595341]]\n",
            "Step: 7231 -> Loss: 0.004357043653726578 -> Predictions: [[0.00361386]\n",
            " [0.99609524]\n",
            " [0.9960835 ]\n",
            " [0.00595339]]\n",
            "Step: 7232 -> Loss: 0.004357019439339638 -> Predictions: [[0.00361384]\n",
            " [0.99609536]\n",
            " [0.9960835 ]\n",
            " [0.00595335]]\n",
            "Step: 7233 -> Loss: 0.004357003141194582 -> Predictions: [[0.00361383]\n",
            " [0.99609536]\n",
            " [0.9960835 ]\n",
            " [0.00595333]]\n",
            "Step: 7234 -> Loss: 0.0043569812551140785 -> Predictions: [[0.00361381]\n",
            " [0.99609536]\n",
            " [0.9960835 ]\n",
            " [0.0059533 ]]\n",
            "Step: 7235 -> Loss: 0.004356961697340012 -> Predictions: [[0.0036138 ]\n",
            " [0.99609536]\n",
            " [0.9960835 ]\n",
            " [0.00595327]]\n",
            "Step: 7236 -> Loss: 0.004356939811259508 -> Predictions: [[0.00361378]\n",
            " [0.99609536]\n",
            " [0.9960835 ]\n",
            " [0.00595324]]\n",
            "Step: 7237 -> Loss: 0.004356918856501579 -> Predictions: [[0.00361376]\n",
            " [0.99609536]\n",
            " [0.9960835 ]\n",
            " [0.0059532 ]]\n",
            "Step: 7238 -> Loss: 0.004356900230050087 -> Predictions: [[0.00361374]\n",
            " [0.99609536]\n",
            " [0.9960836 ]\n",
            " [0.00595318]]\n",
            "Step: 7239 -> Loss: 0.004356878809630871 -> Predictions: [[0.00361373]\n",
            " [0.9960955 ]\n",
            " [0.9960836 ]\n",
            " [0.00595314]]\n",
            "Step: 7240 -> Loss: 0.004356858786195517 -> Predictions: [[0.00361371]\n",
            " [0.9960955 ]\n",
            " [0.9960836 ]\n",
            " [0.00595311]]\n",
            "Step: 7241 -> Loss: 0.004356838762760162 -> Predictions: [[0.0036137 ]\n",
            " [0.9960955 ]\n",
            " [0.9960836 ]\n",
            " [0.00595309]]\n",
            "Step: 7242 -> Loss: 0.004356818273663521 -> Predictions: [[0.00361368]\n",
            " [0.9960955 ]\n",
            " [0.9960836 ]\n",
            " [0.00595306]]\n",
            "Step: 7243 -> Loss: 0.004356801509857178 -> Predictions: [[0.00361366]\n",
            " [0.9960955 ]\n",
            " [0.9960836 ]\n",
            " [0.00595303]]\n",
            "Step: 7244 -> Loss: 0.00435677682980895 -> Predictions: [[0.00361364]\n",
            " [0.9960955 ]\n",
            " [0.9960836 ]\n",
            " [0.005953  ]]\n",
            "Step: 7245 -> Loss: 0.0043567572720348835 -> Predictions: [[0.00361363]\n",
            " [0.9960955 ]\n",
            " [0.99608374]\n",
            " [0.00595297]]\n",
            "Step: 7246 -> Loss: 0.004356738179922104 -> Predictions: [[0.00361362]\n",
            " [0.9960956 ]\n",
            " [0.99608374]\n",
            " [0.00595294]]\n",
            "Step: 7247 -> Loss: 0.004356716759502888 -> Predictions: [[0.0036136 ]\n",
            " [0.9960956 ]\n",
            " [0.99608374]\n",
            " [0.00595291]]\n",
            "Step: 7248 -> Loss: 0.004356698133051395 -> Predictions: [[0.00361358]\n",
            " [0.9960956 ]\n",
            " [0.99608374]\n",
            " [0.00595288]]\n",
            "Step: 7249 -> Loss: 0.004356677643954754 -> Predictions: [[0.00361357]\n",
            " [0.9960956 ]\n",
            " [0.99608374]\n",
            " [0.00595285]]\n",
            "Step: 7250 -> Loss: 0.004356657154858112 -> Predictions: [[0.00361355]\n",
            " [0.9960956 ]\n",
            " [0.99608374]\n",
            " [0.00595282]]\n",
            "Step: 7251 -> Loss: 0.004356637131422758 -> Predictions: [[0.00361354]\n",
            " [0.9960956 ]\n",
            " [0.99608374]\n",
            " [0.00595279]]\n",
            "Step: 7252 -> Loss: 0.004356615711003542 -> Predictions: [[0.00361351]\n",
            " [0.9960957 ]\n",
            " [0.99608386]\n",
            " [0.00595276]]\n",
            "Step: 7253 -> Loss: 0.004356594756245613 -> Predictions: [[0.0036135 ]\n",
            " [0.9960957 ]\n",
            " [0.99608386]\n",
            " [0.00595273]]\n",
            "Step: 7254 -> Loss: 0.004356577061116695 -> Predictions: [[0.00361348]\n",
            " [0.9960957 ]\n",
            " [0.99608386]\n",
            " [0.0059527 ]]\n",
            "Step: 7255 -> Loss: 0.00435655377805233 -> Predictions: [[0.00361347]\n",
            " [0.9960957 ]\n",
            " [0.99608386]\n",
            " [0.00595267]]\n",
            "Step: 7256 -> Loss: 0.004356535151600838 -> Predictions: [[0.00361345]\n",
            " [0.9960957 ]\n",
            " [0.99608386]\n",
            " [0.00595264]]\n",
            "Step: 7257 -> Loss: 0.0043565137311816216 -> Predictions: [[0.00361343]\n",
            " [0.9960957 ]\n",
            " [0.99608386]\n",
            " [0.00595261]]\n",
            "Step: 7258 -> Loss: 0.004356491379439831 -> Predictions: [[0.00361342]\n",
            " [0.9960957 ]\n",
            " [0.996084  ]\n",
            " [0.00595258]]\n",
            "Step: 7259 -> Loss: 0.004356476478278637 -> Predictions: [[0.0036134 ]\n",
            " [0.9960957 ]\n",
            " [0.996084  ]\n",
            " [0.00595255]]\n",
            "Step: 7260 -> Loss: 0.0043564531952142715 -> Predictions: [[0.00361338]\n",
            " [0.99609584]\n",
            " [0.996084  ]\n",
            " [0.00595252]]\n",
            "Step: 7261 -> Loss: 0.004356432240456343 -> Predictions: [[0.00361337]\n",
            " [0.99609584]\n",
            " [0.996084  ]\n",
            " [0.00595249]]\n",
            "Step: 7262 -> Loss: 0.004356411285698414 -> Predictions: [[0.00361335]\n",
            " [0.99609584]\n",
            " [0.996084  ]\n",
            " [0.00595245]]\n",
            "Step: 7263 -> Loss: 0.004356394521892071 -> Predictions: [[0.00361334]\n",
            " [0.99609584]\n",
            " [0.996084  ]\n",
            " [0.00595243]]\n",
            "Step: 7264 -> Loss: 0.004356371704488993 -> Predictions: [[0.00361332]\n",
            " [0.99609584]\n",
            " [0.996084  ]\n",
            " [0.0059524 ]]\n",
            "Step: 7265 -> Loss: 0.004356352146714926 -> Predictions: [[0.0036133 ]\n",
            " [0.99609584]\n",
            " [0.9960841 ]\n",
            " [0.00595237]]\n",
            "Step: 7266 -> Loss: 0.004356330260634422 -> Predictions: [[0.00361329]\n",
            " [0.99609596]\n",
            " [0.9960841 ]\n",
            " [0.00595234]]\n",
            "Step: 7267 -> Loss: 0.004356309771537781 -> Predictions: [[0.00361327]\n",
            " [0.99609596]\n",
            " [0.9960841 ]\n",
            " [0.00595231]]\n",
            "Step: 7268 -> Loss: 0.004356293473392725 -> Predictions: [[0.00361325]\n",
            " [0.99609596]\n",
            " [0.9960841 ]\n",
            " [0.00595229]]\n",
            "Step: 7269 -> Loss: 0.004356272052973509 -> Predictions: [[0.00361324]\n",
            " [0.99609596]\n",
            " [0.9960841 ]\n",
            " [0.00595225]]\n",
            "Step: 7270 -> Loss: 0.004356252029538155 -> Predictions: [[0.00361322]\n",
            " [0.99609596]\n",
            " [0.9960841 ]\n",
            " [0.00595223]]\n",
            "Step: 7271 -> Loss: 0.004356229677796364 -> Predictions: [[0.0036132 ]\n",
            " [0.99609596]\n",
            " [0.9960841 ]\n",
            " [0.00595219]]\n",
            "Step: 7272 -> Loss: 0.004356208257377148 -> Predictions: [[0.00361319]\n",
            " [0.99609596]\n",
            " [0.9960842 ]\n",
            " [0.00595216]]\n",
            "Step: 7273 -> Loss: 0.004356190096586943 -> Predictions: [[0.00361317]\n",
            " [0.9960961 ]\n",
            " [0.9960842 ]\n",
            " [0.00595213]]\n",
            "Step: 7274 -> Loss: 0.004356169607490301 -> Predictions: [[0.00361316]\n",
            " [0.9960961 ]\n",
            " [0.9960842 ]\n",
            " [0.0059521 ]]\n",
            "Step: 7275 -> Loss: 0.004356147721409798 -> Predictions: [[0.00361314]\n",
            " [0.9960961 ]\n",
            " [0.9960842 ]\n",
            " [0.00595207]]\n",
            "Step: 7276 -> Loss: 0.004356128629297018 -> Predictions: [[0.00361312]\n",
            " [0.9960961 ]\n",
            " [0.9960842 ]\n",
            " [0.00595204]]\n",
            "Step: 7277 -> Loss: 0.004356107674539089 -> Predictions: [[0.00361311]\n",
            " [0.9960961 ]\n",
            " [0.9960842 ]\n",
            " [0.00595201]]\n",
            "Step: 7278 -> Loss: 0.004356089048087597 -> Predictions: [[0.00361309]\n",
            " [0.9960961 ]\n",
            " [0.9960842 ]\n",
            " [0.00595199]]\n",
            "Step: 7279 -> Loss: 0.004356069955974817 -> Predictions: [[0.00361308]\n",
            " [0.9960961 ]\n",
            " [0.99608433]\n",
            " [0.00595195]]\n",
            "Step: 7280 -> Loss: 0.004356048069894314 -> Predictions: [[0.00361306]\n",
            " [0.9960962 ]\n",
            " [0.99608433]\n",
            " [0.00595192]]\n",
            "Step: 7281 -> Loss: 0.004356027580797672 -> Predictions: [[0.00361304]\n",
            " [0.9960962 ]\n",
            " [0.99608433]\n",
            " [0.0059519 ]]\n",
            "Step: 7282 -> Loss: 0.004356008023023605 -> Predictions: [[0.00361303]\n",
            " [0.9960962 ]\n",
            " [0.99608433]\n",
            " [0.00595187]]\n",
            "Step: 7283 -> Loss: 0.004355986602604389 -> Predictions: [[0.00361301]\n",
            " [0.9960962 ]\n",
            " [0.99608433]\n",
            " [0.00595183]]\n",
            "Step: 7284 -> Loss: 0.004355968441814184 -> Predictions: [[0.003613  ]\n",
            " [0.9960962 ]\n",
            " [0.99608433]\n",
            " [0.00595181]]\n",
            "Step: 7285 -> Loss: 0.004355951212346554 -> Predictions: [[0.00361299]\n",
            " [0.9960962 ]\n",
            " [0.99608433]\n",
            " [0.00595178]]\n",
            "Step: 7286 -> Loss: 0.004355925600975752 -> Predictions: [[0.00361297]\n",
            " [0.9960962 ]\n",
            " [0.99608445]\n",
            " [0.00595174]]\n",
            "Step: 7287 -> Loss: 0.004355908837169409 -> Predictions: [[0.00361295]\n",
            " [0.9960963 ]\n",
            " [0.99608445]\n",
            " [0.00595172]]\n",
            "Step: 7288 -> Loss: 0.004355887416750193 -> Predictions: [[0.00361293]\n",
            " [0.9960963 ]\n",
            " [0.99608445]\n",
            " [0.00595169]]\n",
            "Step: 7289 -> Loss: 0.004355868324637413 -> Predictions: [[0.00361292]\n",
            " [0.9960963 ]\n",
            " [0.99608445]\n",
            " [0.00595166]]\n",
            "Step: 7290 -> Loss: 0.0043558464385569096 -> Predictions: [[0.0036129 ]\n",
            " [0.9960963 ]\n",
            " [0.99608445]\n",
            " [0.00595162]]\n",
            "Step: 7291 -> Loss: 0.004355825949460268 -> Predictions: [[0.00361288]\n",
            " [0.9960963 ]\n",
            " [0.99608445]\n",
            " [0.00595159]]\n",
            "Step: 7292 -> Loss: 0.00435580313205719 -> Predictions: [[0.00361286]\n",
            " [0.9960963 ]\n",
            " [0.9960846 ]\n",
            " [0.00595157]]\n",
            "Step: 7293 -> Loss: 0.004355783108621836 -> Predictions: [[0.00361285]\n",
            " [0.9960963 ]\n",
            " [0.9960846 ]\n",
            " [0.00595153]]\n",
            "Step: 7294 -> Loss: 0.004355763550847769 -> Predictions: [[0.00361283]\n",
            " [0.99609643]\n",
            " [0.9960846 ]\n",
            " [0.0059515 ]]\n",
            "Step: 7295 -> Loss: 0.004355745390057564 -> Predictions: [[0.00361281]\n",
            " [0.99609643]\n",
            " [0.9960846 ]\n",
            " [0.00595148]]\n",
            "Step: 7296 -> Loss: 0.004355724900960922 -> Predictions: [[0.0036128 ]\n",
            " [0.99609643]\n",
            " [0.9960846 ]\n",
            " [0.00595145]]\n",
            "Step: 7297 -> Loss: 0.0043557011522352695 -> Predictions: [[0.00361278]\n",
            " [0.99609643]\n",
            " [0.9960846 ]\n",
            " [0.00595141]]\n",
            "Step: 7298 -> Loss: 0.00435568206012249 -> Predictions: [[0.00361277]\n",
            " [0.99609643]\n",
            " [0.9960846 ]\n",
            " [0.00595138]]\n",
            "Step: 7299 -> Loss: 0.004355662036687136 -> Predictions: [[0.00361275]\n",
            " [0.99609643]\n",
            " [0.9960847 ]\n",
            " [0.00595136]]\n",
            "Step: 7300 -> Loss: 0.004355641081929207 -> Predictions: [[0.00361273]\n",
            " [0.99609655]\n",
            " [0.9960847 ]\n",
            " [0.00595132]]\n",
            "Step: 7301 -> Loss: 0.0043556224554777145 -> Predictions: [[0.00361272]\n",
            " [0.99609655]\n",
            " [0.9960847 ]\n",
            " [0.0059513 ]]\n",
            "Step: 7302 -> Loss: 0.004355601035058498 -> Predictions: [[0.0036127 ]\n",
            " [0.99609655]\n",
            " [0.9960847 ]\n",
            " [0.00595127]]\n",
            "Step: 7303 -> Loss: 0.004355583339929581 -> Predictions: [[0.00361269]\n",
            " [0.99609655]\n",
            " [0.9960847 ]\n",
            " [0.00595124]]\n",
            "Step: 7304 -> Loss: 0.004355560056865215 -> Predictions: [[0.00361267]\n",
            " [0.99609655]\n",
            " [0.9960847 ]\n",
            " [0.0059512 ]]\n",
            "Step: 7305 -> Loss: 0.00435554189607501 -> Predictions: [[0.00361265]\n",
            " [0.99609655]\n",
            " [0.9960847 ]\n",
            " [0.00595118]]\n",
            "Step: 7306 -> Loss: 0.004355523735284805 -> Predictions: [[0.00361264]\n",
            " [0.99609655]\n",
            " [0.9960848 ]\n",
            " [0.00595115]]\n",
            "Step: 7307 -> Loss: 0.004355499520897865 -> Predictions: [[0.00361262]\n",
            " [0.9960967 ]\n",
            " [0.9960848 ]\n",
            " [0.00595112]]\n",
            "Step: 7308 -> Loss: 0.004355480894446373 -> Predictions: [[0.00361261]\n",
            " [0.9960967 ]\n",
            " [0.9960848 ]\n",
            " [0.00595109]]\n",
            "Step: 7309 -> Loss: 0.00435546413064003 -> Predictions: [[0.00361259]\n",
            " [0.9960967 ]\n",
            " [0.9960848 ]\n",
            " [0.00595106]]\n",
            "Step: 7310 -> Loss: 0.004355438984930515 -> Predictions: [[0.00361257]\n",
            " [0.9960967 ]\n",
            " [0.9960848 ]\n",
            " [0.00595103]]\n",
            "Step: 7311 -> Loss: 0.004355419892817736 -> Predictions: [[0.00361256]\n",
            " [0.9960967 ]\n",
            " [0.9960848 ]\n",
            " [0.005951  ]]\n",
            "Step: 7312 -> Loss: 0.004355398006737232 -> Predictions: [[0.00361254]\n",
            " [0.9960967 ]\n",
            " [0.9960848 ]\n",
            " [0.00595097]]\n",
            "Step: 7313 -> Loss: 0.004355378914624453 -> Predictions: [[0.00361252]\n",
            " [0.9960967 ]\n",
            " [0.9960849 ]\n",
            " [0.00595094]]\n",
            "Step: 7314 -> Loss: 0.004355359356850386 -> Predictions: [[0.00361251]\n",
            " [0.9960968 ]\n",
            " [0.9960849 ]\n",
            " [0.00595091]]\n",
            "Step: 7315 -> Loss: 0.0043553379364311695 -> Predictions: [[0.00361249]\n",
            " [0.9960968 ]\n",
            " [0.9960849 ]\n",
            " [0.00595088]]\n",
            "Step: 7316 -> Loss: 0.00435531884431839 -> Predictions: [[0.00361247]\n",
            " [0.9960968 ]\n",
            " [0.9960849 ]\n",
            " [0.00595085]]\n",
            "Step: 7317 -> Loss: 0.004355297423899174 -> Predictions: [[0.00361246]\n",
            " [0.9960968 ]\n",
            " [0.9960849 ]\n",
            " [0.00595082]]\n",
            "Step: 7318 -> Loss: 0.004355278797447681 -> Predictions: [[0.00361244]\n",
            " [0.9960968 ]\n",
            " [0.9960849 ]\n",
            " [0.00595079]]\n",
            "Step: 7319 -> Loss: 0.004355257377028465 -> Predictions: [[0.00361242]\n",
            " [0.9960968 ]\n",
            " [0.9960849 ]\n",
            " [0.00595076]]\n",
            "Step: 7320 -> Loss: 0.004355237353593111 -> Predictions: [[0.00361241]\n",
            " [0.9960968 ]\n",
            " [0.99608505]\n",
            " [0.00595073]]\n",
            "Step: 7321 -> Loss: 0.004355216398835182 -> Predictions: [[0.00361239]\n",
            " [0.9960969 ]\n",
            " [0.99608505]\n",
            " [0.0059507 ]]\n",
            "Step: 7322 -> Loss: 0.004355194047093391 -> Predictions: [[0.00361237]\n",
            " [0.9960969 ]\n",
            " [0.99608505]\n",
            " [0.00595067]]\n",
            "Step: 7323 -> Loss: 0.004355178214609623 -> Predictions: [[0.00361236]\n",
            " [0.9960969 ]\n",
            " [0.99608505]\n",
            " [0.00595065]]\n",
            "Step: 7324 -> Loss: 0.0043551563285291195 -> Predictions: [[0.00361234]\n",
            " [0.9960969 ]\n",
            " [0.99608505]\n",
            " [0.00595061]]\n",
            "Step: 7325 -> Loss: 0.004355134908109903 -> Predictions: [[0.00361233]\n",
            " [0.9960969 ]\n",
            " [0.99608505]\n",
            " [0.00595058]]\n",
            "Step: 7326 -> Loss: 0.0043551139533519745 -> Predictions: [[0.00361231]\n",
            " [0.9960969 ]\n",
            " [0.99608505]\n",
            " [0.00595055]]\n",
            "Step: 7327 -> Loss: 0.004355093464255333 -> Predictions: [[0.00361229]\n",
            " [0.9960969 ]\n",
            " [0.99608517]\n",
            " [0.00595052]]\n",
            "Step: 7328 -> Loss: 0.004355075303465128 -> Predictions: [[0.00361228]\n",
            " [0.996097  ]\n",
            " [0.99608517]\n",
            " [0.0059505 ]]\n",
            "Step: 7329 -> Loss: 0.004355053883045912 -> Predictions: [[0.00361226]\n",
            " [0.996097  ]\n",
            " [0.99608517]\n",
            " [0.00595047]]\n",
            "Step: 7330 -> Loss: 0.004355034325271845 -> Predictions: [[0.00361224]\n",
            " [0.996097  ]\n",
            " [0.99608517]\n",
            " [0.00595043]]\n",
            "Step: 7331 -> Loss: 0.004355012439191341 -> Predictions: [[0.00361223]\n",
            " [0.996097  ]\n",
            " [0.99608517]\n",
            " [0.0059504 ]]\n",
            "Step: 7332 -> Loss: 0.004354992415755987 -> Predictions: [[0.00361221]\n",
            " [0.996097  ]\n",
            " [0.99608517]\n",
            " [0.00595037]]\n",
            "Step: 7333 -> Loss: 0.004354975186288357 -> Predictions: [[0.0036122 ]\n",
            " [0.996097  ]\n",
            " [0.99608517]\n",
            " [0.00595035]]\n",
            "Step: 7334 -> Loss: 0.004354950040578842 -> Predictions: [[0.00361218]\n",
            " [0.99609715]\n",
            " [0.9960853 ]\n",
            " [0.00595031]]\n",
            "Step: 7335 -> Loss: 0.0043549309484660625 -> Predictions: [[0.00361216]\n",
            " [0.99609715]\n",
            " [0.9960853 ]\n",
            " [0.00595028]]\n",
            "Step: 7336 -> Loss: 0.00435491232201457 -> Predictions: [[0.00361214]\n",
            " [0.99609715]\n",
            " [0.9960853 ]\n",
            " [0.00595025]]\n",
            "Step: 7337 -> Loss: 0.004354893229901791 -> Predictions: [[0.00361213]\n",
            " [0.99609715]\n",
            " [0.9960853 ]\n",
            " [0.00595022]]\n",
            "Step: 7338 -> Loss: 0.004354871343821287 -> Predictions: [[0.00361211]\n",
            " [0.99609715]\n",
            " [0.9960853 ]\n",
            " [0.00595019]]\n",
            "Step: 7339 -> Loss: 0.004354851320385933 -> Predictions: [[0.00361209]\n",
            " [0.99609715]\n",
            " [0.9960853 ]\n",
            " [0.00595016]]\n",
            "Step: 7340 -> Loss: 0.004354831296950579 -> Predictions: [[0.00361208]\n",
            " [0.99609715]\n",
            " [0.9960854 ]\n",
            " [0.00595014]]\n",
            "Step: 7341 -> Loss: 0.004354812670499086 -> Predictions: [[0.00361207]\n",
            " [0.99609727]\n",
            " [0.9960854 ]\n",
            " [0.00595011]]\n",
            "Step: 7342 -> Loss: 0.004354788456112146 -> Predictions: [[0.00361205]\n",
            " [0.99609727]\n",
            " [0.9960854 ]\n",
            " [0.00595007]]\n",
            "Step: 7343 -> Loss: 0.004354770295321941 -> Predictions: [[0.00361203]\n",
            " [0.99609727]\n",
            " [0.9960854 ]\n",
            " [0.00595005]]\n",
            "Step: 7344 -> Loss: 0.004354748874902725 -> Predictions: [[0.00361202]\n",
            " [0.99609727]\n",
            " [0.9960854 ]\n",
            " [0.00595001]]\n",
            "Step: 7345 -> Loss: 0.004354731645435095 -> Predictions: [[0.003612  ]\n",
            " [0.99609727]\n",
            " [0.9960854 ]\n",
            " [0.00594999]]\n",
            "Step: 7346 -> Loss: 0.004354711621999741 -> Predictions: [[0.00361199]\n",
            " [0.99609727]\n",
            " [0.9960854 ]\n",
            " [0.00594996]]\n",
            "Step: 7347 -> Loss: 0.004354688338935375 -> Predictions: [[0.00361197]\n",
            " [0.99609727]\n",
            " [0.9960855 ]\n",
            " [0.00594992]]\n",
            "Step: 7348 -> Loss: 0.00435467017814517 -> Predictions: [[0.00361195]\n",
            " [0.9960974 ]\n",
            " [0.9960855 ]\n",
            " [0.00594989]]\n",
            "Step: 7349 -> Loss: 0.004354648292064667 -> Predictions: [[0.00361193]\n",
            " [0.9960974 ]\n",
            " [0.9960855 ]\n",
            " [0.00594987]]\n",
            "Step: 7350 -> Loss: 0.0043546287342906 -> Predictions: [[0.00361192]\n",
            " [0.9960974 ]\n",
            " [0.9960855 ]\n",
            " [0.00594983]]\n",
            "Step: 7351 -> Loss: 0.004354610573500395 -> Predictions: [[0.0036119 ]\n",
            " [0.9960974 ]\n",
            " [0.9960855 ]\n",
            " [0.00594981]]\n",
            "Step: 7352 -> Loss: 0.004354588687419891 -> Predictions: [[0.00361189]\n",
            " [0.9960974 ]\n",
            " [0.9960855 ]\n",
            " [0.00594978]]\n",
            "Step: 7353 -> Loss: 0.004354566335678101 -> Predictions: [[0.00361187]\n",
            " [0.9960974 ]\n",
            " [0.9960855 ]\n",
            " [0.00594974]]\n",
            "Step: 7354 -> Loss: 0.004354547243565321 -> Predictions: [[0.00361185]\n",
            " [0.9960974 ]\n",
            " [0.99608564]\n",
            " [0.00594971]]\n",
            "Step: 7355 -> Loss: 0.004354524426162243 -> Predictions: [[0.00361184]\n",
            " [0.9960975 ]\n",
            " [0.99608564]\n",
            " [0.00594968]]\n",
            "Step: 7356 -> Loss: 0.004354506265372038 -> Predictions: [[0.00361182]\n",
            " [0.9960975 ]\n",
            " [0.99608564]\n",
            " [0.00594966]]\n",
            "Step: 7357 -> Loss: 0.004354488104581833 -> Predictions: [[0.00361181]\n",
            " [0.9960975 ]\n",
            " [0.99608564]\n",
            " [0.00594962]]\n",
            "Step: 7358 -> Loss: 0.004354467149823904 -> Predictions: [[0.00361179]\n",
            " [0.9960975 ]\n",
            " [0.99608564]\n",
            " [0.0059496 ]]\n",
            "Step: 7359 -> Loss: 0.004354448523372412 -> Predictions: [[0.00361177]\n",
            " [0.9960975 ]\n",
            " [0.99608564]\n",
            " [0.00594957]]\n",
            "Step: 7360 -> Loss: 0.004354427102953196 -> Predictions: [[0.00361175]\n",
            " [0.9960975 ]\n",
            " [0.99608564]\n",
            " [0.00594954]]\n",
            "Step: 7361 -> Loss: 0.004354404751211405 -> Predictions: [[0.00361174]\n",
            " [0.9960975 ]\n",
            " [0.99608576]\n",
            " [0.00594951]]\n",
            "Step: 7362 -> Loss: 0.004354385659098625 -> Predictions: [[0.00361173]\n",
            " [0.99609756]\n",
            " [0.99608576]\n",
            " [0.00594948]]\n",
            "Step: 7363 -> Loss: 0.004354366101324558 -> Predictions: [[0.00361171]\n",
            " [0.99609756]\n",
            " [0.99608576]\n",
            " [0.00594945]]\n",
            "Step: 7364 -> Loss: 0.0043543437495827675 -> Predictions: [[0.00361169]\n",
            " [0.99609756]\n",
            " [0.99608576]\n",
            " [0.00594942]]\n",
            "Step: 7365 -> Loss: 0.004354325123131275 -> Predictions: [[0.00361167]\n",
            " [0.99609756]\n",
            " [0.99608576]\n",
            " [0.00594939]]\n",
            "Step: 7366 -> Loss: 0.004354306496679783 -> Predictions: [[0.00361166]\n",
            " [0.99609756]\n",
            " [0.99608576]\n",
            " [0.00594936]]\n",
            "Step: 7367 -> Loss: 0.004354284144937992 -> Predictions: [[0.00361164]\n",
            " [0.99609756]\n",
            " [0.99608576]\n",
            " [0.00594933]]\n",
            "Step: 7368 -> Loss: 0.004354262724518776 -> Predictions: [[0.00361162]\n",
            " [0.99609756]\n",
            " [0.9960859 ]\n",
            " [0.0059493 ]]\n",
            "Step: 7369 -> Loss: 0.004354244563728571 -> Predictions: [[0.00361161]\n",
            " [0.9960977 ]\n",
            " [0.9960859 ]\n",
            " [0.00594927]]\n",
            "Step: 7370 -> Loss: 0.004354223143309355 -> Predictions: [[0.00361159]\n",
            " [0.9960977 ]\n",
            " [0.9960859 ]\n",
            " [0.00594924]]\n",
            "Step: 7371 -> Loss: 0.004354201722890139 -> Predictions: [[0.00361158]\n",
            " [0.9960977 ]\n",
            " [0.9960859 ]\n",
            " [0.0059492 ]]\n",
            "Step: 7372 -> Loss: 0.004354181699454784 -> Predictions: [[0.00361156]\n",
            " [0.9960977 ]\n",
            " [0.9960859 ]\n",
            " [0.00594918]]\n",
            "Step: 7373 -> Loss: 0.004354161210358143 -> Predictions: [[0.00361154]\n",
            " [0.9960977 ]\n",
            " [0.9960859 ]\n",
            " [0.00594915]]\n",
            "Step: 7374 -> Loss: 0.004354141652584076 -> Predictions: [[0.00361152]\n",
            " [0.9960977 ]\n",
            " [0.996086  ]\n",
            " [0.00594912]]\n",
            "Step: 7375 -> Loss: 0.004354121163487434 -> Predictions: [[0.00361151]\n",
            " [0.9960977 ]\n",
            " [0.996086  ]\n",
            " [0.00594909]]\n",
            "Step: 7376 -> Loss: 0.004354103002697229 -> Predictions: [[0.0036115 ]\n",
            " [0.9960978 ]\n",
            " [0.996086  ]\n",
            " [0.00594906]]\n",
            "Step: 7377 -> Loss: 0.004354079253971577 -> Predictions: [[0.00361148]\n",
            " [0.9960978 ]\n",
            " [0.996086  ]\n",
            " [0.00594903]]\n",
            "Step: 7378 -> Loss: 0.004354058764874935 -> Predictions: [[0.00361146]\n",
            " [0.9960978 ]\n",
            " [0.996086  ]\n",
            " [0.00594899]]\n",
            "Step: 7379 -> Loss: 0.004354041535407305 -> Predictions: [[0.00361144]\n",
            " [0.9960978 ]\n",
            " [0.996086  ]\n",
            " [0.00594897]]\n",
            "Step: 7380 -> Loss: 0.004354020580649376 -> Predictions: [[0.00361143]\n",
            " [0.9960978 ]\n",
            " [0.996086  ]\n",
            " [0.00594894]]\n",
            "Step: 7381 -> Loss: 0.004354000091552734 -> Predictions: [[0.00361141]\n",
            " [0.9960978 ]\n",
            " [0.996086  ]\n",
            " [0.00594891]]\n",
            "Step: 7382 -> Loss: 0.0043539805337786674 -> Predictions: [[0.0036114 ]\n",
            " [0.9960979 ]\n",
            " [0.9960861 ]\n",
            " [0.00594888]]\n",
            "Step: 7383 -> Loss: 0.004353961907327175 -> Predictions: [[0.00361138]\n",
            " [0.9960979 ]\n",
            " [0.9960861 ]\n",
            " [0.00594886]]\n",
            "Step: 7384 -> Loss: 0.00435393862426281 -> Predictions: [[0.00361136]\n",
            " [0.9960979 ]\n",
            " [0.9960861 ]\n",
            " [0.00594882]]\n",
            "Step: 7385 -> Loss: 0.0043539199978113174 -> Predictions: [[0.00361135]\n",
            " [0.9960979 ]\n",
            " [0.9960861 ]\n",
            " [0.00594879]]\n",
            "Step: 7386 -> Loss: 0.004353897180408239 -> Predictions: [[0.00361133]\n",
            " [0.9960979 ]\n",
            " [0.9960861 ]\n",
            " [0.00594876]]\n",
            "Step: 7387 -> Loss: 0.004353879950940609 -> Predictions: [[0.00361131]\n",
            " [0.9960979 ]\n",
            " [0.9960861 ]\n",
            " [0.00594874]]\n",
            "Step: 7388 -> Loss: 0.0043538594618439674 -> Predictions: [[0.0036113 ]\n",
            " [0.9960979 ]\n",
            " [0.99608624]\n",
            " [0.0059487 ]]\n",
            "Step: 7389 -> Loss: 0.004353838041424751 -> Predictions: [[0.00361128]\n",
            " [0.99609804]\n",
            " [0.99608624]\n",
            " [0.00594867]]\n",
            "Step: 7390 -> Loss: 0.004353818017989397 -> Predictions: [[0.00361127]\n",
            " [0.99609804]\n",
            " [0.99608624]\n",
            " [0.00594864]]\n",
            "Step: 7391 -> Loss: 0.004353796131908894 -> Predictions: [[0.00361125]\n",
            " [0.99609804]\n",
            " [0.99608624]\n",
            " [0.00594861]]\n",
            "Step: 7392 -> Loss: 0.004353776574134827 -> Predictions: [[0.00361123]\n",
            " [0.99609804]\n",
            " [0.99608624]\n",
            " [0.00594858]]\n",
            "Step: 7393 -> Loss: 0.004353756085038185 -> Predictions: [[0.00361122]\n",
            " [0.99609804]\n",
            " [0.99608624]\n",
            " [0.00594855]]\n",
            "Step: 7394 -> Loss: 0.0043537369929254055 -> Predictions: [[0.0036112 ]\n",
            " [0.99609804]\n",
            " [0.99608624]\n",
            " [0.00594852]]\n",
            "Step: 7395 -> Loss: 0.004353716038167477 -> Predictions: [[0.00361118]\n",
            " [0.99609804]\n",
            " [0.99608636]\n",
            " [0.00594849]]\n",
            "Step: 7396 -> Loss: 0.004353695083409548 -> Predictions: [[0.00361117]\n",
            " [0.99609816]\n",
            " [0.99608636]\n",
            " [0.00594846]]\n",
            "Step: 7397 -> Loss: 0.004353675059974194 -> Predictions: [[0.00361115]\n",
            " [0.99609816]\n",
            " [0.99608636]\n",
            " [0.00594843]]\n",
            "Step: 7398 -> Loss: 0.004353655502200127 -> Predictions: [[0.00361114]\n",
            " [0.99609816]\n",
            " [0.99608636]\n",
            " [0.0059484 ]]\n",
            "Step: 7399 -> Loss: 0.004353633616119623 -> Predictions: [[0.00361112]\n",
            " [0.99609816]\n",
            " [0.99608636]\n",
            " [0.00594837]]\n",
            "Step: 7400 -> Loss: 0.004353616386651993 -> Predictions: [[0.0036111 ]\n",
            " [0.99609816]\n",
            " [0.99608636]\n",
            " [0.00594835]]\n",
            "Step: 7401 -> Loss: 0.004353592172265053 -> Predictions: [[0.00361108]\n",
            " [0.99609816]\n",
            " [0.99608636]\n",
            " [0.00594831]]\n",
            "Step: 7402 -> Loss: 0.004353574477136135 -> Predictions: [[0.00361107]\n",
            " [0.99609816]\n",
            " [0.9960865 ]\n",
            " [0.00594828]]\n",
            "Step: 7403 -> Loss: 0.0043535539880394936 -> Predictions: [[0.00361106]\n",
            " [0.9960983 ]\n",
            " [0.9960865 ]\n",
            " [0.00594825]]\n",
            "Step: 7404 -> Loss: 0.00435353210195899 -> Predictions: [[0.00361104]\n",
            " [0.9960983 ]\n",
            " [0.9960865 ]\n",
            " [0.00594822]]\n",
            "Step: 7405 -> Loss: 0.004353515338152647 -> Predictions: [[0.00361102]\n",
            " [0.9960983 ]\n",
            " [0.9960865 ]\n",
            " [0.0059482 ]]\n",
            "Step: 7406 -> Loss: 0.004353492520749569 -> Predictions: [[0.003611  ]\n",
            " [0.9960983 ]\n",
            " [0.9960865 ]\n",
            " [0.00594817]]\n",
            "Step: 7407 -> Loss: 0.004353472497314215 -> Predictions: [[0.00361099]\n",
            " [0.9960983 ]\n",
            " [0.9960865 ]\n",
            " [0.00594814]]\n",
            "Step: 7408 -> Loss: 0.0043534524738788605 -> Predictions: [[0.00361097]\n",
            " [0.9960983 ]\n",
            " [0.9960865 ]\n",
            " [0.0059481 ]]\n",
            "Step: 7409 -> Loss: 0.0043534329161047935 -> Predictions: [[0.00361095]\n",
            " [0.9960983 ]\n",
            " [0.9960866 ]\n",
            " [0.00594808]]\n",
            "Step: 7410 -> Loss: 0.004353412892669439 -> Predictions: [[0.00361094]\n",
            " [0.9960984 ]\n",
            " [0.9960866 ]\n",
            " [0.00594805]]\n",
            "Step: 7411 -> Loss: 0.004353391006588936 -> Predictions: [[0.00361092]\n",
            " [0.9960984 ]\n",
            " [0.9960866 ]\n",
            " [0.00594801]]\n",
            "Step: 7412 -> Loss: 0.004353370983153582 -> Predictions: [[0.00361091]\n",
            " [0.9960984 ]\n",
            " [0.9960866 ]\n",
            " [0.00594799]]\n",
            "Step: 7413 -> Loss: 0.004353352822363377 -> Predictions: [[0.00361089]\n",
            " [0.9960984 ]\n",
            " [0.9960866 ]\n",
            " [0.00594796]]\n",
            "Step: 7414 -> Loss: 0.004353330470621586 -> Predictions: [[0.00361088]\n",
            " [0.9960984 ]\n",
            " [0.9960866 ]\n",
            " [0.00594792]]\n",
            "Step: 7415 -> Loss: 0.004353312775492668 -> Predictions: [[0.00361086]\n",
            " [0.9960984 ]\n",
            " [0.9960866 ]\n",
            " [0.0059479 ]]\n",
            "Step: 7416 -> Loss: 0.0043532890267670155 -> Predictions: [[0.00361084]\n",
            " [0.9960984 ]\n",
            " [0.9960867 ]\n",
            " [0.00594787]]\n",
            "Step: 7417 -> Loss: 0.004353269934654236 -> Predictions: [[0.00361083]\n",
            " [0.9960985 ]\n",
            " [0.9960867 ]\n",
            " [0.00594783]]\n",
            "Step: 7418 -> Loss: 0.004353250376880169 -> Predictions: [[0.00361081]\n",
            " [0.9960985 ]\n",
            " [0.9960867 ]\n",
            " [0.00594781]]\n",
            "Step: 7419 -> Loss: 0.004353229887783527 -> Predictions: [[0.00361079]\n",
            " [0.9960985 ]\n",
            " [0.9960867 ]\n",
            " [0.00594778]]\n",
            "Step: 7420 -> Loss: 0.004353209864348173 -> Predictions: [[0.00361078]\n",
            " [0.9960985 ]\n",
            " [0.9960867 ]\n",
            " [0.00594775]]\n",
            "Step: 7421 -> Loss: 0.004353186581283808 -> Predictions: [[0.00361076]\n",
            " [0.9960985 ]\n",
            " [0.9960867 ]\n",
            " [0.00594772]]\n",
            "Step: 7422 -> Loss: 0.004353169351816177 -> Predictions: [[0.00361074]\n",
            " [0.9960985 ]\n",
            " [0.99608684]\n",
            " [0.00594769]]\n",
            "Step: 7423 -> Loss: 0.004353148862719536 -> Predictions: [[0.00361073]\n",
            " [0.99609864]\n",
            " [0.99608684]\n",
            " [0.00594766]]\n",
            "Step: 7424 -> Loss: 0.004353129304945469 -> Predictions: [[0.00361071]\n",
            " [0.99609864]\n",
            " [0.99608684]\n",
            " [0.00594763]]\n",
            "Step: 7425 -> Loss: 0.004353111144155264 -> Predictions: [[0.0036107 ]\n",
            " [0.99609864]\n",
            " [0.99608684]\n",
            " [0.0059476 ]]\n",
            "Step: 7426 -> Loss: 0.004353087395429611 -> Predictions: [[0.00361068]\n",
            " [0.99609864]\n",
            " [0.99608684]\n",
            " [0.00594757]]\n",
            "Step: 7427 -> Loss: 0.004353068768978119 -> Predictions: [[0.00361066]\n",
            " [0.99609864]\n",
            " [0.99608684]\n",
            " [0.00594754]]\n",
            "Step: 7428 -> Loss: 0.004353047348558903 -> Predictions: [[0.00361065]\n",
            " [0.99609864]\n",
            " [0.99608684]\n",
            " [0.00594751]]\n",
            "Step: 7429 -> Loss: 0.004353026859462261 -> Predictions: [[0.00361063]\n",
            " [0.99609864]\n",
            " [0.99608696]\n",
            " [0.00594748]]\n",
            "Step: 7430 -> Loss: 0.00435300637036562 -> Predictions: [[0.00361061]\n",
            " [0.99609864]\n",
            " [0.99608696]\n",
            " [0.00594745]]\n",
            "Step: 7431 -> Loss: 0.004352988209575415 -> Predictions: [[0.0036106 ]\n",
            " [0.99609876]\n",
            " [0.99608696]\n",
            " [0.00594742]]\n",
            "Step: 7432 -> Loss: 0.004352965392172337 -> Predictions: [[0.00361058]\n",
            " [0.99609876]\n",
            " [0.99608696]\n",
            " [0.00594739]]\n",
            "Step: 7433 -> Loss: 0.004352946765720844 -> Predictions: [[0.00361056]\n",
            " [0.99609876]\n",
            " [0.99608696]\n",
            " [0.00594736]]\n",
            "Step: 7434 -> Loss: 0.00435292674228549 -> Predictions: [[0.00361055]\n",
            " [0.99609876]\n",
            " [0.99608696]\n",
            " [0.00594733]]\n",
            "Step: 7435 -> Loss: 0.004352904390543699 -> Predictions: [[0.00361053]\n",
            " [0.99609876]\n",
            " [0.99608696]\n",
            " [0.00594729]]\n",
            "Step: 7436 -> Loss: 0.004352882970124483 -> Predictions: [[0.00361051]\n",
            " [0.99609876]\n",
            " [0.9960871 ]\n",
            " [0.00594727]]\n",
            "Step: 7437 -> Loss: 0.004352863412350416 -> Predictions: [[0.0036105 ]\n",
            " [0.9960989 ]\n",
            " [0.9960871 ]\n",
            " [0.00594724]]\n",
            "Step: 7438 -> Loss: 0.0043528443202376366 -> Predictions: [[0.00361048]\n",
            " [0.9960989 ]\n",
            " [0.9960871 ]\n",
            " [0.00594721]]\n",
            "Step: 7439 -> Loss: 0.00435282476246357 -> Predictions: [[0.00361047]\n",
            " [0.9960989 ]\n",
            " [0.9960871 ]\n",
            " [0.00594718]]\n",
            "Step: 7440 -> Loss: 0.004352804273366928 -> Predictions: [[0.00361045]\n",
            " [0.9960989 ]\n",
            " [0.9960871 ]\n",
            " [0.00594715]]\n",
            "Step: 7441 -> Loss: 0.004352786112576723 -> Predictions: [[0.00361044]\n",
            " [0.9960989 ]\n",
            " [0.9960871 ]\n",
            " [0.00594713]]\n",
            "Step: 7442 -> Loss: 0.0043527656234800816 -> Predictions: [[0.00361042]\n",
            " [0.9960989 ]\n",
            " [0.9960871 ]\n",
            " [0.0059471 ]]\n",
            "Step: 7443 -> Loss: 0.004352744203060865 -> Predictions: [[0.0036104 ]\n",
            " [0.9960989 ]\n",
            " [0.9960872 ]\n",
            " [0.00594706]]\n",
            "Step: 7444 -> Loss: 0.0043527232483029366 -> Predictions: [[0.00361038]\n",
            " [0.996099  ]\n",
            " [0.9960872 ]\n",
            " [0.00594703]]\n",
            "Step: 7445 -> Loss: 0.0043527004308998585 -> Predictions: [[0.00361037]\n",
            " [0.996099  ]\n",
            " [0.9960872 ]\n",
            " [0.005947  ]]\n",
            "Step: 7446 -> Loss: 0.004352683667093515 -> Predictions: [[0.00361036]\n",
            " [0.996099  ]\n",
            " [0.9960872 ]\n",
            " [0.00594697]]\n",
            "Step: 7447 -> Loss: 0.004352659918367863 -> Predictions: [[0.00361033]\n",
            " [0.996099  ]\n",
            " [0.9960872 ]\n",
            " [0.00594694]]\n",
            "Step: 7448 -> Loss: 0.004352642688900232 -> Predictions: [[0.00361032]\n",
            " [0.996099  ]\n",
            " [0.9960872 ]\n",
            " [0.00594691]]\n",
            "Step: 7449 -> Loss: 0.004352620802819729 -> Predictions: [[0.0036103 ]\n",
            " [0.996099  ]\n",
            " [0.9960872 ]\n",
            " [0.00594688]]\n",
            "Step: 7450 -> Loss: 0.004352601245045662 -> Predictions: [[0.00361029]\n",
            " [0.996099  ]\n",
            " [0.9960873 ]\n",
            " [0.00594685]]\n",
            "Step: 7451 -> Loss: 0.00435258075594902 -> Predictions: [[0.00361027]\n",
            " [0.9960991 ]\n",
            " [0.9960873 ]\n",
            " [0.00594682]]\n",
            "Step: 7452 -> Loss: 0.00435255840420723 -> Predictions: [[0.00361025]\n",
            " [0.9960991 ]\n",
            " [0.9960873 ]\n",
            " [0.00594679]]\n",
            "Step: 7453 -> Loss: 0.004352539777755737 -> Predictions: [[0.00361024]\n",
            " [0.9960991 ]\n",
            " [0.9960873 ]\n",
            " [0.00594676]]\n",
            "Step: 7454 -> Loss: 0.004352519288659096 -> Predictions: [[0.00361022]\n",
            " [0.9960991 ]\n",
            " [0.9960873 ]\n",
            " [0.00594673]]\n",
            "Step: 7455 -> Loss: 0.004352499730885029 -> Predictions: [[0.00361021]\n",
            " [0.9960991 ]\n",
            " [0.9960873 ]\n",
            " [0.0059467 ]]\n",
            "Step: 7456 -> Loss: 0.0043524811044335365 -> Predictions: [[0.00361019]\n",
            " [0.9960991 ]\n",
            " [0.99608743]\n",
            " [0.00594668]]\n",
            "Step: 7457 -> Loss: 0.004352457821369171 -> Predictions: [[0.00361017]\n",
            " [0.9960991 ]\n",
            " [0.99608743]\n",
            " [0.00594664]]\n",
            "Step: 7458 -> Loss: 0.0043524387292563915 -> Predictions: [[0.00361016]\n",
            " [0.99609923]\n",
            " [0.99608743]\n",
            " [0.00594661]]\n",
            "Step: 7459 -> Loss: 0.004352416843175888 -> Predictions: [[0.00361014]\n",
            " [0.99609923]\n",
            " [0.99608743]\n",
            " [0.00594658]]\n",
            "Step: 7460 -> Loss: 0.004352398682385683 -> Predictions: [[0.00361012]\n",
            " [0.99609923]\n",
            " [0.99608743]\n",
            " [0.00594655]]\n",
            "Step: 7461 -> Loss: 0.004352379124611616 -> Predictions: [[0.0036101 ]\n",
            " [0.99609923]\n",
            " [0.99608743]\n",
            " [0.00594653]]\n",
            "Step: 7462 -> Loss: 0.004352356307208538 -> Predictions: [[0.00361009]\n",
            " [0.99609923]\n",
            " [0.99608743]\n",
            " [0.0059465 ]]\n",
            "Step: 7463 -> Loss: 0.004352333955466747 -> Predictions: [[0.00361007]\n",
            " [0.99609923]\n",
            " [0.99608755]\n",
            " [0.00594646]]\n",
            "Step: 7464 -> Loss: 0.0043523176573216915 -> Predictions: [[0.00361006]\n",
            " [0.99609923]\n",
            " [0.99608755]\n",
            " [0.00594644]]\n",
            "Step: 7465 -> Loss: 0.0043522948399186134 -> Predictions: [[0.00361004]\n",
            " [0.99609935]\n",
            " [0.99608755]\n",
            " [0.00594641]]\n",
            "Step: 7466 -> Loss: 0.004352277144789696 -> Predictions: [[0.00361002]\n",
            " [0.99609935]\n",
            " [0.99608755]\n",
            " [0.00594638]]\n",
            "Step: 7467 -> Loss: 0.00435225572437048 -> Predictions: [[0.00361001]\n",
            " [0.99609935]\n",
            " [0.99608755]\n",
            " [0.00594635]]\n",
            "Step: 7468 -> Loss: 0.004352236166596413 -> Predictions: [[0.00360999]\n",
            " [0.99609935]\n",
            " [0.99608755]\n",
            " [0.00594631]]\n",
            "Step: 7469 -> Loss: 0.004352217074483633 -> Predictions: [[0.00360998]\n",
            " [0.99609935]\n",
            " [0.99608755]\n",
            " [0.00594629]]\n",
            "Step: 7470 -> Loss: 0.004352195654064417 -> Predictions: [[0.00360996]\n",
            " [0.99609935]\n",
            " [0.9960877 ]\n",
            " [0.00594626]]\n",
            "Step: 7471 -> Loss: 0.004352175164967775 -> Predictions: [[0.00360995]\n",
            " [0.99609935]\n",
            " [0.9960877 ]\n",
            " [0.00594622]]\n",
            "Step: 7472 -> Loss: 0.0043521542102098465 -> Predictions: [[0.00360993]\n",
            " [0.9960995 ]\n",
            " [0.9960877 ]\n",
            " [0.0059462 ]]\n",
            "Step: 7473 -> Loss: 0.004352135118097067 -> Predictions: [[0.00360991]\n",
            " [0.9960995 ]\n",
            " [0.9960877 ]\n",
            " [0.00594617]]\n",
            "Step: 7474 -> Loss: 0.004352116025984287 -> Predictions: [[0.0036099 ]\n",
            " [0.9960995 ]\n",
            " [0.9960877 ]\n",
            " [0.00594614]]\n",
            "Step: 7475 -> Loss: 0.004352093208581209 -> Predictions: [[0.00360988]\n",
            " [0.9960995 ]\n",
            " [0.9960877 ]\n",
            " [0.00594611]]\n",
            "Step: 7476 -> Loss: 0.004352073185145855 -> Predictions: [[0.00360986]\n",
            " [0.9960995 ]\n",
            " [0.9960877 ]\n",
            " [0.00594607]]\n",
            "Step: 7477 -> Loss: 0.004352054093033075 -> Predictions: [[0.00360985]\n",
            " [0.9960995 ]\n",
            " [0.9960878 ]\n",
            " [0.00594604]]\n",
            "Step: 7478 -> Loss: 0.004352034069597721 -> Predictions: [[0.00360983]\n",
            " [0.9960996 ]\n",
            " [0.9960878 ]\n",
            " [0.00594602]]\n",
            "Step: 7479 -> Loss: 0.004352012649178505 -> Predictions: [[0.00360981]\n",
            " [0.9960996 ]\n",
            " [0.9960878 ]\n",
            " [0.00594599]]\n",
            "Step: 7480 -> Loss: 0.004351993557065725 -> Predictions: [[0.0036098 ]\n",
            " [0.9960996 ]\n",
            " [0.9960878 ]\n",
            " [0.00594596]]\n",
            "Step: 7481 -> Loss: 0.004351972136646509 -> Predictions: [[0.00360978]\n",
            " [0.9960996 ]\n",
            " [0.9960878 ]\n",
            " [0.00594593]]\n",
            "Step: 7482 -> Loss: 0.004351952113211155 -> Predictions: [[0.00360977]\n",
            " [0.9960996 ]\n",
            " [0.9960878 ]\n",
            " [0.0059459 ]]\n",
            "Step: 7483 -> Loss: 0.004351930692791939 -> Predictions: [[0.00360974]\n",
            " [0.9960996 ]\n",
            " [0.9960878 ]\n",
            " [0.00594587]]\n",
            "Step: 7484 -> Loss: 0.004351911600679159 -> Predictions: [[0.00360973]\n",
            " [0.9960996 ]\n",
            " [0.9960879 ]\n",
            " [0.00594584]]\n",
            "Step: 7485 -> Loss: 0.0043518925085663795 -> Predictions: [[0.00360972]\n",
            " [0.9960997 ]\n",
            " [0.9960879 ]\n",
            " [0.00594582]]\n",
            "Step: 7486 -> Loss: 0.004351872950792313 -> Predictions: [[0.0036097 ]\n",
            " [0.9960997 ]\n",
            " [0.9960879 ]\n",
            " [0.00594578]]\n",
            "Step: 7487 -> Loss: 0.0043518515303730965 -> Predictions: [[0.00360968]\n",
            " [0.9960997 ]\n",
            " [0.9960879 ]\n",
            " [0.00594575]]\n",
            "Step: 7488 -> Loss: 0.004351829178631306 -> Predictions: [[0.00360967]\n",
            " [0.9960997 ]\n",
            " [0.9960879 ]\n",
            " [0.00594572]]\n",
            "Step: 7489 -> Loss: 0.004351811483502388 -> Predictions: [[0.00360965]\n",
            " [0.9960997 ]\n",
            " [0.9960879 ]\n",
            " [0.0059457 ]]\n",
            "Step: 7490 -> Loss: 0.004351791460067034 -> Predictions: [[0.00360964]\n",
            " [0.9960997 ]\n",
            " [0.996088  ]\n",
            " [0.00594566]]\n",
            "Step: 7491 -> Loss: 0.00435176957398653 -> Predictions: [[0.00360962]\n",
            " [0.9960997 ]\n",
            " [0.996088  ]\n",
            " [0.00594563]]\n",
            "Step: 7492 -> Loss: 0.004351751413196325 -> Predictions: [[0.0036096]\n",
            " [0.9960998]\n",
            " [0.996088 ]\n",
            " [0.0059456]]\n",
            "Step: 7493 -> Loss: 0.004351728595793247 -> Predictions: [[0.00360958]\n",
            " [0.9960998 ]\n",
            " [0.996088  ]\n",
            " [0.00594557]]\n",
            "Step: 7494 -> Loss: 0.00435170903801918 -> Predictions: [[0.00360957]\n",
            " [0.9960998 ]\n",
            " [0.996088  ]\n",
            " [0.00594554]]\n",
            "Step: 7495 -> Loss: 0.004351689480245113 -> Predictions: [[0.00360955]\n",
            " [0.9960998 ]\n",
            " [0.996088  ]\n",
            " [0.00594551]]\n",
            "Step: 7496 -> Loss: 0.0043516685254871845 -> Predictions: [[0.00360953]\n",
            " [0.9960998 ]\n",
            " [0.996088  ]\n",
            " [0.00594548]]\n",
            "Step: 7497 -> Loss: 0.004351647105067968 -> Predictions: [[0.00360952]\n",
            " [0.9960998 ]\n",
            " [0.996088  ]\n",
            " [0.00594545]]\n",
            "Step: 7498 -> Loss: 0.004351629409939051 -> Predictions: [[0.0036095 ]\n",
            " [0.9960998 ]\n",
            " [0.99608815]\n",
            " [0.00594542]]\n",
            "Step: 7499 -> Loss: 0.004351608455181122 -> Predictions: [[0.00360949]\n",
            " [0.99609995]\n",
            " [0.99608815]\n",
            " [0.00594539]]\n",
            "Step: 7501 -> Loss: 0.004351567942649126 -> Predictions: [[0.00360945]\n",
            " [0.99609995]\n",
            " [0.99608815]\n",
            " [0.00594533]]\n",
            "Step: 7502 -> Loss: 0.004351546987891197 -> Predictions: [[0.00360944]\n",
            " [0.99609995]\n",
            " [0.99608815]\n",
            " [0.0059453 ]]\n",
            "Step: 7503 -> Loss: 0.004351526498794556 -> Predictions: [[0.00360942]\n",
            " [0.99609995]\n",
            " [0.99608815]\n",
            " [0.00594528]]\n",
            "Step: 7504 -> Loss: 0.004351506475359201 -> Predictions: [[0.00360941]\n",
            " [0.99609995]\n",
            " [0.99608827]\n",
            " [0.00594525]]\n",
            "Step: 7505 -> Loss: 0.004351484123617411 -> Predictions: [[0.00360939]\n",
            " [0.99610007]\n",
            " [0.99608827]\n",
            " [0.00594521]]\n",
            "Step: 7506 -> Loss: 0.004351466428488493 -> Predictions: [[0.00360937]\n",
            " [0.99610007]\n",
            " [0.99608827]\n",
            " [0.00594518]]\n",
            "Step: 7507 -> Loss: 0.004351445473730564 -> Predictions: [[0.00360935]\n",
            " [0.99610007]\n",
            " [0.99608827]\n",
            " [0.00594515]]\n",
            "Step: 7508 -> Loss: 0.004351424053311348 -> Predictions: [[0.00360934]\n",
            " [0.99610007]\n",
            " [0.99608827]\n",
            " [0.00594512]]\n",
            "Step: 7509 -> Loss: 0.004351405426859856 -> Predictions: [[0.00360933]\n",
            " [0.99610007]\n",
            " [0.99608827]\n",
            " [0.00594509]]\n",
            "Step: 7510 -> Loss: 0.004351383540779352 -> Predictions: [[0.00360931]\n",
            " [0.99610007]\n",
            " [0.99608827]\n",
            " [0.00594507]]\n",
            "Step: 7511 -> Loss: 0.00435136491432786 -> Predictions: [[0.00360929]\n",
            " [0.99610007]\n",
            " [0.9960884 ]\n",
            " [0.00594504]]\n",
            "Step: 7512 -> Loss: 0.004351343028247356 -> Predictions: [[0.00360927]\n",
            " [0.99610007]\n",
            " [0.9960884 ]\n",
            " [0.005945  ]]\n",
            "Step: 7513 -> Loss: 0.0043513234704732895 -> Predictions: [[0.00360926]\n",
            " [0.9961002 ]\n",
            " [0.9960884 ]\n",
            " [0.00594498]]\n",
            "Step: 7514 -> Loss: 0.0043513039126992226 -> Predictions: [[0.00360924]\n",
            " [0.9961002 ]\n",
            " [0.9960884 ]\n",
            " [0.00594495]]\n",
            "Step: 7515 -> Loss: 0.004351284820586443 -> Predictions: [[0.00360922]\n",
            " [0.9961002 ]\n",
            " [0.9960884 ]\n",
            " [0.00594492]]\n",
            "Step: 7516 -> Loss: 0.004351265728473663 -> Predictions: [[0.00360921]\n",
            " [0.9961002 ]\n",
            " [0.9960884 ]\n",
            " [0.00594489]]\n",
            "Step: 7517 -> Loss: 0.004351242445409298 -> Predictions: [[0.00360919]\n",
            " [0.9961002 ]\n",
            " [0.9960884 ]\n",
            " [0.00594485]]\n",
            "Step: 7518 -> Loss: 0.004351221956312656 -> Predictions: [[0.00360918]\n",
            " [0.9961002 ]\n",
            " [0.9960885 ]\n",
            " [0.00594483]]\n",
            "Step: 7519 -> Loss: 0.00435120053589344 -> Predictions: [[0.00360916]\n",
            " [0.9961003 ]\n",
            " [0.9960885 ]\n",
            " [0.00594479]]\n",
            "Step: 7520 -> Loss: 0.004351181443780661 -> Predictions: [[0.00360914]\n",
            " [0.9961003 ]\n",
            " [0.9960885 ]\n",
            " [0.00594477]]\n",
            "Step: 7521 -> Loss: 0.004351161420345306 -> Predictions: [[0.00360913]\n",
            " [0.9961003 ]\n",
            " [0.9960885 ]\n",
            " [0.00594473]]\n",
            "Step: 7522 -> Loss: 0.004351138602942228 -> Predictions: [[0.00360911]\n",
            " [0.9961003 ]\n",
            " [0.9960885 ]\n",
            " [0.0059447 ]]\n",
            "Step: 7523 -> Loss: 0.004351119510829449 -> Predictions: [[0.00360909]\n",
            " [0.9961003 ]\n",
            " [0.9960885 ]\n",
            " [0.00594468]]\n",
            "Step: 7524 -> Loss: 0.004351102747023106 -> Predictions: [[0.00360908]\n",
            " [0.9961003 ]\n",
            " [0.9960885 ]\n",
            " [0.00594465]]\n",
            "Step: 7525 -> Loss: 0.004351080395281315 -> Predictions: [[0.00360907]\n",
            " [0.9961003 ]\n",
            " [0.9960886 ]\n",
            " [0.00594462]]\n",
            "Step: 7526 -> Loss: 0.004351060837507248 -> Predictions: [[0.00360905]\n",
            " [0.9961004 ]\n",
            " [0.9960886 ]\n",
            " [0.00594459]]\n",
            "Step: 7527 -> Loss: 0.004351041745394468 -> Predictions: [[0.00360903]\n",
            " [0.9961004 ]\n",
            " [0.9960886 ]\n",
            " [0.00594456]]\n",
            "Step: 7528 -> Loss: 0.004351020324975252 -> Predictions: [[0.00360901]\n",
            " [0.9961004 ]\n",
            " [0.9960886 ]\n",
            " [0.00594453]]\n",
            "Step: 7529 -> Loss: 0.004350999835878611 -> Predictions: [[0.003609 ]\n",
            " [0.9961004]\n",
            " [0.9960886]\n",
            " [0.0059445]]\n",
            "Step: 7530 -> Loss: 0.0043509784154593945 -> Predictions: [[0.00360898]\n",
            " [0.9961004 ]\n",
            " [0.9960886 ]\n",
            " [0.00594446]]\n",
            "Step: 7531 -> Loss: 0.00435095839202404 -> Predictions: [[0.00360896]\n",
            " [0.9961004 ]\n",
            " [0.9960886 ]\n",
            " [0.00594444]]\n",
            "Step: 7532 -> Loss: 0.004350937902927399 -> Predictions: [[0.00360895]\n",
            " [0.9961004 ]\n",
            " [0.99608874]\n",
            " [0.0059444 ]]\n",
            "Step: 7533 -> Loss: 0.004350918810814619 -> Predictions: [[0.00360893]\n",
            " [0.99610054]\n",
            " [0.99608874]\n",
            " [0.00594438]]\n",
            "Step: 7534 -> Loss: 0.00435089785605669 -> Predictions: [[0.00360892]\n",
            " [0.99610054]\n",
            " [0.99608874]\n",
            " [0.00594435]]\n",
            "Step: 7535 -> Loss: 0.004350879229605198 -> Predictions: [[0.0036089 ]\n",
            " [0.99610054]\n",
            " [0.99608874]\n",
            " [0.00594432]]\n",
            "Step: 7536 -> Loss: 0.004350857809185982 -> Predictions: [[0.00360889]\n",
            " [0.99610054]\n",
            " [0.99608874]\n",
            " [0.00594429]]\n",
            "Step: 7537 -> Loss: 0.004350838717073202 -> Predictions: [[0.00360887]\n",
            " [0.99610054]\n",
            " [0.99608874]\n",
            " [0.00594426]]\n",
            "Step: 7538 -> Loss: 0.004350818227976561 -> Predictions: [[0.00360885]\n",
            " [0.99610054]\n",
            " [0.99608886]\n",
            " [0.00594423]]\n",
            "Step: 7539 -> Loss: 0.004350796341896057 -> Predictions: [[0.00360884]\n",
            " [0.99610054]\n",
            " [0.99608886]\n",
            " [0.0059442 ]]\n",
            "Step: 7540 -> Loss: 0.004350777715444565 -> Predictions: [[0.00360882]\n",
            " [0.99610066]\n",
            " [0.99608886]\n",
            " [0.00594417]]\n",
            "Step: 7541 -> Loss: 0.0043507590889930725 -> Predictions: [[0.0036088 ]\n",
            " [0.99610066]\n",
            " [0.99608886]\n",
            " [0.00594414]]\n",
            "Step: 7542 -> Loss: 0.00435073534026742 -> Predictions: [[0.00360879]\n",
            " [0.99610066]\n",
            " [0.99608886]\n",
            " [0.00594411]]\n",
            "Step: 7543 -> Loss: 0.004350715316832066 -> Predictions: [[0.00360877]\n",
            " [0.99610066]\n",
            " [0.99608886]\n",
            " [0.00594408]]\n",
            "Step: 7544 -> Loss: 0.004350695293396711 -> Predictions: [[0.00360875]\n",
            " [0.99610066]\n",
            " [0.99608886]\n",
            " [0.00594405]]\n",
            "Step: 7545 -> Loss: 0.0043506743386387825 -> Predictions: [[0.00360873]\n",
            " [0.99610066]\n",
            " [0.996089  ]\n",
            " [0.00594402]]\n",
            "Step: 7546 -> Loss: 0.00435065571218729 -> Predictions: [[0.00360872]\n",
            " [0.99610066]\n",
            " [0.996089  ]\n",
            " [0.00594399]]\n",
            "Step: 7547 -> Loss: 0.004350635223090649 -> Predictions: [[0.0036087 ]\n",
            " [0.9961008 ]\n",
            " [0.996089  ]\n",
            " [0.00594397]]\n",
            "Step: 7548 -> Loss: 0.0043506138026714325 -> Predictions: [[0.00360869]\n",
            " [0.9961008 ]\n",
            " [0.996089  ]\n",
            " [0.00594393]]\n",
            "Step: 7549 -> Loss: 0.004350593313574791 -> Predictions: [[0.00360867]\n",
            " [0.9961008 ]\n",
            " [0.996089  ]\n",
            " [0.0059439 ]]\n",
            "Step: 7550 -> Loss: 0.004350574687123299 -> Predictions: [[0.00360866]\n",
            " [0.9961008 ]\n",
            " [0.996089  ]\n",
            " [0.00594387]]\n",
            "Step: 7551 -> Loss: 0.004350552801042795 -> Predictions: [[0.00360864]\n",
            " [0.9961008 ]\n",
            " [0.996089  ]\n",
            " [0.00594384]]\n",
            "Step: 7552 -> Loss: 0.004350533243268728 -> Predictions: [[0.00360862]\n",
            " [0.9961008 ]\n",
            " [0.9960891 ]\n",
            " [0.00594381]]\n",
            "Step: 7553 -> Loss: 0.004350514151155949 -> Predictions: [[0.00360861]\n",
            " [0.9961008 ]\n",
            " [0.9960891 ]\n",
            " [0.00594378]]\n",
            "Step: 7554 -> Loss: 0.0043504927307367325 -> Predictions: [[0.00360859]\n",
            " [0.9961009 ]\n",
            " [0.9960891 ]\n",
            " [0.00594375]]\n",
            "Step: 7555 -> Loss: 0.0043504731729626656 -> Predictions: [[0.00360858]\n",
            " [0.9961009 ]\n",
            " [0.9960891 ]\n",
            " [0.00594372]]\n",
            "Step: 7556 -> Loss: 0.004350451752543449 -> Predictions: [[0.00360856]\n",
            " [0.9961009 ]\n",
            " [0.9960891 ]\n",
            " [0.00594369]]\n",
            "Step: 7557 -> Loss: 0.004350433591753244 -> Predictions: [[0.00360854]\n",
            " [0.9961009 ]\n",
            " [0.9960891 ]\n",
            " [0.00594366]]\n",
            "Step: 7558 -> Loss: 0.004350412171334028 -> Predictions: [[0.00360853]\n",
            " [0.9961009 ]\n",
            " [0.9960891 ]\n",
            " [0.00594363]]\n",
            "Step: 7559 -> Loss: 0.004350391682237387 -> Predictions: [[0.00360851]\n",
            " [0.9961009 ]\n",
            " [0.9960892 ]\n",
            " [0.0059436 ]]\n",
            "Step: 7560 -> Loss: 0.004350370727479458 -> Predictions: [[0.00360849]\n",
            " [0.996101  ]\n",
            " [0.9960892 ]\n",
            " [0.00594357]]\n",
            "Step: 7561 -> Loss: 0.0043503521010279655 -> Predictions: [[0.00360848]\n",
            " [0.996101  ]\n",
            " [0.9960892 ]\n",
            " [0.00594354]]\n",
            "Step: 7562 -> Loss: 0.004350334871560335 -> Predictions: [[0.00360846]\n",
            " [0.996101  ]\n",
            " [0.9960892 ]\n",
            " [0.00594352]]\n",
            "Step: 7563 -> Loss: 0.0043503097258508205 -> Predictions: [[0.00360844]\n",
            " [0.996101  ]\n",
            " [0.9960892 ]\n",
            " [0.00594349]]\n",
            "Step: 7564 -> Loss: 0.004350290168076754 -> Predictions: [[0.00360843]\n",
            " [0.996101  ]\n",
            " [0.9960892 ]\n",
            " [0.00594346]]\n",
            "Step: 7565 -> Loss: 0.004350271075963974 -> Predictions: [[0.00360841]\n",
            " [0.996101  ]\n",
            " [0.9960892 ]\n",
            " [0.00594343]]\n",
            "Step: 7566 -> Loss: 0.004350249655544758 -> Predictions: [[0.00360839]\n",
            " [0.996101  ]\n",
            " [0.99608934]\n",
            " [0.0059434 ]]\n",
            "Step: 7567 -> Loss: 0.0043502310290932655 -> Predictions: [[0.00360837]\n",
            " [0.996101  ]\n",
            " [0.99608934]\n",
            " [0.00594337]]\n",
            "Step: 7568 -> Loss: 0.004350208677351475 -> Predictions: [[0.00360836]\n",
            " [0.99610114]\n",
            " [0.99608934]\n",
            " [0.00594333]]\n",
            "Step: 7569 -> Loss: 0.004350189119577408 -> Predictions: [[0.00360835]\n",
            " [0.99610114]\n",
            " [0.99608934]\n",
            " [0.00594331]]\n",
            "Step: 7570 -> Loss: 0.0043501704931259155 -> Predictions: [[0.00360833]\n",
            " [0.99610114]\n",
            " [0.99608934]\n",
            " [0.00594328]]\n",
            "Step: 7571 -> Loss: 0.004350148607045412 -> Predictions: [[0.00360831]\n",
            " [0.99610114]\n",
            " [0.99608934]\n",
            " [0.00594324]]\n",
            "Step: 7572 -> Loss: 0.004350130446255207 -> Predictions: [[0.0036083 ]\n",
            " [0.99610114]\n",
            " [0.99608934]\n",
            " [0.00594322]]\n",
            "Step: 7573 -> Loss: 0.004350109491497278 -> Predictions: [[0.00360828]\n",
            " [0.99610114]\n",
            " [0.99608946]\n",
            " [0.00594319]]\n",
            "Step: 7574 -> Loss: 0.004350089468061924 -> Predictions: [[0.00360827]\n",
            " [0.99610126]\n",
            " [0.99608946]\n",
            " [0.00594316]]\n",
            "Step: 7575 -> Loss: 0.0043500675819814205 -> Predictions: [[0.00360825]\n",
            " [0.99610126]\n",
            " [0.99608946]\n",
            " [0.00594313]]\n",
            "Step: 7576 -> Loss: 0.004350048024207354 -> Predictions: [[0.00360823]\n",
            " [0.99610126]\n",
            " [0.99608946]\n",
            " [0.0059431 ]]\n",
            "Step: 7577 -> Loss: 0.004350027069449425 -> Predictions: [[0.00360821]\n",
            " [0.99610126]\n",
            " [0.99608946]\n",
            " [0.00594307]]\n",
            "Step: 7578 -> Loss: 0.004350007511675358 -> Predictions: [[0.0036082 ]\n",
            " [0.99610126]\n",
            " [0.99608946]\n",
            " [0.00594304]]\n",
            "Step: 7579 -> Loss: 0.004349987022578716 -> Predictions: [[0.00360819]\n",
            " [0.99610126]\n",
            " [0.99608946]\n",
            " [0.00594301]]\n",
            "Step: 7580 -> Loss: 0.004349963739514351 -> Predictions: [[0.00360816]\n",
            " [0.99610126]\n",
            " [0.9960896 ]\n",
            " [0.00594298]]\n",
            "Step: 7581 -> Loss: 0.004349945113062859 -> Predictions: [[0.00360815]\n",
            " [0.9961014 ]\n",
            " [0.9960896 ]\n",
            " [0.00594295]]\n",
            "Step: 7582 -> Loss: 0.004349925555288792 -> Predictions: [[0.00360813]\n",
            " [0.9961014 ]\n",
            " [0.9960896 ]\n",
            " [0.00594292]]\n",
            "Step: 7583 -> Loss: 0.004349905531853437 -> Predictions: [[0.00360812]\n",
            " [0.9961014 ]\n",
            " [0.9960896 ]\n",
            " [0.00594289]]\n",
            "Step: 7584 -> Loss: 0.004349885508418083 -> Predictions: [[0.0036081 ]\n",
            " [0.9961014 ]\n",
            " [0.9960896 ]\n",
            " [0.00594286]]\n",
            "Step: 7585 -> Loss: 0.004349866881966591 -> Predictions: [[0.00360808]\n",
            " [0.9961014 ]\n",
            " [0.9960896 ]\n",
            " [0.00594284]]\n",
            "Step: 7586 -> Loss: 0.004349845927208662 -> Predictions: [[0.00360807]\n",
            " [0.9961014 ]\n",
            " [0.9960897 ]\n",
            " [0.0059428 ]]\n",
            "Step: 7587 -> Loss: 0.004349823109805584 -> Predictions: [[0.00360805]\n",
            " [0.9961014 ]\n",
            " [0.9960897 ]\n",
            " [0.00594277]]\n",
            "Step: 7588 -> Loss: 0.004349804017692804 -> Predictions: [[0.00360803]\n",
            " [0.9961015 ]\n",
            " [0.9960897 ]\n",
            " [0.00594274]]\n",
            "Step: 7589 -> Loss: 0.00434978399425745 -> Predictions: [[0.00360802]\n",
            " [0.9961015 ]\n",
            " [0.9960897 ]\n",
            " [0.00594272]]\n",
            "Step: 7590 -> Loss: 0.004349763970822096 -> Predictions: [[0.003608  ]\n",
            " [0.9961015 ]\n",
            " [0.9960897 ]\n",
            " [0.00594268]]\n",
            "Step: 7591 -> Loss: 0.004349743016064167 -> Predictions: [[0.00360799]\n",
            " [0.9961015 ]\n",
            " [0.9960897 ]\n",
            " [0.00594265]]\n",
            "Step: 7592 -> Loss: 0.004349722992628813 -> Predictions: [[0.00360797]\n",
            " [0.9961015 ]\n",
            " [0.9960897 ]\n",
            " [0.00594262]]\n",
            "Step: 7593 -> Loss: 0.004349703900516033 -> Predictions: [[0.00360796]\n",
            " [0.9961015 ]\n",
            " [0.9960898 ]\n",
            " [0.00594259]]\n",
            "Step: 7594 -> Loss: 0.00434968201443553 -> Predictions: [[0.00360794]\n",
            " [0.9961015 ]\n",
            " [0.9960898 ]\n",
            " [0.00594256]]\n",
            "Step: 7595 -> Loss: 0.004349662456661463 -> Predictions: [[0.00360792]\n",
            " [0.9961016 ]\n",
            " [0.9960898 ]\n",
            " [0.00594253]]\n",
            "Step: 7596 -> Loss: 0.004349642898887396 -> Predictions: [[0.00360791]\n",
            " [0.9961016 ]\n",
            " [0.9960898 ]\n",
            " [0.0059425 ]]\n",
            "Step: 7597 -> Loss: 0.004349622409790754 -> Predictions: [[0.00360789]\n",
            " [0.9961016 ]\n",
            " [0.9960898 ]\n",
            " [0.00594247]]\n",
            "Step: 7598 -> Loss: 0.0043496014550328255 -> Predictions: [[0.00360787]\n",
            " [0.9961016 ]\n",
            " [0.9960898 ]\n",
            " [0.00594244]]\n",
            "Step: 7599 -> Loss: 0.004349580965936184 -> Predictions: [[0.00360785]\n",
            " [0.9961016 ]\n",
            " [0.9960898 ]\n",
            " [0.00594242]]\n",
            "Step: 7600 -> Loss: 0.004349563270807266 -> Predictions: [[0.00360784]\n",
            " [0.9961016 ]\n",
            " [0.99608994]\n",
            " [0.00594239]]\n",
            "Step: 7601 -> Loss: 0.0043495409190654755 -> Predictions: [[0.00360782]\n",
            " [0.9961016 ]\n",
            " [0.99608994]\n",
            " [0.00594235]]\n",
            "Step: 7602 -> Loss: 0.004349522292613983 -> Predictions: [[0.00360781]\n",
            " [0.99610174]\n",
            " [0.99608994]\n",
            " [0.00594233]]\n",
            "Step: 7603 -> Loss: 0.004349501337856054 -> Predictions: [[0.00360779]\n",
            " [0.99610174]\n",
            " [0.99608994]\n",
            " [0.00594229]]\n",
            "Step: 7604 -> Loss: 0.004349479451775551 -> Predictions: [[0.00360778]\n",
            " [0.99610174]\n",
            " [0.99608994]\n",
            " [0.00594226]]\n",
            "Step: 7605 -> Loss: 0.004349459894001484 -> Predictions: [[0.00360776]\n",
            " [0.99610174]\n",
            " [0.99608994]\n",
            " [0.00594223]]\n",
            "Step: 7606 -> Loss: 0.004349439404904842 -> Predictions: [[0.00360774]\n",
            " [0.99610174]\n",
            " [0.99608994]\n",
            " [0.00594221]]\n",
            "Step: 7607 -> Loss: 0.0043494198471307755 -> Predictions: [[0.00360773]\n",
            " [0.99610174]\n",
            " [0.99609   ]\n",
            " [0.00594217]]\n",
            "Step: 7608 -> Loss: 0.0043494002893567085 -> Predictions: [[0.00360771]\n",
            " [0.99610174]\n",
            " [0.99609   ]\n",
            " [0.00594214]]\n",
            "Step: 7609 -> Loss: 0.004349380731582642 -> Predictions: [[0.0036077 ]\n",
            " [0.99610186]\n",
            " [0.99609   ]\n",
            " [0.00594212]]\n",
            "Step: 7610 -> Loss: 0.004349360708147287 -> Predictions: [[0.00360768]\n",
            " [0.99610186]\n",
            " [0.99609   ]\n",
            " [0.00594209]]\n",
            "Step: 7611 -> Loss: 0.004349337890744209 -> Predictions: [[0.00360766]\n",
            " [0.99610186]\n",
            " [0.99609   ]\n",
            " [0.00594206]]\n",
            "Step: 7612 -> Loss: 0.004349317867308855 -> Predictions: [[0.00360765]\n",
            " [0.99610186]\n",
            " [0.99609   ]\n",
            " [0.00594202]]\n",
            "Step: 7613 -> Loss: 0.004349297843873501 -> Predictions: [[0.00360763]\n",
            " [0.99610186]\n",
            " [0.9960901 ]\n",
            " [0.005942  ]]\n",
            "Step: 7614 -> Loss: 0.004349277354776859 -> Predictions: [[0.00360761]\n",
            " [0.99610186]\n",
            " [0.9960901 ]\n",
            " [0.00594197]]\n",
            "Step: 7615 -> Loss: 0.004349255934357643 -> Predictions: [[0.0036076 ]\n",
            " [0.996102  ]\n",
            " [0.9960901 ]\n",
            " [0.00594193]]\n",
            "Step: 7616 -> Loss: 0.004349238239228725 -> Predictions: [[0.00360758]\n",
            " [0.996102  ]\n",
            " [0.9960901 ]\n",
            " [0.00594191]]\n",
            "Step: 7617 -> Loss: 0.004349216353148222 -> Predictions: [[0.00360756]\n",
            " [0.996102  ]\n",
            " [0.9960901 ]\n",
            " [0.00594187]]\n",
            "Step: 7618 -> Loss: 0.004349195398390293 -> Predictions: [[0.00360754]\n",
            " [0.996102  ]\n",
            " [0.9960901 ]\n",
            " [0.00594184]]\n",
            "Step: 7619 -> Loss: 0.004349176771938801 -> Predictions: [[0.00360753]\n",
            " [0.996102  ]\n",
            " [0.9960901 ]\n",
            " [0.00594182]]\n",
            "Step: 7620 -> Loss: 0.004349155351519585 -> Predictions: [[0.00360751]\n",
            " [0.996102  ]\n",
            " [0.99609023]\n",
            " [0.00594179]]\n",
            "Step: 7621 -> Loss: 0.004349134862422943 -> Predictions: [[0.0036075 ]\n",
            " [0.996102  ]\n",
            " [0.99609023]\n",
            " [0.00594176]]\n",
            "Step: 7622 -> Loss: 0.004349114373326302 -> Predictions: [[0.00360748]\n",
            " [0.9961021 ]\n",
            " [0.99609023]\n",
            " [0.00594173]]\n",
            "Step: 7623 -> Loss: 0.004349092952907085 -> Predictions: [[0.00360746]\n",
            " [0.9961021 ]\n",
            " [0.99609023]\n",
            " [0.00594169]]\n",
            "Step: 7624 -> Loss: 0.004349077586084604 -> Predictions: [[0.00360745]\n",
            " [0.9961021 ]\n",
            " [0.99609023]\n",
            " [0.00594167]]\n",
            "Step: 7625 -> Loss: 0.004349054303020239 -> Predictions: [[0.00360743]\n",
            " [0.9961021 ]\n",
            " [0.99609023]\n",
            " [0.00594164]]\n",
            "Step: 7626 -> Loss: 0.004349034279584885 -> Predictions: [[0.00360741]\n",
            " [0.9961021 ]\n",
            " [0.99609023]\n",
            " [0.00594161]]\n",
            "Step: 7627 -> Loss: 0.004349013790488243 -> Predictions: [[0.0036074 ]\n",
            " [0.9961021 ]\n",
            " [0.99609035]\n",
            " [0.00594158]]\n",
            "Step: 7628 -> Loss: 0.0043489933013916016 -> Predictions: [[0.00360738]\n",
            " [0.9961021 ]\n",
            " [0.99609035]\n",
            " [0.00594155]]\n",
            "Step: 7629 -> Loss: 0.00434897281229496 -> Predictions: [[0.00360736]\n",
            " [0.9961022 ]\n",
            " [0.99609035]\n",
            " [0.00594152]]\n",
            "Step: 7630 -> Loss: 0.0043489523231983185 -> Predictions: [[0.00360735]\n",
            " [0.9961022 ]\n",
            " [0.99609035]\n",
            " [0.00594149]]\n",
            "Step: 7631 -> Loss: 0.004348933696746826 -> Predictions: [[0.00360733]\n",
            " [0.9961022 ]\n",
            " [0.99609035]\n",
            " [0.00594146]]\n",
            "Step: 7632 -> Loss: 0.004348911810666323 -> Predictions: [[0.00360732]\n",
            " [0.9961022 ]\n",
            " [0.99609035]\n",
            " [0.00594142]]\n",
            "Step: 7633 -> Loss: 0.0043488917872309685 -> Predictions: [[0.0036073 ]\n",
            " [0.9961022 ]\n",
            " [0.99609035]\n",
            " [0.0059414 ]]\n",
            "Step: 7634 -> Loss: 0.0043488722294569016 -> Predictions: [[0.00360729]\n",
            " [0.9961022 ]\n",
            " [0.9960905 ]\n",
            " [0.00594137]]\n",
            "Step: 7635 -> Loss: 0.004348850809037685 -> Predictions: [[0.00360727]\n",
            " [0.9961022 ]\n",
            " [0.9960905 ]\n",
            " [0.00594134]]\n",
            "Step: 7636 -> Loss: 0.004348833113908768 -> Predictions: [[0.00360726]\n",
            " [0.99610233]\n",
            " [0.9960905 ]\n",
            " [0.00594131]]\n",
            "Step: 7637 -> Loss: 0.00434881029650569 -> Predictions: [[0.00360723]\n",
            " [0.99610233]\n",
            " [0.9960905 ]\n",
            " [0.00594128]]\n",
            "Step: 7638 -> Loss: 0.004348793067038059 -> Predictions: [[0.00360722]\n",
            " [0.99610233]\n",
            " [0.9960905 ]\n",
            " [0.00594125]]\n",
            "Step: 7639 -> Loss: 0.004348771646618843 -> Predictions: [[0.0036072 ]\n",
            " [0.99610233]\n",
            " [0.9960905 ]\n",
            " [0.00594122]]\n",
            "Step: 7640 -> Loss: 0.004348750226199627 -> Predictions: [[0.00360718]\n",
            " [0.99610233]\n",
            " [0.9960905 ]\n",
            " [0.00594119]]\n",
            "Step: 7641 -> Loss: 0.004348731134086847 -> Predictions: [[0.00360717]\n",
            " [0.99610233]\n",
            " [0.9960906 ]\n",
            " [0.00594117]]\n",
            "Step: 7642 -> Loss: 0.004348709713667631 -> Predictions: [[0.00360715]\n",
            " [0.99610233]\n",
            " [0.9960906 ]\n",
            " [0.00594113]]\n",
            "Step: 7643 -> Loss: 0.00434868922457099 -> Predictions: [[0.00360714]\n",
            " [0.99610245]\n",
            " [0.9960906 ]\n",
            " [0.00594109]]\n",
            "Step: 7644 -> Loss: 0.0043486724607646465 -> Predictions: [[0.00360713]\n",
            " [0.99610245]\n",
            " [0.9960906 ]\n",
            " [0.00594107]]\n",
            "Step: 7645 -> Loss: 0.004348650574684143 -> Predictions: [[0.00360711]\n",
            " [0.99610245]\n",
            " [0.9960906 ]\n",
            " [0.00594104]]\n",
            "Step: 7646 -> Loss: 0.0043486300855875015 -> Predictions: [[0.00360709]\n",
            " [0.99610245]\n",
            " [0.9960906 ]\n",
            " [0.00594101]]\n",
            "Step: 7647 -> Loss: 0.004348609130829573 -> Predictions: [[0.00360707]\n",
            " [0.99610245]\n",
            " [0.9960906 ]\n",
            " [0.00594098]]\n",
            "Step: 7648 -> Loss: 0.0043485891073942184 -> Predictions: [[0.00360706]\n",
            " [0.99610245]\n",
            " [0.9960907 ]\n",
            " [0.00594095]]\n",
            "Step: 7649 -> Loss: 0.004348568618297577 -> Predictions: [[0.00360704]\n",
            " [0.99610245]\n",
            " [0.9960907 ]\n",
            " [0.00594093]]\n",
            "Step: 7650 -> Loss: 0.00434854906052351 -> Predictions: [[0.00360702]\n",
            " [0.9961026 ]\n",
            " [0.9960907 ]\n",
            " [0.00594089]]\n",
            "Step: 7651 -> Loss: 0.0043485285714268684 -> Predictions: [[0.00360701]\n",
            " [0.9961026 ]\n",
            " [0.9960907 ]\n",
            " [0.00594087]]\n",
            "Step: 7652 -> Loss: 0.004348507151007652 -> Predictions: [[0.00360699]\n",
            " [0.9961026 ]\n",
            " [0.9960907 ]\n",
            " [0.00594083]]\n",
            "Step: 7653 -> Loss: 0.004348487593233585 -> Predictions: [[0.00360698]\n",
            " [0.9961026 ]\n",
            " [0.9960907 ]\n",
            " [0.0059408 ]]\n",
            "Step: 7654 -> Loss: 0.004348468035459518 -> Predictions: [[0.00360696]\n",
            " [0.9961026 ]\n",
            " [0.9960907 ]\n",
            " [0.00594077]]\n",
            "Step: 7655 -> Loss: 0.004348447546362877 -> Predictions: [[0.00360695]\n",
            " [0.9961026 ]\n",
            " [0.9960908 ]\n",
            " [0.00594075]]\n",
            "Step: 7656 -> Loss: 0.00434842798858881 -> Predictions: [[0.00360693]\n",
            " [0.9961026 ]\n",
            " [0.9960908 ]\n",
            " [0.00594071]]\n",
            "Step: 7657 -> Loss: 0.004348406568169594 -> Predictions: [[0.00360691]\n",
            " [0.9961027 ]\n",
            " [0.9960908 ]\n",
            " [0.00594068]]\n",
            "Step: 7658 -> Loss: 0.004348385147750378 -> Predictions: [[0.00360689]\n",
            " [0.9961027 ]\n",
            " [0.9960908 ]\n",
            " [0.00594065]]\n",
            "Step: 7659 -> Loss: 0.004348366521298885 -> Predictions: [[0.00360688]\n",
            " [0.9961027 ]\n",
            " [0.9960908 ]\n",
            " [0.00594062]]\n",
            "Step: 7660 -> Loss: 0.004348345100879669 -> Predictions: [[0.00360686]\n",
            " [0.9961027 ]\n",
            " [0.9960908 ]\n",
            " [0.0059406 ]]\n",
            "Step: 7661 -> Loss: 0.004348323680460453 -> Predictions: [[0.00360684]\n",
            " [0.9961027 ]\n",
            " [0.99609095]\n",
            " [0.00594057]]\n",
            "Step: 7662 -> Loss: 0.004348307847976685 -> Predictions: [[0.00360683]\n",
            " [0.9961027 ]\n",
            " [0.99609095]\n",
            " [0.00594054]]\n",
            "Step: 7663 -> Loss: 0.004348284564912319 -> Predictions: [[0.00360681]\n",
            " [0.9961028 ]\n",
            " [0.99609095]\n",
            " [0.00594051]]\n",
            "Step: 7664 -> Loss: 0.004348265938460827 -> Predictions: [[0.00360679]\n",
            " [0.9961028 ]\n",
            " [0.99609095]\n",
            " [0.00594048]]\n",
            "Step: 7665 -> Loss: 0.004348244518041611 -> Predictions: [[0.00360679]\n",
            " [0.9961028 ]\n",
            " [0.99609095]\n",
            " [0.00594044]]\n",
            "Step: 7666 -> Loss: 0.004348225425928831 -> Predictions: [[0.00360677]\n",
            " [0.9961028 ]\n",
            " [0.99609095]\n",
            " [0.00594042]]\n",
            "Step: 7667 -> Loss: 0.004348203539848328 -> Predictions: [[0.00360674]\n",
            " [0.9961028 ]\n",
            " [0.99609095]\n",
            " [0.00594039]]\n",
            "Step: 7668 -> Loss: 0.004348184447735548 -> Predictions: [[0.00360673]\n",
            " [0.9961028 ]\n",
            " [0.99609107]\n",
            " [0.00594036]]\n",
            "Step: 7669 -> Loss: 0.004348163492977619 -> Predictions: [[0.00360671]\n",
            " [0.9961028 ]\n",
            " [0.99609107]\n",
            " [0.00594033]]\n",
            "Step: 7670 -> Loss: 0.004348143935203552 -> Predictions: [[0.00360669]\n",
            " [0.9961029 ]\n",
            " [0.99609107]\n",
            " [0.0059403 ]]\n",
            "Step: 7671 -> Loss: 0.0043481201864778996 -> Predictions: [[0.00360668]\n",
            " [0.9961029 ]\n",
            " [0.99609107]\n",
            " [0.00594026]]\n",
            "Step: 7672 -> Loss: 0.004348102957010269 -> Predictions: [[0.00360666]\n",
            " [0.9961029 ]\n",
            " [0.99609107]\n",
            " [0.00594024]]\n",
            "Step: 7673 -> Loss: 0.004348083399236202 -> Predictions: [[0.00360665]\n",
            " [0.9961029 ]\n",
            " [0.99609107]\n",
            " [0.00594021]]\n",
            "Step: 7674 -> Loss: 0.004348062444478273 -> Predictions: [[0.00360664]\n",
            " [0.9961029 ]\n",
            " [0.99609107]\n",
            " [0.00594018]]\n",
            "Step: 7675 -> Loss: 0.004348044283688068 -> Predictions: [[0.00360662]\n",
            " [0.9961029 ]\n",
            " [0.9960912 ]\n",
            " [0.00594015]]\n",
            "Step: 7676 -> Loss: 0.0043480247259140015 -> Predictions: [[0.00360661]\n",
            " [0.9961029 ]\n",
            " [0.9960912 ]\n",
            " [0.00594012]]\n",
            "Step: 7677 -> Loss: 0.0043480005115270615 -> Predictions: [[0.00360658]\n",
            " [0.99610305]\n",
            " [0.9960912 ]\n",
            " [0.00594009]]\n",
            "Step: 7678 -> Loss: 0.004347982816398144 -> Predictions: [[0.00360657]\n",
            " [0.99610305]\n",
            " [0.9960912 ]\n",
            " [0.00594006]]\n",
            "Step: 7679 -> Loss: 0.0043479641899466515 -> Predictions: [[0.00360656]\n",
            " [0.99610305]\n",
            " [0.9960912 ]\n",
            " [0.00594004]]\n",
            "Step: 7680 -> Loss: 0.004347942303866148 -> Predictions: [[0.00360654]\n",
            " [0.99610305]\n",
            " [0.9960912 ]\n",
            " [0.00594   ]]\n",
            "Step: 7681 -> Loss: 0.004347922280430794 -> Predictions: [[0.00360652]\n",
            " [0.99610305]\n",
            " [0.9960912 ]\n",
            " [0.00593997]]\n",
            "Step: 7682 -> Loss: 0.004347900860011578 -> Predictions: [[0.0036065 ]\n",
            " [0.99610305]\n",
            " [0.9960913 ]\n",
            " [0.00593994]]\n",
            "Step: 7683 -> Loss: 0.004347881302237511 -> Predictions: [[0.00360649]\n",
            " [0.99610305]\n",
            " [0.9960913 ]\n",
            " [0.00593991]]\n",
            "Step: 7684 -> Loss: 0.00434785895049572 -> Predictions: [[0.00360647]\n",
            " [0.99610317]\n",
            " [0.9960913 ]\n",
            " [0.00593988]]\n",
            "Step: 7685 -> Loss: 0.004347839392721653 -> Predictions: [[0.00360645]\n",
            " [0.99610317]\n",
            " [0.9960913 ]\n",
            " [0.00593985]]\n",
            "Step: 7686 -> Loss: 0.004347821697592735 -> Predictions: [[0.00360644]\n",
            " [0.99610317]\n",
            " [0.9960913 ]\n",
            " [0.00593982]]\n",
            "Step: 7687 -> Loss: 0.004347797948867083 -> Predictions: [[0.00360642]\n",
            " [0.99610317]\n",
            " [0.9960913 ]\n",
            " [0.00593979]]\n",
            "Step: 7688 -> Loss: 0.004347776994109154 -> Predictions: [[0.00360641]\n",
            " [0.99610317]\n",
            " [0.9960913 ]\n",
            " [0.00593976]]\n",
            "Step: 7689 -> Loss: 0.004347757436335087 -> Predictions: [[0.00360639]\n",
            " [0.99610317]\n",
            " [0.9960914 ]\n",
            " [0.00593973]]\n",
            "Step: 7690 -> Loss: 0.00434773787856102 -> Predictions: [[0.00360637]\n",
            " [0.99610317]\n",
            " [0.9960914 ]\n",
            " [0.00593971]]\n",
            "Step: 7691 -> Loss: 0.004347716923803091 -> Predictions: [[0.00360635]\n",
            " [0.9961033 ]\n",
            " [0.9960914 ]\n",
            " [0.00593967]]\n",
            "Step: 7692 -> Loss: 0.004347696900367737 -> Predictions: [[0.00360634]\n",
            " [0.9961033 ]\n",
            " [0.9960914 ]\n",
            " [0.00593964]]\n",
            "Step: 7693 -> Loss: 0.0043476782739162445 -> Predictions: [[0.00360633]\n",
            " [0.9961033 ]\n",
            " [0.9960914 ]\n",
            " [0.00593961]]\n",
            "Step: 7694 -> Loss: 0.004347655456513166 -> Predictions: [[0.00360631]\n",
            " [0.9961033 ]\n",
            " [0.9960914 ]\n",
            " [0.00593958]]\n",
            "Step: 7695 -> Loss: 0.004347638227045536 -> Predictions: [[0.0036063 ]\n",
            " [0.9961033 ]\n",
            " [0.9960914 ]\n",
            " [0.00593955]]\n",
            "Step: 7696 -> Loss: 0.00434761680662632 -> Predictions: [[0.00360628]\n",
            " [0.9961033 ]\n",
            " [0.99609154]\n",
            " [0.00593952]]\n",
            "Step: 7697 -> Loss: 0.004347594454884529 -> Predictions: [[0.00360625]\n",
            " [0.9961033 ]\n",
            " [0.99609154]\n",
            " [0.00593949]]\n",
            "Step: 7698 -> Loss: 0.004347578156739473 -> Predictions: [[0.00360625]\n",
            " [0.9961034 ]\n",
            " [0.99609154]\n",
            " [0.00593946]]\n",
            "Step: 7699 -> Loss: 0.00434755627065897 -> Predictions: [[0.00360622]\n",
            " [0.9961034 ]\n",
            " [0.99609154]\n",
            " [0.00593943]]\n",
            "Step: 7700 -> Loss: 0.004347536712884903 -> Predictions: [[0.00360621]\n",
            " [0.9961034 ]\n",
            " [0.99609154]\n",
            " [0.0059394 ]]\n",
            "Step: 7701 -> Loss: 0.004347514361143112 -> Predictions: [[0.00360619]\n",
            " [0.9961034 ]\n",
            " [0.99609154]\n",
            " [0.00593937]]\n",
            "Step: 7702 -> Loss: 0.0043474966660141945 -> Predictions: [[0.00360618]\n",
            " [0.9961034 ]\n",
            " [0.99609166]\n",
            " [0.00593935]]\n",
            "Step: 7703 -> Loss: 0.00434747664257884 -> Predictions: [[0.00360616]\n",
            " [0.9961034 ]\n",
            " [0.99609166]\n",
            " [0.00593932]]\n",
            "Step: 7704 -> Loss: 0.004347455687820911 -> Predictions: [[0.00360615]\n",
            " [0.9961035 ]\n",
            " [0.99609166]\n",
            " [0.00593929]]\n",
            "Step: 7705 -> Loss: 0.0043474347330629826 -> Predictions: [[0.00360613]\n",
            " [0.9961035 ]\n",
            " [0.99609166]\n",
            " [0.00593926]]\n",
            "Step: 7706 -> Loss: 0.004347415640950203 -> Predictions: [[0.00360612]\n",
            " [0.9961035 ]\n",
            " [0.99609166]\n",
            " [0.00593923]]\n",
            "Step: 7707 -> Loss: 0.004347393289208412 -> Predictions: [[0.0036061 ]\n",
            " [0.9961035 ]\n",
            " [0.99609166]\n",
            " [0.00593919]]\n",
            "Step: 7708 -> Loss: 0.004347372334450483 -> Predictions: [[0.00360608]\n",
            " [0.9961035 ]\n",
            " [0.99609166]\n",
            " [0.00593916]]\n",
            "Step: 7709 -> Loss: 0.004347354639321566 -> Predictions: [[0.00360607]\n",
            " [0.9961035 ]\n",
            " [0.9960918 ]\n",
            " [0.00593914]]\n",
            "Step: 7710 -> Loss: 0.004347335081547499 -> Predictions: [[0.00360605]\n",
            " [0.9961035 ]\n",
            " [0.9960918 ]\n",
            " [0.00593911]]\n",
            "Step: 7711 -> Loss: 0.004347313195466995 -> Predictions: [[0.00360603]\n",
            " [0.9961035 ]\n",
            " [0.9960918 ]\n",
            " [0.00593908]]\n",
            "Step: 7712 -> Loss: 0.004347294569015503 -> Predictions: [[0.00360601]\n",
            " [0.99610364]\n",
            " [0.9960918 ]\n",
            " [0.00593905]]\n",
            "Step: 7713 -> Loss: 0.004347273148596287 -> Predictions: [[0.003606  ]\n",
            " [0.99610364]\n",
            " [0.9960918 ]\n",
            " [0.00593901]]\n",
            "Step: 7714 -> Loss: 0.004347251728177071 -> Predictions: [[0.00360598]\n",
            " [0.99610364]\n",
            " [0.9960918 ]\n",
            " [0.00593899]]\n",
            "Step: 7715 -> Loss: 0.00434723449870944 -> Predictions: [[0.00360597]\n",
            " [0.99610364]\n",
            " [0.9960918 ]\n",
            " [0.00593896]]\n",
            "Step: 7716 -> Loss: 0.0043472121469676495 -> Predictions: [[0.00360595]\n",
            " [0.99610364]\n",
            " [0.9960919 ]\n",
            " [0.00593892]]\n",
            "Step: 7717 -> Loss: 0.0043471925891935825 -> Predictions: [[0.00360593]\n",
            " [0.99610364]\n",
            " [0.9960919 ]\n",
            " [0.0059389 ]]\n",
            "Step: 7718 -> Loss: 0.004347173031419516 -> Predictions: [[0.00360592]\n",
            " [0.99610376]\n",
            " [0.9960919 ]\n",
            " [0.00593887]]\n",
            "Step: 7719 -> Loss: 0.004347152542322874 -> Predictions: [[0.00360591]\n",
            " [0.99610376]\n",
            " [0.9960919 ]\n",
            " [0.00593884]]\n",
            "Step: 7720 -> Loss: 0.0043471320532262325 -> Predictions: [[0.00360589]\n",
            " [0.99610376]\n",
            " [0.9960919 ]\n",
            " [0.00593881]]\n",
            "Step: 7721 -> Loss: 0.004347112029790878 -> Predictions: [[0.00360587]\n",
            " [0.99610376]\n",
            " [0.9960919 ]\n",
            " [0.00593878]]\n",
            "Step: 7722 -> Loss: 0.004347090143710375 -> Predictions: [[0.00360585]\n",
            " [0.99610376]\n",
            " [0.9960919 ]\n",
            " [0.00593875]]\n",
            "Step: 7723 -> Loss: 0.004347070120275021 -> Predictions: [[0.00360584]\n",
            " [0.99610376]\n",
            " [0.996092  ]\n",
            " [0.00593872]]\n",
            "Step: 7724 -> Loss: 0.004347050562500954 -> Predictions: [[0.00360582]\n",
            " [0.99610376]\n",
            " [0.996092  ]\n",
            " [0.00593869]]\n",
            "Step: 7725 -> Loss: 0.004347029607743025 -> Predictions: [[0.00360581]\n",
            " [0.9961039 ]\n",
            " [0.996092  ]\n",
            " [0.00593866]]\n",
            "Step: 7726 -> Loss: 0.004347009118646383 -> Predictions: [[0.00360578]\n",
            " [0.9961039 ]\n",
            " [0.996092  ]\n",
            " [0.00593863]]\n",
            "Step: 7727 -> Loss: 0.004346990026533604 -> Predictions: [[0.00360577]\n",
            " [0.9961039 ]\n",
            " [0.996092  ]\n",
            " [0.0059386 ]]\n",
            "Step: 7728 -> Loss: 0.004346969537436962 -> Predictions: [[0.00360576]\n",
            " [0.9961039 ]\n",
            " [0.996092  ]\n",
            " [0.00593857]]\n",
            "Step: 7729 -> Loss: 0.004346949979662895 -> Predictions: [[0.00360574]\n",
            " [0.9961039 ]\n",
            " [0.996092  ]\n",
            " [0.00593854]]\n",
            "Step: 7730 -> Loss: 0.004346928559243679 -> Predictions: [[0.00360572]\n",
            " [0.9961039 ]\n",
            " [0.99609214]\n",
            " [0.00593851]]\n",
            "Step: 7731 -> Loss: 0.00434690760448575 -> Predictions: [[0.0036057 ]\n",
            " [0.9961039 ]\n",
            " [0.99609214]\n",
            " [0.00593848]]\n",
            "Step: 7732 -> Loss: 0.0043468899093568325 -> Predictions: [[0.00360569]\n",
            " [0.996104  ]\n",
            " [0.99609214]\n",
            " [0.00593845]]\n",
            "Step: 7733 -> Loss: 0.004346868023276329 -> Predictions: [[0.00360568]\n",
            " [0.996104  ]\n",
            " [0.99609214]\n",
            " [0.00593842]]\n",
            "Step: 7734 -> Loss: 0.0043468470685184 -> Predictions: [[0.00360566]\n",
            " [0.996104  ]\n",
            " [0.99609214]\n",
            " [0.00593839]]\n",
            "Step: 7735 -> Loss: 0.004346828907728195 -> Predictions: [[0.00360564]\n",
            " [0.996104  ]\n",
            " [0.99609214]\n",
            " [0.00593837]]\n",
            "Step: 7736 -> Loss: 0.004346804227679968 -> Predictions: [[0.00360562]\n",
            " [0.996104  ]\n",
            " [0.99609214]\n",
            " [0.00593833]]\n",
            "Step: 7737 -> Loss: 0.004346785135567188 -> Predictions: [[0.00360561]\n",
            " [0.996104  ]\n",
            " [0.99609226]\n",
            " [0.0059383 ]]\n",
            "Step: 7738 -> Loss: 0.004346767440438271 -> Predictions: [[0.00360559]\n",
            " [0.996104  ]\n",
            " [0.99609226]\n",
            " [0.00593827]]\n",
            "Step: 7739 -> Loss: 0.004346746485680342 -> Predictions: [[0.00360558]\n",
            " [0.9961041 ]\n",
            " [0.99609226]\n",
            " [0.00593824]]\n",
            "Step: 7740 -> Loss: 0.004346726927906275 -> Predictions: [[0.00360556]\n",
            " [0.9961041 ]\n",
            " [0.99609226]\n",
            " [0.00593822]]\n",
            "Step: 7741 -> Loss: 0.004346705041825771 -> Predictions: [[0.00360554]\n",
            " [0.9961041 ]\n",
            " [0.99609226]\n",
            " [0.00593818]]\n",
            "Step: 7742 -> Loss: 0.004346685484051704 -> Predictions: [[0.00360552]\n",
            " [0.9961041 ]\n",
            " [0.99609226]\n",
            " [0.00593816]]\n",
            "Step: 7743 -> Loss: 0.0043466645292937756 -> Predictions: [[0.0036055 ]\n",
            " [0.9961041 ]\n",
            " [0.99609226]\n",
            " [0.00593812]]\n",
            "Step: 7744 -> Loss: 0.004346645437180996 -> Predictions: [[0.00360549]\n",
            " [0.9961041 ]\n",
            " [0.9960924 ]\n",
            " [0.0059381 ]]\n",
            "Step: 7745 -> Loss: 0.004346624482423067 -> Predictions: [[0.00360548]\n",
            " [0.9961041 ]\n",
            " [0.9960924 ]\n",
            " [0.00593806]]\n",
            "Step: 7746 -> Loss: 0.004346603527665138 -> Predictions: [[0.00360546]\n",
            " [0.99610424]\n",
            " [0.9960924 ]\n",
            " [0.00593803]]\n",
            "Step: 7747 -> Loss: 0.004346583504229784 -> Predictions: [[0.00360544]\n",
            " [0.99610424]\n",
            " [0.9960924 ]\n",
            " [0.00593801]]\n",
            "Step: 7748 -> Loss: 0.004346564412117004 -> Predictions: [[0.00360543]\n",
            " [0.99610424]\n",
            " [0.9960924 ]\n",
            " [0.00593797]]\n",
            "Step: 7749 -> Loss: 0.004346542991697788 -> Predictions: [[0.00360541]\n",
            " [0.99610424]\n",
            " [0.9960924 ]\n",
            " [0.00593795]]\n",
            "Step: 7750 -> Loss: 0.004346523433923721 -> Predictions: [[0.0036054 ]\n",
            " [0.99610424]\n",
            " [0.9960925 ]\n",
            " [0.00593792]]\n",
            "Step: 7751 -> Loss: 0.00434650294482708 -> Predictions: [[0.00360538]\n",
            " [0.99610424]\n",
            " [0.9960925 ]\n",
            " [0.00593789]]\n",
            "Step: 7752 -> Loss: 0.004346480593085289 -> Predictions: [[0.00360536]\n",
            " [0.99610436]\n",
            " [0.9960925 ]\n",
            " [0.00593785]]\n",
            "Step: 7753 -> Loss: 0.004346461500972509 -> Predictions: [[0.00360534]\n",
            " [0.99610436]\n",
            " [0.9960925 ]\n",
            " [0.00593783]]\n",
            "Step: 7754 -> Loss: 0.004346442874521017 -> Predictions: [[0.00360533]\n",
            " [0.99610436]\n",
            " [0.9960925 ]\n",
            " [0.0059378 ]]\n",
            "Step: 7755 -> Loss: 0.004346422851085663 -> Predictions: [[0.00360531]\n",
            " [0.99610436]\n",
            " [0.9960925 ]\n",
            " [0.00593777]]\n",
            "Step: 7756 -> Loss: 0.004346400499343872 -> Predictions: [[0.00360529]\n",
            " [0.99610436]\n",
            " [0.9960925 ]\n",
            " [0.00593774]]\n",
            "Step: 7757 -> Loss: 0.004346382804214954 -> Predictions: [[0.00360528]\n",
            " [0.99610436]\n",
            " [0.9960926 ]\n",
            " [0.00593771]]\n",
            "Step: 7758 -> Loss: 0.004346360918134451 -> Predictions: [[0.00360526]\n",
            " [0.99610436]\n",
            " [0.9960926 ]\n",
            " [0.00593768]]\n",
            "Step: 7759 -> Loss: 0.004346341360360384 -> Predictions: [[0.00360525]\n",
            " [0.9961045 ]\n",
            " [0.9960926 ]\n",
            " [0.00593765]]\n",
            "Step: 7760 -> Loss: 0.0043463194742798805 -> Predictions: [[0.00360523]\n",
            " [0.9961045 ]\n",
            " [0.9960926 ]\n",
            " [0.00593762]]\n",
            "Step: 7761 -> Loss: 0.004346301779150963 -> Predictions: [[0.00360521]\n",
            " [0.9961045 ]\n",
            " [0.9960926 ]\n",
            " [0.00593759]]\n",
            "Step: 7762 -> Loss: 0.004346282221376896 -> Predictions: [[0.0036052 ]\n",
            " [0.9961045 ]\n",
            " [0.9960926 ]\n",
            " [0.00593756]]\n",
            "Step: 7763 -> Loss: 0.00434626080095768 -> Predictions: [[0.00360519]\n",
            " [0.9961045 ]\n",
            " [0.9960926 ]\n",
            " [0.00593752]]\n",
            "Step: 7764 -> Loss: 0.004346238449215889 -> Predictions: [[0.00360517]\n",
            " [0.9961045 ]\n",
            " [0.99609274]\n",
            " [0.0059375 ]]\n",
            "Step: 7765 -> Loss: 0.004346219822764397 -> Predictions: [[0.00360515]\n",
            " [0.9961045 ]\n",
            " [0.99609274]\n",
            " [0.00593747]]\n",
            "Step: 7766 -> Loss: 0.00434620026499033 -> Predictions: [[0.00360514]\n",
            " [0.9961046 ]\n",
            " [0.99609274]\n",
            " [0.00593744]]\n",
            "Step: 7767 -> Loss: 0.004346179775893688 -> Predictions: [[0.00360512]\n",
            " [0.9961046 ]\n",
            " [0.99609274]\n",
            " [0.00593741]]\n",
            "Step: 7768 -> Loss: 0.004346159286797047 -> Predictions: [[0.0036051 ]\n",
            " [0.9961046 ]\n",
            " [0.99609274]\n",
            " [0.00593738]]\n",
            "Step: 7769 -> Loss: 0.004346138797700405 -> Predictions: [[0.00360509]\n",
            " [0.9961046 ]\n",
            " [0.99609274]\n",
            " [0.00593735]]\n",
            "Step: 7770 -> Loss: 0.004346119239926338 -> Predictions: [[0.00360507]\n",
            " [0.9961046 ]\n",
            " [0.99609274]\n",
            " [0.00593732]]\n",
            "Step: 7771 -> Loss: 0.004346097819507122 -> Predictions: [[0.00360505]\n",
            " [0.9961046 ]\n",
            " [0.99609286]\n",
            " [0.00593729]]\n",
            "Step: 7772 -> Loss: 0.00434607919305563 -> Predictions: [[0.00360504]\n",
            " [0.9961046 ]\n",
            " [0.99609286]\n",
            " [0.00593726]]\n",
            "Step: 7773 -> Loss: 0.004346056841313839 -> Predictions: [[0.00360502]\n",
            " [0.9961047 ]\n",
            " [0.99609286]\n",
            " [0.00593723]]\n",
            "Step: 7774 -> Loss: 0.004346037749201059 -> Predictions: [[0.003605  ]\n",
            " [0.9961047 ]\n",
            " [0.99609286]\n",
            " [0.0059372 ]]\n",
            "Step: 7775 -> Loss: 0.004346014931797981 -> Predictions: [[0.00360498]\n",
            " [0.9961047 ]\n",
            " [0.99609286]\n",
            " [0.00593717]]\n",
            "Step: 7776 -> Loss: 0.00434599444270134 -> Predictions: [[0.00360497]\n",
            " [0.9961047 ]\n",
            " [0.99609286]\n",
            " [0.00593714]]\n",
            "Step: 7777 -> Loss: 0.004345977678894997 -> Predictions: [[0.00360496]\n",
            " [0.9961047 ]\n",
            " [0.99609286]\n",
            " [0.00593711]]\n",
            "Step: 7778 -> Loss: 0.004345955792814493 -> Predictions: [[0.00360494]\n",
            " [0.9961047 ]\n",
            " [0.996093  ]\n",
            " [0.00593708]]\n",
            "Step: 7779 -> Loss: 0.004345935769379139 -> Predictions: [[0.00360492]\n",
            " [0.9961047 ]\n",
            " [0.996093  ]\n",
            " [0.00593705]]\n",
            "Step: 7780 -> Loss: 0.004345915745943785 -> Predictions: [[0.0036049 ]\n",
            " [0.99610484]\n",
            " [0.996093  ]\n",
            " [0.00593702]]\n",
            "Step: 7781 -> Loss: 0.004345896188169718 -> Predictions: [[0.00360489]\n",
            " [0.99610484]\n",
            " [0.996093  ]\n",
            " [0.00593699]]\n",
            "Step: 7782 -> Loss: 0.0043458761647343636 -> Predictions: [[0.00360488]\n",
            " [0.99610484]\n",
            " [0.996093  ]\n",
            " [0.00593696]]\n",
            "Step: 7783 -> Loss: 0.004345855675637722 -> Predictions: [[0.00360486]\n",
            " [0.99610484]\n",
            " [0.996093  ]\n",
            " [0.00593693]]\n",
            "Step: 7784 -> Loss: 0.0043458351865410805 -> Predictions: [[0.00360484]\n",
            " [0.99610484]\n",
            " [0.996093  ]\n",
            " [0.00593691]]\n",
            "Step: 7785 -> Loss: 0.004345813766121864 -> Predictions: [[0.00360482]\n",
            " [0.99610484]\n",
            " [0.9960931 ]\n",
            " [0.00593687]]\n",
            "Step: 7786 -> Loss: 0.004345794208347797 -> Predictions: [[0.00360481]\n",
            " [0.99610484]\n",
            " [0.9960931 ]\n",
            " [0.00593684]]\n",
            "Step: 7787 -> Loss: 0.0043457732535898685 -> Predictions: [[0.00360479]\n",
            " [0.99610496]\n",
            " [0.9960931 ]\n",
            " [0.00593681]]\n",
            "Step: 7788 -> Loss: 0.004345756024122238 -> Predictions: [[0.00360478]\n",
            " [0.99610496]\n",
            " [0.9960931 ]\n",
            " [0.00593679]]\n",
            "Step: 7789 -> Loss: 0.00434573320671916 -> Predictions: [[0.00360476]\n",
            " [0.99610496]\n",
            " [0.9960931 ]\n",
            " [0.00593675]]\n",
            "Step: 7790 -> Loss: 0.004345713183283806 -> Predictions: [[0.00360474]\n",
            " [0.99610496]\n",
            " [0.9960931 ]\n",
            " [0.00593673]]\n",
            "Step: 7791 -> Loss: 0.004345693159848452 -> Predictions: [[0.00360472]\n",
            " [0.99610496]\n",
            " [0.9960932 ]\n",
            " [0.00593669]]\n",
            "Step: 7792 -> Loss: 0.004345673136413097 -> Predictions: [[0.00360471]\n",
            " [0.99610496]\n",
            " [0.9960932 ]\n",
            " [0.00593667]]\n",
            "Step: 7793 -> Loss: 0.004345653112977743 -> Predictions: [[0.0036047 ]\n",
            " [0.99610496]\n",
            " [0.9960932 ]\n",
            " [0.00593664]]\n",
            "Step: 7794 -> Loss: 0.004345631692558527 -> Predictions: [[0.00360467]\n",
            " [0.9961051 ]\n",
            " [0.9960932 ]\n",
            " [0.00593661]]\n",
            "Step: 7795 -> Loss: 0.004345612600445747 -> Predictions: [[0.00360466]\n",
            " [0.9961051 ]\n",
            " [0.9960932 ]\n",
            " [0.00593658]]\n",
            "Step: 7796 -> Loss: 0.004345592111349106 -> Predictions: [[0.00360464]\n",
            " [0.9961051 ]\n",
            " [0.9960932 ]\n",
            " [0.00593655]]\n",
            "Step: 7797 -> Loss: 0.004345572087913752 -> Predictions: [[0.00360463]\n",
            " [0.9961051 ]\n",
            " [0.9960932 ]\n",
            " [0.00593652]]\n",
            "Step: 7798 -> Loss: 0.0043455506674945354 -> Predictions: [[0.00360461]\n",
            " [0.9961051 ]\n",
            " [0.99609333]\n",
            " [0.00593648]]\n",
            "Step: 7799 -> Loss: 0.0043455311097204685 -> Predictions: [[0.00360459]\n",
            " [0.9961051 ]\n",
            " [0.99609333]\n",
            " [0.00593646]]\n",
            "Step: 7800 -> Loss: 0.004345509689301252 -> Predictions: [[0.00360458]\n",
            " [0.9961052 ]\n",
            " [0.99609333]\n",
            " [0.00593642]]\n",
            "Step: 7801 -> Loss: 0.004345490597188473 -> Predictions: [[0.00360456]\n",
            " [0.9961052 ]\n",
            " [0.99609333]\n",
            " [0.0059364 ]]\n",
            "Step: 7802 -> Loss: 0.004345469642430544 -> Predictions: [[0.00360454]\n",
            " [0.9961052 ]\n",
            " [0.99609333]\n",
            " [0.00593637]]\n",
            "Step: 7803 -> Loss: 0.004345450550317764 -> Predictions: [[0.00360453]\n",
            " [0.9961052 ]\n",
            " [0.99609333]\n",
            " [0.00593634]]\n",
            "Step: 7804 -> Loss: 0.004345429129898548 -> Predictions: [[0.00360451]\n",
            " [0.9961052 ]\n",
            " [0.99609333]\n",
            " [0.00593631]]\n",
            "Step: 7805 -> Loss: 0.0043454100377857685 -> Predictions: [[0.0036045 ]\n",
            " [0.9961052 ]\n",
            " [0.99609345]\n",
            " [0.00593628]]\n",
            "Step: 7806 -> Loss: 0.004345388151705265 -> Predictions: [[0.00360448]\n",
            " [0.9961052 ]\n",
            " [0.99609345]\n",
            " [0.00593625]]\n",
            "Step: 7807 -> Loss: 0.004345371387898922 -> Predictions: [[0.00360447]\n",
            " [0.9961052 ]\n",
            " [0.99609345]\n",
            " [0.00593622]]\n",
            "Step: 7808 -> Loss: 0.004345351364463568 -> Predictions: [[0.00360445]\n",
            " [0.99610525]\n",
            " [0.99609345]\n",
            " [0.00593619]]\n",
            "Step: 7809 -> Loss: 0.004345332272350788 -> Predictions: [[0.00360444]\n",
            " [0.99610525]\n",
            " [0.99609345]\n",
            " [0.00593616]]\n",
            "Step: 7810 -> Loss: 0.004345310851931572 -> Predictions: [[0.00360442]\n",
            " [0.99610525]\n",
            " [0.99609345]\n",
            " [0.00593613]]\n",
            "Step: 7811 -> Loss: 0.004345286171883345 -> Predictions: [[0.0036044 ]\n",
            " [0.99610525]\n",
            " [0.99609345]\n",
            " [0.0059361 ]]\n",
            "Step: 7812 -> Loss: 0.004345270339399576 -> Predictions: [[0.00360439]\n",
            " [0.99610525]\n",
            " [0.9960936 ]\n",
            " [0.00593607]]\n",
            "Step: 7813 -> Loss: 0.004345249384641647 -> Predictions: [[0.00360437]\n",
            " [0.99610525]\n",
            " [0.9960936 ]\n",
            " [0.00593604]]\n",
            "Step: 7814 -> Loss: 0.004345227964222431 -> Predictions: [[0.00360435]\n",
            " [0.9961054 ]\n",
            " [0.9960936 ]\n",
            " [0.00593601]]\n",
            "Step: 7815 -> Loss: 0.00434520747512579 -> Predictions: [[0.00360433]\n",
            " [0.9961054 ]\n",
            " [0.9960936 ]\n",
            " [0.00593598]]\n",
            "Step: 7816 -> Loss: 0.004345189779996872 -> Predictions: [[0.00360432]\n",
            " [0.9961054 ]\n",
            " [0.9960936 ]\n",
            " [0.00593595]]\n",
            "Step: 7817 -> Loss: 0.004345168825238943 -> Predictions: [[0.00360431]\n",
            " [0.9961054 ]\n",
            " [0.9960936 ]\n",
            " [0.00593592]]\n",
            "Step: 7818 -> Loss: 0.004345147404819727 -> Predictions: [[0.00360428]\n",
            " [0.9961054 ]\n",
            " [0.9960936 ]\n",
            " [0.00593589]]\n",
            "Step: 7819 -> Loss: 0.004345126450061798 -> Predictions: [[0.00360427]\n",
            " [0.9961054 ]\n",
            " [0.9960937 ]\n",
            " [0.00593587]]\n",
            "Step: 7820 -> Loss: 0.0043451059609651566 -> Predictions: [[0.00360426]\n",
            " [0.9961054 ]\n",
            " [0.9960937 ]\n",
            " [0.00593583]]\n",
            "Step: 7821 -> Loss: 0.004345088731497526 -> Predictions: [[0.00360424]\n",
            " [0.9961055 ]\n",
            " [0.9960937 ]\n",
            " [0.00593581]]\n",
            "Step: 7822 -> Loss: 0.004345067776739597 -> Predictions: [[0.00360423]\n",
            " [0.9961055 ]\n",
            " [0.9960937 ]\n",
            " [0.00593577]]\n",
            "Step: 7823 -> Loss: 0.004345042631030083 -> Predictions: [[0.0036042 ]\n",
            " [0.9961055 ]\n",
            " [0.9960937 ]\n",
            " [0.00593574]]\n",
            "Step: 7824 -> Loss: 0.004345024470239878 -> Predictions: [[0.00360419]\n",
            " [0.9961055 ]\n",
            " [0.9960937 ]\n",
            " [0.00593571]]\n",
            "Step: 7825 -> Loss: 0.0043450030498206615 -> Predictions: [[0.00360417]\n",
            " [0.9961055 ]\n",
            " [0.9960938 ]\n",
            " [0.00593569]]\n",
            "Step: 7826 -> Loss: 0.004344985354691744 -> Predictions: [[0.00360416]\n",
            " [0.9961055 ]\n",
            " [0.9960938 ]\n",
            " [0.00593565]]\n",
            "Step: 7827 -> Loss: 0.004344964399933815 -> Predictions: [[0.00360414]\n",
            " [0.9961055 ]\n",
            " [0.9960938 ]\n",
            " [0.00593562]]\n",
            "Step: 7828 -> Loss: 0.004344945307821035 -> Predictions: [[0.00360412]\n",
            " [0.9961056 ]\n",
            " [0.9960938 ]\n",
            " [0.0059356 ]]\n",
            "Step: 7829 -> Loss: 0.004344925284385681 -> Predictions: [[0.00360411]\n",
            " [0.9961056 ]\n",
            " [0.9960938 ]\n",
            " [0.00593556]]\n",
            "Step: 7830 -> Loss: 0.004344905260950327 -> Predictions: [[0.00360409]\n",
            " [0.9961056 ]\n",
            " [0.9960938 ]\n",
            " [0.00593554]]\n",
            "Step: 7831 -> Loss: 0.0043448833748698235 -> Predictions: [[0.00360407]\n",
            " [0.9961056 ]\n",
            " [0.9960938 ]\n",
            " [0.00593551]]\n",
            "Step: 7832 -> Loss: 0.004344864748418331 -> Predictions: [[0.00360406]\n",
            " [0.9961056 ]\n",
            " [0.9960939 ]\n",
            " [0.00593548]]\n",
            "Step: 7833 -> Loss: 0.0043448456563055515 -> Predictions: [[0.00360404]\n",
            " [0.9961056 ]\n",
            " [0.9960939 ]\n",
            " [0.00593545]]\n",
            "Step: 7834 -> Loss: 0.004344822373241186 -> Predictions: [[0.00360402]\n",
            " [0.9961056 ]\n",
            " [0.9960939 ]\n",
            " [0.00593542]]\n",
            "Step: 7835 -> Loss: 0.0043448032811284065 -> Predictions: [[0.00360401]\n",
            " [0.99610573]\n",
            " [0.9960939 ]\n",
            " [0.00593539]]\n",
            "Step: 7836 -> Loss: 0.004344782326370478 -> Predictions: [[0.003604  ]\n",
            " [0.99610573]\n",
            " [0.9960939 ]\n",
            " [0.00593536]]\n",
            "Step: 7837 -> Loss: 0.0043447609059512615 -> Predictions: [[0.00360397]\n",
            " [0.99610573]\n",
            " [0.9960939 ]\n",
            " [0.00593533]]\n",
            "Step: 7838 -> Loss: 0.0043447427451610565 -> Predictions: [[0.00360396]\n",
            " [0.99610573]\n",
            " [0.9960939 ]\n",
            " [0.0059353 ]]\n",
            "Step: 7839 -> Loss: 0.004344722721725702 -> Predictions: [[0.00360395]\n",
            " [0.99610573]\n",
            " [0.99609405]\n",
            " [0.00593527]]\n",
            "Step: 7840 -> Loss: 0.004344702698290348 -> Predictions: [[0.00360393]\n",
            " [0.99610573]\n",
            " [0.99609405]\n",
            " [0.00593524]]\n",
            "Step: 7841 -> Loss: 0.0043446822091937065 -> Predictions: [[0.00360391]\n",
            " [0.99610573]\n",
            " [0.99609405]\n",
            " [0.00593521]]\n",
            "Step: 7842 -> Loss: 0.004344661254435778 -> Predictions: [[0.00360389]\n",
            " [0.99610585]\n",
            " [0.99609405]\n",
            " [0.00593518]]\n",
            "Step: 7843 -> Loss: 0.004344641231000423 -> Predictions: [[0.00360388]\n",
            " [0.99610585]\n",
            " [0.99609405]\n",
            " [0.00593514]]\n",
            "Step: 7844 -> Loss: 0.004344621207565069 -> Predictions: [[0.00360386]\n",
            " [0.99610585]\n",
            " [0.99609405]\n",
            " [0.00593512]]\n",
            "Step: 7845 -> Loss: 0.004344599321484566 -> Predictions: [[0.00360384]\n",
            " [0.99610585]\n",
            " [0.99609405]\n",
            " [0.00593509]]\n",
            "Step: 7846 -> Loss: 0.004344579763710499 -> Predictions: [[0.00360383]\n",
            " [0.99610585]\n",
            " [0.99609417]\n",
            " [0.00593506]]\n",
            "Step: 7847 -> Loss: 0.0043445611372590065 -> Predictions: [[0.00360382]\n",
            " [0.99610585]\n",
            " [0.99609417]\n",
            " [0.00593503]]\n",
            "Step: 7848 -> Loss: 0.004344538319855928 -> Predictions: [[0.00360379]\n",
            " [0.99610585]\n",
            " [0.99609417]\n",
            " [0.005935  ]]\n",
            "Step: 7849 -> Loss: 0.004344517830759287 -> Predictions: [[0.00360378]\n",
            " [0.99610597]\n",
            " [0.99609417]\n",
            " [0.00593497]]\n",
            "Step: 7850 -> Loss: 0.0043445006012916565 -> Predictions: [[0.00360377]\n",
            " [0.99610597]\n",
            " [0.99609417]\n",
            " [0.00593494]]\n",
            "Step: 7851 -> Loss: 0.004344481974840164 -> Predictions: [[0.00360375]\n",
            " [0.99610597]\n",
            " [0.99609417]\n",
            " [0.00593491]]\n",
            "Step: 7852 -> Loss: 0.004344460088759661 -> Predictions: [[0.00360374]\n",
            " [0.99610597]\n",
            " [0.99609417]\n",
            " [0.00593488]]\n",
            "Step: 7853 -> Loss: 0.0043444400653243065 -> Predictions: [[0.00360372]\n",
            " [0.99610597]\n",
            " [0.9960943 ]\n",
            " [0.00593485]]\n",
            "Step: 7854 -> Loss: 0.00434441864490509 -> Predictions: [[0.0036037 ]\n",
            " [0.99610597]\n",
            " [0.9960943 ]\n",
            " [0.00593482]]\n",
            "Step: 7855 -> Loss: 0.004344399087131023 -> Predictions: [[0.00360369]\n",
            " [0.99610597]\n",
            " [0.9960943 ]\n",
            " [0.00593479]]\n",
            "Step: 7856 -> Loss: 0.0043443795293569565 -> Predictions: [[0.00360367]\n",
            " [0.9961061 ]\n",
            " [0.9960943 ]\n",
            " [0.00593476]]\n",
            "Step: 7857 -> Loss: 0.004344356711953878 -> Predictions: [[0.00360365]\n",
            " [0.9961061 ]\n",
            " [0.9960943 ]\n",
            " [0.00593473]]\n",
            "Step: 7858 -> Loss: 0.004344337619841099 -> Predictions: [[0.00360364]\n",
            " [0.9961061 ]\n",
            " [0.9960943 ]\n",
            " [0.0059347 ]]\n",
            "Step: 7859 -> Loss: 0.004344319924712181 -> Predictions: [[0.00360362]\n",
            " [0.9961061 ]\n",
            " [0.9960943 ]\n",
            " [0.00593467]]\n",
            "Step: 7860 -> Loss: 0.00434429757297039 -> Predictions: [[0.0036036 ]\n",
            " [0.9961061 ]\n",
            " [0.9960944 ]\n",
            " [0.00593464]]\n",
            "Step: 7861 -> Loss: 0.004344278015196323 -> Predictions: [[0.00360359]\n",
            " [0.9961061 ]\n",
            " [0.9960944 ]\n",
            " [0.00593461]]\n",
            "Step: 7862 -> Loss: 0.004344258923083544 -> Predictions: [[0.00360357]\n",
            " [0.9961062 ]\n",
            " [0.9960944 ]\n",
            " [0.00593459]]\n",
            "Step: 7863 -> Loss: 0.00434423703700304 -> Predictions: [[0.00360356]\n",
            " [0.9961062 ]\n",
            " [0.9960944 ]\n",
            " [0.00593455]]\n",
            "Step: 7864 -> Loss: 0.004344216547906399 -> Predictions: [[0.00360354]\n",
            " [0.9961062 ]\n",
            " [0.9960944 ]\n",
            " [0.00593452]]\n",
            "Step: 7865 -> Loss: 0.0043441965244710445 -> Predictions: [[0.00360352]\n",
            " [0.9961062 ]\n",
            " [0.9960944 ]\n",
            " [0.00593449]]\n",
            "Step: 7866 -> Loss: 0.004344175569713116 -> Predictions: [[0.0036035 ]\n",
            " [0.9961062 ]\n",
            " [0.9960944 ]\n",
            " [0.00593447]]\n",
            "Step: 7867 -> Loss: 0.004344155080616474 -> Predictions: [[0.00360349]\n",
            " [0.9961062 ]\n",
            " [0.9960945 ]\n",
            " [0.00593443]]\n",
            "Step: 7868 -> Loss: 0.0043441359885036945 -> Predictions: [[0.00360347]\n",
            " [0.9961062 ]\n",
            " [0.9960945 ]\n",
            " [0.0059344 ]]\n",
            "Step: 7869 -> Loss: 0.004344114102423191 -> Predictions: [[0.00360346]\n",
            " [0.9961063 ]\n",
            " [0.9960945 ]\n",
            " [0.00593437]]\n",
            "Step: 7870 -> Loss: 0.004344098269939423 -> Predictions: [[0.00360344]\n",
            " [0.9961063 ]\n",
            " [0.9960945 ]\n",
            " [0.00593435]]\n",
            "Step: 7871 -> Loss: 0.004344073589891195 -> Predictions: [[0.00360342]\n",
            " [0.9961063 ]\n",
            " [0.9960945 ]\n",
            " [0.00593432]]\n",
            "Step: 7872 -> Loss: 0.004344056360423565 -> Predictions: [[0.00360341]\n",
            " [0.9961063 ]\n",
            " [0.9960945 ]\n",
            " [0.00593429]]\n",
            "Step: 7873 -> Loss: 0.004344034940004349 -> Predictions: [[0.00360339]\n",
            " [0.9961063 ]\n",
            " [0.9960945 ]\n",
            " [0.00593426]]\n",
            "Step: 7874 -> Loss: 0.004344013519585133 -> Predictions: [[0.00360338]\n",
            " [0.9961063 ]\n",
            " [0.99609464]\n",
            " [0.00593422]]\n",
            "Step: 7875 -> Loss: 0.0043439967557787895 -> Predictions: [[0.00360336]\n",
            " [0.9961063 ]\n",
            " [0.99609464]\n",
            " [0.0059342 ]]\n",
            "Step: 7876 -> Loss: 0.0043439725413918495 -> Predictions: [[0.00360334]\n",
            " [0.99610645]\n",
            " [0.99609464]\n",
            " [0.00593417]]\n",
            "Step: 7877 -> Loss: 0.004343952983617783 -> Predictions: [[0.00360333]\n",
            " [0.99610645]\n",
            " [0.99609464]\n",
            " [0.00593413]]\n",
            "Step: 7878 -> Loss: 0.00434393435716629 -> Predictions: [[0.00360331]\n",
            " [0.99610645]\n",
            " [0.99609464]\n",
            " [0.00593411]]\n",
            "Step: 7879 -> Loss: 0.0043439120054244995 -> Predictions: [[0.00360329]\n",
            " [0.99610645]\n",
            " [0.99609464]\n",
            " [0.00593408]]\n",
            "Step: 7880 -> Loss: 0.0043438938446342945 -> Predictions: [[0.00360328]\n",
            " [0.99610645]\n",
            " [0.99609476]\n",
            " [0.00593405]]\n",
            "Step: 7881 -> Loss: 0.00434387382119894 -> Predictions: [[0.00360326]\n",
            " [0.99610645]\n",
            " [0.99609476]\n",
            " [0.00593402]]\n",
            "Step: 7882 -> Loss: 0.0043438514694571495 -> Predictions: [[0.00360325]\n",
            " [0.99610645]\n",
            " [0.99609476]\n",
            " [0.00593399]]\n",
            "Step: 7883 -> Loss: 0.004343832843005657 -> Predictions: [[0.00360323]\n",
            " [0.99610656]\n",
            " [0.99609476]\n",
            " [0.00593396]]\n",
            "Step: 7884 -> Loss: 0.004343811422586441 -> Predictions: [[0.00360321]\n",
            " [0.99610656]\n",
            " [0.99609476]\n",
            " [0.00593393]]\n",
            "Step: 7885 -> Loss: 0.004343790002167225 -> Predictions: [[0.0036032 ]\n",
            " [0.99610656]\n",
            " [0.99609476]\n",
            " [0.0059339 ]]\n",
            "Step: 7886 -> Loss: 0.004343771375715733 -> Predictions: [[0.00360318]\n",
            " [0.99610656]\n",
            " [0.99609476]\n",
            " [0.00593387]]\n",
            "Step: 7887 -> Loss: 0.004343752283602953 -> Predictions: [[0.00360316]\n",
            " [0.99610656]\n",
            " [0.9960949 ]\n",
            " [0.00593384]]\n",
            "Step: 7888 -> Loss: 0.004343729000538588 -> Predictions: [[0.00360315]\n",
            " [0.99610656]\n",
            " [0.9960949 ]\n",
            " [0.00593381]]\n",
            "Step: 7889 -> Loss: 0.004343710839748383 -> Predictions: [[0.00360313]\n",
            " [0.99610656]\n",
            " [0.9960949 ]\n",
            " [0.00593378]]\n",
            "Step: 7890 -> Loss: 0.004343689419329166 -> Predictions: [[0.00360311]\n",
            " [0.9961067 ]\n",
            " [0.9960949 ]\n",
            " [0.00593375]]\n",
            "Step: 7891 -> Loss: 0.004343668930232525 -> Predictions: [[0.0036031 ]\n",
            " [0.9961067 ]\n",
            " [0.9960949 ]\n",
            " [0.00593372]]\n",
            "Step: 7892 -> Loss: 0.004343652632087469 -> Predictions: [[0.00360308]\n",
            " [0.9961067 ]\n",
            " [0.9960949 ]\n",
            " [0.00593369]]\n",
            "Step: 7893 -> Loss: 0.004343630280345678 -> Predictions: [[0.00360307]\n",
            " [0.9961067 ]\n",
            " [0.9960949 ]\n",
            " [0.00593366]]\n",
            "Step: 7894 -> Loss: 0.0043436074629426 -> Predictions: [[0.00360305]\n",
            " [0.9961067 ]\n",
            " [0.996095  ]\n",
            " [0.00593363]]\n",
            "Step: 7895 -> Loss: 0.004343589302152395 -> Predictions: [[0.00360303]\n",
            " [0.9961067 ]\n",
            " [0.996095  ]\n",
            " [0.0059336 ]]\n",
            "Step: 7896 -> Loss: 0.004343569744378328 -> Predictions: [[0.00360302]\n",
            " [0.9961067 ]\n",
            " [0.996095  ]\n",
            " [0.00593357]]\n",
            "Step: 7897 -> Loss: 0.00434354692697525 -> Predictions: [[0.003603  ]\n",
            " [0.9961068 ]\n",
            " [0.996095  ]\n",
            " [0.00593354]]\n",
            "Step: 7898 -> Loss: 0.004343527369201183 -> Predictions: [[0.00360299]\n",
            " [0.9961068 ]\n",
            " [0.996095  ]\n",
            " [0.00593351]]\n",
            "Step: 7899 -> Loss: 0.004343509674072266 -> Predictions: [[0.00360297]\n",
            " [0.9961068 ]\n",
            " [0.996095  ]\n",
            " [0.00593348]]\n",
            "Step: 7900 -> Loss: 0.0043434863910079 -> Predictions: [[0.00360295]\n",
            " [0.9961068 ]\n",
            " [0.996095  ]\n",
            " [0.00593345]]\n",
            "Step: 7901 -> Loss: 0.0043434700928628445 -> Predictions: [[0.00360294]\n",
            " [0.9961068 ]\n",
            " [0.9960951 ]\n",
            " [0.00593343]]\n",
            "Step: 7902 -> Loss: 0.004343446809798479 -> Predictions: [[0.00360292]\n",
            " [0.9961068 ]\n",
            " [0.9960951 ]\n",
            " [0.00593339]]\n",
            "Step: 7903 -> Loss: 0.004343428183346987 -> Predictions: [[0.00360291]\n",
            " [0.9961069 ]\n",
            " [0.9960951 ]\n",
            " [0.00593337]]\n",
            "Step: 7904 -> Loss: 0.004343405365943909 -> Predictions: [[0.00360289]\n",
            " [0.9961069 ]\n",
            " [0.9960951 ]\n",
            " [0.00593333]]\n",
            "Step: 7905 -> Loss: 0.004343386739492416 -> Predictions: [[0.00360287]\n",
            " [0.9961069 ]\n",
            " [0.9960951 ]\n",
            " [0.0059333 ]]\n",
            "Step: 7906 -> Loss: 0.0043433671817183495 -> Predictions: [[0.00360285]\n",
            " [0.9961069 ]\n",
            " [0.9960951 ]\n",
            " [0.00593328]]\n",
            "Step: 7907 -> Loss: 0.0043433476239442825 -> Predictions: [[0.00360283]\n",
            " [0.9961069 ]\n",
            " [0.9960951 ]\n",
            " [0.00593325]]\n",
            "Step: 7908 -> Loss: 0.004343325272202492 -> Predictions: [[0.00360282]\n",
            " [0.9961069 ]\n",
            " [0.99609524]\n",
            " [0.00593321]]\n",
            "Step: 7909 -> Loss: 0.0043433052487671375 -> Predictions: [[0.0036028 ]\n",
            " [0.9961069 ]\n",
            " [0.99609524]\n",
            " [0.00593319]]\n",
            "Step: 7910 -> Loss: 0.004343288019299507 -> Predictions: [[0.00360279]\n",
            " [0.9961069 ]\n",
            " [0.99609524]\n",
            " [0.00593316]]\n",
            "Step: 7911 -> Loss: 0.004343265201896429 -> Predictions: [[0.00360278]\n",
            " [0.99610704]\n",
            " [0.99609524]\n",
            " [0.00593312]]\n",
            "Step: 7912 -> Loss: 0.004343243315815926 -> Predictions: [[0.00360275]\n",
            " [0.99610704]\n",
            " [0.99609524]\n",
            " [0.00593309]]\n",
            "Step: 7913 -> Loss: 0.004343224689364433 -> Predictions: [[0.00360274]\n",
            " [0.99610704]\n",
            " [0.99609524]\n",
            " [0.00593306]]\n",
            "Step: 7914 -> Loss: 0.004343203268945217 -> Predictions: [[0.00360272]\n",
            " [0.99610704]\n",
            " [0.99609524]\n",
            " [0.00593303]]\n",
            "Step: 7915 -> Loss: 0.004343184642493725 -> Predictions: [[0.00360271]\n",
            " [0.99610704]\n",
            " [0.99609536]\n",
            " [0.005933  ]]\n",
            "Step: 7916 -> Loss: 0.004343164153397083 -> Predictions: [[0.00360269]\n",
            " [0.99610704]\n",
            " [0.99609536]\n",
            " [0.00593298]]\n",
            "Step: 7917 -> Loss: 0.004343142732977867 -> Predictions: [[0.00360267]\n",
            " [0.99610716]\n",
            " [0.99609536]\n",
            " [0.00593295]]\n",
            "Step: 7918 -> Loss: 0.004343125969171524 -> Predictions: [[0.00360266]\n",
            " [0.99610716]\n",
            " [0.99609536]\n",
            " [0.00593292]]\n",
            "Step: 7919 -> Loss: 0.004343104083091021 -> Predictions: [[0.00360265]\n",
            " [0.99610716]\n",
            " [0.99609536]\n",
            " [0.00593289]]\n",
            "Step: 7920 -> Loss: 0.004343083128333092 -> Predictions: [[0.00360263]\n",
            " [0.99610716]\n",
            " [0.99609536]\n",
            " [0.00593286]]\n",
            "Step: 7921 -> Loss: 0.00434306263923645 -> Predictions: [[0.00360261]\n",
            " [0.99610716]\n",
            " [0.9960955 ]\n",
            " [0.00593283]]\n",
            "Step: 7922 -> Loss: 0.00434304540976882 -> Predictions: [[0.00360259]\n",
            " [0.99610716]\n",
            " [0.9960955 ]\n",
            " [0.0059328 ]]\n",
            "Step: 7923 -> Loss: 0.004343023989349604 -> Predictions: [[0.00360258]\n",
            " [0.99610716]\n",
            " [0.9960955 ]\n",
            " [0.00593277]]\n",
            "Step: 7924 -> Loss: 0.004343003965914249 -> Predictions: [[0.00360257]\n",
            " [0.9961073 ]\n",
            " [0.9960955 ]\n",
            " [0.00593274]]\n",
            "Step: 7925 -> Loss: 0.004342982079833746 -> Predictions: [[0.00360254]\n",
            " [0.9961073 ]\n",
            " [0.9960955 ]\n",
            " [0.00593271]]\n",
            "Step: 7926 -> Loss: 0.0043429601937532425 -> Predictions: [[0.00360253]\n",
            " [0.9961073 ]\n",
            " [0.9960955 ]\n",
            " [0.00593267]]\n",
            "Step: 7927 -> Loss: 0.004342940635979176 -> Predictions: [[0.00360251]\n",
            " [0.9961073 ]\n",
            " [0.9960955 ]\n",
            " [0.00593265]]\n",
            "Step: 7928 -> Loss: 0.004342921078205109 -> Predictions: [[0.0036025 ]\n",
            " [0.9961073 ]\n",
            " [0.9960956 ]\n",
            " [0.00593262]]\n",
            "Step: 7929 -> Loss: 0.004342902917414904 -> Predictions: [[0.00360248]\n",
            " [0.9961073 ]\n",
            " [0.9960956 ]\n",
            " [0.00593259]]\n",
            "Step: 7930 -> Loss: 0.004342882428318262 -> Predictions: [[0.00360246]\n",
            " [0.9961073 ]\n",
            " [0.9960956 ]\n",
            " [0.00593256]]\n",
            "Step: 7931 -> Loss: 0.004342857748270035 -> Predictions: [[0.00360244]\n",
            " [0.9961074 ]\n",
            " [0.9960956 ]\n",
            " [0.00593253]]\n",
            "Step: 7932 -> Loss: 0.00434283958747983 -> Predictions: [[0.00360243]\n",
            " [0.9961074 ]\n",
            " [0.9960956 ]\n",
            " [0.0059325 ]]\n",
            "Step: 7933 -> Loss: 0.0043428209610283375 -> Predictions: [[0.00360242]\n",
            " [0.9961074 ]\n",
            " [0.9960956 ]\n",
            " [0.00593247]]\n",
            "Step: 7934 -> Loss: 0.004342800471931696 -> Predictions: [[0.0036024 ]\n",
            " [0.9961074 ]\n",
            " [0.9960956 ]\n",
            " [0.00593244]]\n",
            "Step: 7935 -> Loss: 0.004342779517173767 -> Predictions: [[0.00360238]\n",
            " [0.9961074 ]\n",
            " [0.9960957 ]\n",
            " [0.00593241]]\n",
            "Step: 7936 -> Loss: 0.0043427590280771255 -> Predictions: [[0.00360237]\n",
            " [0.9961074 ]\n",
            " [0.9960957 ]\n",
            " [0.00593238]]\n",
            "Step: 7937 -> Loss: 0.004342738538980484 -> Predictions: [[0.00360235]\n",
            " [0.9961074 ]\n",
            " [0.9960957 ]\n",
            " [0.00593235]]\n",
            "Step: 7938 -> Loss: 0.004342716187238693 -> Predictions: [[0.00360233]\n",
            " [0.9961075 ]\n",
            " [0.9960957 ]\n",
            " [0.00593232]]\n",
            "Step: 7939 -> Loss: 0.004342696629464626 -> Predictions: [[0.00360231]\n",
            " [0.9961075 ]\n",
            " [0.9960957 ]\n",
            " [0.00593229]]\n",
            "Step: 7940 -> Loss: 0.0043426803313195705 -> Predictions: [[0.0036023 ]\n",
            " [0.9961075 ]\n",
            " [0.9960957 ]\n",
            " [0.00593226]]\n",
            "Step: 7941 -> Loss: 0.004342658910900354 -> Predictions: [[0.00360229]\n",
            " [0.9961075 ]\n",
            " [0.9960957 ]\n",
            " [0.00593223]]\n",
            "Step: 7942 -> Loss: 0.004342639818787575 -> Predictions: [[0.00360227]\n",
            " [0.9961075 ]\n",
            " [0.99609584]\n",
            " [0.00593221]]\n",
            "Step: 7943 -> Loss: 0.004342618398368359 -> Predictions: [[0.00360225]\n",
            " [0.9961075 ]\n",
            " [0.99609584]\n",
            " [0.00593217]]\n",
            "Step: 7944 -> Loss: 0.004342596046626568 -> Predictions: [[0.00360223]\n",
            " [0.9961075 ]\n",
            " [0.99609584]\n",
            " [0.00593214]]\n",
            "Step: 7945 -> Loss: 0.004342580214142799 -> Predictions: [[0.00360222]\n",
            " [0.99610764]\n",
            " [0.99609584]\n",
            " [0.00593212]]\n",
            "Step: 7946 -> Loss: 0.004342558793723583 -> Predictions: [[0.0036022 ]\n",
            " [0.99610764]\n",
            " [0.99609584]\n",
            " [0.00593208]]\n",
            "Step: 7947 -> Loss: 0.004342537838965654 -> Predictions: [[0.00360219]\n",
            " [0.99610764]\n",
            " [0.99609584]\n",
            " [0.00593206]]\n",
            "Step: 7948 -> Loss: 0.0043425168842077255 -> Predictions: [[0.00360218]\n",
            " [0.99610764]\n",
            " [0.99609596]\n",
            " [0.00593203]]\n",
            "Step: 7949 -> Loss: 0.004342496395111084 -> Predictions: [[0.00360216]\n",
            " [0.99610764]\n",
            " [0.99609596]\n",
            " [0.005932  ]]\n",
            "Step: 7950 -> Loss: 0.004342477302998304 -> Predictions: [[0.00360214]\n",
            " [0.99610764]\n",
            " [0.99609596]\n",
            " [0.00593197]]\n",
            "Step: 7951 -> Loss: 0.00434245727956295 -> Predictions: [[0.00360212]\n",
            " [0.99610776]\n",
            " [0.99609596]\n",
            " [0.00593193]]\n",
            "Step: 7952 -> Loss: 0.004342438653111458 -> Predictions: [[0.00360211]\n",
            " [0.99610776]\n",
            " [0.99609596]\n",
            " [0.00593191]]\n",
            "Step: 7953 -> Loss: 0.004342417232692242 -> Predictions: [[0.00360209]\n",
            " [0.99610776]\n",
            " [0.99609596]\n",
            " [0.00593187]]\n",
            "Step: 7954 -> Loss: 0.0043423958122730255 -> Predictions: [[0.00360207]\n",
            " [0.99610776]\n",
            " [0.99609596]\n",
            " [0.00593185]]\n",
            "Step: 7955 -> Loss: 0.004342376720160246 -> Predictions: [[0.00360206]\n",
            " [0.99610776]\n",
            " [0.99609596]\n",
            " [0.00593181]]\n",
            "Step: 7956 -> Loss: 0.0043423534370958805 -> Predictions: [[0.00360204]\n",
            " [0.99610776]\n",
            " [0.9960961 ]\n",
            " [0.00593179]]\n",
            "Step: 7957 -> Loss: 0.004342335741966963 -> Predictions: [[0.00360202]\n",
            " [0.99610776]\n",
            " [0.9960961 ]\n",
            " [0.00593176]]\n",
            "Step: 7958 -> Loss: 0.004342315252870321 -> Predictions: [[0.00360201]\n",
            " [0.9961079 ]\n",
            " [0.9960961 ]\n",
            " [0.00593173]]\n",
            "Step: 7959 -> Loss: 0.004342292435467243 -> Predictions: [[0.00360199]\n",
            " [0.9961079 ]\n",
            " [0.9960961 ]\n",
            " [0.00593169]]\n",
            "Step: 7960 -> Loss: 0.004342274274677038 -> Predictions: [[0.00360197]\n",
            " [0.9961079 ]\n",
            " [0.9960961 ]\n",
            " [0.00593167]]\n",
            "Step: 7961 -> Loss: 0.004342254716902971 -> Predictions: [[0.00360196]\n",
            " [0.9961079 ]\n",
            " [0.9960961 ]\n",
            " [0.00593164]]\n",
            "Step: 7962 -> Loss: 0.004342233296483755 -> Predictions: [[0.00360194]\n",
            " [0.9961079 ]\n",
            " [0.9960962 ]\n",
            " [0.00593161]]\n",
            "Step: 7963 -> Loss: 0.004342213738709688 -> Predictions: [[0.00360193]\n",
            " [0.9961079 ]\n",
            " [0.9960962 ]\n",
            " [0.00593158]]\n",
            "Step: 7964 -> Loss: 0.004342192318290472 -> Predictions: [[0.00360191]\n",
            " [0.9961079 ]\n",
            " [0.9960962 ]\n",
            " [0.00593155]]\n",
            "Step: 7965 -> Loss: 0.00434217369183898 -> Predictions: [[0.00360189]\n",
            " [0.996108  ]\n",
            " [0.9960962 ]\n",
            " [0.00593153]]\n",
            "Step: 7966 -> Loss: 0.004342155065387487 -> Predictions: [[0.00360188]\n",
            " [0.996108  ]\n",
            " [0.9960962 ]\n",
            " [0.00593149]]\n",
            "Step: 7967 -> Loss: 0.004342131782323122 -> Predictions: [[0.00360186]\n",
            " [0.996108  ]\n",
            " [0.9960962 ]\n",
            " [0.00593146]]\n",
            "Step: 7968 -> Loss: 0.004342112224549055 -> Predictions: [[0.00360185]\n",
            " [0.996108  ]\n",
            " [0.9960962 ]\n",
            " [0.00593143]]\n",
            "Step: 7969 -> Loss: 0.00434209406375885 -> Predictions: [[0.00360183]\n",
            " [0.996108  ]\n",
            " [0.9960963 ]\n",
            " [0.00593141]]\n",
            "Step: 7970 -> Loss: 0.004342071712017059 -> Predictions: [[0.00360181]\n",
            " [0.996108  ]\n",
            " [0.9960963 ]\n",
            " [0.00593137]]\n",
            "Step: 7971 -> Loss: 0.00434205261990428 -> Predictions: [[0.0036018 ]\n",
            " [0.996108  ]\n",
            " [0.9960963 ]\n",
            " [0.00593134]]\n",
            "Step: 7972 -> Loss: 0.004342033993452787 -> Predictions: [[0.00360178]\n",
            " [0.9961081 ]\n",
            " [0.9960963 ]\n",
            " [0.00593131]]\n",
            "Step: 7973 -> Loss: 0.004342011641710997 -> Predictions: [[0.00360176]\n",
            " [0.9961081 ]\n",
            " [0.9960963 ]\n",
            " [0.00593128]]\n",
            "Step: 7974 -> Loss: 0.004341991618275642 -> Predictions: [[0.00360175]\n",
            " [0.9961081 ]\n",
            " [0.9960963 ]\n",
            " [0.00593125]]\n",
            "Step: 7975 -> Loss: 0.004341968335211277 -> Predictions: [[0.00360173]\n",
            " [0.9961081 ]\n",
            " [0.9960963 ]\n",
            " [0.00593122]]\n",
            "Step: 7976 -> Loss: 0.004341952037066221 -> Predictions: [[0.00360172]\n",
            " [0.9961081 ]\n",
            " [0.99609643]\n",
            " [0.0059312 ]]\n",
            "Step: 7977 -> Loss: 0.004341931082308292 -> Predictions: [[0.0036017 ]\n",
            " [0.9961081 ]\n",
            " [0.99609643]\n",
            " [0.00593116]]\n",
            "Step: 7978 -> Loss: 0.004341909196227789 -> Predictions: [[0.00360168]\n",
            " [0.9961081 ]\n",
            " [0.99609643]\n",
            " [0.00593113]]\n",
            "Step: 7979 -> Loss: 0.00434188824146986 -> Predictions: [[0.00360166]\n",
            " [0.99610823]\n",
            " [0.99609643]\n",
            " [0.0059311 ]]\n",
            "Step: 7980 -> Loss: 0.004341870080679655 -> Predictions: [[0.00360164]\n",
            " [0.99610823]\n",
            " [0.99609643]\n",
            " [0.00593108]]\n",
            "Step: 7981 -> Loss: 0.004341850057244301 -> Predictions: [[0.00360163]\n",
            " [0.99610823]\n",
            " [0.99609643]\n",
            " [0.00593104]]\n",
            "Step: 7982 -> Loss: 0.004341828636825085 -> Predictions: [[0.00360162]\n",
            " [0.99610823]\n",
            " [0.99609643]\n",
            " [0.00593101]]\n",
            "Step: 7983 -> Loss: 0.004341809079051018 -> Predictions: [[0.0036016 ]\n",
            " [0.99610823]\n",
            " [0.99609655]\n",
            " [0.00593098]]\n",
            "Step: 7984 -> Loss: 0.0043417890556156635 -> Predictions: [[0.00360158]\n",
            " [0.99610823]\n",
            " [0.99609655]\n",
            " [0.00593096]]\n",
            "Step: 7985 -> Loss: 0.004341769963502884 -> Predictions: [[0.00360157]\n",
            " [0.99610823]\n",
            " [0.99609655]\n",
            " [0.00593093]]\n",
            "Step: 7986 -> Loss: 0.004341747146099806 -> Predictions: [[0.00360155]\n",
            " [0.99610835]\n",
            " [0.99609655]\n",
            " [0.0059309 ]]\n",
            "Step: 7987 -> Loss: 0.0043417285196483135 -> Predictions: [[0.00360153]\n",
            " [0.99610835]\n",
            " [0.99609655]\n",
            " [0.00593087]]\n",
            "Step: 7988 -> Loss: 0.004341707564890385 -> Predictions: [[0.00360152]\n",
            " [0.99610835]\n",
            " [0.99609655]\n",
            " [0.00593083]]\n",
            "Step: 7989 -> Loss: 0.004341688938438892 -> Predictions: [[0.0036015 ]\n",
            " [0.99610835]\n",
            " [0.99609655]\n",
            " [0.00593081]]\n",
            "Step: 7990 -> Loss: 0.004341666586697102 -> Predictions: [[0.00360149]\n",
            " [0.99610835]\n",
            " [0.9960967 ]\n",
            " [0.00593077]]\n",
            "Step: 7991 -> Loss: 0.004341647028923035 -> Predictions: [[0.00360147]\n",
            " [0.99610835]\n",
            " [0.9960967 ]\n",
            " [0.00593075]]\n",
            "Step: 7992 -> Loss: 0.004341624677181244 -> Predictions: [[0.00360145]\n",
            " [0.99610835]\n",
            " [0.9960967 ]\n",
            " [0.00593071]]\n",
            "Step: 7993 -> Loss: 0.004341606982052326 -> Predictions: [[0.00360144]\n",
            " [0.9961085 ]\n",
            " [0.9960967 ]\n",
            " [0.00593068]]\n",
            "Step: 7994 -> Loss: 0.004341587889939547 -> Predictions: [[0.00360142]\n",
            " [0.9961085 ]\n",
            " [0.9960967 ]\n",
            " [0.00593066]]\n",
            "Step: 7995 -> Loss: 0.004341566935181618 -> Predictions: [[0.00360141]\n",
            " [0.9961085 ]\n",
            " [0.9960967 ]\n",
            " [0.00593063]]\n",
            "Step: 7996 -> Loss: 0.004341546446084976 -> Predictions: [[0.00360139]\n",
            " [0.9961085 ]\n",
            " [0.9960967 ]\n",
            " [0.0059306 ]]\n",
            "Step: 7997 -> Loss: 0.00434152502566576 -> Predictions: [[0.00360137]\n",
            " [0.9961085 ]\n",
            " [0.9960968 ]\n",
            " [0.00593057]]\n",
            "Step: 7998 -> Loss: 0.004341505467891693 -> Predictions: [[0.00360136]\n",
            " [0.9961085 ]\n",
            " [0.9960968 ]\n",
            " [0.00593054]]\n",
            "Step: 7999 -> Loss: 0.004341485444456339 -> Predictions: [[0.00360134]\n",
            " [0.9961085 ]\n",
            " [0.9960968 ]\n",
            " [0.0059305 ]]\n",
            "Step: 8001 -> Loss: 0.004341445863246918 -> Predictions: [[0.00360131]\n",
            " [0.9961086 ]\n",
            " [0.9960968 ]\n",
            " [0.00593045]]\n",
            "Step: 8002 -> Loss: 0.004341424442827702 -> Predictions: [[0.00360129]\n",
            " [0.9961086 ]\n",
            " [0.9960968 ]\n",
            " [0.00593042]]\n",
            "Step: 8003 -> Loss: 0.00434140395373106 -> Predictions: [[0.00360128]\n",
            " [0.9961086 ]\n",
            " [0.9960968 ]\n",
            " [0.00593039]]\n",
            "Step: 8004 -> Loss: 0.004341385792940855 -> Predictions: [[0.00360126]\n",
            " [0.9961086 ]\n",
            " [0.9960969 ]\n",
            " [0.00593036]]\n",
            "Step: 8005 -> Loss: 0.004341364838182926 -> Predictions: [[0.00360124]\n",
            " [0.9961086 ]\n",
            " [0.9960969 ]\n",
            " [0.00593033]]\n",
            "Step: 8006 -> Loss: 0.004341344349086285 -> Predictions: [[0.00360122]\n",
            " [0.9961087 ]\n",
            " [0.9960969 ]\n",
            " [0.0059303 ]]\n",
            "Step: 8007 -> Loss: 0.004341323859989643 -> Predictions: [[0.00360121]\n",
            " [0.9961087 ]\n",
            " [0.9960969 ]\n",
            " [0.00593027]]\n",
            "Step: 8008 -> Loss: 0.004341301508247852 -> Predictions: [[0.00360119]\n",
            " [0.9961087 ]\n",
            " [0.9960969 ]\n",
            " [0.00593023]]\n",
            "Step: 8009 -> Loss: 0.004341283813118935 -> Predictions: [[0.00360118]\n",
            " [0.9961087 ]\n",
            " [0.9960969 ]\n",
            " [0.00593021]]\n",
            "Step: 8010 -> Loss: 0.00434126378968358 -> Predictions: [[0.00360116]\n",
            " [0.9961087 ]\n",
            " [0.996097  ]\n",
            " [0.00593018]]\n",
            "Step: 8011 -> Loss: 0.004341241903603077 -> Predictions: [[0.00360114]\n",
            " [0.9961087 ]\n",
            " [0.996097  ]\n",
            " [0.00593015]]\n",
            "Step: 8012 -> Loss: 0.004341225605458021 -> Predictions: [[0.00360113]\n",
            " [0.9961087 ]\n",
            " [0.996097  ]\n",
            " [0.00593012]]\n",
            "Step: 8013 -> Loss: 0.004341205582022667 -> Predictions: [[0.00360112]\n",
            " [0.99610883]\n",
            " [0.996097  ]\n",
            " [0.0059301 ]]\n",
            "Step: 8014 -> Loss: 0.00434118090197444 -> Predictions: [[0.0036011 ]\n",
            " [0.99610883]\n",
            " [0.996097  ]\n",
            " [0.00593006]]\n",
            "Step: 8015 -> Loss: 0.004341163206845522 -> Predictions: [[0.00360108]\n",
            " [0.99610883]\n",
            " [0.996097  ]\n",
            " [0.00593003]]\n",
            "Step: 8016 -> Loss: 0.004341142252087593 -> Predictions: [[0.00360106]\n",
            " [0.99610883]\n",
            " [0.996097  ]\n",
            " [0.00593   ]]\n",
            "Step: 8017 -> Loss: 0.004341122694313526 -> Predictions: [[0.00360105]\n",
            " [0.99610883]\n",
            " [0.99609715]\n",
            " [0.00592998]]\n",
            "Step: 8018 -> Loss: 0.0043411036022007465 -> Predictions: [[0.00360103]\n",
            " [0.99610883]\n",
            " [0.99609715]\n",
            " [0.00592995]]\n",
            "Step: 8019 -> Loss: 0.004341081716120243 -> Predictions: [[0.00360102]\n",
            " [0.99610883]\n",
            " [0.99609715]\n",
            " [0.00592991]]\n",
            "Step: 8020 -> Loss: 0.0043410612270236015 -> Predictions: [[0.003601  ]\n",
            " [0.99610895]\n",
            " [0.99609715]\n",
            " [0.00592988]]\n",
            "Step: 8021 -> Loss: 0.00434104073792696 -> Predictions: [[0.00360098]\n",
            " [0.99610895]\n",
            " [0.99609715]\n",
            " [0.00592985]]\n",
            "Step: 8022 -> Loss: 0.00434102164581418 -> Predictions: [[0.00360097]\n",
            " [0.99610895]\n",
            " [0.99609715]\n",
            " [0.00592983]]\n",
            "Step: 8023 -> Loss: 0.0043410006910562515 -> Predictions: [[0.00360095]\n",
            " [0.99610895]\n",
            " [0.99609715]\n",
            " [0.0059298 ]]\n",
            "Step: 8024 -> Loss: 0.004340981598943472 -> Predictions: [[0.00360094]\n",
            " [0.99610895]\n",
            " [0.99609727]\n",
            " [0.00592977]]\n",
            "Step: 8025 -> Loss: 0.004340962506830692 -> Predictions: [[0.00360092]\n",
            " [0.99610895]\n",
            " [0.99609727]\n",
            " [0.00592973]]\n",
            "Step: 8026 -> Loss: 0.0043409401550889015 -> Predictions: [[0.0036009 ]\n",
            " [0.99610895]\n",
            " [0.99609727]\n",
            " [0.00592971]]\n",
            "Step: 8027 -> Loss: 0.004340920597314835 -> Predictions: [[0.00360089]\n",
            " [0.99610907]\n",
            " [0.99609727]\n",
            " [0.00592967]]\n",
            "Step: 8028 -> Loss: 0.004340898245573044 -> Predictions: [[0.00360086]\n",
            " [0.99610907]\n",
            " [0.99609727]\n",
            " [0.00592965]]\n",
            "Step: 8029 -> Loss: 0.004340878687798977 -> Predictions: [[0.00360085]\n",
            " [0.99610907]\n",
            " [0.99609727]\n",
            " [0.00592961]]\n",
            "Step: 8030 -> Loss: 0.00434085913002491 -> Predictions: [[0.00360084]\n",
            " [0.99610907]\n",
            " [0.99609727]\n",
            " [0.00592958]]\n",
            "Step: 8031 -> Loss: 0.004340838640928268 -> Predictions: [[0.00360082]\n",
            " [0.99610907]\n",
            " [0.9960974 ]\n",
            " [0.00592956]]\n",
            "Step: 8032 -> Loss: 0.004340816754847765 -> Predictions: [[0.0036008 ]\n",
            " [0.99610907]\n",
            " [0.9960974 ]\n",
            " [0.00592952]]\n",
            "Step: 8033 -> Loss: 0.004340799059718847 -> Predictions: [[0.00360078]\n",
            " [0.99610907]\n",
            " [0.9960974 ]\n",
            " [0.0059295 ]]\n",
            "Step: 8034 -> Loss: 0.004340778570622206 -> Predictions: [[0.00360077]\n",
            " [0.9961092 ]\n",
            " [0.9960974 ]\n",
            " [0.00592947]]\n",
            "Step: 8035 -> Loss: 0.004340758081525564 -> Predictions: [[0.00360075]\n",
            " [0.9961092 ]\n",
            " [0.9960974 ]\n",
            " [0.00592944]]\n",
            "Step: 8036 -> Loss: 0.004340739455074072 -> Predictions: [[0.00360074]\n",
            " [0.9961092 ]\n",
            " [0.9960974 ]\n",
            " [0.00592941]]\n",
            "Step: 8037 -> Loss: 0.004340717103332281 -> Predictions: [[0.00360073]\n",
            " [0.9961092 ]\n",
            " [0.9960975 ]\n",
            " [0.00592938]]\n",
            "Step: 8038 -> Loss: 0.004340697079896927 -> Predictions: [[0.0036007 ]\n",
            " [0.9961092 ]\n",
            " [0.9960975 ]\n",
            " [0.00592935]]\n",
            "Step: 8039 -> Loss: 0.00434067752212286 -> Predictions: [[0.00360069]\n",
            " [0.9961092 ]\n",
            " [0.9960975 ]\n",
            " [0.00592932]]\n",
            "Step: 8040 -> Loss: 0.00434065330773592 -> Predictions: [[0.00360067]\n",
            " [0.9961092 ]\n",
            " [0.9960975 ]\n",
            " [0.00592929]]\n",
            "Step: 8041 -> Loss: 0.0043406374752521515 -> Predictions: [[0.00360066]\n",
            " [0.9961093 ]\n",
            " [0.9960975 ]\n",
            " [0.00592926]]\n",
            "Step: 8042 -> Loss: 0.004340615123510361 -> Predictions: [[0.00360064]\n",
            " [0.9961093 ]\n",
            " [0.9960975 ]\n",
            " [0.00592923]]\n",
            "Step: 8043 -> Loss: 0.004340596497058868 -> Predictions: [[0.00360063]\n",
            " [0.9961093 ]\n",
            " [0.9960975 ]\n",
            " [0.0059292 ]]\n",
            "Step: 8044 -> Loss: 0.004340577870607376 -> Predictions: [[0.00360061]\n",
            " [0.9961093 ]\n",
            " [0.9960975 ]\n",
            " [0.00592917]]\n",
            "Step: 8045 -> Loss: 0.004340553656220436 -> Predictions: [[0.00360059]\n",
            " [0.9961093 ]\n",
            " [0.99609756]\n",
            " [0.00592914]]\n",
            "Step: 8046 -> Loss: 0.004340536892414093 -> Predictions: [[0.00360058]\n",
            " [0.9961093 ]\n",
            " [0.99609756]\n",
            " [0.00592912]]\n",
            "Step: 8047 -> Loss: 0.0043405164033174515 -> Predictions: [[0.00360056]\n",
            " [0.9961093 ]\n",
            " [0.99609756]\n",
            " [0.00592908]]\n",
            "Step: 8048 -> Loss: 0.004340497311204672 -> Predictions: [[0.00360054]\n",
            " [0.9961094 ]\n",
            " [0.99609756]\n",
            " [0.00592906]]\n",
            "Step: 8049 -> Loss: 0.004340475425124168 -> Predictions: [[0.00360053]\n",
            " [0.9961094 ]\n",
            " [0.99609756]\n",
            " [0.00592902]]\n",
            "Step: 8050 -> Loss: 0.0043404544703662395 -> Predictions: [[0.00360051]\n",
            " [0.9961094 ]\n",
            " [0.99609756]\n",
            " [0.00592899]]\n",
            "Step: 8051 -> Loss: 0.0043404363095760345 -> Predictions: [[0.0036005 ]\n",
            " [0.9961094 ]\n",
            " [0.9960977 ]\n",
            " [0.00592896]]\n",
            "Step: 8052 -> Loss: 0.004340414889156818 -> Predictions: [[0.00360048]\n",
            " [0.9961094 ]\n",
            " [0.9960977 ]\n",
            " [0.00592893]]\n",
            "Step: 8053 -> Loss: 0.004340394400060177 -> Predictions: [[0.00360046]\n",
            " [0.9961094 ]\n",
            " [0.9960977 ]\n",
            " [0.0059289 ]]\n",
            "Step: 8054 -> Loss: 0.00434037484228611 -> Predictions: [[0.00360045]\n",
            " [0.99610955]\n",
            " [0.9960977 ]\n",
            " [0.00592888]]\n",
            "Step: 8055 -> Loss: 0.004340353421866894 -> Predictions: [[0.00360043]\n",
            " [0.99610955]\n",
            " [0.9960977 ]\n",
            " [0.00592884]]\n",
            "Step: 8056 -> Loss: 0.004340333864092827 -> Predictions: [[0.00360042]\n",
            " [0.99610955]\n",
            " [0.9960977 ]\n",
            " [0.00592881]]\n",
            "Step: 8057 -> Loss: 0.004340312443673611 -> Predictions: [[0.00360039]\n",
            " [0.99610955]\n",
            " [0.9960977 ]\n",
            " [0.00592879]]\n",
            "Step: 8058 -> Loss: 0.004340293817222118 -> Predictions: [[0.00360038]\n",
            " [0.99610955]\n",
            " [0.9960978 ]\n",
            " [0.00592876]]\n",
            "Step: 8059 -> Loss: 0.0043402742594480515 -> Predictions: [[0.00360037]\n",
            " [0.99610955]\n",
            " [0.9960978 ]\n",
            " [0.00592873]]\n",
            "Step: 8060 -> Loss: 0.00434025377035141 -> Predictions: [[0.00360035]\n",
            " [0.99610955]\n",
            " [0.9960978 ]\n",
            " [0.00592869]]\n",
            "Step: 8061 -> Loss: 0.004340232349932194 -> Predictions: [[0.00360033]\n",
            " [0.99610966]\n",
            " [0.9960978 ]\n",
            " [0.00592867]]\n",
            "Step: 8062 -> Loss: 0.004340211860835552 -> Predictions: [[0.00360032]\n",
            " [0.99610966]\n",
            " [0.9960978 ]\n",
            " [0.00592863]]\n",
            "Step: 8063 -> Loss: 0.004340191371738911 -> Predictions: [[0.0036003 ]\n",
            " [0.99610966]\n",
            " [0.9960978 ]\n",
            " [0.0059286 ]]\n",
            "Step: 8064 -> Loss: 0.004340171813964844 -> Predictions: [[0.00360028]\n",
            " [0.99610966]\n",
            " [0.9960978 ]\n",
            " [0.00592858]]\n",
            "Step: 8065 -> Loss: 0.0043401517905294895 -> Predictions: [[0.00360027]\n",
            " [0.99610966]\n",
            " [0.9960979 ]\n",
            " [0.00592855]]\n",
            "Step: 8066 -> Loss: 0.0043401289731264114 -> Predictions: [[0.00360025]\n",
            " [0.99610966]\n",
            " [0.9960979 ]\n",
            " [0.00592851]]\n",
            "Step: 8067 -> Loss: 0.004340111277997494 -> Predictions: [[0.00360024]\n",
            " [0.99610966]\n",
            " [0.9960979 ]\n",
            " [0.00592849]]\n",
            "Step: 8068 -> Loss: 0.004340090788900852 -> Predictions: [[0.00360022]\n",
            " [0.9961098 ]\n",
            " [0.9960979 ]\n",
            " [0.00592846]]\n",
            "Step: 8069 -> Loss: 0.004340071231126785 -> Predictions: [[0.0036002 ]\n",
            " [0.9961098 ]\n",
            " [0.9960979 ]\n",
            " [0.00592843]]\n",
            "Step: 8070 -> Loss: 0.004340052604675293 -> Predictions: [[0.00360019]\n",
            " [0.9961098 ]\n",
            " [0.9960979 ]\n",
            " [0.0059284 ]]\n",
            "Step: 8071 -> Loss: 0.004340032115578651 -> Predictions: [[0.00360017]\n",
            " [0.9961098 ]\n",
            " [0.9960979 ]\n",
            " [0.00592837]]\n",
            "Step: 8072 -> Loss: 0.004340009763836861 -> Predictions: [[0.00360015]\n",
            " [0.9961098 ]\n",
            " [0.99609804]\n",
            " [0.00592834]]\n",
            "Step: 8073 -> Loss: 0.0043399883434176445 -> Predictions: [[0.00360014]\n",
            " [0.9961098 ]\n",
            " [0.99609804]\n",
            " [0.00592831]]\n",
            "Step: 8074 -> Loss: 0.004339969251304865 -> Predictions: [[0.00360012]\n",
            " [0.9961098 ]\n",
            " [0.99609804]\n",
            " [0.00592828]]\n",
            "Step: 8075 -> Loss: 0.004339949227869511 -> Predictions: [[0.00360011]\n",
            " [0.9961099 ]\n",
            " [0.99609804]\n",
            " [0.00592825]]\n",
            "Step: 8076 -> Loss: 0.004339928273111582 -> Predictions: [[0.00360009]\n",
            " [0.9961099 ]\n",
            " [0.99609804]\n",
            " [0.00592822]]\n",
            "Step: 8077 -> Loss: 0.004339908249676228 -> Predictions: [[0.00360007]\n",
            " [0.9961099 ]\n",
            " [0.99609804]\n",
            " [0.00592819]]\n",
            "Step: 8078 -> Loss: 0.004339888691902161 -> Predictions: [[0.00360006]\n",
            " [0.9961099 ]\n",
            " [0.99609804]\n",
            " [0.00592816]]\n",
            "Step: 8079 -> Loss: 0.004339867737144232 -> Predictions: [[0.00360004]\n",
            " [0.9961099 ]\n",
            " [0.99609816]\n",
            " [0.00592813]]\n",
            "Step: 8080 -> Loss: 0.004339849576354027 -> Predictions: [[0.00360002]\n",
            " [0.9961099 ]\n",
            " [0.99609816]\n",
            " [0.0059281 ]]\n",
            "Step: 8081 -> Loss: 0.004339828621596098 -> Predictions: [[0.0036    ]\n",
            " [0.9961099 ]\n",
            " [0.99609816]\n",
            " [0.00592807]]\n",
            "Step: 8082 -> Loss: 0.0043398053385317326 -> Predictions: [[0.00359999]\n",
            " [0.99611   ]\n",
            " [0.99609816]\n",
            " [0.00592804]]\n",
            "Step: 8083 -> Loss: 0.004339785780757666 -> Predictions: [[0.00359997]\n",
            " [0.99611   ]\n",
            " [0.99609816]\n",
            " [0.00592801]]\n",
            "Step: 8084 -> Loss: 0.00433976948261261 -> Predictions: [[0.00359996]\n",
            " [0.99611   ]\n",
            " [0.99609816]\n",
            " [0.00592798]]\n",
            "Step: 8085 -> Loss: 0.004339747130870819 -> Predictions: [[0.00359994]\n",
            " [0.99611   ]\n",
            " [0.99609816]\n",
            " [0.00592795]]\n",
            "Step: 8086 -> Loss: 0.00433972617611289 -> Predictions: [[0.00359993]\n",
            " [0.99611   ]\n",
            " [0.9960983 ]\n",
            " [0.00592792]]\n",
            "Step: 8087 -> Loss: 0.00433970894664526 -> Predictions: [[0.00359991]\n",
            " [0.99611   ]\n",
            " [0.9960983 ]\n",
            " [0.0059279 ]]\n",
            "Step: 8088 -> Loss: 0.004339688457548618 -> Predictions: [[0.0035999 ]\n",
            " [0.99611   ]\n",
            " [0.9960983 ]\n",
            " [0.00592787]]\n",
            "Step: 8089 -> Loss: 0.00433966564014554 -> Predictions: [[0.00359988]\n",
            " [0.99611014]\n",
            " [0.9960983 ]\n",
            " [0.00592783]]\n",
            "Step: 8090 -> Loss: 0.004339647013694048 -> Predictions: [[0.00359986]\n",
            " [0.99611014]\n",
            " [0.9960983 ]\n",
            " [0.0059278 ]]\n",
            "Step: 8091 -> Loss: 0.004339626990258694 -> Predictions: [[0.00359985]\n",
            " [0.99611014]\n",
            " [0.9960983 ]\n",
            " [0.00592778]]\n",
            "Step: 8092 -> Loss: 0.00433960510417819 -> Predictions: [[0.00359983]\n",
            " [0.99611014]\n",
            " [0.9960984 ]\n",
            " [0.00592774]]\n",
            "Step: 8093 -> Loss: 0.004339586943387985 -> Predictions: [[0.00359981]\n",
            " [0.99611014]\n",
            " [0.9960984 ]\n",
            " [0.00592772]]\n",
            "Step: 8094 -> Loss: 0.004339565988630056 -> Predictions: [[0.0035998 ]\n",
            " [0.99611014]\n",
            " [0.9960984 ]\n",
            " [0.00592769]]\n",
            "Step: 8095 -> Loss: 0.004339545499533415 -> Predictions: [[0.00359978]\n",
            " [0.99611014]\n",
            " [0.9960984 ]\n",
            " [0.00592766]]\n",
            "Step: 8096 -> Loss: 0.004339524544775486 -> Predictions: [[0.00359976]\n",
            " [0.99611026]\n",
            " [0.9960984 ]\n",
            " [0.00592762]]\n",
            "Step: 8097 -> Loss: 0.0043395040556788445 -> Predictions: [[0.00359974]\n",
            " [0.99611026]\n",
            " [0.9960984 ]\n",
            " [0.0059276 ]]\n",
            "Step: 8098 -> Loss: 0.004339484963566065 -> Predictions: [[0.00359973]\n",
            " [0.99611026]\n",
            " [0.9960984 ]\n",
            " [0.00592757]]\n",
            "Step: 8099 -> Loss: 0.004339464008808136 -> Predictions: [[0.00359971]\n",
            " [0.99611026]\n",
            " [0.9960985 ]\n",
            " [0.00592754]]\n",
            "Step: 8100 -> Loss: 0.004339440260082483 -> Predictions: [[0.00359969]\n",
            " [0.99611026]\n",
            " [0.9960985 ]\n",
            " [0.0059275 ]]\n",
            "Step: 8101 -> Loss: 0.004339423030614853 -> Predictions: [[0.00359968]\n",
            " [0.99611026]\n",
            " [0.9960985 ]\n",
            " [0.00592747]]\n",
            "Step: 8102 -> Loss: 0.004339403007179499 -> Predictions: [[0.00359966]\n",
            " [0.99611026]\n",
            " [0.9960985 ]\n",
            " [0.00592745]]\n",
            "Step: 8103 -> Loss: 0.0043393815867602825 -> Predictions: [[0.00359965]\n",
            " [0.9961104 ]\n",
            " [0.9960985 ]\n",
            " [0.00592742]]\n",
            "Step: 8104 -> Loss: 0.0043393634259700775 -> Predictions: [[0.00359963]\n",
            " [0.9961104 ]\n",
            " [0.9960985 ]\n",
            " [0.00592739]]\n",
            "Step: 8105 -> Loss: 0.004339342936873436 -> Predictions: [[0.00359962]\n",
            " [0.9961104 ]\n",
            " [0.9960985 ]\n",
            " [0.00592735]]\n",
            "Step: 8106 -> Loss: 0.004339322447776794 -> Predictions: [[0.0035996 ]\n",
            " [0.9961104 ]\n",
            " [0.99609864]\n",
            " [0.00592733]]\n",
            "Step: 8107 -> Loss: 0.004339301493018866 -> Predictions: [[0.00359958]\n",
            " [0.9961104 ]\n",
            " [0.99609864]\n",
            " [0.0059273 ]]\n",
            "Step: 8108 -> Loss: 0.004339281469583511 -> Predictions: [[0.00359957]\n",
            " [0.9961104 ]\n",
            " [0.99609864]\n",
            " [0.00592727]]\n",
            "Step: 8109 -> Loss: 0.004339262843132019 -> Predictions: [[0.00359955]\n",
            " [0.9961104 ]\n",
            " [0.99609864]\n",
            " [0.00592724]]\n",
            "Step: 8110 -> Loss: 0.004339243751019239 -> Predictions: [[0.00359954]\n",
            " [0.9961105 ]\n",
            " [0.99609864]\n",
            " [0.00592721]]\n",
            "Step: 8111 -> Loss: 0.004339222330600023 -> Predictions: [[0.00359952]\n",
            " [0.9961105 ]\n",
            " [0.99609864]\n",
            " [0.00592718]]\n",
            "Step: 8112 -> Loss: 0.00433920044451952 -> Predictions: [[0.0035995 ]\n",
            " [0.9961105 ]\n",
            " [0.99609864]\n",
            " [0.00592715]]\n",
            "Step: 8113 -> Loss: 0.004339179955422878 -> Predictions: [[0.00359948]\n",
            " [0.9961105 ]\n",
            " [0.99609876]\n",
            " [0.00592712]]\n",
            "Step: 8114 -> Loss: 0.004339160397648811 -> Predictions: [[0.00359947]\n",
            " [0.9961105 ]\n",
            " [0.99609876]\n",
            " [0.00592709]]\n",
            "Step: 8115 -> Loss: 0.00433913990855217 -> Predictions: [[0.00359945]\n",
            " [0.9961105 ]\n",
            " [0.99609876]\n",
            " [0.00592706]]\n",
            "Step: 8116 -> Loss: 0.004339120350778103 -> Predictions: [[0.00359944]\n",
            " [0.9961106 ]\n",
            " [0.99609876]\n",
            " [0.00592704]]\n",
            "Step: 8117 -> Loss: 0.004339098930358887 -> Predictions: [[0.00359942]\n",
            " [0.9961106 ]\n",
            " [0.99609876]\n",
            " [0.005927  ]]\n",
            "Step: 8118 -> Loss: 0.004339080303907394 -> Predictions: [[0.0035994 ]\n",
            " [0.9961106 ]\n",
            " [0.99609876]\n",
            " [0.00592697]]\n",
            "Step: 8119 -> Loss: 0.0043390607461333275 -> Predictions: [[0.00359939]\n",
            " [0.9961106 ]\n",
            " [0.99609876]\n",
            " [0.00592694]]\n",
            "Step: 8120 -> Loss: 0.004339037928730249 -> Predictions: [[0.00359937]\n",
            " [0.9961106 ]\n",
            " [0.9960989 ]\n",
            " [0.00592691]]\n",
            "Step: 8121 -> Loss: 0.00433901883661747 -> Predictions: [[0.00359936]\n",
            " [0.9961106 ]\n",
            " [0.9960989 ]\n",
            " [0.00592688]]\n",
            "Step: 8122 -> Loss: 0.004339001607149839 -> Predictions: [[0.00359934]\n",
            " [0.9961106 ]\n",
            " [0.9960989 ]\n",
            " [0.00592686]]\n",
            "Step: 8123 -> Loss: 0.004338977858424187 -> Predictions: [[0.00359932]\n",
            " [0.99611074]\n",
            " [0.9960989 ]\n",
            " [0.00592682]]\n",
            "Step: 8124 -> Loss: 0.0043389578349888325 -> Predictions: [[0.00359931]\n",
            " [0.99611074]\n",
            " [0.9960989 ]\n",
            " [0.00592679]]\n",
            "Step: 8125 -> Loss: 0.004338937345892191 -> Predictions: [[0.00359929]\n",
            " [0.99611074]\n",
            " [0.9960989 ]\n",
            " [0.00592676]]\n",
            "Step: 8126 -> Loss: 0.004338918253779411 -> Predictions: [[0.00359928]\n",
            " [0.99611074]\n",
            " [0.9960989 ]\n",
            " [0.00592674]]\n",
            "Step: 8127 -> Loss: 0.004338898696005344 -> Predictions: [[0.00359925]\n",
            " [0.99611074]\n",
            " [0.996099  ]\n",
            " [0.00592671]]\n",
            "Step: 8128 -> Loss: 0.004338877275586128 -> Predictions: [[0.00359924]\n",
            " [0.99611074]\n",
            " [0.996099  ]\n",
            " [0.00592667]]\n",
            "Step: 8129 -> Loss: 0.004338859114795923 -> Predictions: [[0.00359922]\n",
            " [0.99611074]\n",
            " [0.996099  ]\n",
            " [0.00592665]]\n",
            "Step: 8130 -> Loss: 0.004338836297392845 -> Predictions: [[0.00359921]\n",
            " [0.99611086]\n",
            " [0.996099  ]\n",
            " [0.00592661]]\n",
            "Step: 8131 -> Loss: 0.004338817670941353 -> Predictions: [[0.00359919]\n",
            " [0.99611086]\n",
            " [0.996099  ]\n",
            " [0.00592659]]\n",
            "Step: 8132 -> Loss: 0.004338798578828573 -> Predictions: [[0.00359918]\n",
            " [0.99611086]\n",
            " [0.996099  ]\n",
            " [0.00592656]]\n",
            "Step: 8133 -> Loss: 0.004338777158409357 -> Predictions: [[0.00359916]\n",
            " [0.99611086]\n",
            " [0.9960991 ]\n",
            " [0.00592653]]\n",
            "Step: 8134 -> Loss: 0.004338755272328854 -> Predictions: [[0.00359914]\n",
            " [0.99611086]\n",
            " [0.9960991 ]\n",
            " [0.0059265 ]]\n",
            "Step: 8135 -> Loss: 0.0043387385085225105 -> Predictions: [[0.00359913]\n",
            " [0.99611086]\n",
            " [0.9960991 ]\n",
            " [0.00592647]]\n",
            "Step: 8136 -> Loss: 0.004338717088103294 -> Predictions: [[0.00359911]\n",
            " [0.99611086]\n",
            " [0.9960991 ]\n",
            " [0.00592644]]\n",
            "Step: 8137 -> Loss: 0.004338695667684078 -> Predictions: [[0.00359909]\n",
            " [0.996111  ]\n",
            " [0.9960991 ]\n",
            " [0.00592641]]\n",
            "Step: 8138 -> Loss: 0.004338677506893873 -> Predictions: [[0.00359908]\n",
            " [0.996111  ]\n",
            " [0.9960991 ]\n",
            " [0.00592638]]\n",
            "Step: 8139 -> Loss: 0.004338656086474657 -> Predictions: [[0.00359906]\n",
            " [0.996111  ]\n",
            " [0.9960991 ]\n",
            " [0.00592635]]\n",
            "Step: 8140 -> Loss: 0.004338634666055441 -> Predictions: [[0.00359905]\n",
            " [0.996111  ]\n",
            " [0.99609923]\n",
            " [0.00592632]]\n",
            "Step: 8141 -> Loss: 0.004338615573942661 -> Predictions: [[0.00359903]\n",
            " [0.996111  ]\n",
            " [0.99609923]\n",
            " [0.00592629]]\n",
            "Step: 8142 -> Loss: 0.004338594153523445 -> Predictions: [[0.00359901]\n",
            " [0.996111  ]\n",
            " [0.99609923]\n",
            " [0.00592626]]\n",
            "Step: 8143 -> Loss: 0.004338574130088091 -> Predictions: [[0.003599  ]\n",
            " [0.996111  ]\n",
            " [0.99609923]\n",
            " [0.00592622]]\n",
            "Step: 8144 -> Loss: 0.004338552709668875 -> Predictions: [[0.00359898]\n",
            " [0.9961111 ]\n",
            " [0.99609923]\n",
            " [0.0059262 ]]\n",
            "Step: 8145 -> Loss: 0.0043385326862335205 -> Predictions: [[0.00359896]\n",
            " [0.9961111 ]\n",
            " [0.99609923]\n",
            " [0.00592617]]\n",
            "Step: 8146 -> Loss: 0.004338512662798166 -> Predictions: [[0.00359895]\n",
            " [0.9961111 ]\n",
            " [0.99609923]\n",
            " [0.00592613]]\n",
            "Step: 8147 -> Loss: 0.004338493570685387 -> Predictions: [[0.00359893]\n",
            " [0.9961111 ]\n",
            " [0.99609935]\n",
            " [0.00592611]]\n",
            "Step: 8148 -> Loss: 0.004338474944233894 -> Predictions: [[0.00359891]\n",
            " [0.9961111 ]\n",
            " [0.99609935]\n",
            " [0.00592608]]\n",
            "Step: 8149 -> Loss: 0.004338454455137253 -> Predictions: [[0.0035989 ]\n",
            " [0.9961111 ]\n",
            " [0.99609935]\n",
            " [0.00592605]]\n",
            "Step: 8150 -> Loss: 0.004338434431701899 -> Predictions: [[0.00359888]\n",
            " [0.9961111 ]\n",
            " [0.99609935]\n",
            " [0.00592603]]\n",
            "Step: 8151 -> Loss: 0.004338412545621395 -> Predictions: [[0.00359886]\n",
            " [0.9961112 ]\n",
            " [0.99609935]\n",
            " [0.00592599]]\n",
            "Step: 8152 -> Loss: 0.004338393919169903 -> Predictions: [[0.00359885]\n",
            " [0.9961112 ]\n",
            " [0.99609935]\n",
            " [0.00592596]]\n",
            "Step: 8153 -> Loss: 0.004338371567428112 -> Predictions: [[0.00359883]\n",
            " [0.9961112 ]\n",
            " [0.99609935]\n",
            " [0.00592593]]\n",
            "Step: 8154 -> Loss: 0.0043383496813476086 -> Predictions: [[0.00359882]\n",
            " [0.9961112 ]\n",
            " [0.9960995 ]\n",
            " [0.0059259 ]]\n",
            "Step: 8155 -> Loss: 0.004338331986218691 -> Predictions: [[0.0035988 ]\n",
            " [0.9961112 ]\n",
            " [0.9960995 ]\n",
            " [0.00592588]]\n",
            "Step: 8156 -> Loss: 0.004338312428444624 -> Predictions: [[0.00359878]\n",
            " [0.9961112 ]\n",
            " [0.9960995 ]\n",
            " [0.00592584]]\n",
            "Step: 8157 -> Loss: 0.004338291008025408 -> Predictions: [[0.00359877]\n",
            " [0.9961112 ]\n",
            " [0.9960995 ]\n",
            " [0.00592581]]\n",
            "Step: 8158 -> Loss: 0.004338270518928766 -> Predictions: [[0.00359875]\n",
            " [0.99611133]\n",
            " [0.9960995 ]\n",
            " [0.00592578]]\n",
            "Step: 8159 -> Loss: 0.004338250961154699 -> Predictions: [[0.00359874]\n",
            " [0.99611133]\n",
            " [0.9960995 ]\n",
            " [0.00592576]]\n",
            "Step: 8160 -> Loss: 0.0043382300063967705 -> Predictions: [[0.00359872]\n",
            " [0.99611133]\n",
            " [0.9960995 ]\n",
            " [0.00592572]]\n",
            "Step: 8161 -> Loss: 0.004338209517300129 -> Predictions: [[0.0035987 ]\n",
            " [0.99611133]\n",
            " [0.9960996 ]\n",
            " [0.00592569]]\n",
            "Step: 8162 -> Loss: 0.004338190425187349 -> Predictions: [[0.00359869]\n",
            " [0.99611133]\n",
            " [0.9960996 ]\n",
            " [0.00592566]]\n",
            "Step: 8163 -> Loss: 0.004338170867413282 -> Predictions: [[0.00359867]\n",
            " [0.99611133]\n",
            " [0.9960996 ]\n",
            " [0.00592563]]\n",
            "Step: 8164 -> Loss: 0.004338148515671492 -> Predictions: [[0.00359866]\n",
            " [0.99611145]\n",
            " [0.9960996 ]\n",
            " [0.0059256 ]]\n",
            "Step: 8165 -> Loss: 0.004338129423558712 -> Predictions: [[0.00359863]\n",
            " [0.99611145]\n",
            " [0.9960996 ]\n",
            " [0.00592558]]\n",
            "Step: 8166 -> Loss: 0.004338109400123358 -> Predictions: [[0.00359862]\n",
            " [0.99611145]\n",
            " [0.9960996 ]\n",
            " [0.00592555]]\n",
            "Step: 8167 -> Loss: 0.004338089842349291 -> Predictions: [[0.00359861]\n",
            " [0.99611145]\n",
            " [0.9960996 ]\n",
            " [0.00592552]]\n",
            "Step: 8168 -> Loss: 0.0043380674906075 -> Predictions: [[0.00359859]\n",
            " [0.99611145]\n",
            " [0.9960997 ]\n",
            " [0.00592549]]\n",
            "Step: 8169 -> Loss: 0.004338048864156008 -> Predictions: [[0.00359857]\n",
            " [0.99611145]\n",
            " [0.9960997 ]\n",
            " [0.00592545]]\n",
            "Step: 8170 -> Loss: 0.0043380288407206535 -> Predictions: [[0.00359856]\n",
            " [0.99611145]\n",
            " [0.9960997 ]\n",
            " [0.00592543]]\n",
            "Step: 8171 -> Loss: 0.004338007420301437 -> Predictions: [[0.00359854]\n",
            " [0.9961116 ]\n",
            " [0.9960997 ]\n",
            " [0.0059254 ]]\n",
            "Step: 8172 -> Loss: 0.004337988793849945 -> Predictions: [[0.00359852]\n",
            " [0.9961116 ]\n",
            " [0.9960997 ]\n",
            " [0.00592537]]\n",
            "Step: 8173 -> Loss: 0.004337971098721027 -> Predictions: [[0.00359851]\n",
            " [0.9961116 ]\n",
            " [0.9960997 ]\n",
            " [0.00592535]]\n",
            "Step: 8174 -> Loss: 0.004337948281317949 -> Predictions: [[0.0035985 ]\n",
            " [0.9961116 ]\n",
            " [0.9960998 ]\n",
            " [0.00592531]]\n",
            "Step: 8175 -> Loss: 0.004337928257882595 -> Predictions: [[0.00359848]\n",
            " [0.9961116 ]\n",
            " [0.9960998 ]\n",
            " [0.00592528]]\n",
            "Step: 8176 -> Loss: 0.004337910562753677 -> Predictions: [[0.00359846]\n",
            " [0.9961116 ]\n",
            " [0.9960998 ]\n",
            " [0.00592525]]\n",
            "Step: 8177 -> Loss: 0.004337888676673174 -> Predictions: [[0.00359844]\n",
            " [0.9961116 ]\n",
            " [0.9960998 ]\n",
            " [0.00592522]]\n",
            "Step: 8178 -> Loss: 0.0043378667905926704 -> Predictions: [[0.00359843]\n",
            " [0.9961117 ]\n",
            " [0.9960998 ]\n",
            " [0.00592519]]\n",
            "Step: 8179 -> Loss: 0.004337845370173454 -> Predictions: [[0.00359841]\n",
            " [0.9961117 ]\n",
            " [0.9960998 ]\n",
            " [0.00592516]]\n",
            "Step: 8180 -> Loss: 0.004337825812399387 -> Predictions: [[0.0035984 ]\n",
            " [0.9961117 ]\n",
            " [0.9960998 ]\n",
            " [0.00592513]]\n",
            "Step: 8181 -> Loss: 0.004337807651609182 -> Predictions: [[0.00359838]\n",
            " [0.9961117 ]\n",
            " [0.9960998 ]\n",
            " [0.0059251 ]]\n",
            "Step: 8182 -> Loss: 0.0043377866968512535 -> Predictions: [[0.00359836]\n",
            " [0.9961117 ]\n",
            " [0.99609995]\n",
            " [0.00592507]]\n",
            "Step: 8183 -> Loss: 0.004337767139077187 -> Predictions: [[0.00359835]\n",
            " [0.9961117 ]\n",
            " [0.99609995]\n",
            " [0.00592504]]\n",
            "Step: 8184 -> Loss: 0.00433774758130312 -> Predictions: [[0.00359833]\n",
            " [0.9961117 ]\n",
            " [0.99609995]\n",
            " [0.00592501]]\n",
            "Step: 8185 -> Loss: 0.004337727557867765 -> Predictions: [[0.00359832]\n",
            " [0.9961118 ]\n",
            " [0.99609995]\n",
            " [0.00592498]]\n",
            "Step: 8186 -> Loss: 0.004337706603109837 -> Predictions: [[0.0035983 ]\n",
            " [0.9961118 ]\n",
            " [0.99609995]\n",
            " [0.00592495]]\n",
            "Step: 8187 -> Loss: 0.004337686114013195 -> Predictions: [[0.00359828]\n",
            " [0.9961118 ]\n",
            " [0.99609995]\n",
            " [0.00592492]]\n",
            "Step: 8188 -> Loss: 0.0043376656249165535 -> Predictions: [[0.00359827]\n",
            " [0.9961118 ]\n",
            " [0.99610007]\n",
            " [0.00592489]]\n",
            "Step: 8189 -> Loss: 0.0043376474641263485 -> Predictions: [[0.00359825]\n",
            " [0.9961118 ]\n",
            " [0.99610007]\n",
            " [0.00592486]]\n",
            "Step: 8190 -> Loss: 0.004337628372013569 -> Predictions: [[0.00359824]\n",
            " [0.9961118 ]\n",
            " [0.99610007]\n",
            " [0.00592484]]\n",
            "Step: 8191 -> Loss: 0.004337606020271778 -> Predictions: [[0.00359822]\n",
            " [0.9961118 ]\n",
            " [0.99610007]\n",
            " [0.0059248 ]]\n",
            "Step: 8192 -> Loss: 0.004337586462497711 -> Predictions: [[0.0035982 ]\n",
            " [0.9961119 ]\n",
            " [0.99610007]\n",
            " [0.00592478]]\n",
            "Step: 8193 -> Loss: 0.004337565042078495 -> Predictions: [[0.00359819]\n",
            " [0.9961119 ]\n",
            " [0.99610007]\n",
            " [0.00592474]]\n",
            "Step: 8194 -> Loss: 0.00433754688128829 -> Predictions: [[0.00359817]\n",
            " [0.9961119 ]\n",
            " [0.99610007]\n",
            " [0.00592472]]\n",
            "Step: 8195 -> Loss: 0.0043375249952077866 -> Predictions: [[0.00359816]\n",
            " [0.9961119 ]\n",
            " [0.9961002 ]\n",
            " [0.00592468]]\n",
            "Step: 8196 -> Loss: 0.00433750357478857 -> Predictions: [[0.00359814]\n",
            " [0.9961119 ]\n",
            " [0.9961002 ]\n",
            " [0.00592465]]\n",
            "Step: 8197 -> Loss: 0.0043374826200306416 -> Predictions: [[0.00359811]\n",
            " [0.9961119 ]\n",
            " [0.9961002 ]\n",
            " [0.00592463]]\n",
            "Step: 8198 -> Loss: 0.004337463527917862 -> Predictions: [[0.0035981 ]\n",
            " [0.9961119 ]\n",
            " [0.9961002 ]\n",
            " [0.00592459]]\n",
            "Step: 8199 -> Loss: 0.0043374416418373585 -> Predictions: [[0.00359808]\n",
            " [0.99611205]\n",
            " [0.9961002 ]\n",
            " [0.00592457]]\n",
            "Step: 8200 -> Loss: 0.004337421152740717 -> Predictions: [[0.00359807]\n",
            " [0.99611205]\n",
            " [0.9961002 ]\n",
            " [0.00592453]]\n",
            "Step: 8201 -> Loss: 0.004337400663644075 -> Predictions: [[0.00359805]\n",
            " [0.99611205]\n",
            " [0.9961002 ]\n",
            " [0.00592451]]\n",
            "Step: 8202 -> Loss: 0.004337381571531296 -> Predictions: [[0.00359803]\n",
            " [0.99611205]\n",
            " [0.9961003 ]\n",
            " [0.00592447]]\n",
            "Step: 8203 -> Loss: 0.004337362479418516 -> Predictions: [[0.00359802]\n",
            " [0.99611205]\n",
            " [0.9961003 ]\n",
            " [0.00592445]]\n",
            "Step: 8204 -> Loss: 0.004337342921644449 -> Predictions: [[0.003598  ]\n",
            " [0.99611205]\n",
            " [0.9961003 ]\n",
            " [0.00592442]]\n",
            "Step: 8205 -> Loss: 0.004337322898209095 -> Predictions: [[0.00359799]\n",
            " [0.99611205]\n",
            " [0.9961003 ]\n",
            " [0.00592439]]\n",
            "Step: 8206 -> Loss: 0.004337303340435028 -> Predictions: [[0.00359798]\n",
            " [0.99611217]\n",
            " [0.9961003 ]\n",
            " [0.00592435]]\n",
            "Step: 8207 -> Loss: 0.0043372842483222485 -> Predictions: [[0.00359796]\n",
            " [0.99611217]\n",
            " [0.9961003 ]\n",
            " [0.00592433]]\n",
            "Step: 8208 -> Loss: 0.004337262362241745 -> Predictions: [[0.00359795]\n",
            " [0.99611217]\n",
            " [0.9961003 ]\n",
            " [0.0059243 ]]\n",
            "Step: 8209 -> Loss: 0.004337243735790253 -> Predictions: [[0.00359793]\n",
            " [0.99611217]\n",
            " [0.9961004 ]\n",
            " [0.00592427]]\n",
            "Step: 8210 -> Loss: 0.0043372223153710365 -> Predictions: [[0.00359791]\n",
            " [0.99611217]\n",
            " [0.9961004 ]\n",
            " [0.00592424]]\n",
            "Step: 8211 -> Loss: 0.00433720089495182 -> Predictions: [[0.00359789]\n",
            " [0.99611217]\n",
            " [0.9961004 ]\n",
            " [0.00592421]]\n",
            "Step: 8212 -> Loss: 0.004337184131145477 -> Predictions: [[0.00359788]\n",
            " [0.99611217]\n",
            " [0.9961004 ]\n",
            " [0.00592418]]\n",
            "Step: 8213 -> Loss: 0.004337160848081112 -> Predictions: [[0.00359786]\n",
            " [0.9961123 ]\n",
            " [0.9961004 ]\n",
            " [0.00592415]]\n",
            "Step: 8214 -> Loss: 0.004337141755968332 -> Predictions: [[0.00359784]\n",
            " [0.9961123 ]\n",
            " [0.9961004 ]\n",
            " [0.00592412]]\n",
            "Step: 8215 -> Loss: 0.004337122663855553 -> Predictions: [[0.00359783]\n",
            " [0.9961123 ]\n",
            " [0.9961004 ]\n",
            " [0.00592409]]\n",
            "Step: 8216 -> Loss: 0.004337099846452475 -> Predictions: [[0.00359781]\n",
            " [0.9961123 ]\n",
            " [0.99610054]\n",
            " [0.00592406]]\n",
            "Step: 8217 -> Loss: 0.00433707982301712 -> Predictions: [[0.00359779]\n",
            " [0.9961123 ]\n",
            " [0.99610054]\n",
            " [0.00592403]]\n",
            "Step: 8218 -> Loss: 0.004337059799581766 -> Predictions: [[0.00359778]\n",
            " [0.9961123 ]\n",
            " [0.99610054]\n",
            " [0.005924  ]]\n",
            "Step: 8219 -> Loss: 0.004337038844823837 -> Predictions: [[0.00359776]\n",
            " [0.9961124 ]\n",
            " [0.99610054]\n",
            " [0.00592397]]\n",
            "Step: 8220 -> Loss: 0.00433701928704977 -> Predictions: [[0.00359775]\n",
            " [0.9961124 ]\n",
            " [0.99610054]\n",
            " [0.00592394]]\n",
            "Step: 8221 -> Loss: 0.004336998797953129 -> Predictions: [[0.00359773]\n",
            " [0.9961124 ]\n",
            " [0.99610054]\n",
            " [0.00592391]]\n",
            "Step: 8222 -> Loss: 0.004336979240179062 -> Predictions: [[0.00359772]\n",
            " [0.9961124 ]\n",
            " [0.99610066]\n",
            " [0.00592388]]\n",
            "Step: 8223 -> Loss: 0.00433695875108242 -> Predictions: [[0.0035977 ]\n",
            " [0.9961124 ]\n",
            " [0.99610066]\n",
            " [0.00592385]]\n",
            "Step: 8224 -> Loss: 0.004336939193308353 -> Predictions: [[0.00359768]\n",
            " [0.9961124 ]\n",
            " [0.99610066]\n",
            " [0.00592382]]\n",
            "Step: 8225 -> Loss: 0.004336916841566563 -> Predictions: [[0.00359767]\n",
            " [0.9961124 ]\n",
            " [0.99610066]\n",
            " [0.00592379]]\n",
            "Step: 8226 -> Loss: 0.004336897749453783 -> Predictions: [[0.00359765]\n",
            " [0.9961125 ]\n",
            " [0.99610066]\n",
            " [0.00592376]]\n",
            "Step: 8227 -> Loss: 0.004336879588663578 -> Predictions: [[0.00359763]\n",
            " [0.9961125 ]\n",
            " [0.99610066]\n",
            " [0.00592374]]\n",
            "Step: 8228 -> Loss: 0.0043368590995669365 -> Predictions: [[0.00359762]\n",
            " [0.9961125 ]\n",
            " [0.99610066]\n",
            " [0.00592371]]\n",
            "Step: 8229 -> Loss: 0.00433683954179287 -> Predictions: [[0.0035976 ]\n",
            " [0.9961125 ]\n",
            " [0.99610066]\n",
            " [0.00592368]]\n",
            "Step: 8230 -> Loss: 0.004336815793067217 -> Predictions: [[0.00359758]\n",
            " [0.9961125 ]\n",
            " [0.9961008 ]\n",
            " [0.00592364]]\n",
            "Step: 8231 -> Loss: 0.004336797632277012 -> Predictions: [[0.00359756]\n",
            " [0.9961125 ]\n",
            " [0.9961008 ]\n",
            " [0.00592362]]\n",
            "Step: 8232 -> Loss: 0.00433677714318037 -> Predictions: [[0.00359755]\n",
            " [0.9961125 ]\n",
            " [0.9961008 ]\n",
            " [0.00592358]]\n",
            "Step: 8233 -> Loss: 0.004336758516728878 -> Predictions: [[0.00359754]\n",
            " [0.99611264]\n",
            " [0.9961008 ]\n",
            " [0.00592356]]\n",
            "Step: 8234 -> Loss: 0.004336737561970949 -> Predictions: [[0.00359752]\n",
            " [0.99611264]\n",
            " [0.9961008 ]\n",
            " [0.00592353]]\n",
            "Step: 8235 -> Loss: 0.004336719401180744 -> Predictions: [[0.0035975 ]\n",
            " [0.99611264]\n",
            " [0.9961008 ]\n",
            " [0.0059235 ]]\n",
            "Step: 8236 -> Loss: 0.004336697049438953 -> Predictions: [[0.00359749]\n",
            " [0.99611264]\n",
            " [0.9961009 ]\n",
            " [0.00592347]]\n",
            "Step: 8237 -> Loss: 0.0043366760946810246 -> Predictions: [[0.00359747]\n",
            " [0.99611264]\n",
            " [0.9961009 ]\n",
            " [0.00592344]]\n",
            "Step: 8238 -> Loss: 0.004336655605584383 -> Predictions: [[0.00359746]\n",
            " [0.99611264]\n",
            " [0.9961009 ]\n",
            " [0.00592341]]\n",
            "Step: 8239 -> Loss: 0.004336637444794178 -> Predictions: [[0.00359744]\n",
            " [0.99611264]\n",
            " [0.9961009 ]\n",
            " [0.00592338]]\n",
            "Step: 8240 -> Loss: 0.004336616024374962 -> Predictions: [[0.00359742]\n",
            " [0.99611276]\n",
            " [0.9961009 ]\n",
            " [0.00592335]]\n",
            "Step: 8241 -> Loss: 0.004336594603955746 -> Predictions: [[0.00359741]\n",
            " [0.99611276]\n",
            " [0.9961009 ]\n",
            " [0.00592332]]\n",
            "Step: 8242 -> Loss: 0.004336575977504253 -> Predictions: [[0.00359739]\n",
            " [0.99611276]\n",
            " [0.9961009 ]\n",
            " [0.00592329]]\n",
            "Step: 8243 -> Loss: 0.004336553625762463 -> Predictions: [[0.00359737]\n",
            " [0.99611276]\n",
            " [0.996101  ]\n",
            " [0.00592326]]\n",
            "Step: 8244 -> Loss: 0.00433653499931097 -> Predictions: [[0.00359736]\n",
            " [0.99611276]\n",
            " [0.996101  ]\n",
            " [0.00592323]]\n",
            "Step: 8245 -> Loss: 0.004336514975875616 -> Predictions: [[0.00359734]\n",
            " [0.99611276]\n",
            " [0.996101  ]\n",
            " [0.0059232 ]]\n",
            "Step: 8246 -> Loss: 0.0043364935554564 -> Predictions: [[0.00359732]\n",
            " [0.99611276]\n",
            " [0.996101  ]\n",
            " [0.00592317]]\n",
            "Step: 8247 -> Loss: 0.004336472600698471 -> Predictions: [[0.00359731]\n",
            " [0.9961128 ]\n",
            " [0.996101  ]\n",
            " [0.00592314]]\n",
            "Step: 8248 -> Loss: 0.004336453974246979 -> Predictions: [[0.00359729]\n",
            " [0.9961128 ]\n",
            " [0.996101  ]\n",
            " [0.00592312]]\n",
            "Step: 8249 -> Loss: 0.0043364353477954865 -> Predictions: [[0.00359728]\n",
            " [0.9961128 ]\n",
            " [0.996101  ]\n",
            " [0.00592308]]\n",
            "Step: 8250 -> Loss: 0.004336412530392408 -> Predictions: [[0.00359726]\n",
            " [0.9961128 ]\n",
            " [0.99610114]\n",
            " [0.00592305]]\n",
            "Step: 8251 -> Loss: 0.004336392041295767 -> Predictions: [[0.00359724]\n",
            " [0.9961128 ]\n",
            " [0.99610114]\n",
            " [0.00592303]]\n",
            "Step: 8252 -> Loss: 0.004336374346166849 -> Predictions: [[0.00359722]\n",
            " [0.9961128 ]\n",
            " [0.99610114]\n",
            " [0.00592299]]\n",
            "Step: 8253 -> Loss: 0.004336352460086346 -> Predictions: [[0.00359721]\n",
            " [0.9961128 ]\n",
            " [0.99610114]\n",
            " [0.00592296]]\n",
            "Step: 8254 -> Loss: 0.004336332902312279 -> Predictions: [[0.00359719]\n",
            " [0.99611294]\n",
            " [0.99610114]\n",
            " [0.00592293]]\n",
            "Step: 8255 -> Loss: 0.004336313344538212 -> Predictions: [[0.00359718]\n",
            " [0.99611294]\n",
            " [0.99610114]\n",
            " [0.0059229 ]]\n",
            "Step: 8256 -> Loss: 0.004336291458457708 -> Predictions: [[0.00359716]\n",
            " [0.99611294]\n",
            " [0.99610114]\n",
            " [0.00592287]]\n",
            "Step: 8257 -> Loss: 0.004336272832006216 -> Predictions: [[0.00359715]\n",
            " [0.99611294]\n",
            " [0.99610126]\n",
            " [0.00592284]]\n",
            "Step: 8258 -> Loss: 0.004336253274232149 -> Predictions: [[0.00359713]\n",
            " [0.99611294]\n",
            " [0.99610126]\n",
            " [0.00592282]]\n",
            "Step: 8259 -> Loss: 0.00433623231947422 -> Predictions: [[0.00359711]\n",
            " [0.99611294]\n",
            " [0.99610126]\n",
            " [0.00592278]]\n",
            "Step: 8260 -> Loss: 0.004336209502071142 -> Predictions: [[0.0035971 ]\n",
            " [0.99611294]\n",
            " [0.99610126]\n",
            " [0.00592275]]\n",
            "Step: 8261 -> Loss: 0.004336189944297075 -> Predictions: [[0.00359708]\n",
            " [0.99611306]\n",
            " [0.99610126]\n",
            " [0.00592272]]\n",
            "Step: 8262 -> Loss: 0.004336172249168158 -> Predictions: [[0.00359707]\n",
            " [0.99611306]\n",
            " [0.99610126]\n",
            " [0.0059227 ]]\n",
            "Step: 8263 -> Loss: 0.004336151294410229 -> Predictions: [[0.00359705]\n",
            " [0.99611306]\n",
            " [0.99610126]\n",
            " [0.00592266]]\n",
            "Step: 8264 -> Loss: 0.004336133599281311 -> Predictions: [[0.00359703]\n",
            " [0.99611306]\n",
            " [0.9961014 ]\n",
            " [0.00592264]]\n",
            "Step: 8265 -> Loss: 0.004336110781878233 -> Predictions: [[0.00359702]\n",
            " [0.99611306]\n",
            " [0.9961014 ]\n",
            " [0.0059226 ]]\n",
            "Step: 8266 -> Loss: 0.004336089361459017 -> Predictions: [[0.003597  ]\n",
            " [0.99611306]\n",
            " [0.9961014 ]\n",
            " [0.00592258]]\n",
            "Step: 8267 -> Loss: 0.004336071200668812 -> Predictions: [[0.00359698]\n",
            " [0.99611306]\n",
            " [0.9961014 ]\n",
            " [0.00592255]]\n",
            "Step: 8268 -> Loss: 0.0043360511772334576 -> Predictions: [[0.00359697]\n",
            " [0.9961132 ]\n",
            " [0.9961014 ]\n",
            " [0.00592251]]\n",
            "Step: 8269 -> Loss: 0.004336028825491667 -> Predictions: [[0.00359695]\n",
            " [0.9961132 ]\n",
            " [0.9961014 ]\n",
            " [0.00592249]]\n",
            "Step: 8270 -> Loss: 0.0043360092677176 -> Predictions: [[0.00359693]\n",
            " [0.9961132 ]\n",
            " [0.9961014 ]\n",
            " [0.00592246]]\n",
            "Step: 8271 -> Loss: 0.004335988312959671 -> Predictions: [[0.00359691]\n",
            " [0.9961132 ]\n",
            " [0.9961015 ]\n",
            " [0.00592243]]\n",
            "Step: 8272 -> Loss: 0.004335968755185604 -> Predictions: [[0.0035969]\n",
            " [0.9961132]\n",
            " [0.9961015]\n",
            " [0.0059224]]\n",
            "Step: 8273 -> Loss: 0.004335950128734112 -> Predictions: [[0.00359689]\n",
            " [0.9961132 ]\n",
            " [0.9961015 ]\n",
            " [0.00592237]]\n",
            "Step: 8274 -> Loss: 0.004335927776992321 -> Predictions: [[0.00359686]\n",
            " [0.9961133 ]\n",
            " [0.9961015 ]\n",
            " [0.00592234]]\n",
            "Step: 8275 -> Loss: 0.004335908684879541 -> Predictions: [[0.00359685]\n",
            " [0.9961133 ]\n",
            " [0.9961015 ]\n",
            " [0.00592231]]\n",
            "Step: 8276 -> Loss: 0.0043358891271054745 -> Predictions: [[0.00359683]\n",
            " [0.9961133 ]\n",
            " [0.9961015 ]\n",
            " [0.00592228]]\n",
            "Step: 8277 -> Loss: 0.004335865844041109 -> Predictions: [[0.00359682]\n",
            " [0.9961133 ]\n",
            " [0.9961016 ]\n",
            " [0.00592225]]\n",
            "Step: 8278 -> Loss: 0.004335849080234766 -> Predictions: [[0.00359681]\n",
            " [0.9961133 ]\n",
            " [0.9961016 ]\n",
            " [0.00592222]]\n",
            "Step: 8279 -> Loss: 0.004335829988121986 -> Predictions: [[0.00359678]\n",
            " [0.9961133 ]\n",
            " [0.9961016 ]\n",
            " [0.00592219]]\n",
            "Step: 8280 -> Loss: 0.004335807170718908 -> Predictions: [[0.00359677]\n",
            " [0.9961133 ]\n",
            " [0.9961016 ]\n",
            " [0.00592216]]\n",
            "Step: 8281 -> Loss: 0.004335786681622267 -> Predictions: [[0.00359675]\n",
            " [0.9961134 ]\n",
            " [0.9961016 ]\n",
            " [0.00592213]]\n",
            "Step: 8282 -> Loss: 0.004335767589509487 -> Predictions: [[0.00359674]\n",
            " [0.9961134 ]\n",
            " [0.9961016 ]\n",
            " [0.0059221 ]]\n",
            "Step: 8283 -> Loss: 0.00433574803173542 -> Predictions: [[0.00359672]\n",
            " [0.9961134 ]\n",
            " [0.9961016 ]\n",
            " [0.00592207]]\n",
            "Step: 8284 -> Loss: 0.004335728473961353 -> Predictions: [[0.0035967 ]\n",
            " [0.9961134 ]\n",
            " [0.9961016 ]\n",
            " [0.00592204]]\n",
            "Step: 8285 -> Loss: 0.004335707984864712 -> Predictions: [[0.00359669]\n",
            " [0.9961134 ]\n",
            " [0.99610174]\n",
            " [0.00592201]]\n",
            "Step: 8286 -> Loss: 0.004335685633122921 -> Predictions: [[0.00359667]\n",
            " [0.9961134 ]\n",
            " [0.99610174]\n",
            " [0.00592198]]\n",
            "Step: 8287 -> Loss: 0.004335668403655291 -> Predictions: [[0.00359666]\n",
            " [0.9961134 ]\n",
            " [0.99610174]\n",
            " [0.00592196]]\n",
            "Step: 8288 -> Loss: 0.0043356460519135 -> Predictions: [[0.00359664]\n",
            " [0.99611354]\n",
            " [0.99610174]\n",
            " [0.00592192]]\n",
            "Step: 8289 -> Loss: 0.004335626028478146 -> Predictions: [[0.00359662]\n",
            " [0.99611354]\n",
            " [0.99610174]\n",
            " [0.00592189]]\n",
            "Step: 8290 -> Loss: 0.004335606005042791 -> Predictions: [[0.00359661]\n",
            " [0.99611354]\n",
            " [0.99610174]\n",
            " [0.00592186]]\n",
            "Step: 8291 -> Loss: 0.004335584584623575 -> Predictions: [[0.00359659]\n",
            " [0.99611354]\n",
            " [0.99610186]\n",
            " [0.00592183]]\n",
            "Step: 8292 -> Loss: 0.004335563629865646 -> Predictions: [[0.00359657]\n",
            " [0.99611354]\n",
            " [0.99610186]\n",
            " [0.0059218 ]]\n",
            "Step: 8293 -> Loss: 0.004335545934736729 -> Predictions: [[0.00359656]\n",
            " [0.99611354]\n",
            " [0.99610186]\n",
            " [0.00592178]]\n",
            "Step: 8294 -> Loss: 0.004335527308285236 -> Predictions: [[0.00359654]\n",
            " [0.99611354]\n",
            " [0.99610186]\n",
            " [0.00592175]]\n",
            "Step: 8295 -> Loss: 0.004335504490882158 -> Predictions: [[0.00359652]\n",
            " [0.99611366]\n",
            " [0.99610186]\n",
            " [0.00592171]]\n",
            "Step: 8296 -> Loss: 0.004335485398769379 -> Predictions: [[0.00359651]\n",
            " [0.99611366]\n",
            " [0.99610186]\n",
            " [0.00592169]]\n",
            "Step: 8297 -> Loss: 0.004335465840995312 -> Predictions: [[0.00359649]\n",
            " [0.99611366]\n",
            " [0.99610186]\n",
            " [0.00592166]]\n",
            "Step: 8298 -> Loss: 0.004335443023592234 -> Predictions: [[0.00359647]\n",
            " [0.99611366]\n",
            " [0.996102  ]\n",
            " [0.00592163]]\n",
            "Step: 8299 -> Loss: 0.004335424862802029 -> Predictions: [[0.00359647]\n",
            " [0.99611366]\n",
            " [0.996102  ]\n",
            " [0.0059216 ]]\n",
            "Step: 8300 -> Loss: 0.004335402511060238 -> Predictions: [[0.00359644]\n",
            " [0.99611366]\n",
            " [0.996102  ]\n",
            " [0.00592156]]\n",
            "Step: 8301 -> Loss: 0.0043353852815926075 -> Predictions: [[0.00359643]\n",
            " [0.99611366]\n",
            " [0.996102  ]\n",
            " [0.00592154]]\n",
            "Step: 8302 -> Loss: 0.004335365258157253 -> Predictions: [[0.00359642]\n",
            " [0.9961138 ]\n",
            " [0.996102  ]\n",
            " [0.00592151]]\n",
            "Step: 8303 -> Loss: 0.0043353429064154625 -> Predictions: [[0.00359639]\n",
            " [0.9961138 ]\n",
            " [0.996102  ]\n",
            " [0.00592148]]\n",
            "Step: 8304 -> Loss: 0.004335320089012384 -> Predictions: [[0.00359638]\n",
            " [0.9961138 ]\n",
            " [0.996102  ]\n",
            " [0.00592144]]\n",
            "Step: 8305 -> Loss: 0.004335303325206041 -> Predictions: [[0.00359636]\n",
            " [0.9961138 ]\n",
            " [0.9961021 ]\n",
            " [0.00592142]]\n",
            "Step: 8306 -> Loss: 0.004335281904786825 -> Predictions: [[0.00359635]\n",
            " [0.9961138 ]\n",
            " [0.9961021 ]\n",
            " [0.00592139]]\n",
            "Step: 8307 -> Loss: 0.004335260950028896 -> Predictions: [[0.00359633]\n",
            " [0.9961138 ]\n",
            " [0.9961021 ]\n",
            " [0.00592136]]\n",
            "Step: 8308 -> Loss: 0.004335242323577404 -> Predictions: [[0.00359632]\n",
            " [0.9961138 ]\n",
            " [0.9961021 ]\n",
            " [0.00592133]]\n",
            "Step: 8309 -> Loss: 0.004335222765803337 -> Predictions: [[0.0035963]\n",
            " [0.9961139]\n",
            " [0.9961021]\n",
            " [0.0059213]]\n",
            "Step: 8310 -> Loss: 0.004335200414061546 -> Predictions: [[0.00359628]\n",
            " [0.9961139 ]\n",
            " [0.9961021 ]\n",
            " [0.00592127]]\n",
            "Step: 8311 -> Loss: 0.004335180856287479 -> Predictions: [[0.00359627]\n",
            " [0.9961139 ]\n",
            " [0.9961021 ]\n",
            " [0.00592123]]\n",
            "Step: 8312 -> Loss: 0.0043351612985134125 -> Predictions: [[0.00359625]\n",
            " [0.9961139 ]\n",
            " [0.9961022 ]\n",
            " [0.00592121]]\n",
            "Step: 8313 -> Loss: 0.0043351417407393456 -> Predictions: [[0.00359623]\n",
            " [0.9961139 ]\n",
            " [0.9961022 ]\n",
            " [0.00592118]]\n",
            "Step: 8314 -> Loss: 0.004335124045610428 -> Predictions: [[0.00359622]\n",
            " [0.9961139 ]\n",
            " [0.9961022 ]\n",
            " [0.00592116]]\n",
            "Step: 8315 -> Loss: 0.004335101693868637 -> Predictions: [[0.0035962 ]\n",
            " [0.9961139 ]\n",
            " [0.9961022 ]\n",
            " [0.00592112]]\n",
            "Step: 8316 -> Loss: 0.004335079342126846 -> Predictions: [[0.00359619]\n",
            " [0.996114  ]\n",
            " [0.9961022 ]\n",
            " [0.00592109]]\n",
            "Step: 8317 -> Loss: 0.004335060715675354 -> Predictions: [[0.00359617]\n",
            " [0.996114  ]\n",
            " [0.9961022 ]\n",
            " [0.00592107]]\n",
            "Step: 8318 -> Loss: 0.0043350402265787125 -> Predictions: [[0.00359615]\n",
            " [0.996114  ]\n",
            " [0.99610233]\n",
            " [0.00592103]]\n",
            "Step: 8319 -> Loss: 0.004335022531449795 -> Predictions: [[0.00359614]\n",
            " [0.996114  ]\n",
            " [0.99610233]\n",
            " [0.005921  ]]\n",
            "Step: 8320 -> Loss: 0.004334998782724142 -> Predictions: [[0.00359612]\n",
            " [0.996114  ]\n",
            " [0.99610233]\n",
            " [0.00592097]]\n",
            "Step: 8321 -> Loss: 0.004334980621933937 -> Predictions: [[0.00359611]\n",
            " [0.996114  ]\n",
            " [0.99610233]\n",
            " [0.00592094]]\n",
            "Step: 8322 -> Loss: 0.0043349601328372955 -> Predictions: [[0.00359609]\n",
            " [0.996114  ]\n",
            " [0.99610233]\n",
            " [0.00592091]]\n",
            "Step: 8323 -> Loss: 0.004334939178079367 -> Predictions: [[0.00359607]\n",
            " [0.99611413]\n",
            " [0.99610233]\n",
            " [0.00592088]]\n",
            "Step: 8324 -> Loss: 0.004334916826337576 -> Predictions: [[0.00359605]\n",
            " [0.99611413]\n",
            " [0.99610233]\n",
            " [0.00592085]]\n",
            "Step: 8325 -> Loss: 0.004334898665547371 -> Predictions: [[0.00359604]\n",
            " [0.99611413]\n",
            " [0.99610233]\n",
            " [0.00592083]]\n",
            "Step: 8326 -> Loss: 0.004334879107773304 -> Predictions: [[0.00359602]\n",
            " [0.99611413]\n",
            " [0.99610245]\n",
            " [0.00592079]]\n",
            "Step: 8327 -> Loss: 0.004334857687354088 -> Predictions: [[0.003596  ]\n",
            " [0.99611413]\n",
            " [0.99610245]\n",
            " [0.00592077]]\n",
            "Step: 8328 -> Loss: 0.004334835801273584 -> Predictions: [[0.00359599]\n",
            " [0.99611413]\n",
            " [0.99610245]\n",
            " [0.00592073]]\n",
            "Step: 8329 -> Loss: 0.004334816709160805 -> Predictions: [[0.00359597]\n",
            " [0.99611425]\n",
            " [0.99610245]\n",
            " [0.00592071]]\n",
            "Step: 8330 -> Loss: 0.004334797617048025 -> Predictions: [[0.00359595]\n",
            " [0.99611425]\n",
            " [0.99610245]\n",
            " [0.00592068]]\n",
            "Step: 8331 -> Loss: 0.0043347799219191074 -> Predictions: [[0.00359594]\n",
            " [0.99611425]\n",
            " [0.99610245]\n",
            " [0.00592065]]\n",
            "Step: 8332 -> Loss: 0.0043347603641450405 -> Predictions: [[0.00359593]\n",
            " [0.99611425]\n",
            " [0.9961026 ]\n",
            " [0.00592062]]\n",
            "Step: 8333 -> Loss: 0.004334737081080675 -> Predictions: [[0.0035959 ]\n",
            " [0.99611425]\n",
            " [0.9961026 ]\n",
            " [0.00592059]]\n",
            "Step: 8334 -> Loss: 0.004334716591984034 -> Predictions: [[0.00359589]\n",
            " [0.99611425]\n",
            " [0.9961026 ]\n",
            " [0.00592056]]\n",
            "Step: 8335 -> Loss: 0.004334696102887392 -> Predictions: [[0.00359587]\n",
            " [0.99611425]\n",
            " [0.9961026 ]\n",
            " [0.00592053]]\n",
            "Step: 8336 -> Loss: 0.004334675148129463 -> Predictions: [[0.00359586]\n",
            " [0.9961144 ]\n",
            " [0.9961026 ]\n",
            " [0.0059205 ]]\n",
            "Step: 8337 -> Loss: 0.004334656987339258 -> Predictions: [[0.00359584]\n",
            " [0.9961144 ]\n",
            " [0.9961026 ]\n",
            " [0.00592047]]\n",
            "Step: 8338 -> Loss: 0.004334637429565191 -> Predictions: [[0.00359583]\n",
            " [0.9961144 ]\n",
            " [0.9961026 ]\n",
            " [0.00592044]]\n",
            "Step: 8339 -> Loss: 0.00433461694046855 -> Predictions: [[0.00359581]\n",
            " [0.9961144 ]\n",
            " [0.9961027 ]\n",
            " [0.00592041]]\n",
            "Step: 8340 -> Loss: 0.004334595985710621 -> Predictions: [[0.0035958 ]\n",
            " [0.9961144 ]\n",
            " [0.9961027 ]\n",
            " [0.00592038]]\n",
            "Step: 8341 -> Loss: 0.004334577359259129 -> Predictions: [[0.00359578]\n",
            " [0.9961144 ]\n",
            " [0.9961027 ]\n",
            " [0.00592036]]\n",
            "Step: 8342 -> Loss: 0.004334555938839912 -> Predictions: [[0.00359576]\n",
            " [0.9961144 ]\n",
            " [0.9961027 ]\n",
            " [0.00592032]]\n",
            "Step: 8343 -> Loss: 0.004334534518420696 -> Predictions: [[0.00359575]\n",
            " [0.9961145 ]\n",
            " [0.9961027 ]\n",
            " [0.00592029]]\n",
            "Step: 8344 -> Loss: 0.0043345168232917786 -> Predictions: [[0.00359573]\n",
            " [0.9961145 ]\n",
            " [0.9961027 ]\n",
            " [0.00592026]]\n",
            "Step: 8345 -> Loss: 0.0043344940058887005 -> Predictions: [[0.00359572]\n",
            " [0.9961145 ]\n",
            " [0.9961027 ]\n",
            " [0.00592023]]\n",
            "Step: 8346 -> Loss: 0.004334473516792059 -> Predictions: [[0.0035957]\n",
            " [0.9961145]\n",
            " [0.9961028]\n",
            " [0.0059202]]\n",
            "Step: 8347 -> Loss: 0.004334455356001854 -> Predictions: [[0.00359568]\n",
            " [0.9961145 ]\n",
            " [0.9961028 ]\n",
            " [0.00592017]]\n",
            "Step: 8348 -> Loss: 0.004334435798227787 -> Predictions: [[0.00359567]\n",
            " [0.9961145 ]\n",
            " [0.9961028 ]\n",
            " [0.00592014]]\n",
            "Step: 8349 -> Loss: 0.0043344153091311455 -> Predictions: [[0.00359565]\n",
            " [0.9961145 ]\n",
            " [0.9961028 ]\n",
            " [0.00592011]]\n",
            "Step: 8350 -> Loss: 0.004334392957389355 -> Predictions: [[0.00359563]\n",
            " [0.9961146 ]\n",
            " [0.9961028 ]\n",
            " [0.00592008]]\n",
            "Step: 8351 -> Loss: 0.004334375262260437 -> Predictions: [[0.00359562]\n",
            " [0.9961146 ]\n",
            " [0.9961028 ]\n",
            " [0.00592006]]\n",
            "Step: 8352 -> Loss: 0.004334353841841221 -> Predictions: [[0.0035956 ]\n",
            " [0.9961146 ]\n",
            " [0.9961028 ]\n",
            " [0.00592002]]\n",
            "Step: 8353 -> Loss: 0.004334333352744579 -> Predictions: [[0.00359559]\n",
            " [0.9961146 ]\n",
            " [0.9961029 ]\n",
            " [0.00591999]]\n",
            "Step: 8354 -> Loss: 0.004334310069680214 -> Predictions: [[0.00359556]\n",
            " [0.9961146 ]\n",
            " [0.9961029 ]\n",
            " [0.00591996]]\n",
            "Step: 8355 -> Loss: 0.004334293771535158 -> Predictions: [[0.00359555]\n",
            " [0.9961146 ]\n",
            " [0.9961029 ]\n",
            " [0.00591994]]\n",
            "Step: 8356 -> Loss: 0.004334273748099804 -> Predictions: [[0.00359553]\n",
            " [0.9961146 ]\n",
            " [0.9961029 ]\n",
            " [0.00591991]]\n",
            "Step: 8357 -> Loss: 0.0043342518620193005 -> Predictions: [[0.00359552]\n",
            " [0.99611473]\n",
            " [0.9961029 ]\n",
            " [0.00591987]]\n",
            "Step: 8358 -> Loss: 0.0043342323042452335 -> Predictions: [[0.0035955 ]\n",
            " [0.99611473]\n",
            " [0.9961029 ]\n",
            " [0.00591984]]\n",
            "Step: 8359 -> Loss: 0.004334212746471167 -> Predictions: [[0.00359549]\n",
            " [0.99611473]\n",
            " [0.9961029 ]\n",
            " [0.00591981]]\n",
            "Step: 8360 -> Loss: 0.004334191791713238 -> Predictions: [[0.00359547]\n",
            " [0.99611473]\n",
            " [0.99610305]\n",
            " [0.00591979]]\n",
            "Step: 8361 -> Loss: 0.004334172699600458 -> Predictions: [[0.00359545]\n",
            " [0.99611473]\n",
            " [0.99610305]\n",
            " [0.00591976]]\n",
            "Step: 8362 -> Loss: 0.004334152210503817 -> Predictions: [[0.00359544]\n",
            " [0.99611473]\n",
            " [0.99610305]\n",
            " [0.00591973]]\n",
            "Step: 8363 -> Loss: 0.00433413265272975 -> Predictions: [[0.00359542]\n",
            " [0.99611473]\n",
            " [0.99610305]\n",
            " [0.00591969]]\n",
            "Step: 8364 -> Loss: 0.004334113094955683 -> Predictions: [[0.00359541]\n",
            " [0.99611485]\n",
            " [0.99610305]\n",
            " [0.00591967]]\n",
            "Step: 8365 -> Loss: 0.004334091674536467 -> Predictions: [[0.00359539]\n",
            " [0.99611485]\n",
            " [0.99610305]\n",
            " [0.00591964]]\n",
            "Step: 8366 -> Loss: 0.004334070719778538 -> Predictions: [[0.00359537]\n",
            " [0.99611485]\n",
            " [0.99610317]\n",
            " [0.00591961]]\n",
            "Step: 8367 -> Loss: 0.0043340506963431835 -> Predictions: [[0.00359536]\n",
            " [0.99611485]\n",
            " [0.99610317]\n",
            " [0.00591958]]\n",
            "Step: 8368 -> Loss: 0.004334031604230404 -> Predictions: [[0.00359534]\n",
            " [0.99611485]\n",
            " [0.99610317]\n",
            " [0.00591954]]\n",
            "Step: 8369 -> Loss: 0.004334011115133762 -> Predictions: [[0.00359533]\n",
            " [0.99611485]\n",
            " [0.99610317]\n",
            " [0.00591952]]\n",
            "Step: 8370 -> Loss: 0.0043339901603758335 -> Predictions: [[0.00359531]\n",
            " [0.99611485]\n",
            " [0.99610317]\n",
            " [0.00591949]]\n",
            "Step: 8371 -> Loss: 0.004333970136940479 -> Predictions: [[0.00359529]\n",
            " [0.99611497]\n",
            " [0.99610317]\n",
            " [0.00591946]]\n",
            "Step: 8372 -> Loss: 0.00433394918218255 -> Predictions: [[0.00359527]\n",
            " [0.99611497]\n",
            " [0.99610317]\n",
            " [0.00591943]]\n",
            "Step: 8373 -> Loss: 0.004333928227424622 -> Predictions: [[0.00359526]\n",
            " [0.99611497]\n",
            " [0.9961033 ]\n",
            " [0.0059194 ]]\n",
            "Step: 8374 -> Loss: 0.004333909600973129 -> Predictions: [[0.00359524]\n",
            " [0.99611497]\n",
            " [0.9961033 ]\n",
            " [0.00591937]]\n",
            "Step: 8375 -> Loss: 0.004333890043199062 -> Predictions: [[0.00359523]\n",
            " [0.99611497]\n",
            " [0.9961033 ]\n",
            " [0.00591934]]\n",
            "Step: 8376 -> Loss: 0.004333869554102421 -> Predictions: [[0.00359521]\n",
            " [0.99611497]\n",
            " [0.9961033 ]\n",
            " [0.00591931]]\n",
            "Step: 8377 -> Loss: 0.004333850461989641 -> Predictions: [[0.00359519]\n",
            " [0.9961151 ]\n",
            " [0.9961033 ]\n",
            " [0.00591928]]\n",
            "Step: 8378 -> Loss: 0.004333827178925276 -> Predictions: [[0.00359518]\n",
            " [0.9961151 ]\n",
            " [0.9961033 ]\n",
            " [0.00591925]]\n",
            "Step: 8379 -> Loss: 0.004333808086812496 -> Predictions: [[0.00359516]\n",
            " [0.9961151 ]\n",
            " [0.9961033 ]\n",
            " [0.00591922]]\n",
            "Step: 8380 -> Loss: 0.004333788529038429 -> Predictions: [[0.00359515]\n",
            " [0.9961151 ]\n",
            " [0.9961034 ]\n",
            " [0.00591919]]\n",
            "Step: 8381 -> Loss: 0.004333768971264362 -> Predictions: [[0.00359513]\n",
            " [0.9961151 ]\n",
            " [0.9961034 ]\n",
            " [0.00591916]]\n",
            "Step: 8382 -> Loss: 0.004333747550845146 -> Predictions: [[0.00359511]\n",
            " [0.9961151 ]\n",
            " [0.9961034 ]\n",
            " [0.00591913]]\n",
            "Step: 8383 -> Loss: 0.004333727527409792 -> Predictions: [[0.0035951]\n",
            " [0.9961151]\n",
            " [0.9961034]\n",
            " [0.0059191]]\n",
            "Step: 8384 -> Loss: 0.004333708435297012 -> Predictions: [[0.00359508]\n",
            " [0.9961152 ]\n",
            " [0.9961034 ]\n",
            " [0.00591907]]\n",
            "Step: 8385 -> Loss: 0.004333688877522945 -> Predictions: [[0.00359507]\n",
            " [0.9961152 ]\n",
            " [0.9961034 ]\n",
            " [0.00591904]]\n",
            "Step: 8386 -> Loss: 0.004333667457103729 -> Predictions: [[0.00359505]\n",
            " [0.9961152 ]\n",
            " [0.9961034 ]\n",
            " [0.00591901]]\n",
            "Step: 8387 -> Loss: 0.0043336465023458 -> Predictions: [[0.00359503]\n",
            " [0.9961152 ]\n",
            " [0.9961035 ]\n",
            " [0.00591899]]\n",
            "Step: 8388 -> Loss: 0.0043336269445717335 -> Predictions: [[0.00359501]\n",
            " [0.9961152 ]\n",
            " [0.9961035 ]\n",
            " [0.00591896]]\n",
            "Step: 8389 -> Loss: 0.00433360505849123 -> Predictions: [[0.003595  ]\n",
            " [0.9961152 ]\n",
            " [0.9961035 ]\n",
            " [0.00591892]]\n",
            "Step: 8390 -> Loss: 0.004333586432039738 -> Predictions: [[0.00359498]\n",
            " [0.9961152 ]\n",
            " [0.9961035 ]\n",
            " [0.00591889]]\n",
            "Step: 8391 -> Loss: 0.004333567339926958 -> Predictions: [[0.00359497]\n",
            " [0.9961153 ]\n",
            " [0.9961035 ]\n",
            " [0.00591887]]\n",
            "Step: 8392 -> Loss: 0.0043335468508303165 -> Predictions: [[0.00359495]\n",
            " [0.9961153 ]\n",
            " [0.9961035 ]\n",
            " [0.00591884]]\n",
            "Step: 8393 -> Loss: 0.004333525896072388 -> Predictions: [[0.00359493]\n",
            " [0.9961153 ]\n",
            " [0.9961035 ]\n",
            " [0.00591881]]\n",
            "Step: 8394 -> Loss: 0.004333506338298321 -> Predictions: [[0.00359492]\n",
            " [0.9961153 ]\n",
            " [0.99610364]\n",
            " [0.00591877]]\n",
            "Step: 8395 -> Loss: 0.0043334863148629665 -> Predictions: [[0.0035949 ]\n",
            " [0.9961153 ]\n",
            " [0.99610364]\n",
            " [0.00591875]]\n",
            "Step: 8396 -> Loss: 0.004333466291427612 -> Predictions: [[0.00359489]\n",
            " [0.9961153 ]\n",
            " [0.99610364]\n",
            " [0.00591872]]\n",
            "Step: 8397 -> Loss: 0.004333444871008396 -> Predictions: [[0.00359487]\n",
            " [0.9961153 ]\n",
            " [0.99610364]\n",
            " [0.00591869]]\n",
            "Step: 8398 -> Loss: 0.004333426244556904 -> Predictions: [[0.00359485]\n",
            " [0.99611545]\n",
            " [0.99610364]\n",
            " [0.00591866]]\n",
            "Step: 8399 -> Loss: 0.004333405289798975 -> Predictions: [[0.00359484]\n",
            " [0.99611545]\n",
            " [0.99610364]\n",
            " [0.00591863]]\n",
            "Step: 8400 -> Loss: 0.0043333834037184715 -> Predictions: [[0.00359482]\n",
            " [0.99611545]\n",
            " [0.99610364]\n",
            " [0.0059186 ]]\n",
            "Step: 8401 -> Loss: 0.004333366174250841 -> Predictions: [[0.0035948 ]\n",
            " [0.99611545]\n",
            " [0.99610376]\n",
            " [0.00591857]]\n",
            "Step: 8402 -> Loss: 0.004333342891186476 -> Predictions: [[0.00359479]\n",
            " [0.99611545]\n",
            " [0.99610376]\n",
            " [0.00591854]]\n",
            "Step: 8403 -> Loss: 0.004333324730396271 -> Predictions: [[0.00359477]\n",
            " [0.99611545]\n",
            " [0.99610376]\n",
            " [0.00591851]]\n",
            "Step: 8404 -> Loss: 0.00433330237865448 -> Predictions: [[0.00359475]\n",
            " [0.99611545]\n",
            " [0.99610376]\n",
            " [0.00591848]]\n",
            "Step: 8405 -> Loss: 0.0043332832865417 -> Predictions: [[0.00359474]\n",
            " [0.99611557]\n",
            " [0.99610376]\n",
            " [0.00591845]]\n",
            "Step: 8406 -> Loss: 0.00433326605707407 -> Predictions: [[0.00359472]\n",
            " [0.99611557]\n",
            " [0.99610376]\n",
            " [0.00591842]]\n",
            "Step: 8407 -> Loss: 0.0043332441709935665 -> Predictions: [[0.00359471]\n",
            " [0.99611557]\n",
            " [0.99610376]\n",
            " [0.00591839]]\n",
            "Step: 8408 -> Loss: 0.004333224147558212 -> Predictions: [[0.00359469]\n",
            " [0.99611557]\n",
            " [0.9961039 ]\n",
            " [0.00591836]]\n",
            "Step: 8409 -> Loss: 0.004333202727138996 -> Predictions: [[0.00359467]\n",
            " [0.99611557]\n",
            " [0.9961039 ]\n",
            " [0.00591833]]\n",
            "Step: 8410 -> Loss: 0.004333182238042355 -> Predictions: [[0.00359466]\n",
            " [0.99611557]\n",
            " [0.9961039 ]\n",
            " [0.0059183 ]]\n",
            "Step: 8411 -> Loss: 0.00433316407725215 -> Predictions: [[0.00359464]\n",
            " [0.99611557]\n",
            " [0.9961039 ]\n",
            " [0.00591827]]\n",
            "Step: 8412 -> Loss: 0.004333142656832933 -> Predictions: [[0.00359462]\n",
            " [0.9961157 ]\n",
            " [0.9961039 ]\n",
            " [0.00591824]]\n",
            "Step: 8413 -> Loss: 0.004333122633397579 -> Predictions: [[0.00359461]\n",
            " [0.9961157 ]\n",
            " [0.9961039 ]\n",
            " [0.00591821]]\n",
            "Step: 8414 -> Loss: 0.00433310167863965 -> Predictions: [[0.00359459]\n",
            " [0.9961157 ]\n",
            " [0.9961039 ]\n",
            " [0.00591818]]\n",
            "Step: 8415 -> Loss: 0.004333081655204296 -> Predictions: [[0.00359458]\n",
            " [0.9961157 ]\n",
            " [0.996104  ]\n",
            " [0.00591815]]\n",
            "Step: 8416 -> Loss: 0.004333061631768942 -> Predictions: [[0.00359456]\n",
            " [0.9961157 ]\n",
            " [0.996104  ]\n",
            " [0.00591813]]\n",
            "Step: 8417 -> Loss: 0.004333042539656162 -> Predictions: [[0.00359454]\n",
            " [0.9961157 ]\n",
            " [0.996104  ]\n",
            " [0.0059181 ]]\n",
            "Step: 8418 -> Loss: 0.004333022981882095 -> Predictions: [[0.00359453]\n",
            " [0.9961157 ]\n",
            " [0.996104  ]\n",
            " [0.00591807]]\n",
            "Step: 8419 -> Loss: 0.004333002492785454 -> Predictions: [[0.00359451]\n",
            " [0.9961158 ]\n",
            " [0.996104  ]\n",
            " [0.00591804]]\n",
            "Step: 8420 -> Loss: 0.00433298060670495 -> Predictions: [[0.0035945]\n",
            " [0.9961158]\n",
            " [0.996104 ]\n",
            " [0.005918 ]]\n",
            "Step: 8421 -> Loss: 0.004332963842898607 -> Predictions: [[0.00359449]\n",
            " [0.9961158 ]\n",
            " [0.9961041 ]\n",
            " [0.00591798]]\n",
            "Step: 8422 -> Loss: 0.004332941956818104 -> Predictions: [[0.00359446]\n",
            " [0.9961158 ]\n",
            " [0.9961041 ]\n",
            " [0.00591795]]\n",
            "Step: 8423 -> Loss: 0.004332921002060175 -> Predictions: [[0.00359445]\n",
            " [0.9961158 ]\n",
            " [0.9961041 ]\n",
            " [0.00591792]]\n",
            "Step: 8424 -> Loss: 0.004332899581640959 -> Predictions: [[0.00359443]\n",
            " [0.9961158 ]\n",
            " [0.9961041 ]\n",
            " [0.00591788]]\n",
            "Step: 8425 -> Loss: 0.004332882352173328 -> Predictions: [[0.00359442]\n",
            " [0.9961158 ]\n",
            " [0.9961041 ]\n",
            " [0.00591786]]\n",
            "Step: 8426 -> Loss: 0.004332860000431538 -> Predictions: [[0.0035944 ]\n",
            " [0.9961159 ]\n",
            " [0.9961041 ]\n",
            " [0.00591783]]\n",
            "Step: 8427 -> Loss: 0.0043328432366251945 -> Predictions: [[0.00359438]\n",
            " [0.9961159 ]\n",
            " [0.9961041 ]\n",
            " [0.0059178 ]]\n",
            "Step: 8428 -> Loss: 0.004332819953560829 -> Predictions: [[0.00359437]\n",
            " [0.9961159 ]\n",
            " [0.99610424]\n",
            " [0.00591777]]\n",
            "Step: 8429 -> Loss: 0.004332798067480326 -> Predictions: [[0.00359435]\n",
            " [0.9961159 ]\n",
            " [0.99610424]\n",
            " [0.00591774]]\n",
            "Step: 8430 -> Loss: 0.004332778975367546 -> Predictions: [[0.00359433]\n",
            " [0.9961159 ]\n",
            " [0.99610424]\n",
            " [0.00591771]]\n",
            "Step: 8431 -> Loss: 0.004332760348916054 -> Predictions: [[0.00359432]\n",
            " [0.9961159 ]\n",
            " [0.99610424]\n",
            " [0.00591768]]\n",
            "Step: 8432 -> Loss: 0.004332740791141987 -> Predictions: [[0.0035943 ]\n",
            " [0.9961159 ]\n",
            " [0.99610424]\n",
            " [0.00591765]]\n",
            "Step: 8433 -> Loss: 0.0043327175080776215 -> Predictions: [[0.00359428]\n",
            " [0.99611604]\n",
            " [0.99610424]\n",
            " [0.00591762]]\n",
            "Step: 8434 -> Loss: 0.004332698415964842 -> Predictions: [[0.00359427]\n",
            " [0.99611604]\n",
            " [0.99610424]\n",
            " [0.00591758]]\n",
            "Step: 8435 -> Loss: 0.0043326779268682 -> Predictions: [[0.00359425]\n",
            " [0.99611604]\n",
            " [0.99610436]\n",
            " [0.00591756]]\n",
            "Step: 8436 -> Loss: 0.004332659766077995 -> Predictions: [[0.00359423]\n",
            " [0.99611604]\n",
            " [0.99610436]\n",
            " [0.00591753]]\n",
            "Step: 8437 -> Loss: 0.0043326388113200665 -> Predictions: [[0.00359422]\n",
            " [0.99611604]\n",
            " [0.99610436]\n",
            " [0.0059175 ]]\n",
            "Step: 8438 -> Loss: 0.004332617856562138 -> Predictions: [[0.00359421]\n",
            " [0.99611604]\n",
            " [0.99610436]\n",
            " [0.00591747]]\n",
            "Step: 8439 -> Loss: 0.004332597833126783 -> Predictions: [[0.00359418]\n",
            " [0.99611616]\n",
            " [0.99610436]\n",
            " [0.00591744]]\n",
            "Step: 8440 -> Loss: 0.004332577809691429 -> Predictions: [[0.00359417]\n",
            " [0.99611616]\n",
            " [0.99610436]\n",
            " [0.00591741]]\n",
            "Step: 8441 -> Loss: 0.004332554992288351 -> Predictions: [[0.00359415]\n",
            " [0.99611616]\n",
            " [0.99610436]\n",
            " [0.00591738]]\n",
            "Step: 8442 -> Loss: 0.004332538694143295 -> Predictions: [[0.00359414]\n",
            " [0.99611616]\n",
            " [0.9961045 ]\n",
            " [0.00591736]]\n",
            "Step: 8443 -> Loss: 0.004332520067691803 -> Predictions: [[0.00359412]\n",
            " [0.99611616]\n",
            " [0.9961045 ]\n",
            " [0.00591733]]\n",
            "Step: 8444 -> Loss: 0.004332498647272587 -> Predictions: [[0.00359411]\n",
            " [0.99611616]\n",
            " [0.9961045 ]\n",
            " [0.0059173 ]]\n",
            "Step: 8445 -> Loss: 0.004332475829869509 -> Predictions: [[0.00359409]\n",
            " [0.99611616]\n",
            " [0.9961045 ]\n",
            " [0.00591726]]\n",
            "Step: 8446 -> Loss: 0.004332455340772867 -> Predictions: [[0.00359407]\n",
            " [0.9961163 ]\n",
            " [0.9961045 ]\n",
            " [0.00591723]]\n",
            "Step: 8447 -> Loss: 0.004332433454692364 -> Predictions: [[0.00359406]\n",
            " [0.9961163 ]\n",
            " [0.9961045 ]\n",
            " [0.0059172 ]]\n",
            "Step: 8448 -> Loss: 0.004332418087869883 -> Predictions: [[0.00359405]\n",
            " [0.9961163 ]\n",
            " [0.9961045 ]\n",
            " [0.00591718]]\n",
            "Step: 8449 -> Loss: 0.004332395736128092 -> Predictions: [[0.00359402]\n",
            " [0.9961163 ]\n",
            " [0.9961046 ]\n",
            " [0.00591714]]\n",
            "Step: 8450 -> Loss: 0.004332374781370163 -> Predictions: [[0.00359401]\n",
            " [0.9961163 ]\n",
            " [0.9961046 ]\n",
            " [0.00591712]]\n",
            "Step: 8451 -> Loss: 0.004332354292273521 -> Predictions: [[0.00359399]\n",
            " [0.9961163 ]\n",
            " [0.9961046 ]\n",
            " [0.00591708]]\n",
            "Step: 8452 -> Loss: 0.004332335665822029 -> Predictions: [[0.00359398]\n",
            " [0.9961163 ]\n",
            " [0.9961046 ]\n",
            " [0.00591705]]\n",
            "Step: 8453 -> Loss: 0.004332315176725388 -> Predictions: [[0.00359396]\n",
            " [0.9961164 ]\n",
            " [0.9961046 ]\n",
            " [0.00591703]]\n",
            "Step: 8454 -> Loss: 0.004332293290644884 -> Predictions: [[0.00359394]\n",
            " [0.9961164 ]\n",
            " [0.9961046 ]\n",
            " [0.00591699]]\n",
            "Step: 8455 -> Loss: 0.004332275595515966 -> Predictions: [[0.00359392]\n",
            " [0.9961164 ]\n",
            " [0.9961046 ]\n",
            " [0.00591697]]\n",
            "Step: 8456 -> Loss: 0.004332255572080612 -> Predictions: [[0.00359391]\n",
            " [0.9961164 ]\n",
            " [0.9961047 ]\n",
            " [0.00591694]]\n",
            "Step: 8457 -> Loss: 0.004332235082983971 -> Predictions: [[0.00359389]\n",
            " [0.9961164 ]\n",
            " [0.9961047 ]\n",
            " [0.00591691]]\n",
            "Step: 8458 -> Loss: 0.00433221273124218 -> Predictions: [[0.00359388]\n",
            " [0.9961164 ]\n",
            " [0.9961047 ]\n",
            " [0.00591688]]\n",
            "Step: 8459 -> Loss: 0.0043321941047906876 -> Predictions: [[0.00359386]\n",
            " [0.9961164 ]\n",
            " [0.9961047 ]\n",
            " [0.00591685]]\n",
            "Step: 8460 -> Loss: 0.004332174547016621 -> Predictions: [[0.00359385]\n",
            " [0.9961165 ]\n",
            " [0.9961047 ]\n",
            " [0.00591682]]\n",
            "Step: 8461 -> Loss: 0.004332154057919979 -> Predictions: [[0.00359383]\n",
            " [0.9961165 ]\n",
            " [0.9961047 ]\n",
            " [0.00591679]]\n",
            "Step: 8462 -> Loss: 0.004332132171839476 -> Predictions: [[0.00359381]\n",
            " [0.9961165 ]\n",
            " [0.9961047 ]\n",
            " [0.00591676]]\n",
            "Step: 8463 -> Loss: 0.004332114011049271 -> Predictions: [[0.0035938 ]\n",
            " [0.9961165 ]\n",
            " [0.99610484]\n",
            " [0.00591673]]\n",
            "Step: 8464 -> Loss: 0.004332096315920353 -> Predictions: [[0.00359378]\n",
            " [0.9961165 ]\n",
            " [0.99610484]\n",
            " [0.00591671]]\n",
            "Step: 8465 -> Loss: 0.0043320725671947 -> Predictions: [[0.00359376]\n",
            " [0.9961165 ]\n",
            " [0.99610484]\n",
            " [0.00591667]]\n",
            "Step: 8466 -> Loss: 0.00433205533772707 -> Predictions: [[0.00359375]\n",
            " [0.9961165 ]\n",
            " [0.99610484]\n",
            " [0.00591665]]\n",
            "Step: 8467 -> Loss: 0.0043320320546627045 -> Predictions: [[0.00359373]\n",
            " [0.99611664]\n",
            " [0.99610484]\n",
            " [0.00591661]]\n",
            "Step: 8468 -> Loss: 0.0043320124968886375 -> Predictions: [[0.00359371]\n",
            " [0.99611664]\n",
            " [0.99610484]\n",
            " [0.00591658]]\n",
            "Step: 8469 -> Loss: 0.0043319957330822945 -> Predictions: [[0.0035937 ]\n",
            " [0.99611664]\n",
            " [0.99610484]\n",
            " [0.00591655]]\n",
            "Step: 8470 -> Loss: 0.004331972915679216 -> Predictions: [[0.00359368]\n",
            " [0.99611664]\n",
            " [0.99610496]\n",
            " [0.00591652]]\n",
            "Step: 8471 -> Loss: 0.004331952426582575 -> Predictions: [[0.00359367]\n",
            " [0.99611664]\n",
            " [0.99610496]\n",
            " [0.00591649]]\n",
            "Step: 8472 -> Loss: 0.004331931471824646 -> Predictions: [[0.00359365]\n",
            " [0.99611664]\n",
            " [0.99610496]\n",
            " [0.00591646]]\n",
            "Step: 8473 -> Loss: 0.00433191005140543 -> Predictions: [[0.00359363]\n",
            " [0.99611664]\n",
            " [0.99610496]\n",
            " [0.00591643]]\n",
            "Step: 8474 -> Loss: 0.0043318928219377995 -> Predictions: [[0.00359362]\n",
            " [0.99611676]\n",
            " [0.99610496]\n",
            " [0.00591641]]\n",
            "Step: 8475 -> Loss: 0.004331870935857296 -> Predictions: [[0.0035936 ]\n",
            " [0.99611676]\n",
            " [0.99610496]\n",
            " [0.00591637]]\n",
            "Step: 8476 -> Loss: 0.00433184951543808 -> Predictions: [[0.00359358]\n",
            " [0.99611676]\n",
            " [0.9961051 ]\n",
            " [0.00591634]]\n",
            "Step: 8477 -> Loss: 0.004331833217293024 -> Predictions: [[0.00359357]\n",
            " [0.99611676]\n",
            " [0.9961051 ]\n",
            " [0.00591632]]\n",
            "Step: 8478 -> Loss: 0.0043318127281963825 -> Predictions: [[0.00359355]\n",
            " [0.99611676]\n",
            " [0.9961051 ]\n",
            " [0.00591629]]\n",
            "Step: 8479 -> Loss: 0.004331791773438454 -> Predictions: [[0.00359354]\n",
            " [0.99611676]\n",
            " [0.9961051 ]\n",
            " [0.00591626]]\n",
            "Step: 8480 -> Loss: 0.004331771284341812 -> Predictions: [[0.00359352]\n",
            " [0.9961169 ]\n",
            " [0.9961051 ]\n",
            " [0.00591623]]\n",
            "Step: 8481 -> Loss: 0.004331750795245171 -> Predictions: [[0.00359351]\n",
            " [0.9961169 ]\n",
            " [0.9961051 ]\n",
            " [0.0059162 ]]\n",
            "Step: 8482 -> Loss: 0.004331731237471104 -> Predictions: [[0.00359349]\n",
            " [0.9961169 ]\n",
            " [0.9961051 ]\n",
            " [0.00591617]]\n",
            "Step: 8483 -> Loss: 0.004331707488745451 -> Predictions: [[0.00359347]\n",
            " [0.9961169 ]\n",
            " [0.9961052 ]\n",
            " [0.00591614]]\n",
            "Step: 8484 -> Loss: 0.004331688862293959 -> Predictions: [[0.00359345]\n",
            " [0.9961169 ]\n",
            " [0.9961052 ]\n",
            " [0.0059161 ]]\n",
            "Step: 8485 -> Loss: 0.004331669304519892 -> Predictions: [[0.00359344]\n",
            " [0.9961169 ]\n",
            " [0.9961052 ]\n",
            " [0.00591608]]\n",
            "Step: 8486 -> Loss: 0.0043316492810845375 -> Predictions: [[0.00359342]\n",
            " [0.9961169 ]\n",
            " [0.9961052 ]\n",
            " [0.00591605]]\n",
            "Step: 8487 -> Loss: 0.004331629257649183 -> Predictions: [[0.00359341]\n",
            " [0.9961169 ]\n",
            " [0.9961052 ]\n",
            " [0.00591602]]\n",
            "Step: 8488 -> Loss: 0.004331608302891254 -> Predictions: [[0.00359339]\n",
            " [0.996117  ]\n",
            " [0.9961052 ]\n",
            " [0.00591599]]\n",
            "Step: 8489 -> Loss: 0.004331585951149464 -> Predictions: [[0.00359337]\n",
            " [0.996117  ]\n",
            " [0.9961052 ]\n",
            " [0.00591595]]\n",
            "Step: 8490 -> Loss: 0.004331569653004408 -> Predictions: [[0.00359336]\n",
            " [0.996117  ]\n",
            " [0.99610525]\n",
            " [0.00591593]]\n",
            "Step: 8491 -> Loss: 0.004331550095230341 -> Predictions: [[0.00359334]\n",
            " [0.996117  ]\n",
            " [0.99610525]\n",
            " [0.0059159 ]]\n",
            "Step: 8492 -> Loss: 0.004331527277827263 -> Predictions: [[0.00359333]\n",
            " [0.996117  ]\n",
            " [0.99610525]\n",
            " [0.00591587]]\n",
            "Step: 8493 -> Loss: 0.004331505857408047 -> Predictions: [[0.00359331]\n",
            " [0.996117  ]\n",
            " [0.99610525]\n",
            " [0.00591583]]\n",
            "Step: 8494 -> Loss: 0.004331489559262991 -> Predictions: [[0.00359329]\n",
            " [0.9961171 ]\n",
            " [0.99610525]\n",
            " [0.00591581]]\n",
            "Step: 8495 -> Loss: 0.004331468138843775 -> Predictions: [[0.00359328]\n",
            " [0.9961171 ]\n",
            " [0.99610525]\n",
            " [0.00591578]]\n",
            "Step: 8496 -> Loss: 0.004331445321440697 -> Predictions: [[0.00359326]\n",
            " [0.9961171 ]\n",
            " [0.99610525]\n",
            " [0.00591574]]\n",
            "Step: 8497 -> Loss: 0.004331426694989204 -> Predictions: [[0.00359325]\n",
            " [0.9961171 ]\n",
            " [0.9961054 ]\n",
            " [0.00591572]]\n",
            "Step: 8498 -> Loss: 0.0043314071372151375 -> Predictions: [[0.00359323]\n",
            " [0.9961171 ]\n",
            " [0.9961054 ]\n",
            " [0.00591569]]\n",
            "Step: 8499 -> Loss: 0.004331388510763645 -> Predictions: [[0.00359321]\n",
            " [0.9961171 ]\n",
            " [0.9961054 ]\n",
            " [0.00591566]]\n",
            "Step: 8501 -> Loss: 0.004331347532570362 -> Predictions: [[0.00359318]\n",
            " [0.99611723]\n",
            " [0.9961054 ]\n",
            " [0.0059156 ]]\n",
            "Step: 8502 -> Loss: 0.0043313270434737206 -> Predictions: [[0.00359316]\n",
            " [0.99611723]\n",
            " [0.9961054 ]\n",
            " [0.00591557]]\n",
            "Step: 8503 -> Loss: 0.004331306554377079 -> Predictions: [[0.00359315]\n",
            " [0.99611723]\n",
            " [0.9961054 ]\n",
            " [0.00591554]]\n",
            "Step: 8504 -> Loss: 0.004331286530941725 -> Predictions: [[0.00359313]\n",
            " [0.99611723]\n",
            " [0.9961055 ]\n",
            " [0.00591551]]\n",
            "Step: 8505 -> Loss: 0.004331265576183796 -> Predictions: [[0.00359311]\n",
            " [0.99611723]\n",
            " [0.9961055 ]\n",
            " [0.00591549]]\n",
            "Step: 8506 -> Loss: 0.004331246484071016 -> Predictions: [[0.0035931 ]\n",
            " [0.99611723]\n",
            " [0.9961055 ]\n",
            " [0.00591546]]\n",
            "Step: 8507 -> Loss: 0.0043312250636518 -> Predictions: [[0.00359308]\n",
            " [0.99611723]\n",
            " [0.9961055 ]\n",
            " [0.00591542]]\n",
            "Step: 8508 -> Loss: 0.004331206437200308 -> Predictions: [[0.00359306]\n",
            " [0.99611735]\n",
            " [0.9961055 ]\n",
            " [0.0059154 ]]\n",
            "Step: 8509 -> Loss: 0.004331186413764954 -> Predictions: [[0.00359305]\n",
            " [0.99611735]\n",
            " [0.9961055 ]\n",
            " [0.00591537]]\n",
            "Step: 8510 -> Loss: 0.0043311649933457375 -> Predictions: [[0.00359303]\n",
            " [0.99611735]\n",
            " [0.9961055 ]\n",
            " [0.00591534]]\n",
            "Step: 8511 -> Loss: 0.004331146366894245 -> Predictions: [[0.00359302]\n",
            " [0.99611735]\n",
            " [0.9961056 ]\n",
            " [0.00591531]]\n",
            "Step: 8512 -> Loss: 0.004331124015152454 -> Predictions: [[0.003593  ]\n",
            " [0.99611735]\n",
            " [0.9961056 ]\n",
            " [0.00591527]]\n",
            "Step: 8513 -> Loss: 0.004331104923039675 -> Predictions: [[0.00359298]\n",
            " [0.99611735]\n",
            " [0.9961056 ]\n",
            " [0.00591525]]\n",
            "Step: 8514 -> Loss: 0.004331085365265608 -> Predictions: [[0.00359297]\n",
            " [0.99611735]\n",
            " [0.9961056 ]\n",
            " [0.00591522]]\n",
            "Step: 8515 -> Loss: 0.004331063479185104 -> Predictions: [[0.00359295]\n",
            " [0.9961175 ]\n",
            " [0.9961056 ]\n",
            " [0.00591518]]\n",
            "Step: 8516 -> Loss: 0.004331044852733612 -> Predictions: [[0.00359294]\n",
            " [0.9961175 ]\n",
            " [0.9961056 ]\n",
            " [0.00591516]]\n",
            "Step: 8517 -> Loss: 0.004331022035330534 -> Predictions: [[0.00359292]\n",
            " [0.9961175 ]\n",
            " [0.99610573]\n",
            " [0.00591512]]\n",
            "Step: 8518 -> Loss: 0.004331003874540329 -> Predictions: [[0.0035929 ]\n",
            " [0.9961175 ]\n",
            " [0.99610573]\n",
            " [0.0059151 ]]\n",
            "Step: 8519 -> Loss: 0.004330984316766262 -> Predictions: [[0.00359288]\n",
            " [0.9961175 ]\n",
            " [0.99610573]\n",
            " [0.00591507]]\n",
            "Step: 8520 -> Loss: 0.0043309638276696205 -> Predictions: [[0.00359287]\n",
            " [0.9961175 ]\n",
            " [0.99610573]\n",
            " [0.00591504]]\n",
            "Step: 8521 -> Loss: 0.004330944269895554 -> Predictions: [[0.00359285]\n",
            " [0.9961175 ]\n",
            " [0.99610573]\n",
            " [0.00591501]]\n",
            "Step: 8522 -> Loss: 0.004330922849476337 -> Predictions: [[0.00359284]\n",
            " [0.9961176 ]\n",
            " [0.99610573]\n",
            " [0.00591498]]\n",
            "Step: 8523 -> Loss: 0.004330902826040983 -> Predictions: [[0.00359282]\n",
            " [0.9961176 ]\n",
            " [0.99610573]\n",
            " [0.00591495]]\n",
            "Step: 8524 -> Loss: 0.004330881871283054 -> Predictions: [[0.00359281]\n",
            " [0.9961176 ]\n",
            " [0.99610585]\n",
            " [0.00591491]]\n",
            "Step: 8525 -> Loss: 0.004330861382186413 -> Predictions: [[0.00359279]\n",
            " [0.9961176 ]\n",
            " [0.99610585]\n",
            " [0.00591489]]\n",
            "Step: 8526 -> Loss: 0.0043308427557349205 -> Predictions: [[0.00359278]\n",
            " [0.9961176 ]\n",
            " [0.99610585]\n",
            " [0.00591486]]\n",
            "Step: 8527 -> Loss: 0.004330823197960854 -> Predictions: [[0.00359276]\n",
            " [0.9961176 ]\n",
            " [0.99610585]\n",
            " [0.00591483]]\n",
            "Step: 8528 -> Loss: 0.004330799914896488 -> Predictions: [[0.00359274]\n",
            " [0.9961176 ]\n",
            " [0.99610585]\n",
            " [0.0059148 ]]\n",
            "Step: 8529 -> Loss: 0.004330783151090145 -> Predictions: [[0.00359272]\n",
            " [0.9961177 ]\n",
            " [0.99610585]\n",
            " [0.00591477]]\n",
            "Step: 8530 -> Loss: 0.004330763593316078 -> Predictions: [[0.00359271]\n",
            " [0.9961177 ]\n",
            " [0.99610585]\n",
            " [0.00591474]]\n",
            "Step: 8531 -> Loss: 0.004330740310251713 -> Predictions: [[0.0035927 ]\n",
            " [0.9961177 ]\n",
            " [0.99610597]\n",
            " [0.00591471]]\n",
            "Step: 8532 -> Loss: 0.004330724477767944 -> Predictions: [[0.00359268]\n",
            " [0.9961177 ]\n",
            " [0.99610597]\n",
            " [0.00591469]]\n",
            "Step: 8533 -> Loss: 0.0043307021260261536 -> Predictions: [[0.00359266]\n",
            " [0.9961177 ]\n",
            " [0.99610597]\n",
            " [0.00591465]]\n",
            "Step: 8534 -> Loss: 0.004330681636929512 -> Predictions: [[0.00359265]\n",
            " [0.9961177 ]\n",
            " [0.99610597]\n",
            " [0.00591462]]\n",
            "Step: 8535 -> Loss: 0.0043306611478328705 -> Predictions: [[0.00359263]\n",
            " [0.9961177 ]\n",
            " [0.99610597]\n",
            " [0.00591459]]\n",
            "Step: 8536 -> Loss: 0.004330642521381378 -> Predictions: [[0.00359261]\n",
            " [0.99611783]\n",
            " [0.99610597]\n",
            " [0.00591457]]\n",
            "Step: 8537 -> Loss: 0.004330620169639587 -> Predictions: [[0.0035926 ]\n",
            " [0.99611783]\n",
            " [0.99610597]\n",
            " [0.00591454]]\n",
            "Step: 8538 -> Loss: 0.004330601543188095 -> Predictions: [[0.00359258]\n",
            " [0.99611783]\n",
            " [0.9961061 ]\n",
            " [0.00591451]]\n",
            "Step: 8539 -> Loss: 0.0043305824510753155 -> Predictions: [[0.00359256]\n",
            " [0.99611783]\n",
            " [0.9961061 ]\n",
            " [0.00591448]]\n",
            "Step: 8540 -> Loss: 0.004330561496317387 -> Predictions: [[0.00359255]\n",
            " [0.99611783]\n",
            " [0.9961061 ]\n",
            " [0.00591445]]\n",
            "Step: 8541 -> Loss: 0.0043305386789143085 -> Predictions: [[0.00359253]\n",
            " [0.99611783]\n",
            " [0.9961061 ]\n",
            " [0.00591442]]\n",
            "Step: 8542 -> Loss: 0.004330518655478954 -> Predictions: [[0.00359251]\n",
            " [0.99611783]\n",
            " [0.9961061 ]\n",
            " [0.00591439]]\n",
            "Step: 8543 -> Loss: 0.004330500029027462 -> Predictions: [[0.0035925 ]\n",
            " [0.99611795]\n",
            " [0.9961061 ]\n",
            " [0.00591436]]\n",
            "Step: 8544 -> Loss: 0.004330480471253395 -> Predictions: [[0.00359248]\n",
            " [0.99611795]\n",
            " [0.9961061 ]\n",
            " [0.00591433]]\n",
            "Step: 8545 -> Loss: 0.004330458585172892 -> Predictions: [[0.00359246]\n",
            " [0.99611795]\n",
            " [0.9961062 ]\n",
            " [0.0059143 ]]\n",
            "Step: 8546 -> Loss: 0.004330439493060112 -> Predictions: [[0.00359245]\n",
            " [0.99611795]\n",
            " [0.9961062 ]\n",
            " [0.00591427]]\n",
            "Step: 8547 -> Loss: 0.004330419469624758 -> Predictions: [[0.00359243]\n",
            " [0.99611795]\n",
            " [0.9961062 ]\n",
            " [0.00591424]]\n",
            "Step: 8548 -> Loss: 0.0043303994461894035 -> Predictions: [[0.00359242]\n",
            " [0.99611795]\n",
            " [0.9961062 ]\n",
            " [0.00591421]]\n",
            "Step: 8549 -> Loss: 0.004330380819737911 -> Predictions: [[0.0035924 ]\n",
            " [0.99611795]\n",
            " [0.9961062 ]\n",
            " [0.00591418]]\n",
            "Step: 8550 -> Loss: 0.0043303584679961205 -> Predictions: [[0.00359239]\n",
            " [0.99611807]\n",
            " [0.9961062 ]\n",
            " [0.00591415]]\n",
            "Step: 8551 -> Loss: 0.004330339375883341 -> Predictions: [[0.00359237]\n",
            " [0.99611807]\n",
            " [0.9961062 ]\n",
            " [0.00591412]]\n",
            "Step: 8552 -> Loss: 0.004330317489802837 -> Predictions: [[0.00359235]\n",
            " [0.99611807]\n",
            " [0.9961063 ]\n",
            " [0.00591409]]\n",
            "Step: 8553 -> Loss: 0.00433029979467392 -> Predictions: [[0.00359234]\n",
            " [0.99611807]\n",
            " [0.9961063 ]\n",
            " [0.00591406]]\n",
            "Step: 8554 -> Loss: 0.0043302797712385654 -> Predictions: [[0.00359232]\n",
            " [0.99611807]\n",
            " [0.9961063 ]\n",
            " [0.00591403]]\n",
            "Step: 8555 -> Loss: 0.004330255091190338 -> Predictions: [[0.0035923 ]\n",
            " [0.99611807]\n",
            " [0.9961063 ]\n",
            " [0.005914  ]]\n",
            "Step: 8556 -> Loss: 0.004330238793045282 -> Predictions: [[0.00359229]\n",
            " [0.9961182 ]\n",
            " [0.9961063 ]\n",
            " [0.00591398]]\n",
            "Step: 8557 -> Loss: 0.004330216441303492 -> Predictions: [[0.00359227]\n",
            " [0.9961182 ]\n",
            " [0.9961063 ]\n",
            " [0.00591394]]\n",
            "Step: 8558 -> Loss: 0.004330196417868137 -> Predictions: [[0.00359225]\n",
            " [0.9961182 ]\n",
            " [0.99610645]\n",
            " [0.00591391]]\n",
            "Step: 8559 -> Loss: 0.004330175928771496 -> Predictions: [[0.00359224]\n",
            " [0.9961182 ]\n",
            " [0.99610645]\n",
            " [0.00591388]]\n",
            "Step: 8560 -> Loss: 0.004330156836658716 -> Predictions: [[0.00359222]\n",
            " [0.9961182 ]\n",
            " [0.99610645]\n",
            " [0.00591385]]\n",
            "Step: 8561 -> Loss: 0.004330136347562075 -> Predictions: [[0.0035922 ]\n",
            " [0.9961182 ]\n",
            " [0.99610645]\n",
            " [0.00591383]]\n",
            "Step: 8562 -> Loss: 0.004330117721110582 -> Predictions: [[0.00359219]\n",
            " [0.9961182 ]\n",
            " [0.99610645]\n",
            " [0.0059138 ]]\n",
            "Step: 8563 -> Loss: 0.004330097232013941 -> Predictions: [[0.00359217]\n",
            " [0.9961183 ]\n",
            " [0.99610645]\n",
            " [0.00591377]]\n",
            "Step: 8564 -> Loss: 0.004330073483288288 -> Predictions: [[0.00359215]\n",
            " [0.9961183 ]\n",
            " [0.99610645]\n",
            " [0.00591373]]\n",
            "Step: 8565 -> Loss: 0.004330057185143232 -> Predictions: [[0.00359214]\n",
            " [0.9961183 ]\n",
            " [0.99610645]\n",
            " [0.00591371]]\n",
            "Step: 8566 -> Loss: 0.0043300362303853035 -> Predictions: [[0.00359212]\n",
            " [0.9961183 ]\n",
            " [0.99610656]\n",
            " [0.00591368]]\n",
            "Step: 8567 -> Loss: 0.004330015741288662 -> Predictions: [[0.0035921 ]\n",
            " [0.9961183 ]\n",
            " [0.99610656]\n",
            " [0.00591365]]\n",
            "Step: 8568 -> Loss: 0.00432999525219202 -> Predictions: [[0.00359209]\n",
            " [0.9961183 ]\n",
            " [0.99610656]\n",
            " [0.00591362]]\n",
            "Step: 8569 -> Loss: 0.0043299756944179535 -> Predictions: [[0.00359208]\n",
            " [0.9961183 ]\n",
            " [0.99610656]\n",
            " [0.00591359]]\n",
            "Step: 8570 -> Loss: 0.004329955205321312 -> Predictions: [[0.00359206]\n",
            " [0.9961184 ]\n",
            " [0.99610656]\n",
            " [0.00591355]]\n",
            "Step: 8571 -> Loss: 0.00432993471622467 -> Predictions: [[0.00359204]\n",
            " [0.9961184 ]\n",
            " [0.99610656]\n",
            " [0.00591353]]\n",
            "Step: 8572 -> Loss: 0.004329912830144167 -> Predictions: [[0.00359203]\n",
            " [0.9961184 ]\n",
            " [0.9961067 ]\n",
            " [0.0059135 ]]\n",
            "Step: 8573 -> Loss: 0.004329895135015249 -> Predictions: [[0.00359201]\n",
            " [0.9961184 ]\n",
            " [0.9961067 ]\n",
            " [0.00591347]]\n",
            "Step: 8574 -> Loss: 0.00432987418025732 -> Predictions: [[0.00359199]\n",
            " [0.9961184 ]\n",
            " [0.9961067 ]\n",
            " [0.00591344]]\n",
            "Step: 8575 -> Loss: 0.004329855553805828 -> Predictions: [[0.00359198]\n",
            " [0.9961184 ]\n",
            " [0.9961067 ]\n",
            " [0.00591341]]\n",
            "Step: 8576 -> Loss: 0.004329836927354336 -> Predictions: [[0.00359197]\n",
            " [0.9961184 ]\n",
            " [0.9961067 ]\n",
            " [0.00591338]]\n",
            "Step: 8577 -> Loss: 0.0043298108503222466 -> Predictions: [[0.00359194]\n",
            " [0.99611855]\n",
            " [0.9961067 ]\n",
            " [0.00591334]]\n",
            "Step: 8578 -> Loss: 0.0043297940865159035 -> Predictions: [[0.00359193]\n",
            " [0.99611855]\n",
            " [0.9961067 ]\n",
            " [0.00591332]]\n",
            "Step: 8579 -> Loss: 0.004329773597419262 -> Predictions: [[0.00359191]\n",
            " [0.99611855]\n",
            " [0.9961068 ]\n",
            " [0.00591329]]\n",
            "Step: 8580 -> Loss: 0.004329754505306482 -> Predictions: [[0.0035919 ]\n",
            " [0.99611855]\n",
            " [0.9961068 ]\n",
            " [0.00591326]]\n",
            "Step: 8581 -> Loss: 0.004329734947532415 -> Predictions: [[0.00359188]\n",
            " [0.99611855]\n",
            " [0.9961068 ]\n",
            " [0.00591324]]\n",
            "Step: 8582 -> Loss: 0.0043297139927744865 -> Predictions: [[0.00359187]\n",
            " [0.99611855]\n",
            " [0.9961068 ]\n",
            " [0.0059132 ]]\n",
            "Step: 8583 -> Loss: 0.004329692106693983 -> Predictions: [[0.00359185]\n",
            " [0.99611855]\n",
            " [0.9961068 ]\n",
            " [0.00591317]]\n",
            "Step: 8584 -> Loss: 0.004329674411565065 -> Predictions: [[0.00359183]\n",
            " [0.99611866]\n",
            " [0.9961068 ]\n",
            " [0.00591315]]\n",
            "Step: 8585 -> Loss: 0.0043296511285007 -> Predictions: [[0.00359182]\n",
            " [0.99611866]\n",
            " [0.9961068 ]\n",
            " [0.00591311]]\n",
            "Step: 8586 -> Loss: 0.004329632967710495 -> Predictions: [[0.0035918 ]\n",
            " [0.99611866]\n",
            " [0.9961069 ]\n",
            " [0.00591308]]\n",
            "Step: 8587 -> Loss: 0.0043296124786138535 -> Predictions: [[0.00359178]\n",
            " [0.99611866]\n",
            " [0.9961069 ]\n",
            " [0.00591306]]\n",
            "Step: 8588 -> Loss: 0.004329591989517212 -> Predictions: [[0.00359177]\n",
            " [0.99611866]\n",
            " [0.9961069 ]\n",
            " [0.00591302]]\n",
            "Step: 8589 -> Loss: 0.00432957336306572 -> Predictions: [[0.00359175]\n",
            " [0.99611866]\n",
            " [0.9961069 ]\n",
            " [0.00591299]]\n",
            "Step: 8590 -> Loss: 0.004329552408307791 -> Predictions: [[0.00359173]\n",
            " [0.99611866]\n",
            " [0.9961069 ]\n",
            " [0.00591297]]\n",
            "Step: 8591 -> Loss: 0.004329531453549862 -> Predictions: [[0.00359172]\n",
            " [0.9961188 ]\n",
            " [0.9961069 ]\n",
            " [0.00591293]]\n",
            "Step: 8592 -> Loss: 0.004329510033130646 -> Predictions: [[0.0035917]\n",
            " [0.9961188]\n",
            " [0.9961069]\n",
            " [0.0059129]]\n",
            "Step: 8593 -> Loss: 0.004329491872340441 -> Predictions: [[0.00359169]\n",
            " [0.9961188 ]\n",
            " [0.99610704]\n",
            " [0.00591288]]\n",
            "Step: 8594 -> Loss: 0.004329469986259937 -> Predictions: [[0.00359167]\n",
            " [0.9961188 ]\n",
            " [0.99610704]\n",
            " [0.00591285]]\n",
            "Step: 8595 -> Loss: 0.004329453222453594 -> Predictions: [[0.00359165]\n",
            " [0.9961188 ]\n",
            " [0.99610704]\n",
            " [0.00591282]]\n",
            "Step: 8596 -> Loss: 0.00432942807674408 -> Predictions: [[0.00359164]\n",
            " [0.9961188 ]\n",
            " [0.99610704]\n",
            " [0.00591278]]\n",
            "Step: 8597 -> Loss: 0.004329408518970013 -> Predictions: [[0.00359162]\n",
            " [0.9961188 ]\n",
            " [0.99610704]\n",
            " [0.00591276]]\n",
            "Step: 8598 -> Loss: 0.00432939175516367 -> Predictions: [[0.00359161]\n",
            " [0.9961189 ]\n",
            " [0.99610704]\n",
            " [0.00591273]]\n",
            "Step: 8599 -> Loss: 0.0043293689377605915 -> Predictions: [[0.00359158]\n",
            " [0.9961189 ]\n",
            " [0.99610704]\n",
            " [0.0059127 ]]\n",
            "Step: 8600 -> Loss: 0.004329351708292961 -> Predictions: [[0.00359157]\n",
            " [0.9961189 ]\n",
            " [0.99610716]\n",
            " [0.00591267]]\n",
            "Step: 8601 -> Loss: 0.00432932935655117 -> Predictions: [[0.00359155]\n",
            " [0.9961189 ]\n",
            " [0.99610716]\n",
            " [0.00591264]]\n",
            "Step: 8602 -> Loss: 0.004329309798777103 -> Predictions: [[0.00359153]\n",
            " [0.9961189 ]\n",
            " [0.99610716]\n",
            " [0.00591261]]\n",
            "Step: 8603 -> Loss: 0.004329291172325611 -> Predictions: [[0.00359152]\n",
            " [0.9961189 ]\n",
            " [0.99610716]\n",
            " [0.00591258]]\n",
            "Step: 8604 -> Loss: 0.004329266957938671 -> Predictions: [[0.0035915 ]\n",
            " [0.996119  ]\n",
            " [0.99610716]\n",
            " [0.00591255]]\n",
            "Step: 8605 -> Loss: 0.004329250194132328 -> Predictions: [[0.00359149]\n",
            " [0.996119  ]\n",
            " [0.99610716]\n",
            " [0.00591252]]\n",
            "Step: 8606 -> Loss: 0.004329230636358261 -> Predictions: [[0.00359148]\n",
            " [0.996119  ]\n",
            " [0.99610716]\n",
            " [0.00591249]]\n",
            "Step: 8607 -> Loss: 0.004329209681600332 -> Predictions: [[0.00359146]\n",
            " [0.996119  ]\n",
            " [0.9961073 ]\n",
            " [0.00591246]]\n",
            "Step: 8608 -> Loss: 0.004329189658164978 -> Predictions: [[0.00359144]\n",
            " [0.996119  ]\n",
            " [0.9961073 ]\n",
            " [0.00591243]]\n",
            "Step: 8609 -> Loss: 0.004329167306423187 -> Predictions: [[0.00359142]\n",
            " [0.996119  ]\n",
            " [0.9961073 ]\n",
            " [0.0059124 ]]\n",
            "Step: 8610 -> Loss: 0.004329148214310408 -> Predictions: [[0.00359141]\n",
            " [0.996119  ]\n",
            " [0.9961073 ]\n",
            " [0.00591237]]\n",
            "Step: 8611 -> Loss: 0.004329128656536341 -> Predictions: [[0.00359139]\n",
            " [0.99611914]\n",
            " [0.9961073 ]\n",
            " [0.00591234]]\n",
            "Step: 8612 -> Loss: 0.004329108167439699 -> Predictions: [[0.00359138]\n",
            " [0.99611914]\n",
            " [0.9961073 ]\n",
            " [0.00591231]]\n",
            "Step: 8613 -> Loss: 0.004329088144004345 -> Predictions: [[0.00359136]\n",
            " [0.99611914]\n",
            " [0.9961073 ]\n",
            " [0.00591228]]\n",
            "Step: 8614 -> Loss: 0.004329067189246416 -> Predictions: [[0.00359135]\n",
            " [0.99611914]\n",
            " [0.9961074 ]\n",
            " [0.00591225]]\n",
            "Step: 8615 -> Loss: 0.004329049959778786 -> Predictions: [[0.00359133]\n",
            " [0.99611914]\n",
            " [0.9961074 ]\n",
            " [0.00591223]]\n",
            "Step: 8616 -> Loss: 0.00432902667671442 -> Predictions: [[0.00359131]\n",
            " [0.99611914]\n",
            " [0.9961074 ]\n",
            " [0.0059122 ]]\n",
            "Step: 8617 -> Loss: 0.004329007118940353 -> Predictions: [[0.0035913 ]\n",
            " [0.99611914]\n",
            " [0.9961074 ]\n",
            " [0.00591217]]\n",
            "Step: 8618 -> Loss: 0.004328988492488861 -> Predictions: [[0.00359128]\n",
            " [0.99611914]\n",
            " [0.9961074 ]\n",
            " [0.00591213]]\n",
            "Step: 8619 -> Loss: 0.004328967072069645 -> Predictions: [[0.00359126]\n",
            " [0.99611926]\n",
            " [0.9961074 ]\n",
            " [0.00591211]]\n",
            "Step: 8620 -> Loss: 0.004328947514295578 -> Predictions: [[0.00359125]\n",
            " [0.99611926]\n",
            " [0.9961075 ]\n",
            " [0.00591208]]\n",
            "Step: 8621 -> Loss: 0.004328926093876362 -> Predictions: [[0.00359123]\n",
            " [0.99611926]\n",
            " [0.9961075 ]\n",
            " [0.00591204]]\n",
            "Step: 8622 -> Loss: 0.004328908398747444 -> Predictions: [[0.00359121]\n",
            " [0.99611926]\n",
            " [0.9961075 ]\n",
            " [0.00591202]]\n",
            "Step: 8623 -> Loss: 0.004328886978328228 -> Predictions: [[0.0035912 ]\n",
            " [0.99611926]\n",
            " [0.9961075 ]\n",
            " [0.00591199]]\n",
            "Step: 8624 -> Loss: 0.004328866954892874 -> Predictions: [[0.00359118]\n",
            " [0.99611926]\n",
            " [0.9961075 ]\n",
            " [0.00591196]]\n",
            "Step: 8625 -> Loss: 0.00432884506881237 -> Predictions: [[0.00359117]\n",
            " [0.9961194 ]\n",
            " [0.9961075 ]\n",
            " [0.00591192]]\n",
            "Step: 8626 -> Loss: 0.0043288241140544415 -> Predictions: [[0.00359115]\n",
            " [0.9961194 ]\n",
            " [0.9961075 ]\n",
            " [0.0059119 ]]\n",
            "Step: 8627 -> Loss: 0.004328805021941662 -> Predictions: [[0.00359113]\n",
            " [0.9961194 ]\n",
            " [0.99610764]\n",
            " [0.00591186]]\n",
            "Step: 8628 -> Loss: 0.004328784998506308 -> Predictions: [[0.00359112]\n",
            " [0.9961194 ]\n",
            " [0.99610764]\n",
            " [0.00591184]]\n",
            "Step: 8629 -> Loss: 0.004328765906393528 -> Predictions: [[0.0035911 ]\n",
            " [0.9961194 ]\n",
            " [0.99610764]\n",
            " [0.00591181]]\n",
            "Step: 8630 -> Loss: 0.004328745882958174 -> Predictions: [[0.00359108]\n",
            " [0.9961194 ]\n",
            " [0.99610764]\n",
            " [0.00591178]]\n",
            "Step: 8631 -> Loss: 0.0043287272565066814 -> Predictions: [[0.00359107]\n",
            " [0.9961194 ]\n",
            " [0.99610764]\n",
            " [0.00591176]]\n",
            "Step: 8632 -> Loss: 0.00432870676741004 -> Predictions: [[0.00359106]\n",
            " [0.9961195 ]\n",
            " [0.99610764]\n",
            " [0.00591172]]\n",
            "Step: 8633 -> Loss: 0.004328684415668249 -> Predictions: [[0.00359104]\n",
            " [0.9961195 ]\n",
            " [0.99610764]\n",
            " [0.00591169]]\n",
            "Step: 8634 -> Loss: 0.004328662063926458 -> Predictions: [[0.00359102]\n",
            " [0.9961195 ]\n",
            " [0.99610776]\n",
            " [0.00591166]]\n",
            "Step: 8635 -> Loss: 0.004328644834458828 -> Predictions: [[0.003591  ]\n",
            " [0.9961195 ]\n",
            " [0.99610776]\n",
            " [0.00591163]]\n",
            "Step: 8636 -> Loss: 0.004328623879700899 -> Predictions: [[0.00359099]\n",
            " [0.9961195 ]\n",
            " [0.99610776]\n",
            " [0.0059116 ]]\n",
            "Step: 8637 -> Loss: 0.00432860292494297 -> Predictions: [[0.00359097]\n",
            " [0.9961195 ]\n",
            " [0.99610776]\n",
            " [0.00591157]]\n",
            "Step: 8638 -> Loss: 0.004328583832830191 -> Predictions: [[0.00359096]\n",
            " [0.9961195 ]\n",
            " [0.99610776]\n",
            " [0.00591154]]\n",
            "Step: 8639 -> Loss: 0.004328564275056124 -> Predictions: [[0.00359094]\n",
            " [0.9961196 ]\n",
            " [0.99610776]\n",
            " [0.00591151]]\n",
            "Step: 8640 -> Loss: 0.004328543320298195 -> Predictions: [[0.00359092]\n",
            " [0.9961196 ]\n",
            " [0.99610776]\n",
            " [0.00591148]]\n",
            "Step: 8641 -> Loss: 0.004328522831201553 -> Predictions: [[0.0035909 ]\n",
            " [0.9961196 ]\n",
            " [0.9961079 ]\n",
            " [0.00591145]]\n",
            "Step: 8642 -> Loss: 0.004328504204750061 -> Predictions: [[0.00359089]\n",
            " [0.9961196 ]\n",
            " [0.9961079 ]\n",
            " [0.00591143]]\n",
            "Step: 8643 -> Loss: 0.004328484181314707 -> Predictions: [[0.00359088]\n",
            " [0.9961196 ]\n",
            " [0.9961079 ]\n",
            " [0.00591139]]\n",
            "Step: 8644 -> Loss: 0.004328462760895491 -> Predictions: [[0.00359086]\n",
            " [0.9961196 ]\n",
            " [0.9961079 ]\n",
            " [0.00591137]]\n",
            "Step: 8645 -> Loss: 0.004328441806137562 -> Predictions: [[0.00359084]\n",
            " [0.9961196 ]\n",
            " [0.9961079 ]\n",
            " [0.00591134]]\n",
            "Step: 8646 -> Loss: 0.004328424111008644 -> Predictions: [[0.00359083]\n",
            " [0.99611974]\n",
            " [0.9961079 ]\n",
            " [0.00591131]]\n",
            "Step: 8647 -> Loss: 0.0043284036219120026 -> Predictions: [[0.00359081]\n",
            " [0.99611974]\n",
            " [0.9961079 ]\n",
            " [0.00591128]]\n",
            "Step: 8648 -> Loss: 0.004328383132815361 -> Predictions: [[0.00359079]\n",
            " [0.99611974]\n",
            " [0.996108  ]\n",
            " [0.00591125]]\n",
            "Step: 8649 -> Loss: 0.004328363575041294 -> Predictions: [[0.00359078]\n",
            " [0.99611974]\n",
            " [0.996108  ]\n",
            " [0.00591121]]\n",
            "Step: 8650 -> Loss: 0.004328342154622078 -> Predictions: [[0.00359076]\n",
            " [0.99611974]\n",
            " [0.996108  ]\n",
            " [0.00591119]]\n",
            "Step: 8651 -> Loss: 0.004328321199864149 -> Predictions: [[0.00359074]\n",
            " [0.99611974]\n",
            " [0.996108  ]\n",
            " [0.00591115]]\n",
            "Step: 8652 -> Loss: 0.0043283021077513695 -> Predictions: [[0.00359073]\n",
            " [0.99611974]\n",
            " [0.996108  ]\n",
            " [0.00591113]]\n",
            "Step: 8653 -> Loss: 0.004328280687332153 -> Predictions: [[0.00359071]\n",
            " [0.99611986]\n",
            " [0.996108  ]\n",
            " [0.0059111 ]]\n",
            "Step: 8654 -> Loss: 0.004328257404267788 -> Predictions: [[0.00359069]\n",
            " [0.99611986]\n",
            " [0.996108  ]\n",
            " [0.00591106]]\n",
            "Step: 8655 -> Loss: 0.004328241106122732 -> Predictions: [[0.00359068]\n",
            " [0.99611986]\n",
            " [0.9961081 ]\n",
            " [0.00591104]]\n",
            "Step: 8656 -> Loss: 0.004328220617026091 -> Predictions: [[0.00359066]\n",
            " [0.99611986]\n",
            " [0.9961081 ]\n",
            " [0.00591101]]\n",
            "Step: 8657 -> Loss: 0.004328202456235886 -> Predictions: [[0.00359065]\n",
            " [0.99611986]\n",
            " [0.9961081 ]\n",
            " [0.00591098]]\n",
            "Step: 8658 -> Loss: 0.0043281810358166695 -> Predictions: [[0.00359063]\n",
            " [0.99611986]\n",
            " [0.9961081 ]\n",
            " [0.00591095]]\n",
            "Step: 8659 -> Loss: 0.0043281628750264645 -> Predictions: [[0.00359062]\n",
            " [0.99611986]\n",
            " [0.9961081 ]\n",
            " [0.00591092]]\n",
            "Step: 8660 -> Loss: 0.004328139591962099 -> Predictions: [[0.0035906 ]\n",
            " [0.99612   ]\n",
            " [0.9961081 ]\n",
            " [0.00591089]]\n",
            "Step: 8661 -> Loss: 0.004328121431171894 -> Predictions: [[0.00359058]\n",
            " [0.99612   ]\n",
            " [0.9961081 ]\n",
            " [0.00591086]]\n",
            "Step: 8662 -> Loss: 0.004328100476413965 -> Predictions: [[0.00359057]\n",
            " [0.99612   ]\n",
            " [0.99610823]\n",
            " [0.00591083]]\n",
            "Step: 8663 -> Loss: 0.004328079521656036 -> Predictions: [[0.00359055]\n",
            " [0.99612   ]\n",
            " [0.99610823]\n",
            " [0.0059108 ]]\n",
            "Step: 8664 -> Loss: 0.004328060429543257 -> Predictions: [[0.00359053]\n",
            " [0.99612   ]\n",
            " [0.99610823]\n",
            " [0.00591077]]\n",
            "Step: 8665 -> Loss: 0.004328039474785328 -> Predictions: [[0.00359052]\n",
            " [0.99612   ]\n",
            " [0.99610823]\n",
            " [0.00591074]]\n",
            "Step: 8666 -> Loss: 0.004328018985688686 -> Predictions: [[0.0035905 ]\n",
            " [0.9961201 ]\n",
            " [0.99610823]\n",
            " [0.00591072]]\n",
            "Step: 8667 -> Loss: 0.004327998496592045 -> Predictions: [[0.00359048]\n",
            " [0.9961201 ]\n",
            " [0.99610823]\n",
            " [0.00591068]]\n",
            "Step: 8668 -> Loss: 0.004327978007495403 -> Predictions: [[0.00359047]\n",
            " [0.9961201 ]\n",
            " [0.99610835]\n",
            " [0.00591065]]\n",
            "Step: 8669 -> Loss: 0.004327958915382624 -> Predictions: [[0.00359045]\n",
            " [0.9961201 ]\n",
            " [0.99610835]\n",
            " [0.00591062]]\n",
            "Step: 8670 -> Loss: 0.004327939357608557 -> Predictions: [[0.00359043]\n",
            " [0.9961201 ]\n",
            " [0.99610835]\n",
            " [0.00591059]]\n",
            "Step: 8671 -> Loss: 0.004327916540205479 -> Predictions: [[0.00359042]\n",
            " [0.9961201 ]\n",
            " [0.99610835]\n",
            " [0.00591056]]\n",
            "Step: 8672 -> Loss: 0.004327899776399136 -> Predictions: [[0.0035904 ]\n",
            " [0.9961201 ]\n",
            " [0.99610835]\n",
            " [0.00591054]]\n",
            "Step: 8673 -> Loss: 0.004327878355979919 -> Predictions: [[0.00359039]\n",
            " [0.9961201 ]\n",
            " [0.99610835]\n",
            " [0.00591051]]\n",
            "Step: 8674 -> Loss: 0.004327857401221991 -> Predictions: [[0.00359037]\n",
            " [0.9961202 ]\n",
            " [0.99610835]\n",
            " [0.00591047]]\n",
            "Step: 8675 -> Loss: 0.004327838309109211 -> Predictions: [[0.00359035]\n",
            " [0.9961202 ]\n",
            " [0.9961085 ]\n",
            " [0.00591044]]\n",
            "Step: 8676 -> Loss: 0.0043278164230287075 -> Predictions: [[0.00359034]\n",
            " [0.9961202 ]\n",
            " [0.9961085 ]\n",
            " [0.00591041]]\n",
            "Step: 8677 -> Loss: 0.004327800590544939 -> Predictions: [[0.00359033]\n",
            " [0.9961202 ]\n",
            " [0.9961085 ]\n",
            " [0.00591039]]\n",
            "Step: 8678 -> Loss: 0.004327777773141861 -> Predictions: [[0.00359031]\n",
            " [0.9961202 ]\n",
            " [0.9961085 ]\n",
            " [0.00591035]]\n",
            "Step: 8679 -> Loss: 0.004327757284045219 -> Predictions: [[0.00359029]\n",
            " [0.9961202 ]\n",
            " [0.9961085 ]\n",
            " [0.00591033]]\n",
            "Step: 8680 -> Loss: 0.004327739588916302 -> Predictions: [[0.00359028]\n",
            " [0.99612033]\n",
            " [0.9961085 ]\n",
            " [0.0059103 ]]\n",
            "Step: 8681 -> Loss: 0.004327718634158373 -> Predictions: [[0.00359026]\n",
            " [0.99612033]\n",
            " [0.9961085 ]\n",
            " [0.00591027]]\n",
            "Step: 8682 -> Loss: 0.004327698610723019 -> Predictions: [[0.00359024]\n",
            " [0.99612033]\n",
            " [0.9961086 ]\n",
            " [0.00591024]]\n",
            "Step: 8683 -> Loss: 0.004327675327658653 -> Predictions: [[0.00359022]\n",
            " [0.99612033]\n",
            " [0.9961086 ]\n",
            " [0.00591021]]\n",
            "Step: 8684 -> Loss: 0.004327653907239437 -> Predictions: [[0.0035902 ]\n",
            " [0.99612033]\n",
            " [0.9961086 ]\n",
            " [0.00591018]]\n",
            "Step: 8685 -> Loss: 0.004327636212110519 -> Predictions: [[0.00359019]\n",
            " [0.99612033]\n",
            " [0.9961086 ]\n",
            " [0.00591015]]\n",
            "Step: 8686 -> Loss: 0.004327614326030016 -> Predictions: [[0.00359017]\n",
            " [0.99612033]\n",
            " [0.9961086 ]\n",
            " [0.00591012]]\n",
            "Step: 8687 -> Loss: 0.004327595233917236 -> Predictions: [[0.00359016]\n",
            " [0.9961204 ]\n",
            " [0.9961086 ]\n",
            " [0.00591009]]\n",
            "Step: 8688 -> Loss: 0.004327575676143169 -> Predictions: [[0.00359014]\n",
            " [0.9961204 ]\n",
            " [0.9961086 ]\n",
            " [0.00591006]]\n",
            "Step: 8689 -> Loss: 0.004327557049691677 -> Predictions: [[0.00359013]\n",
            " [0.9961204 ]\n",
            " [0.9961087 ]\n",
            " [0.00591003]]\n",
            "Step: 8690 -> Loss: 0.004327532835304737 -> Predictions: [[0.00359011]\n",
            " [0.9961204 ]\n",
            " [0.9961087 ]\n",
            " [0.00591   ]]\n",
            "Step: 8691 -> Loss: 0.004327516071498394 -> Predictions: [[0.0035901 ]\n",
            " [0.9961204 ]\n",
            " [0.9961087 ]\n",
            " [0.00590997]]\n",
            "Step: 8692 -> Loss: 0.004327496979385614 -> Predictions: [[0.00359008]\n",
            " [0.9961204 ]\n",
            " [0.9961087 ]\n",
            " [0.00590994]]\n",
            "Step: 8693 -> Loss: 0.004327472299337387 -> Predictions: [[0.00359006]\n",
            " [0.9961204 ]\n",
            " [0.9961087 ]\n",
            " [0.00590991]]\n",
            "Step: 8694 -> Loss: 0.004327458329498768 -> Predictions: [[0.00359005]\n",
            " [0.9961205 ]\n",
            " [0.9961087 ]\n",
            " [0.00590989]]\n",
            "Step: 8695 -> Loss: 0.0043274336494505405 -> Predictions: [[0.00359003]\n",
            " [0.9961205 ]\n",
            " [0.9961087 ]\n",
            " [0.00590985]]\n",
            "Step: 8696 -> Loss: 0.00432741129770875 -> Predictions: [[0.00359001]\n",
            " [0.9961205 ]\n",
            " [0.99610883]\n",
            " [0.00590982]]\n",
            "Step: 8697 -> Loss: 0.004327396396547556 -> Predictions: [[0.00359   ]\n",
            " [0.9961205 ]\n",
            " [0.99610883]\n",
            " [0.00590979]]\n",
            "Step: 8698 -> Loss: 0.00432737497612834 -> Predictions: [[0.00358998]\n",
            " [0.9961205 ]\n",
            " [0.99610883]\n",
            " [0.00590977]]\n",
            "Step: 8699 -> Loss: 0.004327354021370411 -> Predictions: [[0.00358997]\n",
            " [0.9961205 ]\n",
            " [0.99610883]\n",
            " [0.00590973]]\n",
            "Step: 8700 -> Loss: 0.004327334463596344 -> Predictions: [[0.00358995]\n",
            " [0.9961205 ]\n",
            " [0.99610883]\n",
            " [0.00590971]]\n",
            "Step: 8701 -> Loss: 0.00432731444016099 -> Predictions: [[0.00358993]\n",
            " [0.99612063]\n",
            " [0.99610883]\n",
            " [0.00590968]]\n",
            "Step: 8702 -> Loss: 0.004327293019741774 -> Predictions: [[0.00358992]\n",
            " [0.99612063]\n",
            " [0.99610883]\n",
            " [0.00590964]]\n",
            "Step: 8703 -> Loss: 0.004327274393290281 -> Predictions: [[0.0035899 ]\n",
            " [0.99612063]\n",
            " [0.99610895]\n",
            " [0.00590962]]\n",
            "Step: 8704 -> Loss: 0.004327252972871065 -> Predictions: [[0.00358989]\n",
            " [0.99612063]\n",
            " [0.99610895]\n",
            " [0.00590958]]\n",
            "Step: 8705 -> Loss: 0.004327235743403435 -> Predictions: [[0.00358987]\n",
            " [0.99612063]\n",
            " [0.99610895]\n",
            " [0.00590956]]\n",
            "Step: 8706 -> Loss: 0.004327214322984219 -> Predictions: [[0.00358985]\n",
            " [0.99612063]\n",
            " [0.99610895]\n",
            " [0.00590953]]\n",
            "Step: 8707 -> Loss: 0.0043271929025650024 -> Predictions: [[0.00358983]\n",
            " [0.99612063]\n",
            " [0.99610895]\n",
            " [0.0059095 ]]\n",
            "Step: 8708 -> Loss: 0.004327172879129648 -> Predictions: [[0.00358982]\n",
            " [0.99612075]\n",
            " [0.99610895]\n",
            " [0.00590947]]\n",
            "Step: 8709 -> Loss: 0.004327151924371719 -> Predictions: [[0.0035898 ]\n",
            " [0.99612075]\n",
            " [0.99610895]\n",
            " [0.00590944]]\n",
            "Step: 8710 -> Loss: 0.004327133297920227 -> Predictions: [[0.00358979]\n",
            " [0.99612075]\n",
            " [0.99610907]\n",
            " [0.00590941]]\n",
            "Step: 8711 -> Loss: 0.0043271128088235855 -> Predictions: [[0.00358977]\n",
            " [0.99612075]\n",
            " [0.99610907]\n",
            " [0.00590938]]\n",
            "Step: 8712 -> Loss: 0.004327093716710806 -> Predictions: [[0.00358975]\n",
            " [0.99612075]\n",
            " [0.99610907]\n",
            " [0.00590935]]\n",
            "Step: 8713 -> Loss: 0.004327071830630302 -> Predictions: [[0.00358974]\n",
            " [0.99612075]\n",
            " [0.99610907]\n",
            " [0.00590932]]\n",
            "Step: 8714 -> Loss: 0.0043270522728562355 -> Predictions: [[0.00358973]\n",
            " [0.99612075]\n",
            " [0.99610907]\n",
            " [0.00590929]]\n",
            "Step: 8715 -> Loss: 0.004327032715082169 -> Predictions: [[0.00358971]\n",
            " [0.99612087]\n",
            " [0.99610907]\n",
            " [0.00590926]]\n",
            "Step: 8716 -> Loss: 0.004327011294662952 -> Predictions: [[0.00358969]\n",
            " [0.99612087]\n",
            " [0.99610907]\n",
            " [0.00590923]]\n",
            "Step: 8717 -> Loss: 0.004326989408582449 -> Predictions: [[0.00358967]\n",
            " [0.99612087]\n",
            " [0.9961092 ]\n",
            " [0.0059092 ]]\n",
            "Step: 8718 -> Loss: 0.004326974041759968 -> Predictions: [[0.00358966]\n",
            " [0.99612087]\n",
            " [0.9961092 ]\n",
            " [0.00590918]]\n",
            "Step: 8719 -> Loss: 0.004326950758695602 -> Predictions: [[0.00358965]\n",
            " [0.99612087]\n",
            " [0.9961092 ]\n",
            " [0.00590914]]\n",
            "Step: 8720 -> Loss: 0.00432693213224411 -> Predictions: [[0.00358963]\n",
            " [0.99612087]\n",
            " [0.9961092 ]\n",
            " [0.00590911]]\n",
            "Step: 8721 -> Loss: 0.004326912574470043 -> Predictions: [[0.00358961]\n",
            " [0.99612087]\n",
            " [0.9961092 ]\n",
            " [0.00590909]]\n",
            "Step: 8722 -> Loss: 0.004326891154050827 -> Predictions: [[0.00358959]\n",
            " [0.996121  ]\n",
            " [0.9961092 ]\n",
            " [0.00590905]]\n",
            "Step: 8723 -> Loss: 0.004326871130615473 -> Predictions: [[0.00358958]\n",
            " [0.996121  ]\n",
            " [0.9961093 ]\n",
            " [0.00590903]]\n",
            "Step: 8724 -> Loss: 0.0043268511071801186 -> Predictions: [[0.00358956]\n",
            " [0.996121  ]\n",
            " [0.9961093 ]\n",
            " [0.00590899]]\n",
            "Step: 8725 -> Loss: 0.00432683015242219 -> Predictions: [[0.00358954]\n",
            " [0.996121  ]\n",
            " [0.9961093 ]\n",
            " [0.00590897]]\n",
            "Step: 8726 -> Loss: 0.00432681106030941 -> Predictions: [[0.00358953]\n",
            " [0.996121  ]\n",
            " [0.9961093 ]\n",
            " [0.00590894]]\n",
            "Step: 8727 -> Loss: 0.004326791036874056 -> Predictions: [[0.00358951]\n",
            " [0.996121  ]\n",
            " [0.9961093 ]\n",
            " [0.0059089 ]]\n",
            "Step: 8728 -> Loss: 0.004326770082116127 -> Predictions: [[0.0035895 ]\n",
            " [0.9961211 ]\n",
            " [0.9961093 ]\n",
            " [0.00590887]]\n",
            "Step: 8729 -> Loss: 0.004326751921325922 -> Predictions: [[0.00358948]\n",
            " [0.9961211 ]\n",
            " [0.9961093 ]\n",
            " [0.00590885]]\n",
            "Step: 8730 -> Loss: 0.004326727241277695 -> Predictions: [[0.00358946]\n",
            " [0.9961211 ]\n",
            " [0.9961094 ]\n",
            " [0.00590882]]\n",
            "Step: 8731 -> Loss: 0.004326710477471352 -> Predictions: [[0.00358945]\n",
            " [0.9961211 ]\n",
            " [0.9961094 ]\n",
            " [0.00590879]]\n",
            "Step: 8732 -> Loss: 0.0043266890570521355 -> Predictions: [[0.00358943]\n",
            " [0.9961211 ]\n",
            " [0.9961094 ]\n",
            " [0.00590876]]\n",
            "Step: 8733 -> Loss: 0.004326668567955494 -> Predictions: [[0.00358942]\n",
            " [0.9961211 ]\n",
            " [0.9961094 ]\n",
            " [0.00590872]]\n",
            "Step: 8734 -> Loss: 0.004326650872826576 -> Predictions: [[0.0035894]\n",
            " [0.9961211]\n",
            " [0.9961094]\n",
            " [0.0059087]]\n",
            "Step: 8735 -> Loss: 0.004326629918068647 -> Predictions: [[0.00358938]\n",
            " [0.9961212 ]\n",
            " [0.9961094 ]\n",
            " [0.00590867]]\n",
            "Step: 8736 -> Loss: 0.004326608497649431 -> Predictions: [[0.00358937]\n",
            " [0.9961212 ]\n",
            " [0.9961094 ]\n",
            " [0.00590864]]\n",
            "Step: 8737 -> Loss: 0.004326588474214077 -> Predictions: [[0.00358935]\n",
            " [0.9961212 ]\n",
            " [0.99610955]\n",
            " [0.00590861]]\n",
            "Step: 8738 -> Loss: 0.00432656891644001 -> Predictions: [[0.00358933]\n",
            " [0.9961212 ]\n",
            " [0.99610955]\n",
            " [0.00590858]]\n",
            "Step: 8739 -> Loss: 0.004326549358665943 -> Predictions: [[0.00358932]\n",
            " [0.9961212 ]\n",
            " [0.99610955]\n",
            " [0.00590855]]\n",
            "Step: 8740 -> Loss: 0.004326531197875738 -> Predictions: [[0.0035893 ]\n",
            " [0.9961212 ]\n",
            " [0.99610955]\n",
            " [0.00590852]]\n",
            "Step: 8741 -> Loss: 0.004326506517827511 -> Predictions: [[0.00358928]\n",
            " [0.9961212 ]\n",
            " [0.99610955]\n",
            " [0.00590849]]\n",
            "Step: 8742 -> Loss: 0.004326486494392157 -> Predictions: [[0.00358926]\n",
            " [0.99612135]\n",
            " [0.99610955]\n",
            " [0.00590846]]\n",
            "Step: 8743 -> Loss: 0.004326467867940664 -> Predictions: [[0.00358925]\n",
            " [0.99612135]\n",
            " [0.99610955]\n",
            " [0.00590844]]\n",
            "Step: 8744 -> Loss: 0.004326448775827885 -> Predictions: [[0.00358923]\n",
            " [0.99612135]\n",
            " [0.99610966]\n",
            " [0.0059084 ]]\n",
            "Step: 8745 -> Loss: 0.004326426424086094 -> Predictions: [[0.00358922]\n",
            " [0.99612135]\n",
            " [0.99610966]\n",
            " [0.00590837]]\n",
            "Step: 8746 -> Loss: 0.004326406866312027 -> Predictions: [[0.0035892 ]\n",
            " [0.99612135]\n",
            " [0.99610966]\n",
            " [0.00590834]]\n",
            "Step: 8747 -> Loss: 0.004326386842876673 -> Predictions: [[0.00358919]\n",
            " [0.99612135]\n",
            " [0.99610966]\n",
            " [0.00590832]]\n",
            "Step: 8748 -> Loss: 0.004326368682086468 -> Predictions: [[0.00358917]\n",
            " [0.99612135]\n",
            " [0.99610966]\n",
            " [0.00590828]]\n",
            "Step: 8749 -> Loss: 0.004326350521296263 -> Predictions: [[0.00358916]\n",
            " [0.99612147]\n",
            " [0.99610966]\n",
            " [0.00590826]]\n",
            "Step: 8750 -> Loss: 0.004326325841248035 -> Predictions: [[0.00358914]\n",
            " [0.99612147]\n",
            " [0.99610966]\n",
            " [0.00590822]]\n",
            "Step: 8751 -> Loss: 0.0043263062834739685 -> Predictions: [[0.00358912]\n",
            " [0.99612147]\n",
            " [0.9961098 ]\n",
            " [0.00590819]]\n",
            "Step: 8752 -> Loss: 0.004326286725699902 -> Predictions: [[0.00358911]\n",
            " [0.99612147]\n",
            " [0.9961098 ]\n",
            " [0.00590816]]\n",
            "Step: 8753 -> Loss: 0.004326268099248409 -> Predictions: [[0.00358909]\n",
            " [0.99612147]\n",
            " [0.9961098 ]\n",
            " [0.00590814]]\n",
            "Step: 8754 -> Loss: 0.004326246213167906 -> Predictions: [[0.00358907]\n",
            " [0.99612147]\n",
            " [0.9961098 ]\n",
            " [0.0059081 ]]\n",
            "Step: 8755 -> Loss: 0.004326226189732552 -> Predictions: [[0.00358906]\n",
            " [0.99612147]\n",
            " [0.9961098 ]\n",
            " [0.00590807]]\n",
            "Step: 8756 -> Loss: 0.00432620570063591 -> Predictions: [[0.00358905]\n",
            " [0.9961216 ]\n",
            " [0.9961098 ]\n",
            " [0.00590805]]\n",
            "Step: 8757 -> Loss: 0.00432618660852313 -> Predictions: [[0.00358903]\n",
            " [0.9961216 ]\n",
            " [0.9961098 ]\n",
            " [0.00590802]]\n",
            "Step: 8758 -> Loss: 0.004326166119426489 -> Predictions: [[0.00358901]\n",
            " [0.9961216 ]\n",
            " [0.9961099 ]\n",
            " [0.00590799]]\n",
            "Step: 8759 -> Loss: 0.004326144699007273 -> Predictions: [[0.003589  ]\n",
            " [0.9961216 ]\n",
            " [0.9961099 ]\n",
            " [0.00590796]]\n",
            "Step: 8760 -> Loss: 0.004326125606894493 -> Predictions: [[0.00358898]\n",
            " [0.9961216 ]\n",
            " [0.9961099 ]\n",
            " [0.00590793]]\n",
            "Step: 8761 -> Loss: 0.004326105583459139 -> Predictions: [[0.00358896]\n",
            " [0.9961216 ]\n",
            " [0.9961099 ]\n",
            " [0.0059079 ]]\n",
            "Step: 8762 -> Loss: 0.004326086491346359 -> Predictions: [[0.00358895]\n",
            " [0.9961216 ]\n",
            " [0.9961099 ]\n",
            " [0.00590787]]\n",
            "Step: 8763 -> Loss: 0.004326063208281994 -> Predictions: [[0.00358893]\n",
            " [0.9961217 ]\n",
            " [0.9961099 ]\n",
            " [0.00590784]]\n",
            "Step: 8764 -> Loss: 0.004326045513153076 -> Predictions: [[0.00358891]\n",
            " [0.9961217 ]\n",
            " [0.9961099 ]\n",
            " [0.00590781]]\n",
            "Step: 8765 -> Loss: 0.004326025024056435 -> Predictions: [[0.00358889]\n",
            " [0.9961217 ]\n",
            " [0.99611   ]\n",
            " [0.00590778]]\n",
            "Step: 8766 -> Loss: 0.004326007794588804 -> Predictions: [[0.00358888]\n",
            " [0.9961217 ]\n",
            " [0.99611   ]\n",
            " [0.00590776]]\n",
            "Step: 8767 -> Loss: 0.004325982183218002 -> Predictions: [[0.00358886]\n",
            " [0.9961217 ]\n",
            " [0.99611   ]\n",
            " [0.00590772]]\n",
            "Step: 8768 -> Loss: 0.004325963091105223 -> Predictions: [[0.00358885]\n",
            " [0.9961217 ]\n",
            " [0.99611   ]\n",
            " [0.00590769]]\n",
            "Step: 8769 -> Loss: 0.004325944930315018 -> Predictions: [[0.00358883]\n",
            " [0.9961217 ]\n",
            " [0.99611   ]\n",
            " [0.00590767]]\n",
            "Step: 8770 -> Loss: 0.004325923975557089 -> Predictions: [[0.00358881]\n",
            " [0.9961218 ]\n",
            " [0.99611   ]\n",
            " [0.00590763]]\n",
            "Step: 8771 -> Loss: 0.0043259053491055965 -> Predictions: [[0.0035888 ]\n",
            " [0.9961218 ]\n",
            " [0.99611014]\n",
            " [0.00590761]]\n",
            "Step: 8772 -> Loss: 0.004325882066041231 -> Predictions: [[0.00358878]\n",
            " [0.9961218 ]\n",
            " [0.99611014]\n",
            " [0.00590757]]\n",
            "Step: 8773 -> Loss: 0.0043258643709123135 -> Predictions: [[0.00358876]\n",
            " [0.9961218 ]\n",
            " [0.99611014]\n",
            " [0.00590754]]\n",
            "Step: 8774 -> Loss: 0.00432584248483181 -> Predictions: [[0.00358875]\n",
            " [0.9961218 ]\n",
            " [0.99611014]\n",
            " [0.00590751]]\n",
            "Step: 8775 -> Loss: 0.004325822927057743 -> Predictions: [[0.00358873]\n",
            " [0.9961218 ]\n",
            " [0.99611014]\n",
            " [0.00590748]]\n",
            "Step: 8776 -> Loss: 0.004325801972299814 -> Predictions: [[0.00358872]\n",
            " [0.9961218 ]\n",
            " [0.99611014]\n",
            " [0.00590746]]\n",
            "Step: 8777 -> Loss: 0.004325783811509609 -> Predictions: [[0.0035887 ]\n",
            " [0.99612194]\n",
            " [0.99611014]\n",
            " [0.00590742]]\n",
            "Step: 8778 -> Loss: 0.004325762391090393 -> Predictions: [[0.00358868]\n",
            " [0.99612194]\n",
            " [0.99611026]\n",
            " [0.0059074 ]]\n",
            "Step: 8779 -> Loss: 0.004325739573687315 -> Predictions: [[0.00358866]\n",
            " [0.99612194]\n",
            " [0.99611026]\n",
            " [0.00590736]]\n",
            "Step: 8780 -> Loss: 0.004325723275542259 -> Predictions: [[0.00358866]\n",
            " [0.99612194]\n",
            " [0.99611026]\n",
            " [0.00590734]]\n",
            "Step: 8781 -> Loss: 0.004325703252106905 -> Predictions: [[0.00358864]\n",
            " [0.99612194]\n",
            " [0.99611026]\n",
            " [0.00590731]]\n",
            "Step: 8782 -> Loss: 0.0043256813660264015 -> Predictions: [[0.00358862]\n",
            " [0.99612194]\n",
            " [0.99611026]\n",
            " [0.00590727]]\n",
            "Step: 8783 -> Loss: 0.004325662273913622 -> Predictions: [[0.0035886 ]\n",
            " [0.99612194]\n",
            " [0.99611026]\n",
            " [0.00590724]]\n",
            "Step: 8784 -> Loss: 0.004325642250478268 -> Predictions: [[0.00358859]\n",
            " [0.99612206]\n",
            " [0.99611026]\n",
            " [0.00590722]]\n",
            "Step: 8785 -> Loss: 0.004325618967413902 -> Predictions: [[0.00358857]\n",
            " [0.99612206]\n",
            " [0.9961104 ]\n",
            " [0.00590719]]\n",
            "Step: 8786 -> Loss: 0.004325604997575283 -> Predictions: [[0.00358856]\n",
            " [0.99612206]\n",
            " [0.9961104 ]\n",
            " [0.00590716]]\n",
            "Step: 8787 -> Loss: 0.004325583577156067 -> Predictions: [[0.00358854]\n",
            " [0.99612206]\n",
            " [0.9961104 ]\n",
            " [0.00590713]]\n",
            "Step: 8788 -> Loss: 0.004325559362769127 -> Predictions: [[0.00358852]\n",
            " [0.99612206]\n",
            " [0.9961104 ]\n",
            " [0.0059071 ]]\n",
            "Step: 8789 -> Loss: 0.004325542598962784 -> Predictions: [[0.00358851]\n",
            " [0.99612206]\n",
            " [0.9961104 ]\n",
            " [0.00590707]]\n",
            "Step: 8790 -> Loss: 0.004325523041188717 -> Predictions: [[0.00358849]\n",
            " [0.99612206]\n",
            " [0.9961104 ]\n",
            " [0.00590704]]\n",
            "Step: 8791 -> Loss: 0.004325501620769501 -> Predictions: [[0.00358847]\n",
            " [0.9961222 ]\n",
            " [0.9961104 ]\n",
            " [0.00590701]]\n",
            "Step: 8792 -> Loss: 0.004325478337705135 -> Predictions: [[0.00358846]\n",
            " [0.9961222 ]\n",
            " [0.9961105 ]\n",
            " [0.00590698]]\n",
            "Step: 8793 -> Loss: 0.004325461573898792 -> Predictions: [[0.00358844]\n",
            " [0.9961222 ]\n",
            " [0.9961105 ]\n",
            " [0.00590695]]\n",
            "Step: 8794 -> Loss: 0.0043254392221570015 -> Predictions: [[0.00358842]\n",
            " [0.9961222 ]\n",
            " [0.9961105 ]\n",
            " [0.00590692]]\n",
            "Step: 8795 -> Loss: 0.0043254210613667965 -> Predictions: [[0.00358841]\n",
            " [0.9961222 ]\n",
            " [0.9961105 ]\n",
            " [0.00590689]]\n",
            "Step: 8796 -> Loss: 0.00432539964094758 -> Predictions: [[0.00358839]\n",
            " [0.9961222 ]\n",
            " [0.9961105 ]\n",
            " [0.00590686]]\n",
            "Step: 8797 -> Loss: 0.0043253786861896515 -> Predictions: [[0.00358838]\n",
            " [0.9961222 ]\n",
            " [0.9961105 ]\n",
            " [0.00590683]]\n",
            "Step: 8798 -> Loss: 0.004325358662754297 -> Predictions: [[0.00358836]\n",
            " [0.9961223 ]\n",
            " [0.9961105 ]\n",
            " [0.00590681]]\n",
            "Step: 8799 -> Loss: 0.004325340501964092 -> Predictions: [[0.00358834]\n",
            " [0.9961223 ]\n",
            " [0.9961106 ]\n",
            " [0.00590677]]\n",
            "Step: 8800 -> Loss: 0.004325318615883589 -> Predictions: [[0.00358832]\n",
            " [0.9961223 ]\n",
            " [0.9961106 ]\n",
            " [0.00590675]]\n",
            "Step: 8801 -> Loss: 0.004325299523770809 -> Predictions: [[0.00358831]\n",
            " [0.9961223 ]\n",
            " [0.9961106 ]\n",
            " [0.00590671]]\n",
            "Step: 8802 -> Loss: 0.004325277172029018 -> Predictions: [[0.00358829]\n",
            " [0.9961223 ]\n",
            " [0.9961106 ]\n",
            " [0.00590668]]\n",
            "Step: 8803 -> Loss: 0.004325256682932377 -> Predictions: [[0.00358827]\n",
            " [0.9961223 ]\n",
            " [0.9961106 ]\n",
            " [0.00590665]]\n",
            "Step: 8804 -> Loss: 0.0043252380564808846 -> Predictions: [[0.00358826]\n",
            " [0.9961224 ]\n",
            " [0.9961106 ]\n",
            " [0.00590663]]\n",
            "Step: 8805 -> Loss: 0.004325216636061668 -> Predictions: [[0.00358824]\n",
            " [0.9961224 ]\n",
            " [0.9961106 ]\n",
            " [0.0059066 ]]\n",
            "Step: 8806 -> Loss: 0.004325199872255325 -> Predictions: [[0.00358823]\n",
            " [0.9961224 ]\n",
            " [0.99611074]\n",
            " [0.00590657]]\n",
            "Step: 8807 -> Loss: 0.004325177054852247 -> Predictions: [[0.00358821]\n",
            " [0.9961224 ]\n",
            " [0.99611074]\n",
            " [0.00590653]]\n",
            "Step: 8808 -> Loss: 0.004325155168771744 -> Predictions: [[0.00358819]\n",
            " [0.9961224 ]\n",
            " [0.99611074]\n",
            " [0.0059065 ]]\n",
            "Step: 8809 -> Loss: 0.004325137007981539 -> Predictions: [[0.00358818]\n",
            " [0.9961224 ]\n",
            " [0.99611074]\n",
            " [0.00590648]]\n",
            "Step: 8810 -> Loss: 0.004325118847191334 -> Predictions: [[0.00358816]\n",
            " [0.9961224 ]\n",
            " [0.99611074]\n",
            " [0.00590644]]\n",
            "Step: 8811 -> Loss: 0.004325098358094692 -> Predictions: [[0.00358815]\n",
            " [0.99612254]\n",
            " [0.99611074]\n",
            " [0.00590642]]\n",
            "Step: 8812 -> Loss: 0.004325078334659338 -> Predictions: [[0.00358813]\n",
            " [0.99612254]\n",
            " [0.99611074]\n",
            " [0.00590639]]\n",
            "Step: 8813 -> Loss: 0.004325059242546558 -> Predictions: [[0.00358812]\n",
            " [0.99612254]\n",
            " [0.99611086]\n",
            " [0.00590636]]\n",
            "Step: 8814 -> Loss: 0.004325035028159618 -> Predictions: [[0.0035881 ]\n",
            " [0.99612254]\n",
            " [0.99611086]\n",
            " [0.00590632]]\n",
            "Step: 8815 -> Loss: 0.004325015936046839 -> Predictions: [[0.00358808]\n",
            " [0.99612254]\n",
            " [0.99611086]\n",
            " [0.0059063 ]]\n",
            "Step: 8816 -> Loss: 0.004324997775256634 -> Predictions: [[0.00358807]\n",
            " [0.99612254]\n",
            " [0.99611086]\n",
            " [0.00590627]]\n",
            "Step: 8817 -> Loss: 0.004324977286159992 -> Predictions: [[0.00358805]\n",
            " [0.99612254]\n",
            " [0.99611086]\n",
            " [0.00590624]]\n",
            "Step: 8818 -> Loss: 0.004324956797063351 -> Predictions: [[0.00358804]\n",
            " [0.99612266]\n",
            " [0.99611086]\n",
            " [0.00590621]]\n",
            "Step: 8819 -> Loss: 0.004324938170611858 -> Predictions: [[0.00358802]\n",
            " [0.99612266]\n",
            " [0.99611086]\n",
            " [0.00590618]]\n",
            "Step: 8820 -> Loss: 0.0043249172158539295 -> Predictions: [[0.00358801]\n",
            " [0.99612266]\n",
            " [0.996111  ]\n",
            " [0.00590615]]\n",
            "Step: 8821 -> Loss: 0.0043248990550637245 -> Predictions: [[0.00358799]\n",
            " [0.99612266]\n",
            " [0.996111  ]\n",
            " [0.00590613]]\n",
            "Step: 8822 -> Loss: 0.004324874375015497 -> Predictions: [[0.00358797]\n",
            " [0.99612266]\n",
            " [0.996111  ]\n",
            " [0.00590609]]\n",
            "Step: 8823 -> Loss: 0.0043248580768704414 -> Predictions: [[0.00358796]\n",
            " [0.99612266]\n",
            " [0.996111  ]\n",
            " [0.00590607]]\n",
            "Step: 8824 -> Loss: 0.0043248385190963745 -> Predictions: [[0.00358794]\n",
            " [0.99612266]\n",
            " [0.996111  ]\n",
            " [0.00590604]]\n",
            "Step: 8825 -> Loss: 0.00432481337338686 -> Predictions: [[0.00358792]\n",
            " [0.9961228 ]\n",
            " [0.996111  ]\n",
            " [0.005906  ]]\n",
            "Step: 8826 -> Loss: 0.004324793815612793 -> Predictions: [[0.0035879 ]\n",
            " [0.9961228 ]\n",
            " [0.9961111 ]\n",
            " [0.00590597]]\n",
            "Step: 8827 -> Loss: 0.004324774257838726 -> Predictions: [[0.00358789]\n",
            " [0.9961228 ]\n",
            " [0.9961111 ]\n",
            " [0.00590594]]\n",
            "Step: 8828 -> Loss: 0.004324754234403372 -> Predictions: [[0.00358787]\n",
            " [0.9961228 ]\n",
            " [0.9961111 ]\n",
            " [0.00590592]]\n",
            "Step: 8829 -> Loss: 0.004324734210968018 -> Predictions: [[0.00358785]\n",
            " [0.9961228 ]\n",
            " [0.9961111 ]\n",
            " [0.00590588]]\n",
            "Step: 8830 -> Loss: 0.004324714187532663 -> Predictions: [[0.00358784]\n",
            " [0.9961228 ]\n",
            " [0.9961111 ]\n",
            " [0.00590585]]\n",
            "Step: 8831 -> Loss: 0.004324696026742458 -> Predictions: [[0.00358782]\n",
            " [0.9961228 ]\n",
            " [0.9961111 ]\n",
            " [0.00590583]]\n",
            "Step: 8832 -> Loss: 0.004324674140661955 -> Predictions: [[0.0035878 ]\n",
            " [0.9961229 ]\n",
            " [0.9961111 ]\n",
            " [0.00590579]]\n",
            "Step: 8833 -> Loss: 0.004324654582887888 -> Predictions: [[0.00358779]\n",
            " [0.9961229 ]\n",
            " [0.9961112 ]\n",
            " [0.00590576]]\n",
            "Step: 8834 -> Loss: 0.004324633628129959 -> Predictions: [[0.00358778]\n",
            " [0.9961229 ]\n",
            " [0.9961112 ]\n",
            " [0.00590573]]\n",
            "Step: 8835 -> Loss: 0.0043246131390333176 -> Predictions: [[0.00358776]\n",
            " [0.9961229 ]\n",
            " [0.9961112 ]\n",
            " [0.00590571]]\n",
            "Step: 8836 -> Loss: 0.004324595909565687 -> Predictions: [[0.00358774]\n",
            " [0.9961229 ]\n",
            " [0.9961112 ]\n",
            " [0.00590568]]\n",
            "Step: 8837 -> Loss: 0.004324575420469046 -> Predictions: [[0.00358773]\n",
            " [0.9961229 ]\n",
            " [0.9961112 ]\n",
            " [0.00590565]]\n",
            "Step: 8838 -> Loss: 0.00432455213740468 -> Predictions: [[0.00358771]\n",
            " [0.9961229 ]\n",
            " [0.9961112 ]\n",
            " [0.00590562]]\n",
            "Step: 8839 -> Loss: 0.004324533045291901 -> Predictions: [[0.00358769]\n",
            " [0.996123  ]\n",
            " [0.9961112 ]\n",
            " [0.00590559]]\n",
            "Step: 8840 -> Loss: 0.004324513021856546 -> Predictions: [[0.00358768]\n",
            " [0.996123  ]\n",
            " [0.99611133]\n",
            " [0.00590555]]\n",
            "Step: 8841 -> Loss: 0.004324494861066341 -> Predictions: [[0.00358767]\n",
            " [0.996123  ]\n",
            " [0.99611133]\n",
            " [0.00590553]]\n",
            "Step: 8842 -> Loss: 0.004324476234614849 -> Predictions: [[0.00358765]\n",
            " [0.996123  ]\n",
            " [0.99611133]\n",
            " [0.00590551]]\n",
            "Step: 8843 -> Loss: 0.004324453882873058 -> Predictions: [[0.00358763]\n",
            " [0.996123  ]\n",
            " [0.99611133]\n",
            " [0.00590547]]\n",
            "Step: 8844 -> Loss: 0.004324433393776417 -> Predictions: [[0.00358762]\n",
            " [0.996123  ]\n",
            " [0.99611133]\n",
            " [0.00590544]]\n",
            "Step: 8845 -> Loss: 0.004324412439018488 -> Predictions: [[0.0035876 ]\n",
            " [0.99612314]\n",
            " [0.99611133]\n",
            " [0.00590541]]\n",
            "Step: 8846 -> Loss: 0.004324392881244421 -> Predictions: [[0.00358758]\n",
            " [0.99612314]\n",
            " [0.99611133]\n",
            " [0.00590539]]\n",
            "Step: 8847 -> Loss: 0.004324372857809067 -> Predictions: [[0.00358757]\n",
            " [0.99612314]\n",
            " [0.99611145]\n",
            " [0.00590535]]\n",
            "Step: 8848 -> Loss: 0.004324353765696287 -> Predictions: [[0.00358755]\n",
            " [0.99612314]\n",
            " [0.99611145]\n",
            " [0.00590533]]\n",
            "Step: 8849 -> Loss: 0.004324332810938358 -> Predictions: [[0.00358753]\n",
            " [0.99612314]\n",
            " [0.99611145]\n",
            " [0.00590529]]\n",
            "Step: 8850 -> Loss: 0.004324313718825579 -> Predictions: [[0.00358752]\n",
            " [0.99612314]\n",
            " [0.99611145]\n",
            " [0.00590527]]\n",
            "Step: 8851 -> Loss: 0.004324291367083788 -> Predictions: [[0.0035875 ]\n",
            " [0.99612314]\n",
            " [0.99611145]\n",
            " [0.00590523]]\n",
            "Step: 8852 -> Loss: 0.004324270412325859 -> Predictions: [[0.00358749]\n",
            " [0.99612325]\n",
            " [0.99611145]\n",
            " [0.0059052 ]]\n",
            "Step: 8853 -> Loss: 0.004324252251535654 -> Predictions: [[0.00358747]\n",
            " [0.99612325]\n",
            " [0.99611145]\n",
            " [0.00590518]]\n",
            "Step: 8854 -> Loss: 0.0043242317624390125 -> Predictions: [[0.00358745]\n",
            " [0.99612325]\n",
            " [0.9961116 ]\n",
            " [0.00590515]]\n",
            "Step: 8855 -> Loss: 0.00432421313598752 -> Predictions: [[0.00358744]\n",
            " [0.99612325]\n",
            " [0.9961116 ]\n",
            " [0.00590512]]\n",
            "Step: 8856 -> Loss: 0.004324193578213453 -> Predictions: [[0.00358742]\n",
            " [0.99612325]\n",
            " [0.9961116 ]\n",
            " [0.00590509]]\n",
            "Step: 8857 -> Loss: 0.004324169829487801 -> Predictions: [[0.00358741]\n",
            " [0.99612325]\n",
            " [0.9961116 ]\n",
            " [0.00590505]]\n",
            "Step: 8858 -> Loss: 0.00432415260002017 -> Predictions: [[0.00358739]\n",
            " [0.99612325]\n",
            " [0.9961116 ]\n",
            " [0.00590503]]\n",
            "Step: 8859 -> Loss: 0.004324132576584816 -> Predictions: [[0.00358737]\n",
            " [0.9961234 ]\n",
            " [0.9961116 ]\n",
            " [0.005905  ]]\n",
            "Step: 8860 -> Loss: 0.0043241111561656 -> Predictions: [[0.00358736]\n",
            " [0.9961234 ]\n",
            " [0.9961116 ]\n",
            " [0.00590497]]\n",
            "Step: 8861 -> Loss: 0.0043240925297141075 -> Predictions: [[0.00358734]\n",
            " [0.9961234 ]\n",
            " [0.9961117 ]\n",
            " [0.00590494]]\n",
            "Step: 8862 -> Loss: 0.004324070177972317 -> Predictions: [[0.00358732]\n",
            " [0.9961234 ]\n",
            " [0.9961117 ]\n",
            " [0.0059049 ]]\n",
            "Step: 8863 -> Loss: 0.004324049223214388 -> Predictions: [[0.00358731]\n",
            " [0.9961234 ]\n",
            " [0.9961117 ]\n",
            " [0.00590488]]\n",
            "Step: 8864 -> Loss: 0.004324029665440321 -> Predictions: [[0.00358729]\n",
            " [0.9961234 ]\n",
            " [0.9961117 ]\n",
            " [0.00590485]]\n",
            "Step: 8865 -> Loss: 0.0043240077793598175 -> Predictions: [[0.00358728]\n",
            " [0.9961234 ]\n",
            " [0.9961117 ]\n",
            " [0.00590481]]\n",
            "Step: 8866 -> Loss: 0.004323991015553474 -> Predictions: [[0.00358726]\n",
            " [0.9961235 ]\n",
            " [0.9961117 ]\n",
            " [0.00590479]]\n",
            "Step: 8867 -> Loss: 0.004323971923440695 -> Predictions: [[0.00358724]\n",
            " [0.9961235 ]\n",
            " [0.9961117 ]\n",
            " [0.00590476]]\n",
            "Step: 8868 -> Loss: 0.004323949571698904 -> Predictions: [[0.00358723]\n",
            " [0.9961235 ]\n",
            " [0.9961118 ]\n",
            " [0.00590473]]\n",
            "Step: 8869 -> Loss: 0.004323930479586124 -> Predictions: [[0.00358721]\n",
            " [0.9961235 ]\n",
            " [0.9961118 ]\n",
            " [0.0059047 ]]\n",
            "Step: 8870 -> Loss: 0.004323907196521759 -> Predictions: [[0.00358719]\n",
            " [0.9961235 ]\n",
            " [0.9961118 ]\n",
            " [0.00590467]]\n",
            "Step: 8871 -> Loss: 0.004323887638747692 -> Predictions: [[0.00358717]\n",
            " [0.9961235 ]\n",
            " [0.9961118 ]\n",
            " [0.00590464]]\n",
            "Step: 8872 -> Loss: 0.0043238690122962 -> Predictions: [[0.00358716]\n",
            " [0.9961235 ]\n",
            " [0.9961118 ]\n",
            " [0.00590461]]\n",
            "Step: 8873 -> Loss: 0.0043238503858447075 -> Predictions: [[0.00358714]\n",
            " [0.9961236 ]\n",
            " [0.9961118 ]\n",
            " [0.00590458]]\n",
            "Step: 8874 -> Loss: 0.004323829431086779 -> Predictions: [[0.00358713]\n",
            " [0.9961236 ]\n",
            " [0.9961119 ]\n",
            " [0.00590456]]\n",
            "Step: 8875 -> Loss: 0.004323809407651424 -> Predictions: [[0.00358711]\n",
            " [0.9961236 ]\n",
            " [0.9961119 ]\n",
            " [0.00590452]]\n",
            "Step: 8876 -> Loss: 0.004323791246861219 -> Predictions: [[0.0035871]\n",
            " [0.9961236]\n",
            " [0.9961119]\n",
            " [0.0059045]]\n",
            "Step: 8877 -> Loss: 0.004323767963796854 -> Predictions: [[0.00358708]\n",
            " [0.9961236 ]\n",
            " [0.9961119 ]\n",
            " [0.00590447]]\n",
            "Step: 8878 -> Loss: 0.004323747009038925 -> Predictions: [[0.00358706]\n",
            " [0.9961236 ]\n",
            " [0.9961119 ]\n",
            " [0.00590443]]\n",
            "Step: 8879 -> Loss: 0.004323730245232582 -> Predictions: [[0.00358705]\n",
            " [0.9961236 ]\n",
            " [0.9961119 ]\n",
            " [0.00590441]]\n",
            "Step: 8880 -> Loss: 0.004323706496506929 -> Predictions: [[0.00358703]\n",
            " [0.99612373]\n",
            " [0.9961119 ]\n",
            " [0.00590438]]\n",
            "Step: 8881 -> Loss: 0.004323688335716724 -> Predictions: [[0.00358702]\n",
            " [0.99612373]\n",
            " [0.99611205]\n",
            " [0.00590435]]\n",
            "Step: 8882 -> Loss: 0.0043236687779426575 -> Predictions: [[0.003587  ]\n",
            " [0.99612373]\n",
            " [0.99611205]\n",
            " [0.00590431]]\n",
            "Step: 8883 -> Loss: 0.004323646426200867 -> Predictions: [[0.00358698]\n",
            " [0.99612373]\n",
            " [0.99611205]\n",
            " [0.00590428]]\n",
            "Step: 8884 -> Loss: 0.004323628731071949 -> Predictions: [[0.00358696]\n",
            " [0.99612373]\n",
            " [0.99611205]\n",
            " [0.00590426]]\n",
            "Step: 8885 -> Loss: 0.004323605913668871 -> Predictions: [[0.00358695]\n",
            " [0.99612373]\n",
            " [0.99611205]\n",
            " [0.00590423]]\n",
            "Step: 8886 -> Loss: 0.00432359054684639 -> Predictions: [[0.00358694]\n",
            " [0.99612373]\n",
            " [0.99611205]\n",
            " [0.00590421]]\n",
            "Step: 8887 -> Loss: 0.004323568195104599 -> Predictions: [[0.00358692]\n",
            " [0.99612385]\n",
            " [0.99611205]\n",
            " [0.00590417]]\n",
            "Step: 8888 -> Loss: 0.004323548637330532 -> Predictions: [[0.0035869 ]\n",
            " [0.99612385]\n",
            " [0.99611217]\n",
            " [0.00590414]]\n",
            "Step: 8889 -> Loss: 0.004323527682572603 -> Predictions: [[0.00358689]\n",
            " [0.99612385]\n",
            " [0.99611217]\n",
            " [0.00590411]]\n",
            "Step: 8890 -> Loss: 0.004323507193475962 -> Predictions: [[0.00358687]\n",
            " [0.99612385]\n",
            " [0.99611217]\n",
            " [0.00590408]]\n",
            "Step: 8891 -> Loss: 0.0043234871700406075 -> Predictions: [[0.00358685]\n",
            " [0.99612385]\n",
            " [0.99611217]\n",
            " [0.00590405]]\n",
            "Step: 8892 -> Loss: 0.004323465749621391 -> Predictions: [[0.00358684]\n",
            " [0.99612385]\n",
            " [0.99611217]\n",
            " [0.00590402]]\n",
            "Step: 8893 -> Loss: 0.004323448054492474 -> Predictions: [[0.00358682]\n",
            " [0.99612385]\n",
            " [0.99611217]\n",
            " [0.00590399]]\n",
            "Step: 8894 -> Loss: 0.0043234266340732574 -> Predictions: [[0.00358681]\n",
            " [0.99612397]\n",
            " [0.99611217]\n",
            " [0.00590396]]\n",
            "Step: 8895 -> Loss: 0.004323404747992754 -> Predictions: [[0.00358679]\n",
            " [0.99612397]\n",
            " [0.9961123 ]\n",
            " [0.00590393]]\n",
            "Step: 8896 -> Loss: 0.0043233847245574 -> Predictions: [[0.00358677]\n",
            " [0.99612397]\n",
            " [0.9961123 ]\n",
            " [0.00590389]]\n",
            "Step: 8897 -> Loss: 0.004323368426412344 -> Predictions: [[0.00358675]\n",
            " [0.99612397]\n",
            " [0.9961123 ]\n",
            " [0.00590388]]\n",
            "Step: 8898 -> Loss: 0.0043233465403318405 -> Predictions: [[0.00358674]\n",
            " [0.99612397]\n",
            " [0.9961123 ]\n",
            " [0.00590385]]\n",
            "Step: 8899 -> Loss: 0.004323325119912624 -> Predictions: [[0.00358672]\n",
            " [0.99612397]\n",
            " [0.9961123 ]\n",
            " [0.00590381]]\n",
            "Step: 8900 -> Loss: 0.004323306027799845 -> Predictions: [[0.00358671]\n",
            " [0.99612397]\n",
            " [0.9961123 ]\n",
            " [0.00590379]]\n",
            "Step: 8901 -> Loss: 0.004323285073041916 -> Predictions: [[0.00358669]\n",
            " [0.9961241 ]\n",
            " [0.9961123 ]\n",
            " [0.00590375]]\n",
            "Step: 8902 -> Loss: 0.004323264583945274 -> Predictions: [[0.00358667]\n",
            " [0.9961241 ]\n",
            " [0.9961124 ]\n",
            " [0.00590372]]\n",
            "Step: 8903 -> Loss: 0.004323245026171207 -> Predictions: [[0.00358666]\n",
            " [0.9961241 ]\n",
            " [0.9961124 ]\n",
            " [0.00590369]]\n",
            "Step: 8904 -> Loss: 0.004323222674429417 -> Predictions: [[0.00358664]\n",
            " [0.9961241 ]\n",
            " [0.9961124 ]\n",
            " [0.00590366]]\n",
            "Step: 8905 -> Loss: 0.004323204047977924 -> Predictions: [[0.00358663]\n",
            " [0.9961241 ]\n",
            " [0.9961124 ]\n",
            " [0.00590363]]\n",
            "Step: 8906 -> Loss: 0.004323182627558708 -> Predictions: [[0.00358661]\n",
            " [0.9961241 ]\n",
            " [0.9961124 ]\n",
            " [0.0059036 ]]\n",
            "Step: 8907 -> Loss: 0.004323163069784641 -> Predictions: [[0.00358659]\n",
            " [0.9961241 ]\n",
            " [0.9961124 ]\n",
            " [0.00590358]]\n",
            "Step: 8908 -> Loss: 0.004323144443333149 -> Predictions: [[0.00358658]\n",
            " [0.9961242 ]\n",
            " [0.9961124 ]\n",
            " [0.00590354]]\n",
            "Step: 8909 -> Loss: 0.004323123022913933 -> Predictions: [[0.00358656]\n",
            " [0.9961242 ]\n",
            " [0.9961125 ]\n",
            " [0.00590351]]\n",
            "Step: 8910 -> Loss: 0.004323105793446302 -> Predictions: [[0.00358655]\n",
            " [0.9961242 ]\n",
            " [0.9961125 ]\n",
            " [0.00590349]]\n",
            "Step: 8911 -> Loss: 0.004323083441704512 -> Predictions: [[0.00358653]\n",
            " [0.9961242 ]\n",
            " [0.9961125 ]\n",
            " [0.00590346]]\n",
            "Step: 8912 -> Loss: 0.004323062486946583 -> Predictions: [[0.00358651]\n",
            " [0.9961242 ]\n",
            " [0.9961125 ]\n",
            " [0.00590342]]\n",
            "Step: 8913 -> Loss: 0.004323041997849941 -> Predictions: [[0.00358649]\n",
            " [0.9961242 ]\n",
            " [0.9961125 ]\n",
            " [0.0059034 ]]\n",
            "Step: 8914 -> Loss: 0.004323023837059736 -> Predictions: [[0.00358648]\n",
            " [0.9961242 ]\n",
            " [0.9961125 ]\n",
            " [0.00590337]]\n",
            "Step: 8915 -> Loss: 0.004323003813624382 -> Predictions: [[0.00358646]\n",
            " [0.9961243 ]\n",
            " [0.9961125 ]\n",
            " [0.00590334]]\n",
            "Step: 8916 -> Loss: 0.00432298518717289 -> Predictions: [[0.00358645]\n",
            " [0.9961243 ]\n",
            " [0.99611264]\n",
            " [0.00590332]]\n",
            "Step: 8917 -> Loss: 0.004322961904108524 -> Predictions: [[0.00358643]\n",
            " [0.9961243 ]\n",
            " [0.99611264]\n",
            " [0.00590327]]\n",
            "Step: 8918 -> Loss: 0.00432294188067317 -> Predictions: [[0.00358641]\n",
            " [0.9961243 ]\n",
            " [0.99611264]\n",
            " [0.00590325]]\n",
            "Step: 8919 -> Loss: 0.004322923254221678 -> Predictions: [[0.0035864 ]\n",
            " [0.9961243 ]\n",
            " [0.99611264]\n",
            " [0.00590322]]\n",
            "Step: 8920 -> Loss: 0.004322902299463749 -> Predictions: [[0.00358638]\n",
            " [0.9961243 ]\n",
            " [0.99611264]\n",
            " [0.00590319]]\n",
            "Step: 8921 -> Loss: 0.004322884604334831 -> Predictions: [[0.00358637]\n",
            " [0.9961243 ]\n",
            " [0.99611264]\n",
            " [0.00590317]]\n",
            "Step: 8922 -> Loss: 0.00432286411523819 -> Predictions: [[0.00358635]\n",
            " [0.99612445]\n",
            " [0.99611264]\n",
            " [0.00590314]]\n",
            "Step: 8923 -> Loss: 0.004322841763496399 -> Predictions: [[0.00358633]\n",
            " [0.99612445]\n",
            " [0.99611276]\n",
            " [0.0059031 ]]\n",
            "Step: 8924 -> Loss: 0.004322820343077183 -> Predictions: [[0.00358632]\n",
            " [0.99612445]\n",
            " [0.99611276]\n",
            " [0.00590307]]\n",
            "Step: 8925 -> Loss: 0.00432280357927084 -> Predictions: [[0.0035863 ]\n",
            " [0.99612445]\n",
            " [0.99611276]\n",
            " [0.00590305]]\n",
            "Step: 8926 -> Loss: 0.004322783090174198 -> Predictions: [[0.00358628]\n",
            " [0.99612445]\n",
            " [0.99611276]\n",
            " [0.00590302]]\n",
            "Step: 8927 -> Loss: 0.004322761204093695 -> Predictions: [[0.00358627]\n",
            " [0.99612445]\n",
            " [0.99611276]\n",
            " [0.00590298]]\n",
            "Step: 8928 -> Loss: 0.004322738852351904 -> Predictions: [[0.00358625]\n",
            " [0.99612457]\n",
            " [0.99611276]\n",
            " [0.00590295]]\n",
            "Step: 8929 -> Loss: 0.004322722088545561 -> Predictions: [[0.00358624]\n",
            " [0.99612457]\n",
            " [0.9961128 ]\n",
            " [0.00590293]]\n",
            "Step: 8930 -> Loss: 0.00432269973680377 -> Predictions: [[0.00358622]\n",
            " [0.99612457]\n",
            " [0.9961128 ]\n",
            " [0.00590289]]\n",
            "Step: 8931 -> Loss: 0.004322682972997427 -> Predictions: [[0.0035862 ]\n",
            " [0.99612457]\n",
            " [0.9961128 ]\n",
            " [0.00590287]]\n",
            "Step: 8932 -> Loss: 0.00432266341522336 -> Predictions: [[0.00358619]\n",
            " [0.99612457]\n",
            " [0.9961128 ]\n",
            " [0.00590284]]\n",
            "Step: 8933 -> Loss: 0.004322638735175133 -> Predictions: [[0.00358617]\n",
            " [0.99612457]\n",
            " [0.9961128 ]\n",
            " [0.0059028 ]]\n",
            "Step: 8934 -> Loss: 0.004322622437030077 -> Predictions: [[0.00358616]\n",
            " [0.99612457]\n",
            " [0.9961128 ]\n",
            " [0.00590278]]\n",
            "Step: 8935 -> Loss: 0.004322598688304424 -> Predictions: [[0.00358614]\n",
            " [0.9961247 ]\n",
            " [0.9961128 ]\n",
            " [0.00590275]]\n",
            "Step: 8936 -> Loss: 0.0043225823901593685 -> Predictions: [[0.00358613]\n",
            " [0.9961247 ]\n",
            " [0.9961128 ]\n",
            " [0.00590272]]\n",
            "Step: 8937 -> Loss: 0.004322562366724014 -> Predictions: [[0.00358611]\n",
            " [0.9961247 ]\n",
            " [0.99611294]\n",
            " [0.00590269]]\n",
            "Step: 8938 -> Loss: 0.004322538152337074 -> Predictions: [[0.00358609]\n",
            " [0.9961247 ]\n",
            " [0.99611294]\n",
            " [0.00590266]]\n",
            "Step: 8939 -> Loss: 0.004322520457208157 -> Predictions: [[0.00358607]\n",
            " [0.9961247 ]\n",
            " [0.99611294]\n",
            " [0.00590263]]\n",
            "Step: 8940 -> Loss: 0.004322499502450228 -> Predictions: [[0.00358606]\n",
            " [0.9961247 ]\n",
            " [0.99611294]\n",
            " [0.0059026 ]]\n",
            "Step: 8941 -> Loss: 0.004322480875998735 -> Predictions: [[0.00358604]\n",
            " [0.9961247 ]\n",
            " [0.99611294]\n",
            " [0.00590257]]\n",
            "Step: 8942 -> Loss: 0.004322459921240807 -> Predictions: [[0.00358603]\n",
            " [0.9961248 ]\n",
            " [0.99611294]\n",
            " [0.00590254]]\n",
            "Step: 8943 -> Loss: 0.004322439897805452 -> Predictions: [[0.00358601]\n",
            " [0.9961248 ]\n",
            " [0.99611306]\n",
            " [0.00590251]]\n",
            "Step: 8944 -> Loss: 0.0043224189430475235 -> Predictions: [[0.00358599]\n",
            " [0.9961248 ]\n",
            " [0.99611306]\n",
            " [0.00590248]]\n",
            "Step: 8945 -> Loss: 0.004322399385273457 -> Predictions: [[0.00358597]\n",
            " [0.9961248 ]\n",
            " [0.99611306]\n",
            " [0.00590245]]\n",
            "Step: 8946 -> Loss: 0.00432237796485424 -> Predictions: [[0.00358596]\n",
            " [0.9961248 ]\n",
            " [0.99611306]\n",
            " [0.00590242]]\n",
            "Step: 8947 -> Loss: 0.004322359804064035 -> Predictions: [[0.00358594]\n",
            " [0.9961248 ]\n",
            " [0.99611306]\n",
            " [0.00590239]]\n",
            "Step: 8948 -> Loss: 0.004322337452322245 -> Predictions: [[0.00358593]\n",
            " [0.9961248 ]\n",
            " [0.99611306]\n",
            " [0.00590236]]\n",
            "Step: 8949 -> Loss: 0.004322318360209465 -> Predictions: [[0.00358591]\n",
            " [0.9961249 ]\n",
            " [0.99611306]\n",
            " [0.00590233]]\n",
            "Step: 8950 -> Loss: 0.004322300665080547 -> Predictions: [[0.0035859 ]\n",
            " [0.9961249 ]\n",
            " [0.9961132 ]\n",
            " [0.00590231]]\n",
            "Step: 8951 -> Loss: 0.0043222797103226185 -> Predictions: [[0.00358588]\n",
            " [0.9961249 ]\n",
            " [0.9961132 ]\n",
            " [0.00590227]]\n",
            "Step: 8952 -> Loss: 0.004322260618209839 -> Predictions: [[0.00358586]\n",
            " [0.9961249 ]\n",
            " [0.9961132 ]\n",
            " [0.00590225]]\n",
            "Step: 8953 -> Loss: 0.004322238732129335 -> Predictions: [[0.00358585]\n",
            " [0.9961249 ]\n",
            " [0.9961132 ]\n",
            " [0.00590222]]\n",
            "Step: 8954 -> Loss: 0.004322218243032694 -> Predictions: [[0.00358583]\n",
            " [0.9961249 ]\n",
            " [0.9961132 ]\n",
            " [0.00590219]]\n",
            "Step: 8955 -> Loss: 0.00432219635695219 -> Predictions: [[0.00358582]\n",
            " [0.9961249 ]\n",
            " [0.9961132 ]\n",
            " [0.00590215]]\n",
            "Step: 8956 -> Loss: 0.004322178196161985 -> Predictions: [[0.0035858 ]\n",
            " [0.99612504]\n",
            " [0.9961132 ]\n",
            " [0.00590213]]\n",
            "Step: 8957 -> Loss: 0.004322159104049206 -> Predictions: [[0.00358578]\n",
            " [0.99612504]\n",
            " [0.9961133 ]\n",
            " [0.0059021 ]]\n",
            "Step: 8958 -> Loss: 0.004322139546275139 -> Predictions: [[0.00358577]\n",
            " [0.99612504]\n",
            " [0.9961133 ]\n",
            " [0.00590207]]\n",
            "Step: 8959 -> Loss: 0.0043221162632107735 -> Predictions: [[0.00358575]\n",
            " [0.99612504]\n",
            " [0.9961133 ]\n",
            " [0.00590203]]\n",
            "Step: 8960 -> Loss: 0.004322096239775419 -> Predictions: [[0.00358573]\n",
            " [0.99612504]\n",
            " [0.9961133 ]\n",
            " [0.00590201]]\n",
            "Step: 8961 -> Loss: 0.004322079010307789 -> Predictions: [[0.00358572]\n",
            " [0.99612504]\n",
            " [0.9961133 ]\n",
            " [0.00590198]]\n",
            "Step: 8962 -> Loss: 0.004322057124227285 -> Predictions: [[0.0035857 ]\n",
            " [0.99612504]\n",
            " [0.9961133 ]\n",
            " [0.00590195]]\n",
            "Step: 8963 -> Loss: 0.004322038032114506 -> Predictions: [[0.00358568]\n",
            " [0.99612516]\n",
            " [0.9961133 ]\n",
            " [0.00590192]]\n",
            "Step: 8964 -> Loss: 0.004322017543017864 -> Predictions: [[0.00358567]\n",
            " [0.99612516]\n",
            " [0.9961134 ]\n",
            " [0.00590189]]\n",
            "Step: 8965 -> Loss: 0.004321997053921223 -> Predictions: [[0.00358565]\n",
            " [0.99612516]\n",
            " [0.9961134 ]\n",
            " [0.00590186]]\n",
            "Step: 8966 -> Loss: 0.004321976564824581 -> Predictions: [[0.00358563]\n",
            " [0.99612516]\n",
            " [0.9961134 ]\n",
            " [0.00590183]]\n",
            "Step: 8967 -> Loss: 0.0043219588696956635 -> Predictions: [[0.00358562]\n",
            " [0.99612516]\n",
            " [0.9961134 ]\n",
            " [0.0059018 ]]\n",
            "Step: 8968 -> Loss: 0.00432193698361516 -> Predictions: [[0.00358561]\n",
            " [0.99612516]\n",
            " [0.9961134 ]\n",
            " [0.00590177]]\n",
            "Step: 8969 -> Loss: 0.004321916960179806 -> Predictions: [[0.00358559]\n",
            " [0.99612516]\n",
            " [0.9961134 ]\n",
            " [0.00590174]]\n",
            "Step: 8970 -> Loss: 0.00432189367711544 -> Predictions: [[0.00358557]\n",
            " [0.9961253 ]\n",
            " [0.9961134 ]\n",
            " [0.00590171]]\n",
            "Step: 8971 -> Loss: 0.004321874585002661 -> Predictions: [[0.00358555]\n",
            " [0.9961253 ]\n",
            " [0.99611354]\n",
            " [0.00590168]]\n",
            "Step: 8972 -> Loss: 0.004321856424212456 -> Predictions: [[0.00358554]\n",
            " [0.9961253 ]\n",
            " [0.99611354]\n",
            " [0.00590165]]\n",
            "Step: 8973 -> Loss: 0.004321836866438389 -> Predictions: [[0.00358552]\n",
            " [0.9961253 ]\n",
            " [0.99611354]\n",
            " [0.00590163]]\n",
            "Step: 8974 -> Loss: 0.004321817774325609 -> Predictions: [[0.00358551]\n",
            " [0.9961253 ]\n",
            " [0.99611354]\n",
            " [0.0059016 ]]\n",
            "Step: 8975 -> Loss: 0.004321795888245106 -> Predictions: [[0.00358549]\n",
            " [0.9961253 ]\n",
            " [0.99611354]\n",
            " [0.00590157]]\n",
            "Step: 8976 -> Loss: 0.004321776330471039 -> Predictions: [[0.00358547]\n",
            " [0.9961253 ]\n",
            " [0.99611354]\n",
            " [0.00590154]]\n",
            "Step: 8977 -> Loss: 0.004321755841374397 -> Predictions: [[0.00358546]\n",
            " [0.9961254 ]\n",
            " [0.99611366]\n",
            " [0.00590151]]\n",
            "Step: 8978 -> Loss: 0.004321737214922905 -> Predictions: [[0.00358545]\n",
            " [0.9961254 ]\n",
            " [0.99611366]\n",
            " [0.00590148]]\n",
            "Step: 8979 -> Loss: 0.004321715794503689 -> Predictions: [[0.00358543]\n",
            " [0.9961254 ]\n",
            " [0.99611366]\n",
            " [0.00590145]]\n",
            "Step: 8980 -> Loss: 0.004321696236729622 -> Predictions: [[0.00358541]\n",
            " [0.9961254 ]\n",
            " [0.99611366]\n",
            " [0.00590142]]\n",
            "Step: 8981 -> Loss: 0.004321675281971693 -> Predictions: [[0.00358539]\n",
            " [0.9961254 ]\n",
            " [0.99611366]\n",
            " [0.00590139]]\n",
            "Step: 8982 -> Loss: 0.004321654327213764 -> Predictions: [[0.00358538]\n",
            " [0.9961254 ]\n",
            " [0.99611366]\n",
            " [0.00590135]]\n",
            "Step: 8983 -> Loss: 0.004321631044149399 -> Predictions: [[0.00358536]\n",
            " [0.9961255 ]\n",
            " [0.99611366]\n",
            " [0.00590132]]\n",
            "Step: 8984 -> Loss: 0.004321613349020481 -> Predictions: [[0.00358534]\n",
            " [0.9961255 ]\n",
            " [0.9961138 ]\n",
            " [0.0059013 ]]\n",
            "Step: 8985 -> Loss: 0.004321595188230276 -> Predictions: [[0.00358533]\n",
            " [0.9961255 ]\n",
            " [0.9961138 ]\n",
            " [0.00590127]]\n",
            "Step: 8986 -> Loss: 0.004321574233472347 -> Predictions: [[0.00358531]\n",
            " [0.9961255 ]\n",
            " [0.9961138 ]\n",
            " [0.00590124]]\n",
            "Step: 8987 -> Loss: 0.004321556072682142 -> Predictions: [[0.00358529]\n",
            " [0.9961255 ]\n",
            " [0.9961138 ]\n",
            " [0.00590122]]\n",
            "Step: 8988 -> Loss: 0.004321534186601639 -> Predictions: [[0.00358528]\n",
            " [0.9961255 ]\n",
            " [0.9961138 ]\n",
            " [0.00590118]]\n",
            "Step: 8989 -> Loss: 0.004321513697504997 -> Predictions: [[0.00358526]\n",
            " [0.9961255 ]\n",
            " [0.9961138 ]\n",
            " [0.00590116]]\n",
            "Step: 8990 -> Loss: 0.0043214913457632065 -> Predictions: [[0.00358524]\n",
            " [0.9961255 ]\n",
            " [0.9961138 ]\n",
            " [0.00590112]]\n",
            "Step: 8991 -> Loss: 0.0043214731849730015 -> Predictions: [[0.00358523]\n",
            " [0.99612564]\n",
            " [0.9961139 ]\n",
            " [0.00590109]]\n",
            "Step: 8992 -> Loss: 0.004321451764553785 -> Predictions: [[0.00358522]\n",
            " [0.99612564]\n",
            " [0.9961139 ]\n",
            " [0.00590106]]\n",
            "Step: 8993 -> Loss: 0.0043214354664087296 -> Predictions: [[0.0035852 ]\n",
            " [0.99612564]\n",
            " [0.9961139 ]\n",
            " [0.00590104]]\n",
            "Step: 8994 -> Loss: 0.004321413114666939 -> Predictions: [[0.00358518]\n",
            " [0.99612564]\n",
            " [0.9961139 ]\n",
            " [0.005901  ]]\n",
            "Step: 8995 -> Loss: 0.004321393556892872 -> Predictions: [[0.00358517]\n",
            " [0.99612564]\n",
            " [0.9961139 ]\n",
            " [0.00590097]]\n",
            "Step: 8996 -> Loss: 0.004321371670812368 -> Predictions: [[0.00358515]\n",
            " [0.99612564]\n",
            " [0.9961139 ]\n",
            " [0.00590094]]\n",
            "Step: 8997 -> Loss: 0.004321352578699589 -> Predictions: [[0.00358513]\n",
            " [0.99612576]\n",
            " [0.9961139 ]\n",
            " [0.00590091]]\n",
            "Step: 8998 -> Loss: 0.0043213339522480965 -> Predictions: [[0.00358512]\n",
            " [0.99612576]\n",
            " [0.996114  ]\n",
            " [0.00590089]]\n",
            "Step: 8999 -> Loss: 0.004321312997490168 -> Predictions: [[0.0035851 ]\n",
            " [0.99612576]\n",
            " [0.996114  ]\n",
            " [0.00590085]]\n",
            "Step: 9001 -> Loss: 0.004321272484958172 -> Predictions: [[0.00358507]\n",
            " [0.99612576]\n",
            " [0.996114  ]\n",
            " [0.0059008 ]]\n",
            "Step: 9002 -> Loss: 0.004321252927184105 -> Predictions: [[0.00358505]\n",
            " [0.99612576]\n",
            " [0.996114  ]\n",
            " [0.00590077]]\n",
            "Step: 9003 -> Loss: 0.004321231506764889 -> Predictions: [[0.00358504]\n",
            " [0.99612576]\n",
            " [0.996114  ]\n",
            " [0.00590074]]\n",
            "Step: 9004 -> Loss: 0.0043212128803133965 -> Predictions: [[0.00358502]\n",
            " [0.9961259 ]\n",
            " [0.996114  ]\n",
            " [0.00590071]]\n",
            "Step: 9005 -> Loss: 0.0043211933225393295 -> Predictions: [[0.00358501]\n",
            " [0.9961259 ]\n",
            " [0.99611413]\n",
            " [0.00590068]]\n",
            "Step: 9006 -> Loss: 0.004321171902120113 -> Predictions: [[0.00358499]\n",
            " [0.9961259 ]\n",
            " [0.99611413]\n",
            " [0.00590065]]\n",
            "Step: 9007 -> Loss: 0.004321149550378323 -> Predictions: [[0.00358497]\n",
            " [0.9961259 ]\n",
            " [0.99611413]\n",
            " [0.00590062]]\n",
            "Step: 9008 -> Loss: 0.004321130458265543 -> Predictions: [[0.00358495]\n",
            " [0.9961259 ]\n",
            " [0.99611413]\n",
            " [0.00590059]]\n",
            "Step: 9009 -> Loss: 0.004321110900491476 -> Predictions: [[0.00358494]\n",
            " [0.9961259 ]\n",
            " [0.99611413]\n",
            " [0.00590056]]\n",
            "Step: 9010 -> Loss: 0.0043210904113948345 -> Predictions: [[0.00358493]\n",
            " [0.9961259 ]\n",
            " [0.99611413]\n",
            " [0.00590053]]\n",
            "Step: 9011 -> Loss: 0.0043210722506046295 -> Predictions: [[0.00358491]\n",
            " [0.996126  ]\n",
            " [0.99611413]\n",
            " [0.0059005 ]]\n",
            "Step: 9012 -> Loss: 0.004321051295846701 -> Predictions: [[0.00358489]\n",
            " [0.996126  ]\n",
            " [0.99611425]\n",
            " [0.00590048]]\n",
            "Step: 9013 -> Loss: 0.004321031738072634 -> Predictions: [[0.00358487]\n",
            " [0.996126  ]\n",
            " [0.99611425]\n",
            " [0.00590044]]\n",
            "Step: 9014 -> Loss: 0.0043210117146372795 -> Predictions: [[0.00358486]\n",
            " [0.996126  ]\n",
            " [0.99611425]\n",
            " [0.00590041]]\n",
            "Step: 9015 -> Loss: 0.004320990294218063 -> Predictions: [[0.00358484]\n",
            " [0.996126  ]\n",
            " [0.99611425]\n",
            " [0.00590038]]\n",
            "Step: 9016 -> Loss: 0.004320969805121422 -> Predictions: [[0.00358483]\n",
            " [0.996126  ]\n",
            " [0.99611425]\n",
            " [0.00590035]]\n",
            "Step: 9017 -> Loss: 0.004320948384702206 -> Predictions: [[0.00358481]\n",
            " [0.996126  ]\n",
            " [0.99611425]\n",
            " [0.00590032]]\n",
            "Step: 9018 -> Loss: 0.004320931620895863 -> Predictions: [[0.0035848 ]\n",
            " [0.9961261 ]\n",
            " [0.99611425]\n",
            " [0.0059003 ]]\n",
            "Step: 9019 -> Loss: 0.004320912063121796 -> Predictions: [[0.00358478]\n",
            " [0.9961261 ]\n",
            " [0.9961144 ]\n",
            " [0.00590026]]\n",
            "Step: 9020 -> Loss: 0.0043208906427025795 -> Predictions: [[0.00358476]\n",
            " [0.9961261 ]\n",
            " [0.9961144 ]\n",
            " [0.00590023]]\n",
            "Step: 9021 -> Loss: 0.004320869222283363 -> Predictions: [[0.00358475]\n",
            " [0.9961261 ]\n",
            " [0.9961144 ]\n",
            " [0.0059002 ]]\n",
            "Step: 9022 -> Loss: 0.004320846870541573 -> Predictions: [[0.00358473]\n",
            " [0.9961261 ]\n",
            " [0.9961144 ]\n",
            " [0.00590017]]\n",
            "Step: 9023 -> Loss: 0.004320830572396517 -> Predictions: [[0.00358472]\n",
            " [0.9961261 ]\n",
            " [0.9961144 ]\n",
            " [0.00590015]]\n",
            "Step: 9024 -> Loss: 0.004320810083299875 -> Predictions: [[0.0035847 ]\n",
            " [0.9961261 ]\n",
            " [0.9961144 ]\n",
            " [0.00590012]]\n",
            "Step: 9025 -> Loss: 0.004320788197219372 -> Predictions: [[0.00358468]\n",
            " [0.99612623]\n",
            " [0.9961144 ]\n",
            " [0.00590008]]\n",
            "Step: 9026 -> Loss: 0.004320768639445305 -> Predictions: [[0.00358467]\n",
            " [0.99612623]\n",
            " [0.9961145 ]\n",
            " [0.00590006]]\n",
            "Step: 9027 -> Loss: 0.004320748150348663 -> Predictions: [[0.00358465]\n",
            " [0.99612623]\n",
            " [0.9961145 ]\n",
            " [0.00590002]]\n",
            "Step: 9028 -> Loss: 0.004320730455219746 -> Predictions: [[0.00358464]\n",
            " [0.99612623]\n",
            " [0.9961145 ]\n",
            " [0.0059    ]]\n",
            "Step: 9029 -> Loss: 0.004320706240832806 -> Predictions: [[0.00358461]\n",
            " [0.99612623]\n",
            " [0.9961145 ]\n",
            " [0.00589997]]\n",
            "Step: 9030 -> Loss: 0.004320688080042601 -> Predictions: [[0.0035846 ]\n",
            " [0.99612623]\n",
            " [0.9961145 ]\n",
            " [0.00589994]]\n",
            "Step: 9031 -> Loss: 0.00432067085057497 -> Predictions: [[0.00358458]\n",
            " [0.99612623]\n",
            " [0.9961145 ]\n",
            " [0.00589992]]\n",
            "Step: 9032 -> Loss: 0.004320648964494467 -> Predictions: [[0.00358456]\n",
            " [0.99612635]\n",
            " [0.9961145 ]\n",
            " [0.00589988]]\n",
            "Step: 9033 -> Loss: 0.004320627544075251 -> Predictions: [[0.00358455]\n",
            " [0.99612635]\n",
            " [0.9961146 ]\n",
            " [0.00589985]]\n",
            "Step: 9034 -> Loss: 0.004320605657994747 -> Predictions: [[0.00358454]\n",
            " [0.99612635]\n",
            " [0.9961146 ]\n",
            " [0.00589982]]\n",
            "Step: 9035 -> Loss: 0.004320588428527117 -> Predictions: [[0.00358452]\n",
            " [0.99612635]\n",
            " [0.9961146 ]\n",
            " [0.0058998 ]]\n",
            "Step: 9036 -> Loss: 0.004320566076785326 -> Predictions: [[0.0035845 ]\n",
            " [0.99612635]\n",
            " [0.9961146 ]\n",
            " [0.00589976]]\n",
            "Step: 9037 -> Loss: 0.004320547915995121 -> Predictions: [[0.00358449]\n",
            " [0.99612635]\n",
            " [0.9961146 ]\n",
            " [0.00589973]]\n",
            "Step: 9038 -> Loss: 0.00432052556425333 -> Predictions: [[0.00358447]\n",
            " [0.99612635]\n",
            " [0.9961146 ]\n",
            " [0.0058997 ]]\n",
            "Step: 9039 -> Loss: 0.004320507403463125 -> Predictions: [[0.00358445]\n",
            " [0.9961265 ]\n",
            " [0.9961146 ]\n",
            " [0.00589967]]\n",
            "Step: 9040 -> Loss: 0.004320487380027771 -> Predictions: [[0.00358443]\n",
            " [0.9961265 ]\n",
            " [0.99611473]\n",
            " [0.00589965]]\n",
            "Step: 9041 -> Loss: 0.004320468287914991 -> Predictions: [[0.00358442]\n",
            " [0.9961265 ]\n",
            " [0.99611473]\n",
            " [0.00589961]]\n",
            "Step: 9042 -> Loss: 0.004320449195802212 -> Predictions: [[0.00358441]\n",
            " [0.9961265 ]\n",
            " [0.99611473]\n",
            " [0.00589959]]\n",
            "Step: 9043 -> Loss: 0.004320428241044283 -> Predictions: [[0.00358439]\n",
            " [0.9961265 ]\n",
            " [0.99611473]\n",
            " [0.00589955]]\n",
            "Step: 9044 -> Loss: 0.004320409148931503 -> Predictions: [[0.00358437]\n",
            " [0.9961265 ]\n",
            " [0.99611473]\n",
            " [0.00589953]]\n",
            "Step: 9045 -> Loss: 0.004320387728512287 -> Predictions: [[0.00358436]\n",
            " [0.9961265 ]\n",
            " [0.99611473]\n",
            " [0.0058995 ]]\n",
            "Step: 9046 -> Loss: 0.004320365842431784 -> Predictions: [[0.00358434]\n",
            " [0.9961266 ]\n",
            " [0.99611485]\n",
            " [0.00589947]]\n",
            "Step: 9047 -> Loss: 0.004320346284657717 -> Predictions: [[0.00358433]\n",
            " [0.9961266 ]\n",
            " [0.99611485]\n",
            " [0.00589943]]\n",
            "Step: 9048 -> Loss: 0.004320329055190086 -> Predictions: [[0.00358431]\n",
            " [0.9961266 ]\n",
            " [0.99611485]\n",
            " [0.00589941]]\n",
            "Step: 9049 -> Loss: 0.004320306703448296 -> Predictions: [[0.00358429]\n",
            " [0.9961266 ]\n",
            " [0.99611485]\n",
            " [0.00589938]]\n",
            "Step: 9050 -> Loss: 0.004320286680012941 -> Predictions: [[0.00358428]\n",
            " [0.9961266 ]\n",
            " [0.99611485]\n",
            " [0.00589935]]\n",
            "Step: 9051 -> Loss: 0.004320266656577587 -> Predictions: [[0.00358426]\n",
            " [0.9961266 ]\n",
            " [0.99611485]\n",
            " [0.00589932]]\n",
            "Step: 9052 -> Loss: 0.004320246167480946 -> Predictions: [[0.00358425]\n",
            " [0.9961266 ]\n",
            " [0.99611485]\n",
            " [0.00589928]]\n",
            "Step: 9053 -> Loss: 0.004320227541029453 -> Predictions: [[0.00358423]\n",
            " [0.9961267 ]\n",
            " [0.99611497]\n",
            " [0.00589926]]\n",
            "Step: 9054 -> Loss: 0.00432020565494895 -> Predictions: [[0.00358421]\n",
            " [0.9961267 ]\n",
            " [0.99611497]\n",
            " [0.00589923]]\n",
            "Step: 9055 -> Loss: 0.004320184700191021 -> Predictions: [[0.00358419]\n",
            " [0.9961267 ]\n",
            " [0.99611497]\n",
            " [0.0058992 ]]\n",
            "Step: 9056 -> Loss: 0.004320165142416954 -> Predictions: [[0.00358417]\n",
            " [0.9961267 ]\n",
            " [0.99611497]\n",
            " [0.00589917]]\n",
            "Step: 9057 -> Loss: 0.004320146515965462 -> Predictions: [[0.00358416]\n",
            " [0.9961267 ]\n",
            " [0.99611497]\n",
            " [0.00589914]]\n",
            "Step: 9058 -> Loss: 0.004320125561207533 -> Predictions: [[0.00358415]\n",
            " [0.9961267 ]\n",
            " [0.99611497]\n",
            " [0.00589911]]\n",
            "Step: 9059 -> Loss: 0.004320104606449604 -> Predictions: [[0.00358413]\n",
            " [0.99612683]\n",
            " [0.99611497]\n",
            " [0.00589908]]\n",
            "Step: 9060 -> Loss: 0.0043200841173529625 -> Predictions: [[0.00358411]\n",
            " [0.99612683]\n",
            " [0.9961151 ]\n",
            " [0.00589905]]\n",
            "Step: 9061 -> Loss: 0.004320064559578896 -> Predictions: [[0.00358409]\n",
            " [0.99612683]\n",
            " [0.9961151 ]\n",
            " [0.00589902]]\n",
            "Step: 9062 -> Loss: 0.004320045933127403 -> Predictions: [[0.00358408]\n",
            " [0.99612683]\n",
            " [0.9961151 ]\n",
            " [0.005899  ]]\n",
            "Step: 9063 -> Loss: 0.004320025444030762 -> Predictions: [[0.00358407]\n",
            " [0.99612683]\n",
            " [0.9961151 ]\n",
            " [0.00589896]]\n",
            "Step: 9064 -> Loss: 0.004320002626627684 -> Predictions: [[0.00358405]\n",
            " [0.99612683]\n",
            " [0.9961151 ]\n",
            " [0.00589893]]\n",
            "Step: 9065 -> Loss: 0.004319982603192329 -> Predictions: [[0.00358403]\n",
            " [0.99612683]\n",
            " [0.9961151 ]\n",
            " [0.0058989 ]]\n",
            "Step: 9066 -> Loss: 0.0043199630454182625 -> Predictions: [[0.00358402]\n",
            " [0.99612695]\n",
            " [0.9961151 ]\n",
            " [0.00589887]]\n",
            "Step: 9067 -> Loss: 0.004319946281611919 -> Predictions: [[0.003584  ]\n",
            " [0.99612695]\n",
            " [0.9961152 ]\n",
            " [0.00589885]]\n",
            "Step: 9068 -> Loss: 0.004319924861192703 -> Predictions: [[0.00358399]\n",
            " [0.99612695]\n",
            " [0.9961152 ]\n",
            " [0.00589881]]\n",
            "Step: 9069 -> Loss: 0.004319903440773487 -> Predictions: [[0.00358397]\n",
            " [0.99612695]\n",
            " [0.9961152 ]\n",
            " [0.00589879]]\n",
            "Step: 9070 -> Loss: 0.004319885279983282 -> Predictions: [[0.00358395]\n",
            " [0.99612695]\n",
            " [0.9961152 ]\n",
            " [0.00589876]]\n",
            "Step: 9071 -> Loss: 0.004319864325225353 -> Predictions: [[0.00358394]\n",
            " [0.99612695]\n",
            " [0.9961152 ]\n",
            " [0.00589873]]\n",
            "Step: 9072 -> Loss: 0.004319842904806137 -> Predictions: [[0.00358391]\n",
            " [0.99612695]\n",
            " [0.9961152 ]\n",
            " [0.0058987 ]]\n",
            "Step: 9073 -> Loss: 0.00431982334703207 -> Predictions: [[0.0035839 ]\n",
            " [0.99612707]\n",
            " [0.9961152 ]\n",
            " [0.00589867]]\n",
            "Step: 9074 -> Loss: 0.0043198056519031525 -> Predictions: [[0.00358389]\n",
            " [0.99612707]\n",
            " [0.9961153 ]\n",
            " [0.00589864]]\n",
            "Step: 9075 -> Loss: 0.004319783765822649 -> Predictions: [[0.00358387]\n",
            " [0.99612707]\n",
            " [0.9961153 ]\n",
            " [0.00589861]]\n",
            "Step: 9076 -> Loss: 0.004319760482758284 -> Predictions: [[0.00358386]\n",
            " [0.99612707]\n",
            " [0.9961153 ]\n",
            " [0.00589857]]\n",
            "Step: 9077 -> Loss: 0.004319743253290653 -> Predictions: [[0.00358384]\n",
            " [0.99612707]\n",
            " [0.9961153 ]\n",
            " [0.00589855]]\n",
            "Step: 9078 -> Loss: 0.004319725092500448 -> Predictions: [[0.00358383]\n",
            " [0.99612707]\n",
            " [0.9961153 ]\n",
            " [0.00589852]]\n",
            "Step: 9079 -> Loss: 0.0043197027407586575 -> Predictions: [[0.00358381]\n",
            " [0.99612707]\n",
            " [0.9961153 ]\n",
            " [0.00589849]]\n",
            "Step: 9080 -> Loss: 0.004319682717323303 -> Predictions: [[0.00358379]\n",
            " [0.9961272 ]\n",
            " [0.9961153 ]\n",
            " [0.00589846]]\n",
            "Step: 9081 -> Loss: 0.0043196603655815125 -> Predictions: [[0.00358377]\n",
            " [0.9961272 ]\n",
            " [0.99611545]\n",
            " [0.00589843]]\n",
            "Step: 9082 -> Loss: 0.0043196422047913074 -> Predictions: [[0.00358376]\n",
            " [0.9961272 ]\n",
            " [0.99611545]\n",
            " [0.0058984 ]]\n",
            "Step: 9083 -> Loss: 0.004319621715694666 -> Predictions: [[0.00358374]\n",
            " [0.9961272 ]\n",
            " [0.99611545]\n",
            " [0.00589837]]\n",
            "Step: 9084 -> Loss: 0.004319600760936737 -> Predictions: [[0.00358373]\n",
            " [0.9961272 ]\n",
            " [0.99611545]\n",
            " [0.00589834]]\n",
            "Step: 9085 -> Loss: 0.004319582134485245 -> Predictions: [[0.00358371]\n",
            " [0.9961272 ]\n",
            " [0.99611545]\n",
            " [0.00589831]]\n",
            "Step: 9086 -> Loss: 0.0043195635080337524 -> Predictions: [[0.00358369]\n",
            " [0.9961272 ]\n",
            " [0.99611545]\n",
            " [0.00589828]]\n",
            "Step: 9087 -> Loss: 0.004319541621953249 -> Predictions: [[0.00358367]\n",
            " [0.9961273 ]\n",
            " [0.99611545]\n",
            " [0.00589826]]\n",
            "Step: 9088 -> Loss: 0.004319522064179182 -> Predictions: [[0.00358366]\n",
            " [0.9961273 ]\n",
            " [0.99611557]\n",
            " [0.00589823]]\n",
            "Step: 9089 -> Loss: 0.0043195029720664024 -> Predictions: [[0.00358365]\n",
            " [0.9961273 ]\n",
            " [0.99611557]\n",
            " [0.00589819]]\n",
            "Step: 9090 -> Loss: 0.004319482482969761 -> Predictions: [[0.00358363]\n",
            " [0.9961273 ]\n",
            " [0.99611557]\n",
            " [0.00589817]]\n",
            "Step: 9091 -> Loss: 0.004319461062550545 -> Predictions: [[0.00358361]\n",
            " [0.9961273 ]\n",
            " [0.99611557]\n",
            " [0.00589813]]\n",
            "Step: 9092 -> Loss: 0.004319441970437765 -> Predictions: [[0.00358359]\n",
            " [0.9961273 ]\n",
            " [0.99611557]\n",
            " [0.00589811]]\n",
            "Step: 9093 -> Loss: 0.004319421015679836 -> Predictions: [[0.00358358]\n",
            " [0.9961273 ]\n",
            " [0.99611557]\n",
            " [0.00589808]]\n",
            "Step: 9094 -> Loss: 0.004319400526583195 -> Predictions: [[0.00358356]\n",
            " [0.9961274 ]\n",
            " [0.99611557]\n",
            " [0.00589805]]\n",
            "Step: 9095 -> Loss: 0.004319381900131702 -> Predictions: [[0.00358355]\n",
            " [0.9961274 ]\n",
            " [0.9961157 ]\n",
            " [0.00589802]]\n",
            "Step: 9096 -> Loss: 0.004319361411035061 -> Predictions: [[0.00358353]\n",
            " [0.9961274 ]\n",
            " [0.9961157 ]\n",
            " [0.00589799]]\n",
            "Step: 9097 -> Loss: 0.004319339524954557 -> Predictions: [[0.00358351]\n",
            " [0.9961274 ]\n",
            " [0.9961157 ]\n",
            " [0.00589796]]\n",
            "Step: 9098 -> Loss: 0.004319321364164352 -> Predictions: [[0.0035835 ]\n",
            " [0.9961274 ]\n",
            " [0.9961157 ]\n",
            " [0.00589793]]\n",
            "Step: 9099 -> Loss: 0.004319300875067711 -> Predictions: [[0.00358349]\n",
            " [0.9961274 ]\n",
            " [0.9961157 ]\n",
            " [0.00589789]]\n",
            "Step: 9100 -> Loss: 0.004319280385971069 -> Predictions: [[0.00358347]\n",
            " [0.9961274 ]\n",
            " [0.9961157 ]\n",
            " [0.00589787]]\n",
            "Step: 9101 -> Loss: 0.004319259896874428 -> Predictions: [[0.00358345]\n",
            " [0.99612755]\n",
            " [0.9961158 ]\n",
            " [0.00589784]]\n",
            "Step: 9102 -> Loss: 0.0043192398734390736 -> Predictions: [[0.00358344]\n",
            " [0.99612755]\n",
            " [0.9961158 ]\n",
            " [0.00589781]]\n",
            "Step: 9103 -> Loss: 0.004319220781326294 -> Predictions: [[0.00358342]\n",
            " [0.99612755]\n",
            " [0.9961158 ]\n",
            " [0.00589779]]\n",
            "Step: 9104 -> Loss: 0.0043191988952457905 -> Predictions: [[0.0035834 ]\n",
            " [0.99612755]\n",
            " [0.9961158 ]\n",
            " [0.00589775]]\n",
            "Step: 9105 -> Loss: 0.004319178871810436 -> Predictions: [[0.00358338]\n",
            " [0.99612755]\n",
            " [0.9961158 ]\n",
            " [0.00589772]]\n",
            "Step: 9106 -> Loss: 0.004319159314036369 -> Predictions: [[0.00358337]\n",
            " [0.99612755]\n",
            " [0.9961158 ]\n",
            " [0.0058977 ]]\n",
            "Step: 9107 -> Loss: 0.004319139290601015 -> Predictions: [[0.00358335]\n",
            " [0.99612755]\n",
            " [0.9961158 ]\n",
            " [0.00589766]]\n",
            "Step: 9108 -> Loss: 0.0043191201984882355 -> Predictions: [[0.00358334]\n",
            " [0.99612767]\n",
            " [0.9961159 ]\n",
            " [0.00589763]]\n",
            "Step: 9109 -> Loss: 0.004319099243730307 -> Predictions: [[0.00358332]\n",
            " [0.99612767]\n",
            " [0.9961159 ]\n",
            " [0.0058976 ]]\n",
            "Step: 9110 -> Loss: 0.004319079220294952 -> Predictions: [[0.0035833 ]\n",
            " [0.99612767]\n",
            " [0.9961159 ]\n",
            " [0.00589758]]\n",
            "Step: 9111 -> Loss: 0.0043190596625208855 -> Predictions: [[0.00358329]\n",
            " [0.99612767]\n",
            " [0.9961159 ]\n",
            " [0.00589755]]\n",
            "Step: 9112 -> Loss: 0.0043190401047468185 -> Predictions: [[0.00358327]\n",
            " [0.99612767]\n",
            " [0.9961159 ]\n",
            " [0.00589752]]\n",
            "Step: 9113 -> Loss: 0.0043190172873437405 -> Predictions: [[0.00358325]\n",
            " [0.99612767]\n",
            " [0.9961159 ]\n",
            " [0.00589748]]\n",
            "Step: 9114 -> Loss: 0.004318997263908386 -> Predictions: [[0.00358324]\n",
            " [0.9961278 ]\n",
            " [0.9961159 ]\n",
            " [0.00589746]]\n",
            "Step: 9115 -> Loss: 0.004318978171795607 -> Predictions: [[0.00358322]\n",
            " [0.9961278 ]\n",
            " [0.99611604]\n",
            " [0.00589742]]\n",
            "Step: 9116 -> Loss: 0.00431895861402154 -> Predictions: [[0.00358321]\n",
            " [0.9961278 ]\n",
            " [0.99611604]\n",
            " [0.00589739]]\n",
            "Step: 9117 -> Loss: 0.0043189385905861855 -> Predictions: [[0.00358319]\n",
            " [0.9961278 ]\n",
            " [0.99611604]\n",
            " [0.00589737]]\n",
            "Step: 9118 -> Loss: 0.004318916704505682 -> Predictions: [[0.00358317]\n",
            " [0.9961278 ]\n",
            " [0.99611604]\n",
            " [0.00589734]]\n",
            "Step: 9119 -> Loss: 0.004318898543715477 -> Predictions: [[0.00358316]\n",
            " [0.9961278 ]\n",
            " [0.99611604]\n",
            " [0.00589731]]\n",
            "Step: 9120 -> Loss: 0.0043188766576349735 -> Predictions: [[0.00358314]\n",
            " [0.9961278 ]\n",
            " [0.99611604]\n",
            " [0.00589728]]\n",
            "Step: 9121 -> Loss: 0.004318857565522194 -> Predictions: [[0.00358313]\n",
            " [0.9961279 ]\n",
            " [0.99611604]\n",
            " [0.00589724]]\n",
            "Step: 9122 -> Loss: 0.004318839404731989 -> Predictions: [[0.00358311]\n",
            " [0.9961279 ]\n",
            " [0.99611616]\n",
            " [0.00589722]]\n",
            "Step: 9123 -> Loss: 0.004318815656006336 -> Predictions: [[0.00358309]\n",
            " [0.9961279 ]\n",
            " [0.99611616]\n",
            " [0.00589719]]\n",
            "Step: 9124 -> Loss: 0.004318799823522568 -> Predictions: [[0.00358308]\n",
            " [0.9961279 ]\n",
            " [0.99611616]\n",
            " [0.00589716]]\n",
            "Step: 9125 -> Loss: 0.004318776540458202 -> Predictions: [[0.00358306]\n",
            " [0.9961279 ]\n",
            " [0.99611616]\n",
            " [0.00589713]]\n",
            "Step: 9126 -> Loss: 0.004318756051361561 -> Predictions: [[0.00358305]\n",
            " [0.9961279 ]\n",
            " [0.99611616]\n",
            " [0.0058971 ]]\n",
            "Step: 9127 -> Loss: 0.004318736959248781 -> Predictions: [[0.00358303]\n",
            " [0.9961279 ]\n",
            " [0.99611616]\n",
            " [0.00589707]]\n",
            "Step: 9128 -> Loss: 0.004318716004490852 -> Predictions: [[0.00358301]\n",
            " [0.996128  ]\n",
            " [0.99611616]\n",
            " [0.00589704]]\n",
            "Step: 9129 -> Loss: 0.004318695981055498 -> Predictions: [[0.00358299]\n",
            " [0.996128  ]\n",
            " [0.9961163 ]\n",
            " [0.00589701]]\n",
            "Step: 9130 -> Loss: 0.004318675957620144 -> Predictions: [[0.00358298]\n",
            " [0.996128  ]\n",
            " [0.9961163 ]\n",
            " [0.00589699]]\n",
            "Step: 9131 -> Loss: 0.004318655002862215 -> Predictions: [[0.00358296]\n",
            " [0.996128  ]\n",
            " [0.9961163 ]\n",
            " [0.00589695]]\n",
            "Step: 9132 -> Loss: 0.00431863684207201 -> Predictions: [[0.00358295]\n",
            " [0.996128  ]\n",
            " [0.9961163 ]\n",
            " [0.00589692]]\n",
            "Step: 9133 -> Loss: 0.004318614955991507 -> Predictions: [[0.00358293]\n",
            " [0.996128  ]\n",
            " [0.9961163 ]\n",
            " [0.00589689]]\n",
            "Step: 9134 -> Loss: 0.004318596795201302 -> Predictions: [[0.00358291]\n",
            " [0.996128  ]\n",
            " [0.9961163 ]\n",
            " [0.00589687]]\n",
            "Step: 9135 -> Loss: 0.004318575374782085 -> Predictions: [[0.0035829 ]\n",
            " [0.9961281 ]\n",
            " [0.9961164 ]\n",
            " [0.00589684]]\n",
            "Step: 9136 -> Loss: 0.004318556282669306 -> Predictions: [[0.00358288]\n",
            " [0.9961281 ]\n",
            " [0.9961164 ]\n",
            " [0.0058968 ]]\n",
            "Step: 9137 -> Loss: 0.004318537190556526 -> Predictions: [[0.00358287]\n",
            " [0.9961281 ]\n",
            " [0.9961164 ]\n",
            " [0.00589678]]\n",
            "Step: 9138 -> Loss: 0.004318515304476023 -> Predictions: [[0.00358285]\n",
            " [0.9961281 ]\n",
            " [0.9961164 ]\n",
            " [0.00589675]]\n",
            "Step: 9139 -> Loss: 0.004318496212363243 -> Predictions: [[0.00358284]\n",
            " [0.9961281 ]\n",
            " [0.9961164 ]\n",
            " [0.00589671]]\n",
            "Step: 9140 -> Loss: 0.0043184757232666016 -> Predictions: [[0.00358282]\n",
            " [0.9961281 ]\n",
            " [0.9961164 ]\n",
            " [0.00589669]]\n",
            "Step: 9141 -> Loss: 0.004318454768508673 -> Predictions: [[0.0035828 ]\n",
            " [0.9961281 ]\n",
            " [0.9961164 ]\n",
            " [0.00589665]]\n",
            "Step: 9142 -> Loss: 0.004318437539041042 -> Predictions: [[0.00358279]\n",
            " [0.9961282 ]\n",
            " [0.9961164 ]\n",
            " [0.00589663]]\n",
            "Step: 9143 -> Loss: 0.0043184151872992516 -> Predictions: [[0.00358277]\n",
            " [0.9961282 ]\n",
            " [0.9961165 ]\n",
            " [0.0058966 ]]\n",
            "Step: 9144 -> Loss: 0.004318395629525185 -> Predictions: [[0.00358275]\n",
            " [0.9961282 ]\n",
            " [0.9961165 ]\n",
            " [0.00589657]]\n",
            "Step: 9145 -> Loss: 0.004318376071751118 -> Predictions: [[0.00358273]\n",
            " [0.9961282 ]\n",
            " [0.9961165 ]\n",
            " [0.00589654]]\n",
            "Step: 9146 -> Loss: 0.00431835325434804 -> Predictions: [[0.00358272]\n",
            " [0.9961282 ]\n",
            " [0.9961165 ]\n",
            " [0.00589651]]\n",
            "Step: 9147 -> Loss: 0.004318335093557835 -> Predictions: [[0.00358271]\n",
            " [0.9961282 ]\n",
            " [0.9961165 ]\n",
            " [0.00589648]]\n",
            "Step: 9148 -> Loss: 0.004318316467106342 -> Predictions: [[0.00358269]\n",
            " [0.9961282 ]\n",
            " [0.9961165 ]\n",
            " [0.00589646]]\n",
            "Step: 9149 -> Loss: 0.004318295046687126 -> Predictions: [[0.00358267]\n",
            " [0.9961283 ]\n",
            " [0.9961165 ]\n",
            " [0.00589642]]\n",
            "Step: 9150 -> Loss: 0.00431827362626791 -> Predictions: [[0.00358265]\n",
            " [0.9961283 ]\n",
            " [0.99611664]\n",
            " [0.00589639]]\n",
            "Step: 9151 -> Loss: 0.004318254999816418 -> Predictions: [[0.00358264]\n",
            " [0.9961283 ]\n",
            " [0.99611664]\n",
            " [0.00589637]]\n",
            "Step: 9152 -> Loss: 0.004318233113735914 -> Predictions: [[0.00358262]\n",
            " [0.9961283 ]\n",
            " [0.99611664]\n",
            " [0.00589633]]\n",
            "Step: 9153 -> Loss: 0.004318213555961847 -> Predictions: [[0.00358261]\n",
            " [0.9961283 ]\n",
            " [0.99611664]\n",
            " [0.0058963 ]]\n",
            "Step: 9154 -> Loss: 0.004318195395171642 -> Predictions: [[0.00358259]\n",
            " [0.9961283 ]\n",
            " [0.99611664]\n",
            " [0.00589628]]\n",
            "Step: 9155 -> Loss: 0.0043181744404137135 -> Predictions: [[0.00358257]\n",
            " [0.9961283 ]\n",
            " [0.99611664]\n",
            " [0.00589625]]\n",
            "Step: 9156 -> Loss: 0.004318154416978359 -> Predictions: [[0.00358256]\n",
            " [0.99612844]\n",
            " [0.99611664]\n",
            " [0.00589621]]\n",
            "Step: 9157 -> Loss: 0.00431813532486558 -> Predictions: [[0.00358254]\n",
            " [0.99612844]\n",
            " [0.99611676]\n",
            " [0.00589619]]\n",
            "Step: 9158 -> Loss: 0.0043181125074625015 -> Predictions: [[0.00358252]\n",
            " [0.99612844]\n",
            " [0.99611676]\n",
            " [0.00589615]]\n",
            "Step: 9159 -> Loss: 0.00431809201836586 -> Predictions: [[0.00358251]\n",
            " [0.99612844]\n",
            " [0.99611676]\n",
            " [0.00589613]]\n",
            "Step: 9160 -> Loss: 0.004318072460591793 -> Predictions: [[0.00358249]\n",
            " [0.99612844]\n",
            " [0.99611676]\n",
            " [0.0058961 ]]\n",
            "Step: 9161 -> Loss: 0.004318054299801588 -> Predictions: [[0.00358248]\n",
            " [0.99612844]\n",
            " [0.99611676]\n",
            " [0.00589607]]\n",
            "Step: 9162 -> Loss: 0.0043180338107049465 -> Predictions: [[0.00358246]\n",
            " [0.99612844]\n",
            " [0.99611676]\n",
            " [0.00589604]]\n",
            "Step: 9163 -> Loss: 0.00431801239028573 -> Predictions: [[0.00358244]\n",
            " [0.99612856]\n",
            " [0.9961169 ]\n",
            " [0.005896  ]]\n",
            "Step: 9164 -> Loss: 0.004317994229495525 -> Predictions: [[0.00358244]\n",
            " [0.99612856]\n",
            " [0.9961169 ]\n",
            " [0.00589597]]\n",
            "Step: 9165 -> Loss: 0.004317974206060171 -> Predictions: [[0.00358242]\n",
            " [0.99612856]\n",
            " [0.9961169 ]\n",
            " [0.00589595]]\n",
            "Step: 9166 -> Loss: 0.004317951388657093 -> Predictions: [[0.00358239]\n",
            " [0.99612856]\n",
            " [0.9961169 ]\n",
            " [0.00589592]]\n",
            "Step: 9167 -> Loss: 0.004317934159189463 -> Predictions: [[0.00358238]\n",
            " [0.99612856]\n",
            " [0.9961169 ]\n",
            " [0.00589589]]\n",
            "Step: 9168 -> Loss: 0.004317915067076683 -> Predictions: [[0.00358237]\n",
            " [0.99612856]\n",
            " [0.9961169 ]\n",
            " [0.00589586]]\n",
            "Step: 9169 -> Loss: 0.004317893646657467 -> Predictions: [[0.00358236]\n",
            " [0.99612856]\n",
            " [0.9961169 ]\n",
            " [0.00589583]]\n",
            "Step: 9170 -> Loss: 0.004317871760576963 -> Predictions: [[0.00358233]\n",
            " [0.9961287 ]\n",
            " [0.996117  ]\n",
            " [0.0058958 ]]\n",
            "Step: 9171 -> Loss: 0.004317853599786758 -> Predictions: [[0.00358232]\n",
            " [0.9961287 ]\n",
            " [0.996117  ]\n",
            " [0.00589577]]\n",
            "Step: 9172 -> Loss: 0.004317830316722393 -> Predictions: [[0.0035823 ]\n",
            " [0.9961287 ]\n",
            " [0.996117  ]\n",
            " [0.00589574]]\n",
            "Step: 9173 -> Loss: 0.004317811690270901 -> Predictions: [[0.00358228]\n",
            " [0.9961287 ]\n",
            " [0.996117  ]\n",
            " [0.00589571]]\n",
            "Step: 9174 -> Loss: 0.004317793063819408 -> Predictions: [[0.00358227]\n",
            " [0.9961287 ]\n",
            " [0.996117  ]\n",
            " [0.00589569]]\n",
            "Step: 9175 -> Loss: 0.0043177735060453415 -> Predictions: [[0.00358225]\n",
            " [0.9961287 ]\n",
            " [0.996117  ]\n",
            " [0.00589566]]\n",
            "Step: 9176 -> Loss: 0.004317750222980976 -> Predictions: [[0.00358223]\n",
            " [0.9961287 ]\n",
            " [0.996117  ]\n",
            " [0.00589562]]\n",
            "Step: 9177 -> Loss: 0.004317730665206909 -> Predictions: [[0.00358221]\n",
            " [0.9961288 ]\n",
            " [0.9961171 ]\n",
            " [0.00589559]]\n",
            "Step: 9178 -> Loss: 0.004317712038755417 -> Predictions: [[0.00358221]\n",
            " [0.9961288 ]\n",
            " [0.9961171 ]\n",
            " [0.00589556]]\n",
            "Step: 9179 -> Loss: 0.00431769248098135 -> Predictions: [[0.00358219]\n",
            " [0.9961288 ]\n",
            " [0.9961171 ]\n",
            " [0.00589554]]\n",
            "Step: 9180 -> Loss: 0.004317671991884708 -> Predictions: [[0.00358217]\n",
            " [0.9961288 ]\n",
            " [0.9961171 ]\n",
            " [0.0058955 ]]\n",
            "Step: 9181 -> Loss: 0.004317650105804205 -> Predictions: [[0.00358216]\n",
            " [0.9961288 ]\n",
            " [0.9961171 ]\n",
            " [0.00589547]]\n",
            "Step: 9182 -> Loss: 0.004317630082368851 -> Predictions: [[0.00358214]\n",
            " [0.9961288 ]\n",
            " [0.9961171 ]\n",
            " [0.00589545]]\n",
            "Step: 9183 -> Loss: 0.004317609593272209 -> Predictions: [[0.00358212]\n",
            " [0.9961289 ]\n",
            " [0.9961171 ]\n",
            " [0.00589542]]\n",
            "Step: 9184 -> Loss: 0.004317589104175568 -> Predictions: [[0.0035821 ]\n",
            " [0.9961289 ]\n",
            " [0.99611723]\n",
            " [0.00589538]]\n",
            "Step: 9185 -> Loss: 0.004317569546401501 -> Predictions: [[0.00358209]\n",
            " [0.9961289 ]\n",
            " [0.99611723]\n",
            " [0.00589535]]\n",
            "Step: 9186 -> Loss: 0.004317549988627434 -> Predictions: [[0.00358207]\n",
            " [0.9961289 ]\n",
            " [0.99611723]\n",
            " [0.00589533]]\n",
            "Step: 9187 -> Loss: 0.004317529499530792 -> Predictions: [[0.00358206]\n",
            " [0.9961289 ]\n",
            " [0.99611723]\n",
            " [0.0058953 ]]\n",
            "Step: 9188 -> Loss: 0.004317510407418013 -> Predictions: [[0.00358204]\n",
            " [0.9961289 ]\n",
            " [0.99611723]\n",
            " [0.00589527]]\n",
            "Step: 9189 -> Loss: 0.004317490383982658 -> Predictions: [[0.00358202]\n",
            " [0.9961289 ]\n",
            " [0.99611723]\n",
            " [0.00589524]]\n",
            "Step: 9190 -> Loss: 0.004317469894886017 -> Predictions: [[0.00358201]\n",
            " [0.99612904]\n",
            " [0.99611723]\n",
            " [0.00589521]]\n",
            "Step: 9191 -> Loss: 0.00431745033711195 -> Predictions: [[0.00358199]\n",
            " [0.99612904]\n",
            " [0.99611735]\n",
            " [0.00589518]]\n",
            "Step: 9192 -> Loss: 0.0043174284510314465 -> Predictions: [[0.00358197]\n",
            " [0.99612904]\n",
            " [0.99611735]\n",
            " [0.00589515]]\n",
            "Step: 9193 -> Loss: 0.0043174088932573795 -> Predictions: [[0.00358195]\n",
            " [0.99612904]\n",
            " [0.99611735]\n",
            " [0.00589512]]\n",
            "Step: 9194 -> Loss: 0.004317388869822025 -> Predictions: [[0.00358194]\n",
            " [0.99612904]\n",
            " [0.99611735]\n",
            " [0.00589509]]\n",
            "Step: 9195 -> Loss: 0.004317370243370533 -> Predictions: [[0.00358193]\n",
            " [0.99612904]\n",
            " [0.99611735]\n",
            " [0.00589506]]\n",
            "Step: 9196 -> Loss: 0.004317350685596466 -> Predictions: [[0.00358192]\n",
            " [0.99612904]\n",
            " [0.99611735]\n",
            " [0.00589503]]\n",
            "Step: 9197 -> Loss: 0.00431732926517725 -> Predictions: [[0.00358189]\n",
            " [0.99612916]\n",
            " [0.99611735]\n",
            " [0.005895  ]]\n",
            "Step: 9198 -> Loss: 0.004317308310419321 -> Predictions: [[0.00358188]\n",
            " [0.99612916]\n",
            " [0.9961175 ]\n",
            " [0.00589497]]\n",
            "Step: 9199 -> Loss: 0.004317287355661392 -> Predictions: [[0.00358186]\n",
            " [0.99612916]\n",
            " [0.9961175 ]\n",
            " [0.00589494]]\n",
            "Step: 9200 -> Loss: 0.0043172687292099 -> Predictions: [[0.00358185]\n",
            " [0.99612916]\n",
            " [0.9961175 ]\n",
            " [0.00589491]]\n",
            "Step: 9201 -> Loss: 0.004317251034080982 -> Predictions: [[0.00358184]\n",
            " [0.99612916]\n",
            " [0.9961175 ]\n",
            " [0.00589488]]\n",
            "Step: 9202 -> Loss: 0.004317231476306915 -> Predictions: [[0.00358182]\n",
            " [0.99612916]\n",
            " [0.9961175 ]\n",
            " [0.00589486]]\n",
            "Step: 9203 -> Loss: 0.0043172091245651245 -> Predictions: [[0.0035818 ]\n",
            " [0.99612916]\n",
            " [0.9961175 ]\n",
            " [0.00589482]]\n",
            "Step: 9204 -> Loss: 0.004317189566791058 -> Predictions: [[0.00358178]\n",
            " [0.9961293 ]\n",
            " [0.9961175 ]\n",
            " [0.00589479]]\n",
            "Step: 9205 -> Loss: 0.004317169077694416 -> Predictions: [[0.00358177]\n",
            " [0.9961293 ]\n",
            " [0.9961176 ]\n",
            " [0.00589477]]\n",
            "Step: 9206 -> Loss: 0.004317151382565498 -> Predictions: [[0.00358176]\n",
            " [0.9961293 ]\n",
            " [0.9961176 ]\n",
            " [0.00589474]]\n",
            "Step: 9207 -> Loss: 0.004317129962146282 -> Predictions: [[0.00358174]\n",
            " [0.9961293 ]\n",
            " [0.9961176 ]\n",
            " [0.00589471]]\n",
            "Step: 9208 -> Loss: 0.004317109473049641 -> Predictions: [[0.00358172]\n",
            " [0.9961293 ]\n",
            " [0.9961176 ]\n",
            " [0.00589468]]\n",
            "Step: 9209 -> Loss: 0.00431708712130785 -> Predictions: [[0.0035817 ]\n",
            " [0.9961293 ]\n",
            " [0.9961176 ]\n",
            " [0.00589465]]\n",
            "Step: 9210 -> Loss: 0.004317069426178932 -> Predictions: [[0.00358169]\n",
            " [0.9961293 ]\n",
            " [0.9961176 ]\n",
            " [0.00589462]]\n",
            "Step: 9211 -> Loss: 0.004317048005759716 -> Predictions: [[0.00358167]\n",
            " [0.9961294 ]\n",
            " [0.9961177 ]\n",
            " [0.00589459]]\n",
            "Step: 9212 -> Loss: 0.004317028447985649 -> Predictions: [[0.00358165]\n",
            " [0.9961294 ]\n",
            " [0.9961177 ]\n",
            " [0.00589456]]\n",
            "Step: 9213 -> Loss: 0.00431700749322772 -> Predictions: [[0.00358164]\n",
            " [0.9961294 ]\n",
            " [0.9961177 ]\n",
            " [0.00589453]]\n",
            "Step: 9214 -> Loss: 0.004316988401114941 -> Predictions: [[0.00358162]\n",
            " [0.9961294 ]\n",
            " [0.9961177 ]\n",
            " [0.0058945 ]]\n",
            "Step: 9215 -> Loss: 0.004316969774663448 -> Predictions: [[0.00358161]\n",
            " [0.9961294 ]\n",
            " [0.9961177 ]\n",
            " [0.00589447]]\n",
            "Step: 9216 -> Loss: 0.00431694695726037 -> Predictions: [[0.00358159]\n",
            " [0.9961294 ]\n",
            " [0.9961177 ]\n",
            " [0.00589444]]\n",
            "Step: 9217 -> Loss: 0.004316927399486303 -> Predictions: [[0.00358157]\n",
            " [0.9961294 ]\n",
            " [0.9961177 ]\n",
            " [0.00589441]]\n",
            "Step: 9218 -> Loss: 0.004316907376050949 -> Predictions: [[0.00358156]\n",
            " [0.9961295 ]\n",
            " [0.99611783]\n",
            " [0.00589438]]\n",
            "Step: 9219 -> Loss: 0.004316887818276882 -> Predictions: [[0.00358154]\n",
            " [0.9961295 ]\n",
            " [0.99611783]\n",
            " [0.00589435]]\n",
            "Step: 9220 -> Loss: 0.004316865466535091 -> Predictions: [[0.00358152]\n",
            " [0.9961295 ]\n",
            " [0.99611783]\n",
            " [0.00589432]]\n",
            "Step: 9221 -> Loss: 0.004316848237067461 -> Predictions: [[0.00358151]\n",
            " [0.9961295 ]\n",
            " [0.99611783]\n",
            " [0.0058943 ]]\n",
            "Step: 9222 -> Loss: 0.00431682588532567 -> Predictions: [[0.00358149]\n",
            " [0.9961295 ]\n",
            " [0.99611783]\n",
            " [0.00589426]]\n",
            "Step: 9223 -> Loss: 0.004316806793212891 -> Predictions: [[0.00358148]\n",
            " [0.9961295 ]\n",
            " [0.99611783]\n",
            " [0.00589423]]\n",
            "Step: 9224 -> Loss: 0.004316785838454962 -> Predictions: [[0.00358146]\n",
            " [0.9961295 ]\n",
            " [0.99611783]\n",
            " [0.0058942 ]]\n",
            "Step: 9225 -> Loss: 0.0043167658150196075 -> Predictions: [[0.00358144]\n",
            " [0.99612963]\n",
            " [0.99611795]\n",
            " [0.00589417]]\n",
            "Step: 9226 -> Loss: 0.0043167476542294025 -> Predictions: [[0.00358143]\n",
            " [0.99612963]\n",
            " [0.99611795]\n",
            " [0.00589415]]\n",
            "Step: 9227 -> Loss: 0.004316726699471474 -> Predictions: [[0.00358142]\n",
            " [0.99612963]\n",
            " [0.99611795]\n",
            " [0.00589411]]\n",
            "Step: 9228 -> Loss: 0.004316707607358694 -> Predictions: [[0.0035814 ]\n",
            " [0.99612963]\n",
            " [0.99611795]\n",
            " [0.00589409]]\n",
            "Step: 9229 -> Loss: 0.004316685255616903 -> Predictions: [[0.00358138]\n",
            " [0.99612963]\n",
            " [0.99611795]\n",
            " [0.00589406]]\n",
            "Step: 9230 -> Loss: 0.004316665232181549 -> Predictions: [[0.00358136]\n",
            " [0.99612963]\n",
            " [0.99611795]\n",
            " [0.00589402]]\n",
            "Step: 9231 -> Loss: 0.004316648468375206 -> Predictions: [[0.00358135]\n",
            " [0.99612963]\n",
            " [0.99611795]\n",
            " [0.005894  ]]\n",
            "Step: 9232 -> Loss: 0.004316625185310841 -> Predictions: [[0.00358133]\n",
            " [0.99612975]\n",
            " [0.99611807]\n",
            " [0.00589397]]\n",
            "Step: 9233 -> Loss: 0.004316605627536774 -> Predictions: [[0.00358131]\n",
            " [0.99612975]\n",
            " [0.99611807]\n",
            " [0.00589394]]\n",
            "Step: 9234 -> Loss: 0.004316587001085281 -> Predictions: [[0.0035813 ]\n",
            " [0.99612975]\n",
            " [0.99611807]\n",
            " [0.00589391]]\n",
            "Step: 9235 -> Loss: 0.004316563252359629 -> Predictions: [[0.00358128]\n",
            " [0.99612975]\n",
            " [0.99611807]\n",
            " [0.00589387]]\n",
            "Step: 9236 -> Loss: 0.004316545091569424 -> Predictions: [[0.00358126]\n",
            " [0.99612975]\n",
            " [0.99611807]\n",
            " [0.00589385]]\n",
            "Step: 9237 -> Loss: 0.004316526465117931 -> Predictions: [[0.00358125]\n",
            " [0.99612975]\n",
            " [0.99611807]\n",
            " [0.00589382]]\n",
            "Step: 9238 -> Loss: 0.004316507838666439 -> Predictions: [[0.00358124]\n",
            " [0.99612975]\n",
            " [0.99611807]\n",
            " [0.00589379]]\n",
            "Step: 9239 -> Loss: 0.004316485486924648 -> Predictions: [[0.00358121]\n",
            " [0.9961299 ]\n",
            " [0.9961182 ]\n",
            " [0.00589376]]\n",
            "Step: 9240 -> Loss: 0.0043164645321667194 -> Predictions: [[0.0035812 ]\n",
            " [0.9961299 ]\n",
            " [0.9961182 ]\n",
            " [0.00589372]]\n",
            "Step: 9241 -> Loss: 0.0043164449743926525 -> Predictions: [[0.00358118]\n",
            " [0.9961299 ]\n",
            " [0.9961182 ]\n",
            " [0.0058937 ]]\n",
            "Step: 9242 -> Loss: 0.004316425882279873 -> Predictions: [[0.00358117]\n",
            " [0.9961299 ]\n",
            " [0.9961182 ]\n",
            " [0.00589367]]\n",
            "Step: 9243 -> Loss: 0.004316406324505806 -> Predictions: [[0.00358115]\n",
            " [0.9961299 ]\n",
            " [0.9961182 ]\n",
            " [0.00589364]]\n",
            "Step: 9244 -> Loss: 0.0043163844384253025 -> Predictions: [[0.00358113]\n",
            " [0.9961299 ]\n",
            " [0.9961182 ]\n",
            " [0.00589362]]\n",
            "Step: 9245 -> Loss: 0.004316364880651236 -> Predictions: [[0.00358112]\n",
            " [0.9961299 ]\n",
            " [0.9961182 ]\n",
            " [0.00589359]]\n",
            "Step: 9246 -> Loss: 0.004316342994570732 -> Predictions: [[0.0035811 ]\n",
            " [0.99613   ]\n",
            " [0.9961183 ]\n",
            " [0.00589355]]\n",
            "Step: 9247 -> Loss: 0.004316325299441814 -> Predictions: [[0.00358109]\n",
            " [0.99613   ]\n",
            " [0.9961183 ]\n",
            " [0.00589353]]\n",
            "Step: 9248 -> Loss: 0.0043163057416677475 -> Predictions: [[0.00358107]\n",
            " [0.99613   ]\n",
            " [0.9961183 ]\n",
            " [0.0058935 ]]\n",
            "Step: 9249 -> Loss: 0.004316285252571106 -> Predictions: [[0.00358106]\n",
            " [0.99613   ]\n",
            " [0.9961183 ]\n",
            " [0.00589347]]\n",
            "Step: 9250 -> Loss: 0.00431626383215189 -> Predictions: [[0.00358104]\n",
            " [0.99613   ]\n",
            " [0.9961183 ]\n",
            " [0.00589344]]\n",
            "Step: 9251 -> Loss: 0.00431624474003911 -> Predictions: [[0.00358102]\n",
            " [0.99613   ]\n",
            " [0.9961183 ]\n",
            " [0.00589341]]\n",
            "Step: 9252 -> Loss: 0.004316223785281181 -> Predictions: [[0.00358101]\n",
            " [0.99613   ]\n",
            " [0.9961183 ]\n",
            " [0.00589338]]\n",
            "Step: 9253 -> Loss: 0.004316204693168402 -> Predictions: [[0.00358099]\n",
            " [0.9961301 ]\n",
            " [0.9961184 ]\n",
            " [0.00589335]]\n",
            "Step: 9254 -> Loss: 0.004316185601055622 -> Predictions: [[0.00358097]\n",
            " [0.9961301 ]\n",
            " [0.9961184 ]\n",
            " [0.00589332]]\n",
            "Step: 9255 -> Loss: 0.004316163249313831 -> Predictions: [[0.00358096]\n",
            " [0.9961301 ]\n",
            " [0.9961184 ]\n",
            " [0.00589329]]\n",
            "Step: 9256 -> Loss: 0.004316143225878477 -> Predictions: [[0.00358094]\n",
            " [0.9961301 ]\n",
            " [0.9961184 ]\n",
            " [0.00589326]]\n",
            "Step: 9257 -> Loss: 0.0043161241337656975 -> Predictions: [[0.00358093]\n",
            " [0.9961301 ]\n",
            " [0.9961184 ]\n",
            " [0.00589323]]\n",
            "Step: 9258 -> Loss: 0.004316103644669056 -> Predictions: [[0.00358091]\n",
            " [0.9961301 ]\n",
            " [0.9961184 ]\n",
            " [0.0058932 ]]\n",
            "Step: 9259 -> Loss: 0.00431608222424984 -> Predictions: [[0.00358089]\n",
            " [0.9961302 ]\n",
            " [0.9961184 ]\n",
            " [0.00589317]]\n",
            "Step: 9260 -> Loss: 0.004316064529120922 -> Predictions: [[0.00358088]\n",
            " [0.9961302 ]\n",
            " [0.99611855]\n",
            " [0.00589314]]\n",
            "Step: 9261 -> Loss: 0.004316042177379131 -> Predictions: [[0.00358086]\n",
            " [0.9961302 ]\n",
            " [0.99611855]\n",
            " [0.00589311]]\n",
            "Step: 9262 -> Loss: 0.004316020756959915 -> Predictions: [[0.00358084]\n",
            " [0.9961302 ]\n",
            " [0.99611855]\n",
            " [0.00589307]]\n",
            "Step: 9263 -> Loss: 0.004316005390137434 -> Predictions: [[0.00358083]\n",
            " [0.9961302 ]\n",
            " [0.99611855]\n",
            " [0.00589306]]\n",
            "Step: 9264 -> Loss: 0.004315982572734356 -> Predictions: [[0.00358081]\n",
            " [0.9961302 ]\n",
            " [0.99611855]\n",
            " [0.00589302]]\n",
            "Step: 9265 -> Loss: 0.00431596115231514 -> Predictions: [[0.00358079]\n",
            " [0.9961302 ]\n",
            " [0.99611855]\n",
            " [0.00589299]]\n",
            "Step: 9266 -> Loss: 0.004315941594541073 -> Predictions: [[0.00358078]\n",
            " [0.99613035]\n",
            " [0.99611866]\n",
            " [0.00589297]]\n",
            "Step: 9267 -> Loss: 0.004315922502428293 -> Predictions: [[0.00358076]\n",
            " [0.99613035]\n",
            " [0.99611866]\n",
            " [0.00589293]]\n",
            "Step: 9268 -> Loss: 0.004315902478992939 -> Predictions: [[0.00358075]\n",
            " [0.99613035]\n",
            " [0.99611866]\n",
            " [0.00589291]]\n",
            "Step: 9269 -> Loss: 0.004315883386880159 -> Predictions: [[0.00358073]\n",
            " [0.99613035]\n",
            " [0.99611866]\n",
            " [0.00589287]]\n",
            "Step: 9270 -> Loss: 0.004315864760428667 -> Predictions: [[0.00358072]\n",
            " [0.99613035]\n",
            " [0.99611866]\n",
            " [0.00589285]]\n",
            "Step: 9271 -> Loss: 0.004315841011703014 -> Predictions: [[0.0035807 ]\n",
            " [0.99613035]\n",
            " [0.99611866]\n",
            " [0.00589282]]\n",
            "Step: 9272 -> Loss: 0.0043158200569450855 -> Predictions: [[0.00358068]\n",
            " [0.99613035]\n",
            " [0.99611866]\n",
            " [0.00589278]]\n",
            "Step: 9273 -> Loss: 0.004315802361816168 -> Predictions: [[0.00358066]\n",
            " [0.99613047]\n",
            " [0.99611866]\n",
            " [0.00589276]]\n",
            "Step: 9274 -> Loss: 0.004315781407058239 -> Predictions: [[0.00358065]\n",
            " [0.99613047]\n",
            " [0.9961188 ]\n",
            " [0.00589273]]\n",
            "Step: 9275 -> Loss: 0.004315762314945459 -> Predictions: [[0.00358064]\n",
            " [0.99613047]\n",
            " [0.9961188 ]\n",
            " [0.00589269]]\n",
            "Step: 9276 -> Loss: 0.004315740428864956 -> Predictions: [[0.00358062]\n",
            " [0.99613047]\n",
            " [0.9961188 ]\n",
            " [0.00589267]]\n",
            "Step: 9277 -> Loss: 0.004315721802413464 -> Predictions: [[0.0035806 ]\n",
            " [0.99613047]\n",
            " [0.9961188 ]\n",
            " [0.00589264]]\n",
            "Step: 9278 -> Loss: 0.004315701778978109 -> Predictions: [[0.00358058]\n",
            " [0.99613047]\n",
            " [0.9961188 ]\n",
            " [0.00589261]]\n",
            "Step: 9279 -> Loss: 0.004315678961575031 -> Predictions: [[0.00358057]\n",
            " [0.99613047]\n",
            " [0.9961188 ]\n",
            " [0.00589258]]\n",
            "Step: 9280 -> Loss: 0.004315661266446114 -> Predictions: [[0.00358055]\n",
            " [0.9961306 ]\n",
            " [0.9961189 ]\n",
            " [0.00589255]]\n",
            "Step: 9281 -> Loss: 0.004315640311688185 -> Predictions: [[0.00358053]\n",
            " [0.9961306 ]\n",
            " [0.9961189 ]\n",
            " [0.00589252]]\n",
            "Step: 9282 -> Loss: 0.004315618891268969 -> Predictions: [[0.00358052]\n",
            " [0.9961306 ]\n",
            " [0.9961189 ]\n",
            " [0.00589249]]\n",
            "Step: 9283 -> Loss: 0.004315598402172327 -> Predictions: [[0.0035805 ]\n",
            " [0.9961306 ]\n",
            " [0.9961189 ]\n",
            " [0.00589246]]\n",
            "Step: 9284 -> Loss: 0.004315580707043409 -> Predictions: [[0.00358048]\n",
            " [0.9961306 ]\n",
            " [0.9961189 ]\n",
            " [0.00589243]]\n",
            "Step: 9285 -> Loss: 0.0043155597522854805 -> Predictions: [[0.00358047]\n",
            " [0.9961306 ]\n",
            " [0.9961189 ]\n",
            " [0.0058924 ]]\n",
            "Step: 9286 -> Loss: 0.004315539728850126 -> Predictions: [[0.00358046]\n",
            " [0.9961306 ]\n",
            " [0.9961189 ]\n",
            " [0.00589237]]\n",
            "Step: 9287 -> Loss: 0.004315521568059921 -> Predictions: [[0.00358044]\n",
            " [0.9961307 ]\n",
            " [0.996119  ]\n",
            " [0.00589235]]\n",
            "Step: 9288 -> Loss: 0.004315500613301992 -> Predictions: [[0.00358042]\n",
            " [0.9961307 ]\n",
            " [0.996119  ]\n",
            " [0.00589231]]\n",
            "Step: 9289 -> Loss: 0.0043154819868505 -> Predictions: [[0.0035804 ]\n",
            " [0.9961307 ]\n",
            " [0.996119  ]\n",
            " [0.00589229]]\n",
            "Step: 9290 -> Loss: 0.004315459169447422 -> Predictions: [[0.00358039]\n",
            " [0.9961307 ]\n",
            " [0.996119  ]\n",
            " [0.00589225]]\n",
            "Step: 9291 -> Loss: 0.0043154386803507805 -> Predictions: [[0.00358037]\n",
            " [0.9961307 ]\n",
            " [0.996119  ]\n",
            " [0.00589223]]\n",
            "Step: 9292 -> Loss: 0.004315420985221863 -> Predictions: [[0.00358036]\n",
            " [0.9961307 ]\n",
            " [0.996119  ]\n",
            " [0.0058922 ]]\n",
            "Step: 9293 -> Loss: 0.004315401427447796 -> Predictions: [[0.00358034]\n",
            " [0.9961307 ]\n",
            " [0.996119  ]\n",
            " [0.00589217]]\n",
            "Step: 9294 -> Loss: 0.004315379075706005 -> Predictions: [[0.00358032]\n",
            " [0.9961308 ]\n",
            " [0.99611914]\n",
            " [0.00589214]]\n",
            "Step: 9295 -> Loss: 0.0043153585866093636 -> Predictions: [[0.00358031]\n",
            " [0.9961308 ]\n",
            " [0.99611914]\n",
            " [0.00589211]]\n",
            "Step: 9296 -> Loss: 0.004315339028835297 -> Predictions: [[0.00358029]\n",
            " [0.9961308 ]\n",
            " [0.99611914]\n",
            " [0.00589208]]\n",
            "Step: 9297 -> Loss: 0.004315318074077368 -> Predictions: [[0.00358027]\n",
            " [0.9961308 ]\n",
            " [0.99611914]\n",
            " [0.00589205]]\n",
            "Step: 9298 -> Loss: 0.004315298516303301 -> Predictions: [[0.00358026]\n",
            " [0.9961308 ]\n",
            " [0.99611914]\n",
            " [0.00589202]]\n",
            "Step: 9299 -> Loss: 0.004315277095884085 -> Predictions: [[0.00358024]\n",
            " [0.9961308 ]\n",
            " [0.99611914]\n",
            " [0.00589199]]\n",
            "Step: 9300 -> Loss: 0.004315256606787443 -> Predictions: [[0.00358023]\n",
            " [0.9961308 ]\n",
            " [0.99611914]\n",
            " [0.00589196]]\n",
            "Step: 9301 -> Loss: 0.0043152375146746635 -> Predictions: [[0.00358021]\n",
            " [0.99613094]\n",
            " [0.99611926]\n",
            " [0.00589192]]\n",
            "Step: 9302 -> Loss: 0.004315217025578022 -> Predictions: [[0.00358019]\n",
            " [0.99613094]\n",
            " [0.99611926]\n",
            " [0.0058919 ]]\n",
            "Step: 9303 -> Loss: 0.004315196070820093 -> Predictions: [[0.00358018]\n",
            " [0.99613094]\n",
            " [0.99611926]\n",
            " [0.00589187]]\n",
            "Step: 9304 -> Loss: 0.0043151783756911755 -> Predictions: [[0.00358016]\n",
            " [0.99613094]\n",
            " [0.99611926]\n",
            " [0.00589184]]\n",
            "Step: 9305 -> Loss: 0.0043151588179171085 -> Predictions: [[0.00358014]\n",
            " [0.99613094]\n",
            " [0.99611926]\n",
            " [0.00589181]]\n",
            "Step: 9306 -> Loss: 0.004315137397497892 -> Predictions: [[0.00358013]\n",
            " [0.99613094]\n",
            " [0.99611926]\n",
            " [0.00589178]]\n",
            "Step: 9307 -> Loss: 0.004315116908401251 -> Predictions: [[0.00358011]\n",
            " [0.99613094]\n",
            " [0.99611926]\n",
            " [0.00589175]]\n",
            "Step: 9308 -> Loss: 0.004315097816288471 -> Predictions: [[0.0035801 ]\n",
            " [0.99613106]\n",
            " [0.9961194 ]\n",
            " [0.00589172]]\n",
            "Step: 9309 -> Loss: 0.004315076395869255 -> Predictions: [[0.00358008]\n",
            " [0.99613106]\n",
            " [0.9961194 ]\n",
            " [0.00589169]]\n",
            "Step: 9310 -> Loss: 0.00431505823507905 -> Predictions: [[0.00358007]\n",
            " [0.99613106]\n",
            " [0.9961194 ]\n",
            " [0.00589166]]\n",
            "Step: 9311 -> Loss: 0.004315033555030823 -> Predictions: [[0.00358005]\n",
            " [0.99613106]\n",
            " [0.9961194 ]\n",
            " [0.00589163]]\n",
            "Step: 9312 -> Loss: 0.00431501679122448 -> Predictions: [[0.00358003]\n",
            " [0.99613106]\n",
            " [0.9961194 ]\n",
            " [0.0058916 ]]\n",
            "Step: 9313 -> Loss: 0.004314998164772987 -> Predictions: [[0.00358002]\n",
            " [0.99613106]\n",
            " [0.9961194 ]\n",
            " [0.00589158]]\n",
            "Step: 9314 -> Loss: 0.004314977675676346 -> Predictions: [[0.00358   ]\n",
            " [0.99613106]\n",
            " [0.9961194 ]\n",
            " [0.00589155]]\n",
            "Step: 9315 -> Loss: 0.0043149590492248535 -> Predictions: [[0.00357999]\n",
            " [0.9961312 ]\n",
            " [0.9961195 ]\n",
            " [0.00589152]]\n",
            "Step: 9316 -> Loss: 0.0043149348348379135 -> Predictions: [[0.00357997]\n",
            " [0.9961312 ]\n",
            " [0.9961195 ]\n",
            " [0.00589148]]\n",
            "Step: 9317 -> Loss: 0.004314918536692858 -> Predictions: [[0.00357995]\n",
            " [0.9961312 ]\n",
            " [0.9961195 ]\n",
            " [0.00589146]]\n",
            "Step: 9318 -> Loss: 0.004314899444580078 -> Predictions: [[0.00357994]\n",
            " [0.9961312 ]\n",
            " [0.9961195 ]\n",
            " [0.00589143]]\n",
            "Step: 9319 -> Loss: 0.004314878955483437 -> Predictions: [[0.00357992]\n",
            " [0.9961312 ]\n",
            " [0.9961195 ]\n",
            " [0.0058914 ]]\n",
            "Step: 9320 -> Loss: 0.004314857069402933 -> Predictions: [[0.0035799 ]\n",
            " [0.9961312 ]\n",
            " [0.9961195 ]\n",
            " [0.00589137]]\n",
            "Step: 9321 -> Loss: 0.004314835648983717 -> Predictions: [[0.00357988]\n",
            " [0.9961312 ]\n",
            " [0.9961195 ]\n",
            " [0.00589134]]\n",
            "Step: 9322 -> Loss: 0.004314815625548363 -> Predictions: [[0.00357987]\n",
            " [0.9961313 ]\n",
            " [0.9961196 ]\n",
            " [0.00589131]]\n",
            "Step: 9323 -> Loss: 0.004314795136451721 -> Predictions: [[0.00357986]\n",
            " [0.9961313 ]\n",
            " [0.9961196 ]\n",
            " [0.00589128]]\n",
            "Step: 9324 -> Loss: 0.004314776975661516 -> Predictions: [[0.00357984]\n",
            " [0.9961313 ]\n",
            " [0.9961196 ]\n",
            " [0.00589125]]\n",
            "Step: 9325 -> Loss: 0.004314754623919725 -> Predictions: [[0.00357982]\n",
            " [0.9961313 ]\n",
            " [0.9961196 ]\n",
            " [0.00589122]]\n",
            "Step: 9326 -> Loss: 0.004314737394452095 -> Predictions: [[0.0035798 ]\n",
            " [0.9961313 ]\n",
            " [0.9961196 ]\n",
            " [0.00589119]]\n",
            "Step: 9327 -> Loss: 0.004314717371016741 -> Predictions: [[0.00357979]\n",
            " [0.9961313 ]\n",
            " [0.9961196 ]\n",
            " [0.00589116]]\n",
            "Step: 9328 -> Loss: 0.004314695950597525 -> Predictions: [[0.00357977]\n",
            " [0.9961313 ]\n",
            " [0.99611974]\n",
            " [0.00589114]]\n",
            "Step: 9329 -> Loss: 0.004314674064517021 -> Predictions: [[0.00357976]\n",
            " [0.9961314 ]\n",
            " [0.99611974]\n",
            " [0.0058911 ]]\n",
            "Step: 9330 -> Loss: 0.004314654506742954 -> Predictions: [[0.00357974]\n",
            " [0.9961314 ]\n",
            " [0.99611974]\n",
            " [0.00589107]]\n",
            "Step: 9331 -> Loss: 0.004314634017646313 -> Predictions: [[0.00357972]\n",
            " [0.9961314 ]\n",
            " [0.99611974]\n",
            " [0.00589104]]\n",
            "Step: 9332 -> Loss: 0.004314614925533533 -> Predictions: [[0.00357971]\n",
            " [0.9961314 ]\n",
            " [0.99611974]\n",
            " [0.00589102]]\n",
            "Step: 9333 -> Loss: 0.004314594902098179 -> Predictions: [[0.00357969]\n",
            " [0.9961314 ]\n",
            " [0.99611974]\n",
            " [0.00589099]]\n",
            "Step: 9334 -> Loss: 0.00431457394734025 -> Predictions: [[0.00357967]\n",
            " [0.9961314 ]\n",
            " [0.99611974]\n",
            " [0.00589095]]\n",
            "Step: 9335 -> Loss: 0.0043145534582436085 -> Predictions: [[0.00357966]\n",
            " [0.9961314 ]\n",
            " [0.99611986]\n",
            " [0.00589093]]\n",
            "Step: 9336 -> Loss: 0.004314536694437265 -> Predictions: [[0.00357965]\n",
            " [0.99613154]\n",
            " [0.99611986]\n",
            " [0.0058909 ]]\n",
            "Step: 9337 -> Loss: 0.0043145171366631985 -> Predictions: [[0.00357963]\n",
            " [0.99613154]\n",
            " [0.99611986]\n",
            " [0.00589087]]\n",
            "Step: 9338 -> Loss: 0.004314493387937546 -> Predictions: [[0.00357961]\n",
            " [0.99613154]\n",
            " [0.99611986]\n",
            " [0.00589084]]\n",
            "Step: 9339 -> Loss: 0.004314475692808628 -> Predictions: [[0.0035796 ]\n",
            " [0.99613154]\n",
            " [0.99611986]\n",
            " [0.00589081]]\n",
            "Step: 9340 -> Loss: 0.004314456135034561 -> Predictions: [[0.00357958]\n",
            " [0.99613154]\n",
            " [0.99611986]\n",
            " [0.00589078]]\n",
            "Step: 9341 -> Loss: 0.004314433317631483 -> Predictions: [[0.00357956]\n",
            " [0.99613154]\n",
            " [0.99611986]\n",
            " [0.00589074]]\n",
            "Step: 9342 -> Loss: 0.004314417019486427 -> Predictions: [[0.00357955]\n",
            " [0.99613166]\n",
            " [0.99612   ]\n",
            " [0.00589072]]\n",
            "Step: 9343 -> Loss: 0.004314391873776913 -> Predictions: [[0.00357953]\n",
            " [0.99613166]\n",
            " [0.99612   ]\n",
            " [0.00589069]]\n",
            "Step: 9344 -> Loss: 0.004314376041293144 -> Predictions: [[0.00357952]\n",
            " [0.99613166]\n",
            " [0.99612   ]\n",
            " [0.00589066]]\n",
            "Step: 9345 -> Loss: 0.004314352758228779 -> Predictions: [[0.00357949]\n",
            " [0.99613166]\n",
            " [0.99612   ]\n",
            " [0.00589063]]\n",
            "Step: 9346 -> Loss: 0.004314331337809563 -> Predictions: [[0.00357948]\n",
            " [0.99613166]\n",
            " [0.99612   ]\n",
            " [0.0058906 ]]\n",
            "Step: 9347 -> Loss: 0.004314315039664507 -> Predictions: [[0.00357947]\n",
            " [0.99613166]\n",
            " [0.99612   ]\n",
            " [0.00589057]]\n",
            "Step: 9348 -> Loss: 0.004314294084906578 -> Predictions: [[0.00357945]\n",
            " [0.99613166]\n",
            " [0.99612   ]\n",
            " [0.00589054]]\n",
            "Step: 9349 -> Loss: 0.0043142735958099365 -> Predictions: [[0.00357944]\n",
            " [0.9961318 ]\n",
            " [0.9961201 ]\n",
            " [0.00589051]]\n",
            "Step: 9350 -> Loss: 0.004314255900681019 -> Predictions: [[0.00357942]\n",
            " [0.9961318 ]\n",
            " [0.9961201 ]\n",
            " [0.00589049]]\n",
            "Step: 9351 -> Loss: 0.004314235411584377 -> Predictions: [[0.0035794 ]\n",
            " [0.9961318 ]\n",
            " [0.9961201 ]\n",
            " [0.00589046]]\n",
            "Step: 9352 -> Loss: 0.00431421585381031 -> Predictions: [[0.00357939]\n",
            " [0.9961318 ]\n",
            " [0.9961201 ]\n",
            " [0.00589042]]\n",
            "Step: 9353 -> Loss: 0.004314194433391094 -> Predictions: [[0.00357937]\n",
            " [0.9961318 ]\n",
            " [0.9961201 ]\n",
            " [0.0058904 ]]\n",
            "Step: 9354 -> Loss: 0.004314173944294453 -> Predictions: [[0.00357936]\n",
            " [0.9961318 ]\n",
            " [0.9961201 ]\n",
            " [0.00589036]]\n",
            "Step: 9355 -> Loss: 0.004314151592552662 -> Predictions: [[0.00357934]\n",
            " [0.9961318 ]\n",
            " [0.9961201 ]\n",
            " [0.00589033]]\n",
            "Step: 9356 -> Loss: 0.004314134828746319 -> Predictions: [[0.00357932]\n",
            " [0.9961319 ]\n",
            " [0.9961202 ]\n",
            " [0.0058903 ]]\n",
            "Step: 9357 -> Loss: 0.004314114339649677 -> Predictions: [[0.0035793 ]\n",
            " [0.9961319 ]\n",
            " [0.9961202 ]\n",
            " [0.00589028]]\n",
            "Step: 9358 -> Loss: 0.0043140919879078865 -> Predictions: [[0.00357929]\n",
            " [0.9961319 ]\n",
            " [0.9961202 ]\n",
            " [0.00589024]]\n",
            "Step: 9359 -> Loss: 0.004314074292778969 -> Predictions: [[0.00357927]\n",
            " [0.9961319 ]\n",
            " [0.9961202 ]\n",
            " [0.00589022]]\n",
            "Step: 9360 -> Loss: 0.004314052872359753 -> Predictions: [[0.00357926]\n",
            " [0.9961319 ]\n",
            " [0.9961202 ]\n",
            " [0.00589019]]\n",
            "Step: 9361 -> Loss: 0.004314033780246973 -> Predictions: [[0.00357924]\n",
            " [0.9961319 ]\n",
            " [0.9961202 ]\n",
            " [0.00589016]]\n",
            "Step: 9362 -> Loss: 0.0043140132911503315 -> Predictions: [[0.00357923]\n",
            " [0.9961319 ]\n",
            " [0.9961202 ]\n",
            " [0.00589013]]\n",
            "Step: 9363 -> Loss: 0.004313991405069828 -> Predictions: [[0.0035792 ]\n",
            " [0.996132  ]\n",
            " [0.99612033]\n",
            " [0.0058901 ]]\n",
            "Step: 9364 -> Loss: 0.004313974641263485 -> Predictions: [[0.0035792 ]\n",
            " [0.996132  ]\n",
            " [0.99612033]\n",
            " [0.00589007]]\n",
            "Step: 9365 -> Loss: 0.004313953686505556 -> Predictions: [[0.00357918]\n",
            " [0.996132  ]\n",
            " [0.99612033]\n",
            " [0.00589004]]\n",
            "Step: 9366 -> Loss: 0.004313931800425053 -> Predictions: [[0.00357916]\n",
            " [0.996132  ]\n",
            " [0.99612033]\n",
            " [0.00589001]]\n",
            "Step: 9367 -> Loss: 0.004313911311328411 -> Predictions: [[0.00357914]\n",
            " [0.996132  ]\n",
            " [0.99612033]\n",
            " [0.00588998]]\n",
            "Step: 9368 -> Loss: 0.004313892684876919 -> Predictions: [[0.00357913]\n",
            " [0.996132  ]\n",
            " [0.99612033]\n",
            " [0.00588995]]\n",
            "Step: 9369 -> Loss: 0.004313872195780277 -> Predictions: [[0.00357911]\n",
            " [0.996132  ]\n",
            " [0.99612033]\n",
            " [0.00588992]]\n",
            "Step: 9370 -> Loss: 0.004313851706683636 -> Predictions: [[0.0035791 ]\n",
            " [0.99613214]\n",
            " [0.9961204 ]\n",
            " [0.00588989]]\n",
            "Step: 9371 -> Loss: 0.004313832614570856 -> Predictions: [[0.00357908]\n",
            " [0.99613214]\n",
            " [0.9961204 ]\n",
            " [0.00588986]]\n",
            "Step: 9372 -> Loss: 0.004313811659812927 -> Predictions: [[0.00357906]\n",
            " [0.99613214]\n",
            " [0.9961204 ]\n",
            " [0.00588983]]\n",
            "Step: 9373 -> Loss: 0.004313793033361435 -> Predictions: [[0.00357905]\n",
            " [0.99613214]\n",
            " [0.9961204 ]\n",
            " [0.00588981]]\n",
            "Step: 9374 -> Loss: 0.004313770681619644 -> Predictions: [[0.00357903]\n",
            " [0.99613214]\n",
            " [0.9961204 ]\n",
            " [0.00588977]]\n",
            "Step: 9375 -> Loss: 0.004313749726861715 -> Predictions: [[0.00357901]\n",
            " [0.99613214]\n",
            " [0.9961204 ]\n",
            " [0.00588974]]\n",
            "Step: 9376 -> Loss: 0.004313732497394085 -> Predictions: [[0.003579  ]\n",
            " [0.99613214]\n",
            " [0.9961204 ]\n",
            " [0.00588972]]\n",
            "Step: 9377 -> Loss: 0.004313712008297443 -> Predictions: [[0.00357898]\n",
            " [0.99613225]\n",
            " [0.9961205 ]\n",
            " [0.00588969]]\n",
            "Step: 9378 -> Loss: 0.004313690587878227 -> Predictions: [[0.00357897]\n",
            " [0.99613225]\n",
            " [0.9961205 ]\n",
            " [0.00588965]]\n",
            "Step: 9379 -> Loss: 0.004313669167459011 -> Predictions: [[0.00357895]\n",
            " [0.99613225]\n",
            " [0.9961205 ]\n",
            " [0.00588962]]\n",
            "Step: 9380 -> Loss: 0.004313651472330093 -> Predictions: [[0.00357894]\n",
            " [0.99613225]\n",
            " [0.9961205 ]\n",
            " [0.00588959]]\n",
            "Step: 9381 -> Loss: 0.004313632845878601 -> Predictions: [[0.00357892]\n",
            " [0.99613225]\n",
            " [0.9961205 ]\n",
            " [0.00588957]]\n",
            "Step: 9382 -> Loss: 0.004313612822443247 -> Predictions: [[0.0035789 ]\n",
            " [0.99613225]\n",
            " [0.9961205 ]\n",
            " [0.00588954]]\n",
            "Step: 9383 -> Loss: 0.004313591867685318 -> Predictions: [[0.00357889]\n",
            " [0.99613225]\n",
            " [0.99612063]\n",
            " [0.00588951]]\n",
            "Step: 9384 -> Loss: 0.004313572775572538 -> Predictions: [[0.00357887]\n",
            " [0.9961324 ]\n",
            " [0.99612063]\n",
            " [0.00588948]]\n",
            "Step: 9385 -> Loss: 0.00431354995816946 -> Predictions: [[0.00357885]\n",
            " [0.9961324 ]\n",
            " [0.99612063]\n",
            " [0.00588944]]\n",
            "Step: 9386 -> Loss: 0.004313529934734106 -> Predictions: [[0.00357884]\n",
            " [0.9961324 ]\n",
            " [0.99612063]\n",
            " [0.00588942]]\n",
            "Step: 9387 -> Loss: 0.004313510376960039 -> Predictions: [[0.00357882]\n",
            " [0.9961324 ]\n",
            " [0.99612063]\n",
            " [0.00588939]]\n",
            "Step: 9388 -> Loss: 0.004313488956540823 -> Predictions: [[0.00357881]\n",
            " [0.9961324 ]\n",
            " [0.99612063]\n",
            " [0.00588935]]\n",
            "Step: 9389 -> Loss: 0.004313470795750618 -> Predictions: [[0.00357879]\n",
            " [0.9961324 ]\n",
            " [0.99612063]\n",
            " [0.00588933]]\n",
            "Step: 9390 -> Loss: 0.004313452634960413 -> Predictions: [[0.00357877]\n",
            " [0.9961324 ]\n",
            " [0.99612063]\n",
            " [0.00588931]]\n",
            "Step: 9391 -> Loss: 0.004313429817557335 -> Predictions: [[0.00357875]\n",
            " [0.9961325 ]\n",
            " [0.99612075]\n",
            " [0.00588928]]\n",
            "Step: 9392 -> Loss: 0.004313407000154257 -> Predictions: [[0.00357874]\n",
            " [0.9961325 ]\n",
            " [0.99612075]\n",
            " [0.00588924]]\n",
            "Step: 9393 -> Loss: 0.004313392098993063 -> Predictions: [[0.00357873]\n",
            " [0.9961325 ]\n",
            " [0.99612075]\n",
            " [0.00588921]]\n",
            "Step: 9394 -> Loss: 0.004313371609896421 -> Predictions: [[0.00357871]\n",
            " [0.9961325 ]\n",
            " [0.99612075]\n",
            " [0.00588918]]\n",
            "Step: 9395 -> Loss: 0.004313350655138493 -> Predictions: [[0.00357869]\n",
            " [0.9961325 ]\n",
            " [0.99612075]\n",
            " [0.00588915]]\n",
            "Step: 9396 -> Loss: 0.004313330166041851 -> Predictions: [[0.00357868]\n",
            " [0.9961325 ]\n",
            " [0.99612075]\n",
            " [0.00588913]]\n",
            "Step: 9397 -> Loss: 0.0043133096769452095 -> Predictions: [[0.00357866]\n",
            " [0.9961325 ]\n",
            " [0.99612087]\n",
            " [0.0058891 ]]\n",
            "Step: 9398 -> Loss: 0.004313290119171143 -> Predictions: [[0.00357864]\n",
            " [0.9961326 ]\n",
            " [0.99612087]\n",
            " [0.00588906]]\n",
            "Step: 9399 -> Loss: 0.004313270095735788 -> Predictions: [[0.00357863]\n",
            " [0.9961326 ]\n",
            " [0.99612087]\n",
            " [0.00588904]]\n",
            "Step: 9400 -> Loss: 0.00431324727833271 -> Predictions: [[0.00357861]\n",
            " [0.9961326 ]\n",
            " [0.99612087]\n",
            " [0.005889  ]]\n",
            "Step: 9401 -> Loss: 0.004313227720558643 -> Predictions: [[0.0035786 ]\n",
            " [0.9961326 ]\n",
            " [0.99612087]\n",
            " [0.00588897]]\n",
            "Step: 9402 -> Loss: 0.004313210025429726 -> Predictions: [[0.00357858]\n",
            " [0.9961326 ]\n",
            " [0.99612087]\n",
            " [0.00588895]]\n",
            "Step: 9403 -> Loss: 0.004313189536333084 -> Predictions: [[0.00357856]\n",
            " [0.9961326 ]\n",
            " [0.99612087]\n",
            " [0.00588892]]\n",
            "Step: 9404 -> Loss: 0.004313169978559017 -> Predictions: [[0.00357855]\n",
            " [0.9961326 ]\n",
            " [0.996121  ]\n",
            " [0.00588889]]\n",
            "Step: 9405 -> Loss: 0.004313147626817226 -> Predictions: [[0.00357853]\n",
            " [0.99613273]\n",
            " [0.996121  ]\n",
            " [0.00588886]]\n",
            "Step: 9406 -> Loss: 0.004313128534704447 -> Predictions: [[0.00357851]\n",
            " [0.99613273]\n",
            " [0.996121  ]\n",
            " [0.00588883]]\n",
            "Step: 9407 -> Loss: 0.0043131099082529545 -> Predictions: [[0.0035785 ]\n",
            " [0.99613273]\n",
            " [0.996121  ]\n",
            " [0.0058888 ]]\n",
            "Step: 9408 -> Loss: 0.0043130903504788876 -> Predictions: [[0.00357849]\n",
            " [0.99613273]\n",
            " [0.996121  ]\n",
            " [0.00588877]]\n",
            "Step: 9409 -> Loss: 0.004313068464398384 -> Predictions: [[0.00357846]\n",
            " [0.99613273]\n",
            " [0.996121  ]\n",
            " [0.00588874]]\n",
            "Step: 9410 -> Loss: 0.004313047043979168 -> Predictions: [[0.00357845]\n",
            " [0.99613273]\n",
            " [0.996121  ]\n",
            " [0.00588871]]\n",
            "Step: 9411 -> Loss: 0.0043130298145115376 -> Predictions: [[0.00357843]\n",
            " [0.99613285]\n",
            " [0.9961211 ]\n",
            " [0.00588868]]\n",
            "Step: 9412 -> Loss: 0.004313007462769747 -> Predictions: [[0.00357842]\n",
            " [0.99613285]\n",
            " [0.9961211 ]\n",
            " [0.00588865]]\n",
            "Step: 9413 -> Loss: 0.004312988370656967 -> Predictions: [[0.0035784 ]\n",
            " [0.99613285]\n",
            " [0.9961211 ]\n",
            " [0.00588862]]\n",
            "Step: 9414 -> Loss: 0.0043129688128829 -> Predictions: [[0.00357838]\n",
            " [0.99613285]\n",
            " [0.9961211 ]\n",
            " [0.0058886 ]]\n",
            "Step: 9415 -> Loss: 0.004312949255108833 -> Predictions: [[0.00357837]\n",
            " [0.99613285]\n",
            " [0.9961211 ]\n",
            " [0.00588856]]\n",
            "Step: 9416 -> Loss: 0.004312925972044468 -> Predictions: [[0.00357835]\n",
            " [0.99613285]\n",
            " [0.9961211 ]\n",
            " [0.00588853]]\n",
            "Step: 9417 -> Loss: 0.004312906414270401 -> Predictions: [[0.00357833]\n",
            " [0.99613285]\n",
            " [0.9961211 ]\n",
            " [0.0058885 ]]\n",
            "Step: 9418 -> Loss: 0.004312888253480196 -> Predictions: [[0.00357832]\n",
            " [0.99613285]\n",
            " [0.9961212 ]\n",
            " [0.00588848]]\n",
            "Step: 9419 -> Loss: 0.004312867298722267 -> Predictions: [[0.0035783 ]\n",
            " [0.99613297]\n",
            " [0.9961212 ]\n",
            " [0.00588845]]\n",
            "Step: 9420 -> Loss: 0.004312846809625626 -> Predictions: [[0.00357829]\n",
            " [0.99613297]\n",
            " [0.9961212 ]\n",
            " [0.00588842]]\n",
            "Step: 9421 -> Loss: 0.004312828183174133 -> Predictions: [[0.00357828]\n",
            " [0.99613297]\n",
            " [0.9961212 ]\n",
            " [0.00588839]]\n",
            "Step: 9422 -> Loss: 0.004312807694077492 -> Predictions: [[0.00357826]\n",
            " [0.99613297]\n",
            " [0.9961212 ]\n",
            " [0.00588835]]\n",
            "Step: 9423 -> Loss: 0.004312788136303425 -> Predictions: [[0.00357824]\n",
            " [0.99613297]\n",
            " [0.9961212 ]\n",
            " [0.00588833]]\n",
            "Step: 9424 -> Loss: 0.004312766715884209 -> Predictions: [[0.00357822]\n",
            " [0.99613297]\n",
            " [0.9961212 ]\n",
            " [0.0058883 ]]\n",
            "Step: 9425 -> Loss: 0.0043127466924488544 -> Predictions: [[0.00357821]\n",
            " [0.9961331 ]\n",
            " [0.99612135]\n",
            " [0.00588827]]\n",
            "Step: 9426 -> Loss: 0.0043127271346747875 -> Predictions: [[0.00357819]\n",
            " [0.9961331 ]\n",
            " [0.99612135]\n",
            " [0.00588823]]\n",
            "Step: 9427 -> Loss: 0.004312707111239433 -> Predictions: [[0.00357817]\n",
            " [0.9961331 ]\n",
            " [0.99612135]\n",
            " [0.00588821]]\n",
            "Step: 9428 -> Loss: 0.004312689416110516 -> Predictions: [[0.00357816]\n",
            " [0.9961331 ]\n",
            " [0.99612135]\n",
            " [0.00588819]]\n",
            "Step: 9429 -> Loss: 0.004312667064368725 -> Predictions: [[0.00357814]\n",
            " [0.9961331 ]\n",
            " [0.99612135]\n",
            " [0.00588815]]\n",
            "Step: 9430 -> Loss: 0.0043126484379172325 -> Predictions: [[0.00357813]\n",
            " [0.9961331 ]\n",
            " [0.99612135]\n",
            " [0.00588812]]\n",
            "Step: 9431 -> Loss: 0.004312627483159304 -> Predictions: [[0.00357811]\n",
            " [0.9961331 ]\n",
            " [0.99612135]\n",
            " [0.00588809]]\n",
            "Step: 9432 -> Loss: 0.004312605131417513 -> Predictions: [[0.00357809]\n",
            " [0.9961332 ]\n",
            " [0.99612147]\n",
            " [0.00588806]]\n",
            "Step: 9433 -> Loss: 0.004312588833272457 -> Predictions: [[0.00357808]\n",
            " [0.9961332 ]\n",
            " [0.99612147]\n",
            " [0.00588804]]\n",
            "Step: 9434 -> Loss: 0.004312566481530666 -> Predictions: [[0.00357806]\n",
            " [0.9961332 ]\n",
            " [0.99612147]\n",
            " [0.005888  ]]\n",
            "Step: 9435 -> Loss: 0.004312545992434025 -> Predictions: [[0.00357804]\n",
            " [0.9961332 ]\n",
            " [0.99612147]\n",
            " [0.00588797]]\n",
            "Step: 9436 -> Loss: 0.004312525503337383 -> Predictions: [[0.00357803]\n",
            " [0.9961332 ]\n",
            " [0.99612147]\n",
            " [0.00588794]]\n",
            "Step: 9437 -> Loss: 0.004312505014240742 -> Predictions: [[0.00357801]\n",
            " [0.9961332 ]\n",
            " [0.99612147]\n",
            " [0.00588791]]\n",
            "Step: 9438 -> Loss: 0.004312485456466675 -> Predictions: [[0.003578  ]\n",
            " [0.9961332 ]\n",
            " [0.99612147]\n",
            " [0.00588789]]\n",
            "Step: 9439 -> Loss: 0.00431246729567647 -> Predictions: [[0.00357798]\n",
            " [0.9961333 ]\n",
            " [0.9961216 ]\n",
            " [0.00588786]]\n",
            "Step: 9440 -> Loss: 0.004312444478273392 -> Predictions: [[0.00357797]\n",
            " [0.9961333 ]\n",
            " [0.9961216 ]\n",
            " [0.00588782]]\n",
            "Step: 9441 -> Loss: 0.004312425386160612 -> Predictions: [[0.00357794]\n",
            " [0.9961333 ]\n",
            " [0.9961216 ]\n",
            " [0.0058878 ]]\n",
            "Step: 9442 -> Loss: 0.004312404431402683 -> Predictions: [[0.00357793]\n",
            " [0.9961333 ]\n",
            " [0.9961216 ]\n",
            " [0.00588777]]\n",
            "Step: 9443 -> Loss: 0.004312387201935053 -> Predictions: [[0.00357792]\n",
            " [0.9961333 ]\n",
            " [0.9961216 ]\n",
            " [0.00588774]]\n",
            "Step: 9444 -> Loss: 0.004312366247177124 -> Predictions: [[0.0035779 ]\n",
            " [0.9961333 ]\n",
            " [0.9961216 ]\n",
            " [0.00588771]]\n",
            "Step: 9445 -> Loss: 0.004312344826757908 -> Predictions: [[0.00357788]\n",
            " [0.9961333 ]\n",
            " [0.9961217 ]\n",
            " [0.00588768]]\n",
            "Step: 9446 -> Loss: 0.004312324337661266 -> Predictions: [[0.00357787]\n",
            " [0.99613345]\n",
            " [0.9961217 ]\n",
            " [0.00588765]]\n",
            "Step: 9447 -> Loss: 0.004312303848564625 -> Predictions: [[0.00357785]\n",
            " [0.99613345]\n",
            " [0.9961217 ]\n",
            " [0.00588762]]\n",
            "Step: 9448 -> Loss: 0.0043122852221131325 -> Predictions: [[0.00357783]\n",
            " [0.99613345]\n",
            " [0.9961217 ]\n",
            " [0.00588759]]\n",
            "Step: 9449 -> Loss: 0.004312264267355204 -> Predictions: [[0.00357781]\n",
            " [0.99613345]\n",
            " [0.9961217 ]\n",
            " [0.00588756]]\n",
            "Step: 9450 -> Loss: 0.004312243312597275 -> Predictions: [[0.0035778 ]\n",
            " [0.99613345]\n",
            " [0.9961217 ]\n",
            " [0.00588753]]\n",
            "Step: 9451 -> Loss: 0.004312224220484495 -> Predictions: [[0.00357778]\n",
            " [0.99613345]\n",
            " [0.9961217 ]\n",
            " [0.0058875 ]]\n",
            "Step: 9452 -> Loss: 0.004312203731387854 -> Predictions: [[0.00357777]\n",
            " [0.99613345]\n",
            " [0.9961217 ]\n",
            " [0.00588747]]\n",
            "Step: 9453 -> Loss: 0.004312185570597649 -> Predictions: [[0.00357775]\n",
            " [0.99613357]\n",
            " [0.9961218 ]\n",
            " [0.00588745]]\n",
            "Step: 9454 -> Loss: 0.0043121627531945705 -> Predictions: [[0.00357773]\n",
            " [0.99613357]\n",
            " [0.9961218 ]\n",
            " [0.00588741]]\n",
            "Step: 9455 -> Loss: 0.0043121445924043655 -> Predictions: [[0.00357772]\n",
            " [0.99613357]\n",
            " [0.9961218 ]\n",
            " [0.00588738]]\n",
            "Step: 9456 -> Loss: 0.004312123171985149 -> Predictions: [[0.00357771]\n",
            " [0.99613357]\n",
            " [0.9961218 ]\n",
            " [0.00588735]]\n",
            "Step: 9457 -> Loss: 0.004312105476856232 -> Predictions: [[0.00357769]\n",
            " [0.99613357]\n",
            " [0.9961218 ]\n",
            " [0.00588732]]\n",
            "Step: 9458 -> Loss: 0.004312083590775728 -> Predictions: [[0.00357767]\n",
            " [0.99613357]\n",
            " [0.9961218 ]\n",
            " [0.00588729]]\n",
            "Step: 9459 -> Loss: 0.004312062636017799 -> Predictions: [[0.00357765]\n",
            " [0.99613357]\n",
            " [0.99612194]\n",
            " [0.00588726]]\n",
            "Step: 9460 -> Loss: 0.0043120430782437325 -> Predictions: [[0.00357764]\n",
            " [0.9961337 ]\n",
            " [0.99612194]\n",
            " [0.00588724]]\n",
            "Step: 9461 -> Loss: 0.00431202445179224 -> Predictions: [[0.00357762]\n",
            " [0.9961337 ]\n",
            " [0.99612194]\n",
            " [0.0058872 ]]\n",
            "Step: 9462 -> Loss: 0.004312001168727875 -> Predictions: [[0.00357761]\n",
            " [0.9961337 ]\n",
            " [0.99612194]\n",
            " [0.00588717]]\n",
            "Step: 9463 -> Loss: 0.00431198300793767 -> Predictions: [[0.00357759]\n",
            " [0.9961337 ]\n",
            " [0.99612194]\n",
            " [0.00588714]]\n",
            "Step: 9464 -> Loss: 0.004311962518841028 -> Predictions: [[0.00357757]\n",
            " [0.9961337 ]\n",
            " [0.99612194]\n",
            " [0.00588712]]\n",
            "Step: 9465 -> Loss: 0.004311945289373398 -> Predictions: [[0.00357756]\n",
            " [0.9961337 ]\n",
            " [0.99612194]\n",
            " [0.00588709]]\n",
            "Step: 9466 -> Loss: 0.004311924800276756 -> Predictions: [[0.00357754]\n",
            " [0.9961337 ]\n",
            " [0.99612206]\n",
            " [0.00588706]]\n",
            "Step: 9467 -> Loss: 0.0043119024485349655 -> Predictions: [[0.00357753]\n",
            " [0.9961338 ]\n",
            " [0.99612206]\n",
            " [0.00588703]]\n",
            "Step: 9468 -> Loss: 0.004311885219067335 -> Predictions: [[0.00357751]\n",
            " [0.9961338 ]\n",
            " [0.99612206]\n",
            " [0.005887  ]]\n",
            "Step: 9469 -> Loss: 0.004311863798648119 -> Predictions: [[0.0035775 ]\n",
            " [0.9961338 ]\n",
            " [0.99612206]\n",
            " [0.00588698]]\n",
            "Step: 9470 -> Loss: 0.004311843775212765 -> Predictions: [[0.00357748]\n",
            " [0.9961338 ]\n",
            " [0.99612206]\n",
            " [0.00588694]]\n",
            "Step: 9471 -> Loss: 0.004311826080083847 -> Predictions: [[0.00357746]\n",
            " [0.9961338 ]\n",
            " [0.99612206]\n",
            " [0.00588691]]\n",
            "Step: 9472 -> Loss: 0.004311805125325918 -> Predictions: [[0.00357745]\n",
            " [0.9961338 ]\n",
            " [0.99612206]\n",
            " [0.00588688]]\n",
            "Step: 9473 -> Loss: 0.004311784170567989 -> Predictions: [[0.00357743]\n",
            " [0.9961339 ]\n",
            " [0.9961222 ]\n",
            " [0.00588685]]\n",
            "Step: 9474 -> Loss: 0.004311762284487486 -> Predictions: [[0.00357741]\n",
            " [0.9961339 ]\n",
            " [0.9961222 ]\n",
            " [0.00588682]]\n",
            "Step: 9475 -> Loss: 0.004311741329729557 -> Predictions: [[0.0035774 ]\n",
            " [0.9961339 ]\n",
            " [0.9961222 ]\n",
            " [0.00588679]]\n",
            "Step: 9476 -> Loss: 0.00431172177195549 -> Predictions: [[0.00357738]\n",
            " [0.9961339 ]\n",
            " [0.9961222 ]\n",
            " [0.00588676]]\n",
            "Step: 9477 -> Loss: 0.004311703145503998 -> Predictions: [[0.00357736]\n",
            " [0.9961339 ]\n",
            " [0.9961222 ]\n",
            " [0.00588674]]\n",
            "Step: 9478 -> Loss: 0.004311683587729931 -> Predictions: [[0.00357735]\n",
            " [0.9961339 ]\n",
            " [0.9961222 ]\n",
            " [0.00588671]]\n",
            "Step: 9479 -> Loss: 0.004311662167310715 -> Predictions: [[0.00357733]\n",
            " [0.9961339 ]\n",
            " [0.9961222 ]\n",
            " [0.00588667]]\n",
            "Step: 9480 -> Loss: 0.0043116421438753605 -> Predictions: [[0.00357732]\n",
            " [0.99613404]\n",
            " [0.9961223 ]\n",
            " [0.00588665]]\n",
            "Step: 9481 -> Loss: 0.004311621189117432 -> Predictions: [[0.0035773 ]\n",
            " [0.99613404]\n",
            " [0.9961223 ]\n",
            " [0.00588662]]\n",
            "Step: 9482 -> Loss: 0.004311603028327227 -> Predictions: [[0.00357729]\n",
            " [0.99613404]\n",
            " [0.9961223 ]\n",
            " [0.00588659]]\n",
            "Step: 9483 -> Loss: 0.004311582539230585 -> Predictions: [[0.00357727]\n",
            " [0.99613404]\n",
            " [0.9961223 ]\n",
            " [0.00588656]]\n",
            "Step: 9484 -> Loss: 0.004311561584472656 -> Predictions: [[0.00357725]\n",
            " [0.99613404]\n",
            " [0.9961223 ]\n",
            " [0.00588653]]\n",
            "Step: 9485 -> Loss: 0.0043115438893437386 -> Predictions: [[0.00357724]\n",
            " [0.99613404]\n",
            " [0.9961223 ]\n",
            " [0.0058865 ]]\n",
            "Step: 9486 -> Loss: 0.004311520140618086 -> Predictions: [[0.00357722]\n",
            " [0.99613404]\n",
            " [0.9961223 ]\n",
            " [0.00588647]]\n",
            "Step: 9487 -> Loss: 0.004311501979827881 -> Predictions: [[0.00357721]\n",
            " [0.99613404]\n",
            " [0.9961224 ]\n",
            " [0.00588644]]\n",
            "Step: 9488 -> Loss: 0.004311483819037676 -> Predictions: [[0.00357719]\n",
            " [0.99613416]\n",
            " [0.9961224 ]\n",
            " [0.00588641]]\n",
            "Step: 9489 -> Loss: 0.004311462864279747 -> Predictions: [[0.00357717]\n",
            " [0.99613416]\n",
            " [0.9961224 ]\n",
            " [0.00588638]]\n",
            "Step: 9490 -> Loss: 0.004311441443860531 -> Predictions: [[0.00357716]\n",
            " [0.99613416]\n",
            " [0.9961224 ]\n",
            " [0.00588635]]\n",
            "Step: 9491 -> Loss: 0.004311421420425177 -> Predictions: [[0.00357714]\n",
            " [0.99613416]\n",
            " [0.9961224 ]\n",
            " [0.00588633]]\n",
            "Step: 9492 -> Loss: 0.00431140186265111 -> Predictions: [[0.00357712]\n",
            " [0.99613416]\n",
            " [0.9961224 ]\n",
            " [0.00588629]]\n",
            "Step: 9493 -> Loss: 0.004311381373554468 -> Predictions: [[0.00357711]\n",
            " [0.99613416]\n",
            " [0.9961224 ]\n",
            " [0.00588626]]\n",
            "Step: 9494 -> Loss: 0.004311361350119114 -> Predictions: [[0.00357709]\n",
            " [0.9961343 ]\n",
            " [0.99612254]\n",
            " [0.00588623]]\n",
            "Step: 9495 -> Loss: 0.004311340861022472 -> Predictions: [[0.00357707]\n",
            " [0.9961343 ]\n",
            " [0.99612254]\n",
            " [0.00588621]]\n",
            "Step: 9496 -> Loss: 0.004311321768909693 -> Predictions: [[0.00357706]\n",
            " [0.9961343 ]\n",
            " [0.99612254]\n",
            " [0.00588618]]\n",
            "Step: 9497 -> Loss: 0.0043113017454743385 -> Predictions: [[0.00357704]\n",
            " [0.9961343 ]\n",
            " [0.99612254]\n",
            " [0.00588614]]\n",
            "Step: 9498 -> Loss: 0.004311280325055122 -> Predictions: [[0.00357702]\n",
            " [0.9961343 ]\n",
            " [0.99612254]\n",
            " [0.00588612]]\n",
            "Step: 9499 -> Loss: 0.004311259835958481 -> Predictions: [[0.00357701]\n",
            " [0.9961343 ]\n",
            " [0.99612254]\n",
            " [0.00588609]]\n",
            "Step: 9501 -> Loss: 0.004311219789087772 -> Predictions: [[0.00357698]\n",
            " [0.9961344 ]\n",
            " [0.99612266]\n",
            " [0.00588602]]\n",
            "Step: 9502 -> Loss: 0.00431120116263628 -> Predictions: [[0.00357696]\n",
            " [0.9961344 ]\n",
            " [0.99612266]\n",
            " [0.005886  ]]\n",
            "Step: 9503 -> Loss: 0.004311181604862213 -> Predictions: [[0.00357695]\n",
            " [0.9961344 ]\n",
            " [0.99612266]\n",
            " [0.00588597]]\n",
            "Step: 9504 -> Loss: 0.00431115971878171 -> Predictions: [[0.00357693]\n",
            " [0.9961344 ]\n",
            " [0.99612266]\n",
            " [0.00588593]]\n",
            "Step: 9505 -> Loss: 0.0043111396953463554 -> Predictions: [[0.00357691]\n",
            " [0.9961344 ]\n",
            " [0.99612266]\n",
            " [0.00588591]]\n",
            "Step: 9506 -> Loss: 0.004311120603233576 -> Predictions: [[0.0035769 ]\n",
            " [0.9961344 ]\n",
            " [0.99612266]\n",
            " [0.00588588]]\n",
            "Step: 9507 -> Loss: 0.004311101045459509 -> Predictions: [[0.00357688]\n",
            " [0.9961344 ]\n",
            " [0.99612266]\n",
            " [0.00588585]]\n",
            "Step: 9508 -> Loss: 0.004311081487685442 -> Predictions: [[0.00357686]\n",
            " [0.9961345 ]\n",
            " [0.9961228 ]\n",
            " [0.00588582]]\n",
            "Step: 9509 -> Loss: 0.004311060532927513 -> Predictions: [[0.00357685]\n",
            " [0.9961345 ]\n",
            " [0.9961228 ]\n",
            " [0.00588579]]\n",
            "Step: 9510 -> Loss: 0.004311040043830872 -> Predictions: [[0.00357683]\n",
            " [0.9961345 ]\n",
            " [0.9961228 ]\n",
            " [0.00588576]]\n",
            "Step: 9511 -> Loss: 0.004311020951718092 -> Predictions: [[0.00357682]\n",
            " [0.9961345 ]\n",
            " [0.9961228 ]\n",
            " [0.00588573]]\n",
            "Step: 9512 -> Loss: 0.004311000928282738 -> Predictions: [[0.0035768]\n",
            " [0.9961345]\n",
            " [0.9961228]\n",
            " [0.0058857]]\n",
            "Step: 9513 -> Loss: 0.0043109809048473835 -> Predictions: [[0.00357678]\n",
            " [0.9961345 ]\n",
            " [0.9961228 ]\n",
            " [0.00588567]]\n",
            "Step: 9514 -> Loss: 0.004310961812734604 -> Predictions: [[0.00357677]\n",
            " [0.9961345 ]\n",
            " [0.9961228 ]\n",
            " [0.00588564]]\n",
            "Step: 9515 -> Loss: 0.0043109399266541 -> Predictions: [[0.00357675]\n",
            " [0.99613464]\n",
            " [0.9961229 ]\n",
            " [0.00588561]]\n",
            "Step: 9516 -> Loss: 0.00431091757491231 -> Predictions: [[0.00357673]\n",
            " [0.99613464]\n",
            " [0.9961229 ]\n",
            " [0.00588558]]\n",
            "Step: 9517 -> Loss: 0.004310900345444679 -> Predictions: [[0.00357672]\n",
            " [0.99613464]\n",
            " [0.9961229 ]\n",
            " [0.00588556]]\n",
            "Step: 9518 -> Loss: 0.004310880322009325 -> Predictions: [[0.0035767 ]\n",
            " [0.99613464]\n",
            " [0.9961229 ]\n",
            " [0.00588553]]\n",
            "Step: 9519 -> Loss: 0.004310860298573971 -> Predictions: [[0.00357669]\n",
            " [0.99613464]\n",
            " [0.9961229 ]\n",
            " [0.0058855 ]]\n",
            "Step: 9520 -> Loss: 0.004310841206461191 -> Predictions: [[0.00357667]\n",
            " [0.99613464]\n",
            " [0.9961229 ]\n",
            " [0.00588546]]\n",
            "Step: 9521 -> Loss: 0.004310818389058113 -> Predictions: [[0.00357666]\n",
            " [0.99613464]\n",
            " [0.996123  ]\n",
            " [0.00588543]]\n",
            "Step: 9522 -> Loss: 0.004310801159590483 -> Predictions: [[0.00357664]\n",
            " [0.99613476]\n",
            " [0.996123  ]\n",
            " [0.00588541]]\n",
            "Step: 9523 -> Loss: 0.0043107797391712666 -> Predictions: [[0.00357662]\n",
            " [0.99613476]\n",
            " [0.996123  ]\n",
            " [0.00588538]]\n",
            "Step: 9524 -> Loss: 0.004310761112719774 -> Predictions: [[0.00357661]\n",
            " [0.99613476]\n",
            " [0.996123  ]\n",
            " [0.00588535]]\n",
            "Step: 9525 -> Loss: 0.0043107387609779835 -> Predictions: [[0.00357659]\n",
            " [0.99613476]\n",
            " [0.996123  ]\n",
            " [0.00588532]]\n",
            "Step: 9526 -> Loss: 0.004310718737542629 -> Predictions: [[0.00357657]\n",
            " [0.99613476]\n",
            " [0.996123  ]\n",
            " [0.00588529]]\n",
            "Step: 9527 -> Loss: 0.004310698714107275 -> Predictions: [[0.00357656]\n",
            " [0.99613476]\n",
            " [0.996123  ]\n",
            " [0.00588526]]\n",
            "Step: 9528 -> Loss: 0.004310678690671921 -> Predictions: [[0.00357654]\n",
            " [0.99613476]\n",
            " [0.99612314]\n",
            " [0.00588523]]\n",
            "Step: 9529 -> Loss: 0.004310660995543003 -> Predictions: [[0.00357653]\n",
            " [0.9961349 ]\n",
            " [0.99612314]\n",
            " [0.0058852 ]]\n",
            "Step: 9530 -> Loss: 0.004310636781156063 -> Predictions: [[0.00357651]\n",
            " [0.9961349 ]\n",
            " [0.99612314]\n",
            " [0.00588517]]\n",
            "Step: 9531 -> Loss: 0.00431062001734972 -> Predictions: [[0.00357649]\n",
            " [0.9961349 ]\n",
            " [0.99612314]\n",
            " [0.00588514]]\n",
            "Step: 9532 -> Loss: 0.004310598596930504 -> Predictions: [[0.00357648]\n",
            " [0.9961349 ]\n",
            " [0.99612314]\n",
            " [0.00588511]]\n",
            "Step: 9533 -> Loss: 0.00431057671085 -> Predictions: [[0.00357646]\n",
            " [0.9961349 ]\n",
            " [0.99612314]\n",
            " [0.00588508]]\n",
            "Step: 9534 -> Loss: 0.004310558550059795 -> Predictions: [[0.00357644]\n",
            " [0.9961349 ]\n",
            " [0.99612314]\n",
            " [0.00588505]]\n",
            "Step: 9535 -> Loss: 0.0043105389922857285 -> Predictions: [[0.00357643]\n",
            " [0.9961349 ]\n",
            " [0.99612325]\n",
            " [0.00588502]]\n",
            "Step: 9536 -> Loss: 0.004310518968850374 -> Predictions: [[0.00357642]\n",
            " [0.996135  ]\n",
            " [0.99612325]\n",
            " [0.005885  ]]\n",
            "Step: 9537 -> Loss: 0.004310497548431158 -> Predictions: [[0.00357639]\n",
            " [0.996135  ]\n",
            " [0.99612325]\n",
            " [0.00588496]]\n",
            "Step: 9538 -> Loss: 0.004310477990657091 -> Predictions: [[0.00357638]\n",
            " [0.996135  ]\n",
            " [0.99612325]\n",
            " [0.00588493]]\n",
            "Step: 9539 -> Loss: 0.004310457035899162 -> Predictions: [[0.00357636]\n",
            " [0.996135  ]\n",
            " [0.99612325]\n",
            " [0.00588491]]\n",
            "Step: 9540 -> Loss: 0.0043104360811412334 -> Predictions: [[0.00357635]\n",
            " [0.996135  ]\n",
            " [0.99612325]\n",
            " [0.00588488]]\n",
            "Step: 9541 -> Loss: 0.004310419782996178 -> Predictions: [[0.00357634]\n",
            " [0.996135  ]\n",
            " [0.99612325]\n",
            " [0.00588484]]\n",
            "Step: 9542 -> Loss: 0.004310399293899536 -> Predictions: [[0.00357632]\n",
            " [0.996135  ]\n",
            " [0.9961234 ]\n",
            " [0.00588482]]\n",
            "Step: 9543 -> Loss: 0.004310379270464182 -> Predictions: [[0.0035763 ]\n",
            " [0.9961351 ]\n",
            " [0.9961234 ]\n",
            " [0.00588479]]\n",
            "Step: 9544 -> Loss: 0.004310356453061104 -> Predictions: [[0.00357628]\n",
            " [0.9961351 ]\n",
            " [0.9961234 ]\n",
            " [0.00588475]]\n",
            "Step: 9545 -> Loss: 0.004310337360948324 -> Predictions: [[0.00357627]\n",
            " [0.9961351 ]\n",
            " [0.9961234 ]\n",
            " [0.00588473]]\n",
            "Step: 9546 -> Loss: 0.004310318268835545 -> Predictions: [[0.00357625]\n",
            " [0.9961351 ]\n",
            " [0.9961234 ]\n",
            " [0.0058847 ]]\n",
            "Step: 9547 -> Loss: 0.00431029824540019 -> Predictions: [[0.00357624]\n",
            " [0.9961351 ]\n",
            " [0.9961234 ]\n",
            " [0.00588467]]\n",
            "Step: 9548 -> Loss: 0.004310279618948698 -> Predictions: [[0.00357622]\n",
            " [0.9961351 ]\n",
            " [0.9961234 ]\n",
            " [0.00588465]]\n",
            "Step: 9549 -> Loss: 0.004310255404561758 -> Predictions: [[0.0035762 ]\n",
            " [0.99613523]\n",
            " [0.9961235 ]\n",
            " [0.00588461]]\n",
            "Step: 9550 -> Loss: 0.004310235846787691 -> Predictions: [[0.00357618]\n",
            " [0.99613523]\n",
            " [0.9961235 ]\n",
            " [0.00588458]]\n",
            "Step: 9551 -> Loss: 0.004310215823352337 -> Predictions: [[0.00357617]\n",
            " [0.99613523]\n",
            " [0.9961235 ]\n",
            " [0.00588455]]\n",
            "Step: 9552 -> Loss: 0.00431019626557827 -> Predictions: [[0.00357615]\n",
            " [0.99613523]\n",
            " [0.9961235 ]\n",
            " [0.00588452]]\n",
            "Step: 9553 -> Loss: 0.004310178104788065 -> Predictions: [[0.00357614]\n",
            " [0.99613523]\n",
            " [0.9961235 ]\n",
            " [0.00588449]]\n",
            "Step: 9554 -> Loss: 0.004310159012675285 -> Predictions: [[0.00357613]\n",
            " [0.99613523]\n",
            " [0.9961235 ]\n",
            " [0.00588447]]\n",
            "Step: 9555 -> Loss: 0.004310136660933495 -> Predictions: [[0.0035761 ]\n",
            " [0.99613523]\n",
            " [0.9961235 ]\n",
            " [0.00588443]]\n",
            "Step: 9556 -> Loss: 0.004310117103159428 -> Predictions: [[0.00357609]\n",
            " [0.99613535]\n",
            " [0.9961236 ]\n",
            " [0.00588441]]\n",
            "Step: 9557 -> Loss: 0.004310097079724073 -> Predictions: [[0.00357607]\n",
            " [0.99613535]\n",
            " [0.9961236 ]\n",
            " [0.00588437]]\n",
            "Step: 9558 -> Loss: 0.004310077056288719 -> Predictions: [[0.00357606]\n",
            " [0.99613535]\n",
            " [0.9961236 ]\n",
            " [0.00588434]]\n",
            "Step: 9559 -> Loss: 0.004310057498514652 -> Predictions: [[0.00357604]\n",
            " [0.99613535]\n",
            " [0.9961236 ]\n",
            " [0.00588432]]\n",
            "Step: 9560 -> Loss: 0.0043100351467728615 -> Predictions: [[0.00357603]\n",
            " [0.99613535]\n",
            " [0.9961236 ]\n",
            " [0.00588428]]\n",
            "Step: 9561 -> Loss: 0.0043100155889987946 -> Predictions: [[0.00357601]\n",
            " [0.99613535]\n",
            " [0.9961236 ]\n",
            " [0.00588425]]\n",
            "Step: 9562 -> Loss: 0.004309995099902153 -> Predictions: [[0.00357599]\n",
            " [0.99613535]\n",
            " [0.9961236 ]\n",
            " [0.00588423]]\n",
            "Step: 9563 -> Loss: 0.004309975542128086 -> Predictions: [[0.00357598]\n",
            " [0.99613535]\n",
            " [0.99612373]\n",
            " [0.00588419]]\n",
            "Step: 9564 -> Loss: 0.004309955518692732 -> Predictions: [[0.00357596]\n",
            " [0.9961355 ]\n",
            " [0.99612373]\n",
            " [0.00588416]]\n",
            "Step: 9565 -> Loss: 0.004309936426579952 -> Predictions: [[0.00357595]\n",
            " [0.9961355 ]\n",
            " [0.99612373]\n",
            " [0.00588414]]\n",
            "Step: 9566 -> Loss: 0.004309915937483311 -> Predictions: [[0.00357593]\n",
            " [0.9961355 ]\n",
            " [0.99612373]\n",
            " [0.00588411]]\n",
            "Step: 9567 -> Loss: 0.0043098959140479565 -> Predictions: [[0.00357591]\n",
            " [0.9961355 ]\n",
            " [0.99612373]\n",
            " [0.00588408]]\n",
            "Step: 9568 -> Loss: 0.0043098777532577515 -> Predictions: [[0.0035759 ]\n",
            " [0.9961355 ]\n",
            " [0.99612373]\n",
            " [0.00588405]]\n",
            "Step: 9569 -> Loss: 0.00430985726416111 -> Predictions: [[0.00357588]\n",
            " [0.9961355 ]\n",
            " [0.99612373]\n",
            " [0.00588402]]\n",
            "Step: 9570 -> Loss: 0.004309835843741894 -> Predictions: [[0.00357586]\n",
            " [0.9961356 ]\n",
            " [0.99612385]\n",
            " [0.00588399]]\n",
            "Step: 9571 -> Loss: 0.0043098158203065395 -> Predictions: [[0.00357585]\n",
            " [0.9961356 ]\n",
            " [0.99612385]\n",
            " [0.00588396]]\n",
            "Step: 9572 -> Loss: 0.004309797193855047 -> Predictions: [[0.00357583]\n",
            " [0.9961356 ]\n",
            " [0.99612385]\n",
            " [0.00588394]]\n",
            "Step: 9573 -> Loss: 0.004309777170419693 -> Predictions: [[0.00357581]\n",
            " [0.9961356 ]\n",
            " [0.99612385]\n",
            " [0.00588391]]\n",
            "Step: 9574 -> Loss: 0.0043097552843391895 -> Predictions: [[0.0035758 ]\n",
            " [0.9961356 ]\n",
            " [0.99612385]\n",
            " [0.00588387]]\n",
            "Step: 9575 -> Loss: 0.004309733398258686 -> Predictions: [[0.00357578]\n",
            " [0.9961356 ]\n",
            " [0.99612385]\n",
            " [0.00588383]]\n",
            "Step: 9576 -> Loss: 0.004309715237468481 -> Predictions: [[0.00357577]\n",
            " [0.9961356 ]\n",
            " [0.99612397]\n",
            " [0.00588382]]\n",
            "Step: 9577 -> Loss: 0.004309694282710552 -> Predictions: [[0.00357575]\n",
            " [0.9961357 ]\n",
            " [0.99612397]\n",
            " [0.00588378]]\n",
            "Step: 9578 -> Loss: 0.004309675190597773 -> Predictions: [[0.00357573]\n",
            " [0.9961357 ]\n",
            " [0.99612397]\n",
            " [0.00588376]]\n",
            "Step: 9579 -> Loss: 0.004309654701501131 -> Predictions: [[0.00357572]\n",
            " [0.9961357 ]\n",
            " [0.99612397]\n",
            " [0.00588373]]\n",
            "Step: 9580 -> Loss: 0.004309635143727064 -> Predictions: [[0.0035757 ]\n",
            " [0.9961357 ]\n",
            " [0.99612397]\n",
            " [0.0058837 ]]\n",
            "Step: 9581 -> Loss: 0.004309613257646561 -> Predictions: [[0.00357569]\n",
            " [0.9961357 ]\n",
            " [0.99612397]\n",
            " [0.00588366]]\n",
            "Step: 9582 -> Loss: 0.004309594165533781 -> Predictions: [[0.00357566]\n",
            " [0.9961357 ]\n",
            " [0.99612397]\n",
            " [0.00588364]]\n",
            "Step: 9583 -> Loss: 0.004309576004743576 -> Predictions: [[0.00357565]\n",
            " [0.9961357 ]\n",
            " [0.9961241 ]\n",
            " [0.00588361]]\n",
            "Step: 9584 -> Loss: 0.004309556446969509 -> Predictions: [[0.00357564]\n",
            " [0.9961358 ]\n",
            " [0.9961241 ]\n",
            " [0.00588358]]\n",
            "Step: 9585 -> Loss: 0.004309535026550293 -> Predictions: [[0.00357562]\n",
            " [0.9961358 ]\n",
            " [0.9961241 ]\n",
            " [0.00588355]]\n",
            "Step: 9586 -> Loss: 0.004309514071792364 -> Predictions: [[0.00357561]\n",
            " [0.9961358 ]\n",
            " [0.9961241 ]\n",
            " [0.00588351]]\n",
            "Step: 9587 -> Loss: 0.004309493117034435 -> Predictions: [[0.00357559]\n",
            " [0.9961358 ]\n",
            " [0.9961241 ]\n",
            " [0.00588349]]\n",
            "Step: 9588 -> Loss: 0.004309474490582943 -> Predictions: [[0.00357557]\n",
            " [0.9961358 ]\n",
            " [0.9961241 ]\n",
            " [0.00588346]]\n",
            "Step: 9589 -> Loss: 0.004309454001486301 -> Predictions: [[0.00357556]\n",
            " [0.9961358 ]\n",
            " [0.9961241 ]\n",
            " [0.00588343]]\n",
            "Step: 9590 -> Loss: 0.00430943351238966 -> Predictions: [[0.00357554]\n",
            " [0.9961358 ]\n",
            " [0.9961242 ]\n",
            " [0.0058834 ]]\n",
            "Step: 9591 -> Loss: 0.004309413954615593 -> Predictions: [[0.00357553]\n",
            " [0.9961359 ]\n",
            " [0.9961242 ]\n",
            " [0.00588337]]\n",
            "Step: 9592 -> Loss: 0.004309393931180239 -> Predictions: [[0.00357551]\n",
            " [0.9961359 ]\n",
            " [0.9961242 ]\n",
            " [0.00588334]]\n",
            "Step: 9593 -> Loss: 0.004309375770390034 -> Predictions: [[0.00357549]\n",
            " [0.9961359 ]\n",
            " [0.9961242 ]\n",
            " [0.00588332]]\n",
            "Step: 9594 -> Loss: 0.004309352487325668 -> Predictions: [[0.00357547]\n",
            " [0.9961359 ]\n",
            " [0.9961242 ]\n",
            " [0.00588328]]\n",
            "Step: 9595 -> Loss: 0.004309333860874176 -> Predictions: [[0.00357546]\n",
            " [0.9961359 ]\n",
            " [0.9961242 ]\n",
            " [0.00588326]]\n",
            "Step: 9596 -> Loss: 0.004309314768761396 -> Predictions: [[0.00357544]\n",
            " [0.9961359 ]\n",
            " [0.9961242 ]\n",
            " [0.00588322]]\n",
            "Step: 9597 -> Loss: 0.004309291951358318 -> Predictions: [[0.00357543]\n",
            " [0.9961359 ]\n",
            " [0.9961243 ]\n",
            " [0.00588319]]\n",
            "Step: 9598 -> Loss: 0.004309274721890688 -> Predictions: [[0.00357541]\n",
            " [0.996136  ]\n",
            " [0.9961243 ]\n",
            " [0.00588317]]\n",
            "Step: 9599 -> Loss: 0.004309254698455334 -> Predictions: [[0.00357539]\n",
            " [0.996136  ]\n",
            " [0.9961243 ]\n",
            " [0.00588314]]\n",
            "Step: 9600 -> Loss: 0.0043092332780361176 -> Predictions: [[0.00357538]\n",
            " [0.996136  ]\n",
            " [0.9961243 ]\n",
            " [0.00588311]]\n",
            "Step: 9601 -> Loss: 0.004309214651584625 -> Predictions: [[0.00357536]\n",
            " [0.996136  ]\n",
            " [0.9961243 ]\n",
            " [0.00588308]]\n",
            "Step: 9602 -> Loss: 0.00430919136852026 -> Predictions: [[0.00357534]\n",
            " [0.996136  ]\n",
            " [0.9961243 ]\n",
            " [0.00588305]]\n",
            "Step: 9603 -> Loss: 0.0043091727420687675 -> Predictions: [[0.00357533]\n",
            " [0.996136  ]\n",
            " [0.9961243 ]\n",
            " [0.00588301]]\n",
            "Step: 9604 -> Loss: 0.004309154115617275 -> Predictions: [[0.00357531]\n",
            " [0.996136  ]\n",
            " [0.99612445]\n",
            " [0.00588299]]\n",
            "Step: 9605 -> Loss: 0.0043091317638754845 -> Predictions: [[0.0035753 ]\n",
            " [0.9961361 ]\n",
            " [0.99612445]\n",
            " [0.00588296]]\n",
            "Step: 9606 -> Loss: 0.0043091122061014175 -> Predictions: [[0.00357528]\n",
            " [0.9961361 ]\n",
            " [0.99612445]\n",
            " [0.00588293]]\n",
            "Step: 9607 -> Loss: 0.004309090785682201 -> Predictions: [[0.00357526]\n",
            " [0.9961361 ]\n",
            " [0.99612445]\n",
            " [0.00588289]]\n",
            "Step: 9608 -> Loss: 0.004309072624891996 -> Predictions: [[0.00357525]\n",
            " [0.9961361 ]\n",
            " [0.99612445]\n",
            " [0.00588287]]\n",
            "Step: 9609 -> Loss: 0.004309052601456642 -> Predictions: [[0.00357523]\n",
            " [0.9961361 ]\n",
            " [0.99612445]\n",
            " [0.00588284]]\n",
            "Step: 9610 -> Loss: 0.004309030249714851 -> Predictions: [[0.00357522]\n",
            " [0.9961361 ]\n",
            " [0.99612445]\n",
            " [0.00588281]]\n",
            "Step: 9611 -> Loss: 0.004309013485908508 -> Predictions: [[0.0035752 ]\n",
            " [0.9961361 ]\n",
            " [0.99612457]\n",
            " [0.00588278]]\n",
            "Step: 9612 -> Loss: 0.0043089911341667175 -> Predictions: [[0.00357518]\n",
            " [0.99613625]\n",
            " [0.99612457]\n",
            " [0.00588275]]\n",
            "Step: 9613 -> Loss: 0.0043089729733765125 -> Predictions: [[0.00357517]\n",
            " [0.99613625]\n",
            " [0.99612457]\n",
            " [0.00588272]]\n",
            "Step: 9614 -> Loss: 0.004308953881263733 -> Predictions: [[0.00357515]\n",
            " [0.99613625]\n",
            " [0.99612457]\n",
            " [0.00588269]]\n",
            "Step: 9615 -> Loss: 0.004308933392167091 -> Predictions: [[0.00357513]\n",
            " [0.99613625]\n",
            " [0.99612457]\n",
            " [0.00588267]]\n",
            "Step: 9616 -> Loss: 0.004308910574764013 -> Predictions: [[0.00357512]\n",
            " [0.99613625]\n",
            " [0.99612457]\n",
            " [0.00588263]]\n",
            "Step: 9617 -> Loss: 0.004308890551328659 -> Predictions: [[0.0035751 ]\n",
            " [0.99613625]\n",
            " [0.99612457]\n",
            " [0.0058826 ]]\n",
            "Step: 9618 -> Loss: 0.004308873787522316 -> Predictions: [[0.00357509]\n",
            " [0.99613625]\n",
            " [0.9961247 ]\n",
            " [0.00588258]]\n",
            "Step: 9619 -> Loss: 0.004308851435780525 -> Predictions: [[0.00357507]\n",
            " [0.99613637]\n",
            " [0.9961247 ]\n",
            " [0.00588255]]\n",
            "Step: 9620 -> Loss: 0.004308831878006458 -> Predictions: [[0.00357505]\n",
            " [0.99613637]\n",
            " [0.9961247 ]\n",
            " [0.00588252]]\n",
            "Step: 9621 -> Loss: 0.0043088109232485294 -> Predictions: [[0.00357504]\n",
            " [0.99613637]\n",
            " [0.9961247 ]\n",
            " [0.00588248]]\n",
            "Step: 9622 -> Loss: 0.00430879183113575 -> Predictions: [[0.00357502]\n",
            " [0.99613637]\n",
            " [0.9961247 ]\n",
            " [0.00588246]]\n",
            "Step: 9623 -> Loss: 0.004308770876377821 -> Predictions: [[0.00357501]\n",
            " [0.99613637]\n",
            " [0.9961247 ]\n",
            " [0.00588243]]\n",
            "Step: 9624 -> Loss: 0.004308751784265041 -> Predictions: [[0.00357499]\n",
            " [0.99613637]\n",
            " [0.9961247 ]\n",
            " [0.0058824 ]]\n",
            "Step: 9625 -> Loss: 0.004308732226490974 -> Predictions: [[0.00357498]\n",
            " [0.99613637]\n",
            " [0.9961248 ]\n",
            " [0.00588237]]\n",
            "Step: 9626 -> Loss: 0.004308711737394333 -> Predictions: [[0.00357496]\n",
            " [0.9961365 ]\n",
            " [0.9961248 ]\n",
            " [0.00588234]]\n",
            "Step: 9627 -> Loss: 0.004308690316975117 -> Predictions: [[0.00357494]\n",
            " [0.9961365 ]\n",
            " [0.9961248 ]\n",
            " [0.00588231]]\n",
            "Step: 9628 -> Loss: 0.004308671690523624 -> Predictions: [[0.00357493]\n",
            " [0.9961365 ]\n",
            " [0.9961248 ]\n",
            " [0.00588228]]\n",
            "Step: 9629 -> Loss: 0.004308649338781834 -> Predictions: [[0.00357491]\n",
            " [0.9961365 ]\n",
            " [0.9961248 ]\n",
            " [0.00588225]]\n",
            "Step: 9630 -> Loss: 0.004308633506298065 -> Predictions: [[0.00357489]\n",
            " [0.9961365 ]\n",
            " [0.9961248 ]\n",
            " [0.00588223]]\n",
            "Step: 9631 -> Loss: 0.004308611620217562 -> Predictions: [[0.00357487]\n",
            " [0.9961365 ]\n",
            " [0.9961248 ]\n",
            " [0.00588219]]\n",
            "Step: 9632 -> Loss: 0.0043085901997983456 -> Predictions: [[0.00357486]\n",
            " [0.9961366 ]\n",
            " [0.9961249 ]\n",
            " [0.00588216]]\n",
            "Step: 9633 -> Loss: 0.004308570176362991 -> Predictions: [[0.00357484]\n",
            " [0.9961366 ]\n",
            " [0.9961249 ]\n",
            " [0.00588213]]\n",
            "Step: 9634 -> Loss: 0.004308550618588924 -> Predictions: [[0.00357483]\n",
            " [0.9961366 ]\n",
            " [0.9961249 ]\n",
            " [0.0058821 ]]\n",
            "Step: 9635 -> Loss: 0.0043085296638309956 -> Predictions: [[0.00357481]\n",
            " [0.9961366 ]\n",
            " [0.9961249 ]\n",
            " [0.00588208]]\n",
            "Step: 9636 -> Loss: 0.004308510571718216 -> Predictions: [[0.00357479]\n",
            " [0.9961366 ]\n",
            " [0.9961249 ]\n",
            " [0.00588205]]\n",
            "Step: 9637 -> Loss: 0.004308490082621574 -> Predictions: [[0.00357478]\n",
            " [0.9961366 ]\n",
            " [0.9961249 ]\n",
            " [0.00588201]]\n",
            "Step: 9638 -> Loss: 0.004308471921831369 -> Predictions: [[0.00357477]\n",
            " [0.9961366 ]\n",
            " [0.9961249 ]\n",
            " [0.00588198]]\n",
            "Step: 9639 -> Loss: 0.0043084509670734406 -> Predictions: [[0.00357475]\n",
            " [0.9961367 ]\n",
            " [0.99612504]\n",
            " [0.00588195]]\n",
            "Step: 9640 -> Loss: 0.00430842861533165 -> Predictions: [[0.00357473]\n",
            " [0.9961367 ]\n",
            " [0.99612504]\n",
            " [0.00588192]]\n",
            "Step: 9641 -> Loss: 0.0043084099888801575 -> Predictions: [[0.00357471]\n",
            " [0.9961367 ]\n",
            " [0.99612504]\n",
            " [0.0058819 ]]\n",
            "Step: 9642 -> Loss: 0.00430839229375124 -> Predictions: [[0.0035747 ]\n",
            " [0.9961367 ]\n",
            " [0.99612504]\n",
            " [0.00588187]]\n",
            "Step: 9643 -> Loss: 0.004308371338993311 -> Predictions: [[0.00357468]\n",
            " [0.9961367 ]\n",
            " [0.99612504]\n",
            " [0.00588184]]\n",
            "Step: 9644 -> Loss: 0.004308352712541819 -> Predictions: [[0.00357467]\n",
            " [0.9961367 ]\n",
            " [0.99612504]\n",
            " [0.00588181]]\n",
            "Step: 9645 -> Loss: 0.004308329429477453 -> Predictions: [[0.00357465]\n",
            " [0.9961367 ]\n",
            " [0.99612504]\n",
            " [0.00588178]]\n",
            "Step: 9646 -> Loss: 0.004308312200009823 -> Predictions: [[0.00357464]\n",
            " [0.9961367 ]\n",
            " [0.99612516]\n",
            " [0.00588175]]\n",
            "Step: 9647 -> Loss: 0.004308290779590607 -> Predictions: [[0.00357462]\n",
            " [0.99613684]\n",
            " [0.99612516]\n",
            " [0.00588172]]\n",
            "Step: 9648 -> Loss: 0.004308268893510103 -> Predictions: [[0.0035746 ]\n",
            " [0.99613684]\n",
            " [0.99612516]\n",
            " [0.00588169]]\n",
            "Step: 9649 -> Loss: 0.004308249335736036 -> Predictions: [[0.00357459]\n",
            " [0.99613684]\n",
            " [0.99612516]\n",
            " [0.00588166]]\n",
            "Step: 9650 -> Loss: 0.004308229777961969 -> Predictions: [[0.00357457]\n",
            " [0.99613684]\n",
            " [0.99612516]\n",
            " [0.00588163]]\n",
            "Step: 9651 -> Loss: 0.004308209288865328 -> Predictions: [[0.00357455]\n",
            " [0.99613684]\n",
            " [0.99612516]\n",
            " [0.0058816 ]]\n",
            "Step: 9652 -> Loss: 0.004308187402784824 -> Predictions: [[0.00357453]\n",
            " [0.99613684]\n",
            " [0.9961253 ]\n",
            " [0.00588157]]\n",
            "Step: 9653 -> Loss: 0.00430816737934947 -> Predictions: [[0.00357452]\n",
            " [0.99613696]\n",
            " [0.9961253 ]\n",
            " [0.00588154]]\n",
            "Step: 9654 -> Loss: 0.00430815014988184 -> Predictions: [[0.0035745 ]\n",
            " [0.99613696]\n",
            " [0.9961253 ]\n",
            " [0.00588152]]\n",
            "Step: 9655 -> Loss: 0.0043081301264464855 -> Predictions: [[0.00357449]\n",
            " [0.99613696]\n",
            " [0.9961253 ]\n",
            " [0.00588149]]\n",
            "Step: 9656 -> Loss: 0.004308111499994993 -> Predictions: [[0.00357447]\n",
            " [0.99613696]\n",
            " [0.9961253 ]\n",
            " [0.00588146]]\n",
            "Step: 9657 -> Loss: 0.004308088682591915 -> Predictions: [[0.00357446]\n",
            " [0.99613696]\n",
            " [0.9961253 ]\n",
            " [0.00588143]]\n",
            "Step: 9658 -> Loss: 0.004308067262172699 -> Predictions: [[0.00357444]\n",
            " [0.99613696]\n",
            " [0.9961253 ]\n",
            " [0.00588139]]\n",
            "Step: 9659 -> Loss: 0.004308049567043781 -> Predictions: [[0.00357442]\n",
            " [0.99613696]\n",
            " [0.9961254 ]\n",
            " [0.00588137]]\n",
            "Step: 9660 -> Loss: 0.004308028612285852 -> Predictions: [[0.00357441]\n",
            " [0.9961371 ]\n",
            " [0.9961254 ]\n",
            " [0.00588133]]\n",
            "Step: 9661 -> Loss: 0.004308009520173073 -> Predictions: [[0.00357439]\n",
            " [0.9961371 ]\n",
            " [0.9961254 ]\n",
            " [0.00588131]]\n",
            "Step: 9662 -> Loss: 0.004307985305786133 -> Predictions: [[0.00357437]\n",
            " [0.9961371 ]\n",
            " [0.9961254 ]\n",
            " [0.00588128]]\n",
            "Step: 9663 -> Loss: 0.00430796854197979 -> Predictions: [[0.00357436]\n",
            " [0.9961371 ]\n",
            " [0.9961254 ]\n",
            " [0.00588124]]\n",
            "Step: 9664 -> Loss: 0.004307947121560574 -> Predictions: [[0.00357434]\n",
            " [0.9961371 ]\n",
            " [0.9961254 ]\n",
            " [0.00588121]]\n",
            "Step: 9665 -> Loss: 0.004307927563786507 -> Predictions: [[0.00357432]\n",
            " [0.9961371 ]\n",
            " [0.9961254 ]\n",
            " [0.00588119]]\n",
            "Step: 9666 -> Loss: 0.0043079061433672905 -> Predictions: [[0.00357431]\n",
            " [0.9961371 ]\n",
            " [0.9961255 ]\n",
            " [0.00588116]]\n",
            "Step: 9667 -> Loss: 0.004307886119931936 -> Predictions: [[0.00357429]\n",
            " [0.9961372 ]\n",
            " [0.9961255 ]\n",
            " [0.00588113]]\n",
            "Step: 9668 -> Loss: 0.0043078698217868805 -> Predictions: [[0.00357428]\n",
            " [0.9961372 ]\n",
            " [0.9961255 ]\n",
            " [0.0058811 ]]\n",
            "Step: 9669 -> Loss: 0.004307849332690239 -> Predictions: [[0.00357426]\n",
            " [0.9961372 ]\n",
            " [0.9961255 ]\n",
            " [0.00588107]]\n",
            "Step: 9670 -> Loss: 0.004307829309254885 -> Predictions: [[0.00357425]\n",
            " [0.9961372 ]\n",
            " [0.9961255 ]\n",
            " [0.00588104]]\n",
            "Step: 9671 -> Loss: 0.004307809751480818 -> Predictions: [[0.00357423]\n",
            " [0.9961372 ]\n",
            " [0.9961255 ]\n",
            " [0.00588101]]\n",
            "Step: 9672 -> Loss: 0.004307790659368038 -> Predictions: [[0.00357422]\n",
            " [0.9961372 ]\n",
            " [0.9961255 ]\n",
            " [0.00588099]]\n",
            "Step: 9673 -> Loss: 0.004307769704610109 -> Predictions: [[0.0035742 ]\n",
            " [0.9961372 ]\n",
            " [0.99612564]\n",
            " [0.00588095]]\n",
            "Step: 9674 -> Loss: 0.004307748284190893 -> Predictions: [[0.00357418]\n",
            " [0.9961373 ]\n",
            " [0.99612564]\n",
            " [0.00588092]]\n",
            "Step: 9675 -> Loss: 0.004307728726416826 -> Predictions: [[0.00357417]\n",
            " [0.9961373 ]\n",
            " [0.99612564]\n",
            " [0.00588089]]\n",
            "Step: 9676 -> Loss: 0.004307708237320185 -> Predictions: [[0.00357415]\n",
            " [0.9961373 ]\n",
            " [0.99612564]\n",
            " [0.00588086]]\n",
            "Step: 9677 -> Loss: 0.004307686351239681 -> Predictions: [[0.00357413]\n",
            " [0.9961373 ]\n",
            " [0.99612564]\n",
            " [0.00588083]]\n",
            "Step: 9678 -> Loss: 0.004307668190449476 -> Predictions: [[0.00357412]\n",
            " [0.9961373 ]\n",
            " [0.99612564]\n",
            " [0.00588081]]\n",
            "Step: 9679 -> Loss: 0.004307647235691547 -> Predictions: [[0.0035741 ]\n",
            " [0.9961373 ]\n",
            " [0.99612564]\n",
            " [0.00588078]]\n",
            "Step: 9680 -> Loss: 0.0043076276779174805 -> Predictions: [[0.00357408]\n",
            " [0.9961373 ]\n",
            " [0.99612576]\n",
            " [0.00588075]]\n",
            "Step: 9681 -> Loss: 0.004307610914111137 -> Predictions: [[0.00357407]\n",
            " [0.99613744]\n",
            " [0.99612576]\n",
            " [0.00588073]]\n",
            "Step: 9682 -> Loss: 0.004307587631046772 -> Predictions: [[0.00357405]\n",
            " [0.99613744]\n",
            " [0.99612576]\n",
            " [0.00588069]]\n",
            "Step: 9683 -> Loss: 0.004307566210627556 -> Predictions: [[0.00357403]\n",
            " [0.99613744]\n",
            " [0.99612576]\n",
            " [0.00588066]]\n",
            "Step: 9684 -> Loss: 0.004307545255869627 -> Predictions: [[0.00357402]\n",
            " [0.99613744]\n",
            " [0.99612576]\n",
            " [0.00588063]]\n",
            "Step: 9685 -> Loss: 0.0043075308203697205 -> Predictions: [[0.00357401]\n",
            " [0.99613744]\n",
            " [0.99612576]\n",
            " [0.0058806 ]]\n",
            "Step: 9686 -> Loss: 0.004307506140321493 -> Predictions: [[0.00357398]\n",
            " [0.99613744]\n",
            " [0.99612576]\n",
            " [0.00588057]]\n",
            "Step: 9687 -> Loss: 0.0043074870482087135 -> Predictions: [[0.00357397]\n",
            " [0.99613744]\n",
            " [0.9961259 ]\n",
            " [0.00588054]]\n",
            "Step: 9688 -> Loss: 0.0043074702844023705 -> Predictions: [[0.00357396]\n",
            " [0.99613756]\n",
            " [0.9961259 ]\n",
            " [0.00588051]]\n",
            "Step: 9689 -> Loss: 0.004307446535676718 -> Predictions: [[0.00357394]\n",
            " [0.99613756]\n",
            " [0.9961259 ]\n",
            " [0.00588048]]\n",
            "Step: 9690 -> Loss: 0.004307424649596214 -> Predictions: [[0.00357392]\n",
            " [0.99613756]\n",
            " [0.9961259 ]\n",
            " [0.00588045]]\n",
            "Step: 9691 -> Loss: 0.004307405091822147 -> Predictions: [[0.00357391]\n",
            " [0.99613756]\n",
            " [0.9961259 ]\n",
            " [0.00588042]]\n",
            "Step: 9692 -> Loss: 0.004307387862354517 -> Predictions: [[0.00357389]\n",
            " [0.99613756]\n",
            " [0.9961259 ]\n",
            " [0.00588039]]\n",
            "Step: 9693 -> Loss: 0.0043073659762740135 -> Predictions: [[0.00357387]\n",
            " [0.99613756]\n",
            " [0.9961259 ]\n",
            " [0.00588036]]\n",
            "Step: 9694 -> Loss: 0.004307345952838659 -> Predictions: [[0.00357386]\n",
            " [0.99613756]\n",
            " [0.996126  ]\n",
            " [0.00588033]]\n",
            "Step: 9695 -> Loss: 0.004307325929403305 -> Predictions: [[0.00357384]\n",
            " [0.9961377 ]\n",
            " [0.996126  ]\n",
            " [0.0058803 ]]\n",
            "Step: 9696 -> Loss: 0.004307307302951813 -> Predictions: [[0.00357383]\n",
            " [0.9961377 ]\n",
            " [0.996126  ]\n",
            " [0.00588028]]\n",
            "Step: 9697 -> Loss: 0.004307286813855171 -> Predictions: [[0.00357381]\n",
            " [0.9961377 ]\n",
            " [0.996126  ]\n",
            " [0.00588024]]\n",
            "Step: 9698 -> Loss: 0.004307267721742392 -> Predictions: [[0.00357379]\n",
            " [0.9961377 ]\n",
            " [0.996126  ]\n",
            " [0.00588022]]\n",
            "Step: 9699 -> Loss: 0.004307244438678026 -> Predictions: [[0.00357378]\n",
            " [0.9961377 ]\n",
            " [0.996126  ]\n",
            " [0.00588018]]\n",
            "Step: 9700 -> Loss: 0.004307227674871683 -> Predictions: [[0.00357377]\n",
            " [0.9961377 ]\n",
            " [0.996126  ]\n",
            " [0.00588016]]\n",
            "Step: 9701 -> Loss: 0.004307207185775042 -> Predictions: [[0.00357375]\n",
            " [0.9961377 ]\n",
            " [0.9961261 ]\n",
            " [0.00588013]]\n",
            "Step: 9702 -> Loss: 0.004307185765355825 -> Predictions: [[0.00357373]\n",
            " [0.9961378 ]\n",
            " [0.9961261 ]\n",
            " [0.0058801 ]]\n",
            "Step: 9703 -> Loss: 0.004307165741920471 -> Predictions: [[0.00357371]\n",
            " [0.9961378 ]\n",
            " [0.9961261 ]\n",
            " [0.00588007]]\n",
            "Step: 9704 -> Loss: 0.004307147581130266 -> Predictions: [[0.0035737 ]\n",
            " [0.9961378 ]\n",
            " [0.9961261 ]\n",
            " [0.00588004]]\n",
            "Step: 9705 -> Loss: 0.004307126626372337 -> Predictions: [[0.00357368]\n",
            " [0.9961378 ]\n",
            " [0.9961261 ]\n",
            " [0.00588001]]\n",
            "Step: 9706 -> Loss: 0.004307106137275696 -> Predictions: [[0.00357367]\n",
            " [0.9961378 ]\n",
            " [0.9961261 ]\n",
            " [0.00587998]]\n",
            "Step: 9707 -> Loss: 0.004307083785533905 -> Predictions: [[0.00357365]\n",
            " [0.9961378 ]\n",
            " [0.99612623]\n",
            " [0.00587995]]\n",
            "Step: 9708 -> Loss: 0.004307067487388849 -> Predictions: [[0.00357363]\n",
            " [0.9961378 ]\n",
            " [0.99612623]\n",
            " [0.00587992]]\n",
            "Step: 9709 -> Loss: 0.004307046998292208 -> Predictions: [[0.00357362]\n",
            " [0.9961379 ]\n",
            " [0.99612623]\n",
            " [0.00587989]]\n",
            "Step: 9710 -> Loss: 0.0043070255778729916 -> Predictions: [[0.0035736 ]\n",
            " [0.9961379 ]\n",
            " [0.99612623]\n",
            " [0.00587986]]\n",
            "Step: 9711 -> Loss: 0.00430700508877635 -> Predictions: [[0.00357358]\n",
            " [0.9961379 ]\n",
            " [0.99612623]\n",
            " [0.00587983]]\n",
            "Step: 9712 -> Loss: 0.004306985065340996 -> Predictions: [[0.00357357]\n",
            " [0.9961379 ]\n",
            " [0.99612623]\n",
            " [0.0058798 ]]\n",
            "Step: 9713 -> Loss: 0.004306964576244354 -> Predictions: [[0.00357355]\n",
            " [0.9961379 ]\n",
            " [0.99612623]\n",
            " [0.00587977]]\n",
            "Step: 9714 -> Loss: 0.004306948743760586 -> Predictions: [[0.00357354]\n",
            " [0.9961379 ]\n",
            " [0.99612623]\n",
            " [0.00587975]]\n",
            "Step: 9715 -> Loss: 0.004306924529373646 -> Predictions: [[0.00357352]\n",
            " [0.9961379 ]\n",
            " [0.99612635]\n",
            " [0.00587971]]\n",
            "Step: 9716 -> Loss: 0.004306904971599579 -> Predictions: [[0.0035735 ]\n",
            " [0.99613804]\n",
            " [0.99612635]\n",
            " [0.00587969]]\n",
            "Step: 9717 -> Loss: 0.004306885413825512 -> Predictions: [[0.00357349]\n",
            " [0.99613804]\n",
            " [0.99612635]\n",
            " [0.00587965]]\n",
            "Step: 9718 -> Loss: 0.004306867253035307 -> Predictions: [[0.00357347]\n",
            " [0.99613804]\n",
            " [0.99612635]\n",
            " [0.00587963]]\n",
            "Step: 9719 -> Loss: 0.004306845832616091 -> Predictions: [[0.00357345]\n",
            " [0.99613804]\n",
            " [0.99612635]\n",
            " [0.0058796 ]]\n",
            "Step: 9720 -> Loss: 0.0043068258091807365 -> Predictions: [[0.00357344]\n",
            " [0.99613804]\n",
            " [0.99612635]\n",
            " [0.00587957]]\n",
            "Step: 9721 -> Loss: 0.004306805320084095 -> Predictions: [[0.00357342]\n",
            " [0.99613804]\n",
            " [0.9961265 ]\n",
            " [0.00587954]]\n",
            "Step: 9722 -> Loss: 0.004306786693632603 -> Predictions: [[0.00357341]\n",
            " [0.99613804]\n",
            " [0.9961265 ]\n",
            " [0.00587951]]\n",
            "Step: 9723 -> Loss: 0.004306766204535961 -> Predictions: [[0.0035734 ]\n",
            " [0.99613816]\n",
            " [0.9961265 ]\n",
            " [0.00587948]]\n",
            "Step: 9724 -> Loss: 0.004306746646761894 -> Predictions: [[0.00357338]\n",
            " [0.99613816]\n",
            " [0.9961265 ]\n",
            " [0.00587945]]\n",
            "Step: 9725 -> Loss: 0.004306727554649115 -> Predictions: [[0.00357336]\n",
            " [0.99613816]\n",
            " [0.9961265 ]\n",
            " [0.00587942]]\n",
            "Step: 9726 -> Loss: 0.00430670753121376 -> Predictions: [[0.00357335]\n",
            " [0.99613816]\n",
            " [0.9961265 ]\n",
            " [0.00587939]]\n",
            "Step: 9727 -> Loss: 0.0043066865764558315 -> Predictions: [[0.00357333]\n",
            " [0.99613816]\n",
            " [0.9961265 ]\n",
            " [0.00587936]]\n",
            "Step: 9728 -> Loss: 0.004306665156036615 -> Predictions: [[0.00357331]\n",
            " [0.99613816]\n",
            " [0.9961266 ]\n",
            " [0.00587933]]\n",
            "Step: 9729 -> Loss: 0.0043066455982625484 -> Predictions: [[0.0035733 ]\n",
            " [0.99613816]\n",
            " [0.9961266 ]\n",
            " [0.0058793 ]]\n",
            "Step: 9730 -> Loss: 0.0043066260404884815 -> Predictions: [[0.00357328]\n",
            " [0.9961383 ]\n",
            " [0.9961266 ]\n",
            " [0.00587927]]\n",
            "Step: 9731 -> Loss: 0.004306606482714415 -> Predictions: [[0.00357327]\n",
            " [0.9961383 ]\n",
            " [0.9961266 ]\n",
            " [0.00587924]]\n",
            "Step: 9732 -> Loss: 0.00430658645927906 -> Predictions: [[0.00357325]\n",
            " [0.9961383 ]\n",
            " [0.9961266 ]\n",
            " [0.00587922]]\n",
            "Step: 9733 -> Loss: 0.0043065669015049934 -> Predictions: [[0.00357323]\n",
            " [0.9961383 ]\n",
            " [0.9961266 ]\n",
            " [0.00587919]]\n",
            "Step: 9734 -> Loss: 0.004306545481085777 -> Predictions: [[0.00357322]\n",
            " [0.9961383 ]\n",
            " [0.9961266 ]\n",
            " [0.00587915]]\n",
            "Step: 9735 -> Loss: 0.004306524991989136 -> Predictions: [[0.0035732 ]\n",
            " [0.9961383 ]\n",
            " [0.9961267 ]\n",
            " [0.00587913]]\n",
            "Step: 9736 -> Loss: 0.00430650357156992 -> Predictions: [[0.00357318]\n",
            " [0.9961384 ]\n",
            " [0.9961267 ]\n",
            " [0.0058791 ]]\n",
            "Step: 9737 -> Loss: 0.004306483082473278 -> Predictions: [[0.00357316]\n",
            " [0.9961384 ]\n",
            " [0.9961267 ]\n",
            " [0.00587906]]\n",
            "Step: 9738 -> Loss: 0.004306466784328222 -> Predictions: [[0.00357315]\n",
            " [0.9961384 ]\n",
            " [0.9961267 ]\n",
            " [0.00587904]]\n",
            "Step: 9739 -> Loss: 0.004306442569941282 -> Predictions: [[0.00357313]\n",
            " [0.9961384 ]\n",
            " [0.9961267 ]\n",
            " [0.00587901]]\n",
            "Step: 9740 -> Loss: 0.004306425340473652 -> Predictions: [[0.00357312]\n",
            " [0.9961384 ]\n",
            " [0.9961267 ]\n",
            " [0.00587898]]\n",
            "Step: 9741 -> Loss: 0.004306402523070574 -> Predictions: [[0.0035731 ]\n",
            " [0.9961384 ]\n",
            " [0.9961267 ]\n",
            " [0.00587894]]\n",
            "Step: 9742 -> Loss: 0.004306381568312645 -> Predictions: [[0.00357308]\n",
            " [0.9961384 ]\n",
            " [0.99612683]\n",
            " [0.00587892]]\n",
            "Step: 9743 -> Loss: 0.004306365270167589 -> Predictions: [[0.00357307]\n",
            " [0.9961385 ]\n",
            " [0.99612683]\n",
            " [0.00587889]]\n",
            "Step: 9744 -> Loss: 0.00430634431540966 -> Predictions: [[0.00357306]\n",
            " [0.9961385 ]\n",
            " [0.99612683]\n",
            " [0.00587886]]\n",
            "Step: 9745 -> Loss: 0.004306322894990444 -> Predictions: [[0.00357303]\n",
            " [0.9961385 ]\n",
            " [0.99612683]\n",
            " [0.00587883]]\n",
            "Step: 9746 -> Loss: 0.004306304734200239 -> Predictions: [[0.00357302]\n",
            " [0.9961385 ]\n",
            " [0.99612683]\n",
            " [0.0058788 ]]\n",
            "Step: 9747 -> Loss: 0.004306281451135874 -> Predictions: [[0.003573  ]\n",
            " [0.9961385 ]\n",
            " [0.99612683]\n",
            " [0.00587877]]\n",
            "Step: 9748 -> Loss: 0.0043062628246843815 -> Predictions: [[0.00357299]\n",
            " [0.9961385 ]\n",
            " [0.99612683]\n",
            " [0.00587874]]\n",
            "Step: 9749 -> Loss: 0.004306243732571602 -> Predictions: [[0.00357297]\n",
            " [0.9961385 ]\n",
            " [0.99612695]\n",
            " [0.00587872]]\n",
            "Step: 9750 -> Loss: 0.004306224640458822 -> Predictions: [[0.00357296]\n",
            " [0.99613863]\n",
            " [0.99612695]\n",
            " [0.00587869]]\n",
            "Step: 9751 -> Loss: 0.004306203685700893 -> Predictions: [[0.00357294]\n",
            " [0.99613863]\n",
            " [0.99612695]\n",
            " [0.00587865]]\n",
            "Step: 9752 -> Loss: 0.004306185059249401 -> Predictions: [[0.00357292]\n",
            " [0.99613863]\n",
            " [0.99612695]\n",
            " [0.00587863]]\n",
            "Step: 9753 -> Loss: 0.004306160844862461 -> Predictions: [[0.0035729 ]\n",
            " [0.99613863]\n",
            " [0.99612695]\n",
            " [0.00587859]]\n",
            "Step: 9754 -> Loss: 0.004306142218410969 -> Predictions: [[0.00357289]\n",
            " [0.99613863]\n",
            " [0.99612695]\n",
            " [0.00587856]]\n",
            "Step: 9755 -> Loss: 0.004306124523282051 -> Predictions: [[0.00357288]\n",
            " [0.99613863]\n",
            " [0.99612695]\n",
            " [0.00587854]]\n",
            "Step: 9756 -> Loss: 0.004306104499846697 -> Predictions: [[0.00357286]\n",
            " [0.99613863]\n",
            " [0.99612707]\n",
            " [0.00587851]]\n",
            "Step: 9757 -> Loss: 0.004306084476411343 -> Predictions: [[0.00357284]\n",
            " [0.99613875]\n",
            " [0.99612707]\n",
            " [0.00587848]]\n",
            "Step: 9758 -> Loss: 0.004306059796363115 -> Predictions: [[0.00357282]\n",
            " [0.99613875]\n",
            " [0.99612707]\n",
            " [0.00587845]]\n",
            "Step: 9759 -> Loss: 0.004306042566895485 -> Predictions: [[0.00357281]\n",
            " [0.99613875]\n",
            " [0.99612707]\n",
            " [0.00587842]]\n",
            "Step: 9760 -> Loss: 0.004306023474782705 -> Predictions: [[0.0035728 ]\n",
            " [0.99613875]\n",
            " [0.99612707]\n",
            " [0.00587839]]\n",
            "Step: 9761 -> Loss: 0.004306002054363489 -> Predictions: [[0.00357277]\n",
            " [0.99613875]\n",
            " [0.99612707]\n",
            " [0.00587836]]\n",
            "Step: 9762 -> Loss: 0.0043059829622507095 -> Predictions: [[0.00357276]\n",
            " [0.99613875]\n",
            " [0.9961272 ]\n",
            " [0.00587833]]\n",
            "Step: 9763 -> Loss: 0.004305963404476643 -> Predictions: [[0.00357275]\n",
            " [0.99613875]\n",
            " [0.9961272 ]\n",
            " [0.0058783 ]]\n",
            "Step: 9764 -> Loss: 0.00430594477802515 -> Predictions: [[0.00357273]\n",
            " [0.9961389 ]\n",
            " [0.9961272 ]\n",
            " [0.00587828]]\n",
            "Step: 9765 -> Loss: 0.0043059238232672215 -> Predictions: [[0.00357272]\n",
            " [0.9961389 ]\n",
            " [0.9961272 ]\n",
            " [0.00587824]]\n",
            "Step: 9766 -> Loss: 0.004305902402848005 -> Predictions: [[0.0035727 ]\n",
            " [0.9961389 ]\n",
            " [0.9961272 ]\n",
            " [0.00587821]]\n",
            "Step: 9767 -> Loss: 0.004305882379412651 -> Predictions: [[0.00357268]\n",
            " [0.9961389 ]\n",
            " [0.9961272 ]\n",
            " [0.00587818]]\n",
            "Step: 9768 -> Loss: 0.004305864218622446 -> Predictions: [[0.00357267]\n",
            " [0.9961389 ]\n",
            " [0.9961272 ]\n",
            " [0.00587815]]\n",
            "Step: 9769 -> Loss: 0.0043058437295258045 -> Predictions: [[0.00357265]\n",
            " [0.9961389 ]\n",
            " [0.9961272 ]\n",
            " [0.00587813]]\n",
            "Step: 9770 -> Loss: 0.004305822774767876 -> Predictions: [[0.00357263]\n",
            " [0.9961389 ]\n",
            " [0.9961273 ]\n",
            " [0.0058781 ]]\n",
            "Step: 9771 -> Loss: 0.004305802285671234 -> Predictions: [[0.00357262]\n",
            " [0.996139  ]\n",
            " [0.9961273 ]\n",
            " [0.00587806]]\n",
            "Step: 9772 -> Loss: 0.004305782727897167 -> Predictions: [[0.0035726 ]\n",
            " [0.996139  ]\n",
            " [0.9961273 ]\n",
            " [0.00587804]]\n",
            "Step: 9773 -> Loss: 0.004305762238800526 -> Predictions: [[0.00357258]\n",
            " [0.996139  ]\n",
            " [0.9961273 ]\n",
            " [0.00587801]]\n",
            "Step: 9774 -> Loss: 0.004305743612349033 -> Predictions: [[0.00357257]\n",
            " [0.996139  ]\n",
            " [0.9961273 ]\n",
            " [0.00587798]]\n",
            "Step: 9775 -> Loss: 0.004305723123252392 -> Predictions: [[0.00357255]\n",
            " [0.996139  ]\n",
            " [0.9961273 ]\n",
            " [0.00587795]]\n",
            "Step: 9776 -> Loss: 0.004305704031139612 -> Predictions: [[0.00357254]\n",
            " [0.996139  ]\n",
            " [0.9961273 ]\n",
            " [0.00587792]]\n",
            "Step: 9777 -> Loss: 0.004305683542042971 -> Predictions: [[0.00357252]\n",
            " [0.996139  ]\n",
            " [0.9961274 ]\n",
            " [0.00587789]]\n",
            "Step: 9778 -> Loss: 0.004305661655962467 -> Predictions: [[0.0035725 ]\n",
            " [0.9961391 ]\n",
            " [0.9961274 ]\n",
            " [0.00587786]]\n",
            "Step: 9779 -> Loss: 0.004305640701204538 -> Predictions: [[0.00357248]\n",
            " [0.9961391 ]\n",
            " [0.9961274 ]\n",
            " [0.00587782]]\n",
            "Step: 9780 -> Loss: 0.004305621609091759 -> Predictions: [[0.00357247]\n",
            " [0.9961391 ]\n",
            " [0.9961274 ]\n",
            " [0.0058778 ]]\n",
            "Step: 9781 -> Loss: 0.0043056015856564045 -> Predictions: [[0.00357245]\n",
            " [0.9961391 ]\n",
            " [0.9961274 ]\n",
            " [0.00587777]]\n",
            "Step: 9782 -> Loss: 0.004305580630898476 -> Predictions: [[0.00357244]\n",
            " [0.9961391 ]\n",
            " [0.9961274 ]\n",
            " [0.00587774]]\n",
            "Step: 9783 -> Loss: 0.004305561538785696 -> Predictions: [[0.00357242]\n",
            " [0.9961391 ]\n",
            " [0.9961274 ]\n",
            " [0.00587771]]\n",
            "Step: 9784 -> Loss: 0.004305541515350342 -> Predictions: [[0.0035724 ]\n",
            " [0.9961391 ]\n",
            " [0.99612755]\n",
            " [0.00587768]]\n",
            "Step: 9785 -> Loss: 0.004305521957576275 -> Predictions: [[0.00357239]\n",
            " [0.9961392 ]\n",
            " [0.99612755]\n",
            " [0.00587765]]\n",
            "Step: 9786 -> Loss: 0.004305502865463495 -> Predictions: [[0.00357237]\n",
            " [0.9961392 ]\n",
            " [0.99612755]\n",
            " [0.00587762]]\n",
            "Step: 9787 -> Loss: 0.004305481910705566 -> Predictions: [[0.00357236]\n",
            " [0.9961392 ]\n",
            " [0.99612755]\n",
            " [0.00587759]]\n",
            "Step: 9788 -> Loss: 0.004305462818592787 -> Predictions: [[0.00357234]\n",
            " [0.9961392 ]\n",
            " [0.99612755]\n",
            " [0.00587757]]\n",
            "Step: 9789 -> Loss: 0.004305441398173571 -> Predictions: [[0.00357232]\n",
            " [0.9961392 ]\n",
            " [0.99612755]\n",
            " [0.00587754]]\n",
            "Step: 9790 -> Loss: 0.00430541904643178 -> Predictions: [[0.00357231]\n",
            " [0.9961392 ]\n",
            " [0.99612767]\n",
            " [0.0058775 ]]\n",
            "Step: 9791 -> Loss: 0.0043054018169641495 -> Predictions: [[0.00357229]\n",
            " [0.9961392 ]\n",
            " [0.99612767]\n",
            " [0.00587747]]\n",
            "Step: 9792 -> Loss: 0.00430538272485137 -> Predictions: [[0.00357228]\n",
            " [0.99613935]\n",
            " [0.99612767]\n",
            " [0.00587744]]\n",
            "Step: 9793 -> Loss: 0.004305360838770866 -> Predictions: [[0.00357226]\n",
            " [0.99613935]\n",
            " [0.99612767]\n",
            " [0.00587742]]\n",
            "Step: 9794 -> Loss: 0.004305341746658087 -> Predictions: [[0.00357224]\n",
            " [0.99613935]\n",
            " [0.99612767]\n",
            " [0.00587739]]\n",
            "Step: 9795 -> Loss: 0.004305320791900158 -> Predictions: [[0.00357223]\n",
            " [0.99613935]\n",
            " [0.99612767]\n",
            " [0.00587736]]\n",
            "Step: 9796 -> Loss: 0.004305300768464804 -> Predictions: [[0.00357221]\n",
            " [0.99613935]\n",
            " [0.99612767]\n",
            " [0.00587733]]\n",
            "Step: 9797 -> Loss: 0.004305282142013311 -> Predictions: [[0.0035722 ]\n",
            " [0.99613935]\n",
            " [0.9961278 ]\n",
            " [0.0058773 ]]\n",
            "Step: 9798 -> Loss: 0.004305260721594095 -> Predictions: [[0.00357218]\n",
            " [0.99613935]\n",
            " [0.9961278 ]\n",
            " [0.00587727]]\n",
            "Step: 9799 -> Loss: 0.004305240698158741 -> Predictions: [[0.00357216]\n",
            " [0.99613947]\n",
            " [0.9961278 ]\n",
            " [0.00587724]]\n",
            "Step: 9800 -> Loss: 0.004305221606045961 -> Predictions: [[0.00357215]\n",
            " [0.99613947]\n",
            " [0.9961278 ]\n",
            " [0.00587721]]\n",
            "Step: 9801 -> Loss: 0.004305202513933182 -> Predictions: [[0.00357213]\n",
            " [0.99613947]\n",
            " [0.9961278 ]\n",
            " [0.00587718]]\n",
            "Step: 9802 -> Loss: 0.004305179230868816 -> Predictions: [[0.00357211]\n",
            " [0.99613947]\n",
            " [0.9961278 ]\n",
            " [0.00587715]]\n",
            "Step: 9803 -> Loss: 0.0043051582761108875 -> Predictions: [[0.0035721 ]\n",
            " [0.99613947]\n",
            " [0.9961278 ]\n",
            " [0.00587712]]\n",
            "Step: 9804 -> Loss: 0.004305138718336821 -> Predictions: [[0.00357208]\n",
            " [0.99613947]\n",
            " [0.9961279 ]\n",
            " [0.00587709]]\n",
            "Step: 9805 -> Loss: 0.004305120557546616 -> Predictions: [[0.00357206]\n",
            " [0.99613947]\n",
            " [0.9961279 ]\n",
            " [0.00587706]]\n",
            "Step: 9806 -> Loss: 0.004305098205804825 -> Predictions: [[0.00357205]\n",
            " [0.9961396 ]\n",
            " [0.9961279 ]\n",
            " [0.00587703]]\n",
            "Step: 9807 -> Loss: 0.004305082373321056 -> Predictions: [[0.00357204]\n",
            " [0.9961396 ]\n",
            " [0.9961279 ]\n",
            " [0.005877  ]]\n",
            "Step: 9808 -> Loss: 0.00430506095290184 -> Predictions: [[0.00357202]\n",
            " [0.9961396 ]\n",
            " [0.9961279 ]\n",
            " [0.00587697]]\n",
            "Step: 9809 -> Loss: 0.004305041395127773 -> Predictions: [[0.003572  ]\n",
            " [0.9961396 ]\n",
            " [0.9961279 ]\n",
            " [0.00587694]]\n",
            "Step: 9810 -> Loss: 0.0043050190433859825 -> Predictions: [[0.00357199]\n",
            " [0.9961396 ]\n",
            " [0.9961279 ]\n",
            " [0.00587692]]\n",
            "Step: 9811 -> Loss: 0.004304999951273203 -> Predictions: [[0.00357197]\n",
            " [0.9961396 ]\n",
            " [0.996128  ]\n",
            " [0.00587689]]\n",
            "Step: 9812 -> Loss: 0.004304979927837849 -> Predictions: [[0.00357195]\n",
            " [0.9961397 ]\n",
            " [0.996128  ]\n",
            " [0.00587686]]\n",
            "Step: 9813 -> Loss: 0.004304959904402494 -> Predictions: [[0.00357194]\n",
            " [0.9961397 ]\n",
            " [0.996128  ]\n",
            " [0.00587683]]\n",
            "Step: 9814 -> Loss: 0.004304940812289715 -> Predictions: [[0.00357192]\n",
            " [0.9961397 ]\n",
            " [0.996128  ]\n",
            " [0.0058768 ]]\n",
            "Step: 9815 -> Loss: 0.004304918926209211 -> Predictions: [[0.0035719 ]\n",
            " [0.9961397 ]\n",
            " [0.996128  ]\n",
            " [0.00587677]]\n",
            "Step: 9816 -> Loss: 0.004304900765419006 -> Predictions: [[0.00357189]\n",
            " [0.9961397 ]\n",
            " [0.996128  ]\n",
            " [0.00587674]]\n",
            "Step: 9817 -> Loss: 0.004304877948015928 -> Predictions: [[0.00357187]\n",
            " [0.9961397 ]\n",
            " [0.996128  ]\n",
            " [0.00587671]]\n",
            "Step: 9818 -> Loss: 0.004304859787225723 -> Predictions: [[0.00357186]\n",
            " [0.9961397 ]\n",
            " [0.9961281 ]\n",
            " [0.00587668]]\n",
            "Step: 9819 -> Loss: 0.0043048374354839325 -> Predictions: [[0.00357184]\n",
            " [0.9961398 ]\n",
            " [0.9961281 ]\n",
            " [0.00587665]]\n",
            "Step: 9820 -> Loss: 0.00430481880903244 -> Predictions: [[0.00357182]\n",
            " [0.9961398 ]\n",
            " [0.9961281 ]\n",
            " [0.00587662]]\n",
            "Step: 9821 -> Loss: 0.004304797854274511 -> Predictions: [[0.0035718 ]\n",
            " [0.9961398 ]\n",
            " [0.9961281 ]\n",
            " [0.00587659]]\n",
            "Step: 9822 -> Loss: 0.004304777830839157 -> Predictions: [[0.00357179]\n",
            " [0.9961398 ]\n",
            " [0.9961281 ]\n",
            " [0.00587656]]\n",
            "Step: 9823 -> Loss: 0.004304757807403803 -> Predictions: [[0.00357177]\n",
            " [0.9961398 ]\n",
            " [0.9961281 ]\n",
            " [0.00587653]]\n",
            "Step: 9824 -> Loss: 0.0043047391809523106 -> Predictions: [[0.00357175]\n",
            " [0.9961398 ]\n",
            " [0.9961281 ]\n",
            " [0.00587651]]\n",
            "Step: 9825 -> Loss: 0.004304720088839531 -> Predictions: [[0.00357174]\n",
            " [0.9961398 ]\n",
            " [0.9961282 ]\n",
            " [0.00587648]]\n",
            "Step: 9826 -> Loss: 0.004304699599742889 -> Predictions: [[0.00357173]\n",
            " [0.99613994]\n",
            " [0.9961282 ]\n",
            " [0.00587644]]\n",
            "Step: 9827 -> Loss: 0.0043046800419688225 -> Predictions: [[0.00357171]\n",
            " [0.99613994]\n",
            " [0.9961282 ]\n",
            " [0.00587642]]\n",
            "Step: 9828 -> Loss: 0.0043046604841947556 -> Predictions: [[0.0035717 ]\n",
            " [0.99613994]\n",
            " [0.9961282 ]\n",
            " [0.00587639]]\n",
            "Step: 9829 -> Loss: 0.004304640926420689 -> Predictions: [[0.00357168]\n",
            " [0.99613994]\n",
            " [0.9961282 ]\n",
            " [0.00587636]]\n",
            "Step: 9830 -> Loss: 0.004304616712033749 -> Predictions: [[0.00357166]\n",
            " [0.99613994]\n",
            " [0.9961282 ]\n",
            " [0.00587632]]\n",
            "Step: 9831 -> Loss: 0.004304600413888693 -> Predictions: [[0.00357165]\n",
            " [0.99613994]\n",
            " [0.9961282 ]\n",
            " [0.0058763 ]]\n",
            "Step: 9832 -> Loss: 0.004304579459130764 -> Predictions: [[0.00357163]\n",
            " [0.99613994]\n",
            " [0.9961283 ]\n",
            " [0.00587627]]\n",
            "Step: 9833 -> Loss: 0.0043045589700341225 -> Predictions: [[0.00357161]\n",
            " [0.99614006]\n",
            " [0.9961283 ]\n",
            " [0.00587624]]\n",
            "Step: 9834 -> Loss: 0.00430454034358263 -> Predictions: [[0.0035716 ]\n",
            " [0.99614006]\n",
            " [0.9961283 ]\n",
            " [0.00587621]]\n",
            "Step: 9835 -> Loss: 0.004304518923163414 -> Predictions: [[0.00357159]\n",
            " [0.99614006]\n",
            " [0.9961283 ]\n",
            " [0.00587618]]\n",
            "Step: 9836 -> Loss: 0.00430449889972806 -> Predictions: [[0.00357157]\n",
            " [0.99614006]\n",
            " [0.9961283 ]\n",
            " [0.00587615]]\n",
            "Step: 9837 -> Loss: 0.004304477944970131 -> Predictions: [[0.00357155]\n",
            " [0.99614006]\n",
            " [0.9961283 ]\n",
            " [0.00587612]]\n",
            "Step: 9838 -> Loss: 0.004304459784179926 -> Predictions: [[0.00357153]\n",
            " [0.99614006]\n",
            " [0.9961283 ]\n",
            " [0.00587609]]\n",
            "Step: 9839 -> Loss: 0.004304438829421997 -> Predictions: [[0.00357152]\n",
            " [0.99614006]\n",
            " [0.99612844]\n",
            " [0.00587606]]\n",
            "Step: 9840 -> Loss: 0.00430441927164793 -> Predictions: [[0.0035715 ]\n",
            " [0.9961402 ]\n",
            " [0.99612844]\n",
            " [0.00587604]]\n",
            "Step: 9841 -> Loss: 0.004304396919906139 -> Predictions: [[0.00357149]\n",
            " [0.9961402 ]\n",
            " [0.99612844]\n",
            " [0.005876  ]]\n",
            "Step: 9842 -> Loss: 0.004304379224777222 -> Predictions: [[0.00357147]\n",
            " [0.9961402 ]\n",
            " [0.99612844]\n",
            " [0.00587597]]\n",
            "Step: 9843 -> Loss: 0.004304355941712856 -> Predictions: [[0.00357145]\n",
            " [0.9961402 ]\n",
            " [0.99612844]\n",
            " [0.00587594]]\n",
            "Step: 9844 -> Loss: 0.004304338712245226 -> Predictions: [[0.00357144]\n",
            " [0.9961402 ]\n",
            " [0.99612844]\n",
            " [0.00587591]]\n",
            "Step: 9845 -> Loss: 0.004304316360503435 -> Predictions: [[0.00357142]\n",
            " [0.9961402 ]\n",
            " [0.99612856]\n",
            " [0.00587588]]\n",
            "Step: 9846 -> Loss: 0.0043042986653745174 -> Predictions: [[0.0035714 ]\n",
            " [0.9961402 ]\n",
            " [0.99612856]\n",
            " [0.00587585]]\n",
            "Step: 9847 -> Loss: 0.004304276313632727 -> Predictions: [[0.00357138]\n",
            " [0.9961403 ]\n",
            " [0.99612856]\n",
            " [0.00587582]]\n",
            "Step: 9848 -> Loss: 0.004304259084165096 -> Predictions: [[0.00357137]\n",
            " [0.9961403 ]\n",
            " [0.99612856]\n",
            " [0.0058758 ]]\n",
            "Step: 9849 -> Loss: 0.004304239060729742 -> Predictions: [[0.00357135]\n",
            " [0.9961403 ]\n",
            " [0.99612856]\n",
            " [0.00587577]]\n",
            "Step: 9850 -> Loss: 0.004304218105971813 -> Predictions: [[0.00357134]\n",
            " [0.9961403 ]\n",
            " [0.99612856]\n",
            " [0.00587574]]\n",
            "Step: 9851 -> Loss: 0.004304199013859034 -> Predictions: [[0.00357132]\n",
            " [0.9961403 ]\n",
            " [0.99612856]\n",
            " [0.00587571]]\n",
            "Step: 9852 -> Loss: 0.004304178524762392 -> Predictions: [[0.00357131]\n",
            " [0.9961403 ]\n",
            " [0.9961287 ]\n",
            " [0.00587568]]\n",
            "Step: 9853 -> Loss: 0.004304160829633474 -> Predictions: [[0.00357129]\n",
            " [0.9961403 ]\n",
            " [0.9961287 ]\n",
            " [0.00587565]]\n",
            "Step: 9854 -> Loss: 0.004304138012230396 -> Predictions: [[0.00357128]\n",
            " [0.9961404 ]\n",
            " [0.9961287 ]\n",
            " [0.00587562]]\n",
            "Step: 9855 -> Loss: 0.004304117988795042 -> Predictions: [[0.00357126]\n",
            " [0.9961404 ]\n",
            " [0.9961287 ]\n",
            " [0.00587559]]\n",
            "Step: 9856 -> Loss: 0.004304096102714539 -> Predictions: [[0.00357125]\n",
            " [0.9961404 ]\n",
            " [0.9961287 ]\n",
            " [0.00587556]]\n",
            "Step: 9857 -> Loss: 0.00430408027023077 -> Predictions: [[0.00357123]\n",
            " [0.9961404 ]\n",
            " [0.9961287 ]\n",
            " [0.00587553]]\n",
            "Step: 9858 -> Loss: 0.004304057918488979 -> Predictions: [[0.0035712 ]\n",
            " [0.9961404 ]\n",
            " [0.9961287 ]\n",
            " [0.00587551]]\n",
            "Step: 9859 -> Loss: 0.004304038360714912 -> Predictions: [[0.0035712 ]\n",
            " [0.9961404 ]\n",
            " [0.9961288 ]\n",
            " [0.00587547]]\n",
            "Step: 9860 -> Loss: 0.004304016940295696 -> Predictions: [[0.00357118]\n",
            " [0.9961404 ]\n",
            " [0.9961288 ]\n",
            " [0.00587544]]\n",
            "Step: 9861 -> Loss: 0.004303996916860342 -> Predictions: [[0.00357116]\n",
            " [0.99614054]\n",
            " [0.9961288 ]\n",
            " [0.00587541]]\n",
            "Step: 9862 -> Loss: 0.004303979221731424 -> Predictions: [[0.00357115]\n",
            " [0.99614054]\n",
            " [0.9961288 ]\n",
            " [0.00587538]]\n",
            "Step: 9863 -> Loss: 0.004303956404328346 -> Predictions: [[0.00357113]\n",
            " [0.99614054]\n",
            " [0.9961288 ]\n",
            " [0.00587535]]\n",
            "Step: 9864 -> Loss: 0.004303936846554279 -> Predictions: [[0.00357111]\n",
            " [0.99614054]\n",
            " [0.9961288 ]\n",
            " [0.00587533]]\n",
            "Step: 9865 -> Loss: 0.004303917288780212 -> Predictions: [[0.0035711 ]\n",
            " [0.99614054]\n",
            " [0.9961288 ]\n",
            " [0.0058753 ]]\n",
            "Step: 9866 -> Loss: 0.004303895868360996 -> Predictions: [[0.00357108]\n",
            " [0.99614054]\n",
            " [0.9961289 ]\n",
            " [0.00587527]]\n",
            "Step: 9867 -> Loss: 0.0043038781732320786 -> Predictions: [[0.00357107]\n",
            " [0.99614054]\n",
            " [0.9961289 ]\n",
            " [0.00587524]]\n",
            "Step: 9868 -> Loss: 0.004303855821490288 -> Predictions: [[0.00357104]\n",
            " [0.99614066]\n",
            " [0.9961289 ]\n",
            " [0.00587521]]\n",
            "Step: 9869 -> Loss: 0.004303839057683945 -> Predictions: [[0.00357104]\n",
            " [0.99614066]\n",
            " [0.9961289 ]\n",
            " [0.00587518]]\n",
            "Step: 9870 -> Loss: 0.0043038176372647285 -> Predictions: [[0.00357101]\n",
            " [0.99614066]\n",
            " [0.9961289 ]\n",
            " [0.00587515]]\n",
            "Step: 9871 -> Loss: 0.004303798545151949 -> Predictions: [[0.003571  ]\n",
            " [0.99614066]\n",
            " [0.9961289 ]\n",
            " [0.00587512]]\n",
            "Step: 9872 -> Loss: 0.004303778521716595 -> Predictions: [[0.00357099]\n",
            " [0.99614066]\n",
            " [0.9961289 ]\n",
            " [0.00587509]]\n",
            "Step: 9873 -> Loss: 0.004303759429603815 -> Predictions: [[0.00357097]\n",
            " [0.99614066]\n",
            " [0.99612904]\n",
            " [0.00587506]]\n",
            "Step: 9874 -> Loss: 0.004303736612200737 -> Predictions: [[0.00357095]\n",
            " [0.99614066]\n",
            " [0.99612904]\n",
            " [0.00587503]]\n",
            "Step: 9875 -> Loss: 0.0043037161231040955 -> Predictions: [[0.00357094]\n",
            " [0.9961408 ]\n",
            " [0.99612904]\n",
            " [0.005875  ]]\n",
            "Step: 9876 -> Loss: 0.0043036965653300285 -> Predictions: [[0.00357092]\n",
            " [0.9961408 ]\n",
            " [0.99612904]\n",
            " [0.00587497]]\n",
            "Step: 9877 -> Loss: 0.0043036798015236855 -> Predictions: [[0.00357091]\n",
            " [0.9961408 ]\n",
            " [0.99612904]\n",
            " [0.00587495]]\n",
            "Step: 9878 -> Loss: 0.004303658381104469 -> Predictions: [[0.00357089]\n",
            " [0.9961408 ]\n",
            " [0.99612904]\n",
            " [0.00587492]]\n",
            "Step: 9879 -> Loss: 0.004303637892007828 -> Predictions: [[0.00357088]\n",
            " [0.9961408 ]\n",
            " [0.99612904]\n",
            " [0.00587488]]\n",
            "Step: 9880 -> Loss: 0.004303617402911186 -> Predictions: [[0.00357086]\n",
            " [0.9961408 ]\n",
            " [0.99612916]\n",
            " [0.00587485]]\n",
            "Step: 9881 -> Loss: 0.004303596913814545 -> Predictions: [[0.00357084]\n",
            " [0.9961408 ]\n",
            " [0.99612916]\n",
            " [0.00587482]]\n",
            "Step: 9882 -> Loss: 0.004303577356040478 -> Predictions: [[0.00357082]\n",
            " [0.9961409 ]\n",
            " [0.99612916]\n",
            " [0.00587479]]\n",
            "Step: 9883 -> Loss: 0.004303556401282549 -> Predictions: [[0.00357081]\n",
            " [0.9961409 ]\n",
            " [0.99612916]\n",
            " [0.00587476]]\n",
            "Step: 9884 -> Loss: 0.004303536843508482 -> Predictions: [[0.00357079]\n",
            " [0.9961409 ]\n",
            " [0.99612916]\n",
            " [0.00587474]]\n",
            "Step: 9885 -> Loss: 0.004303517751395702 -> Predictions: [[0.00357078]\n",
            " [0.9961409 ]\n",
            " [0.99612916]\n",
            " [0.00587471]]\n",
            "Step: 9886 -> Loss: 0.004303494468331337 -> Predictions: [[0.00357076]\n",
            " [0.9961409 ]\n",
            " [0.9961293 ]\n",
            " [0.00587467]]\n",
            "Step: 9887 -> Loss: 0.004303477704524994 -> Predictions: [[0.00357074]\n",
            " [0.9961409 ]\n",
            " [0.9961293 ]\n",
            " [0.00587465]]\n",
            "Step: 9888 -> Loss: 0.004303457215428352 -> Predictions: [[0.00357073]\n",
            " [0.9961409 ]\n",
            " [0.9961293 ]\n",
            " [0.00587462]]\n",
            "Step: 9889 -> Loss: 0.004303433932363987 -> Predictions: [[0.00357071]\n",
            " [0.996141  ]\n",
            " [0.9961293 ]\n",
            " [0.00587459]]\n",
            "Step: 9890 -> Loss: 0.0043034180998802185 -> Predictions: [[0.0035707 ]\n",
            " [0.996141  ]\n",
            " [0.9961293 ]\n",
            " [0.00587456]]\n",
            "Step: 9891 -> Loss: 0.004303395748138428 -> Predictions: [[0.00357068]\n",
            " [0.996141  ]\n",
            " [0.9961293 ]\n",
            " [0.00587453]]\n",
            "Step: 9892 -> Loss: 0.004303377121686935 -> Predictions: [[0.00357066]\n",
            " [0.996141  ]\n",
            " [0.9961293 ]\n",
            " [0.0058745 ]]\n",
            "Step: 9893 -> Loss: 0.004303358029574156 -> Predictions: [[0.00357065]\n",
            " [0.996141  ]\n",
            " [0.9961293 ]\n",
            " [0.00587447]]\n",
            "Step: 9894 -> Loss: 0.004303338471800089 -> Predictions: [[0.00357063]\n",
            " [0.996141  ]\n",
            " [0.9961294 ]\n",
            " [0.00587444]]\n",
            "Step: 9895 -> Loss: 0.004303313791751862 -> Predictions: [[0.00357061]\n",
            " [0.99614114]\n",
            " [0.9961294 ]\n",
            " [0.00587441]]\n",
            "Step: 9896 -> Loss: 0.004303295630961657 -> Predictions: [[0.0035706 ]\n",
            " [0.99614114]\n",
            " [0.9961294 ]\n",
            " [0.00587438]]\n",
            "Step: 9897 -> Loss: 0.004303277935832739 -> Predictions: [[0.00357058]\n",
            " [0.99614114]\n",
            " [0.9961294 ]\n",
            " [0.00587435]]\n",
            "Step: 9898 -> Loss: 0.004303256049752235 -> Predictions: [[0.00357056]\n",
            " [0.99614114]\n",
            " [0.9961294 ]\n",
            " [0.00587433]]\n",
            "Step: 9899 -> Loss: 0.004303239285945892 -> Predictions: [[0.00357055]\n",
            " [0.99614114]\n",
            " [0.9961294 ]\n",
            " [0.0058743 ]]\n",
            "Step: 9900 -> Loss: 0.004303215071558952 -> Predictions: [[0.00357053]\n",
            " [0.99614114]\n",
            " [0.9961294 ]\n",
            " [0.00587426]]\n",
            "Step: 9901 -> Loss: 0.00430319644510746 -> Predictions: [[0.00357052]\n",
            " [0.99614114]\n",
            " [0.9961295 ]\n",
            " [0.00587424]]\n",
            "Step: 9902 -> Loss: 0.0043031759560108185 -> Predictions: [[0.0035705 ]\n",
            " [0.99614125]\n",
            " [0.9961295 ]\n",
            " [0.0058742 ]]\n",
            "Step: 9903 -> Loss: 0.0043031563982367516 -> Predictions: [[0.00357049]\n",
            " [0.99614125]\n",
            " [0.9961295 ]\n",
            " [0.00587418]]\n",
            "Step: 9904 -> Loss: 0.004303136840462685 -> Predictions: [[0.00357047]\n",
            " [0.99614125]\n",
            " [0.9961295 ]\n",
            " [0.00587415]]\n",
            "Step: 9905 -> Loss: 0.0043031154200434685 -> Predictions: [[0.00357045]\n",
            " [0.99614125]\n",
            " [0.9961295 ]\n",
            " [0.00587412]]\n",
            "Step: 9906 -> Loss: 0.004303093068301678 -> Predictions: [[0.00357044]\n",
            " [0.99614125]\n",
            " [0.9961295 ]\n",
            " [0.00587408]]\n",
            "Step: 9907 -> Loss: 0.004303077235817909 -> Predictions: [[0.00357042]\n",
            " [0.99614125]\n",
            " [0.9961295 ]\n",
            " [0.00587406]]\n",
            "Step: 9908 -> Loss: 0.004303056746721268 -> Predictions: [[0.0035704 ]\n",
            " [0.99614125]\n",
            " [0.99612963]\n",
            " [0.00587403]]\n",
            "Step: 9909 -> Loss: 0.0043030367232859135 -> Predictions: [[0.00357039]\n",
            " [0.9961414 ]\n",
            " [0.99612963]\n",
            " [0.005874  ]]\n",
            "Step: 9910 -> Loss: 0.004303016699850559 -> Predictions: [[0.00357037]\n",
            " [0.9961414 ]\n",
            " [0.99612963]\n",
            " [0.00587398]]\n",
            "Step: 9911 -> Loss: 0.00430299574509263 -> Predictions: [[0.00357036]\n",
            " [0.9961414 ]\n",
            " [0.99612963]\n",
            " [0.00587394]]\n",
            "Step: 9912 -> Loss: 0.004302975721657276 -> Predictions: [[0.00357034]\n",
            " [0.9961414 ]\n",
            " [0.99612963]\n",
            " [0.00587391]]\n",
            "Step: 9913 -> Loss: 0.004302955232560635 -> Predictions: [[0.00357032]\n",
            " [0.9961414 ]\n",
            " [0.99612963]\n",
            " [0.00587388]]\n",
            "Step: 9914 -> Loss: 0.004302935674786568 -> Predictions: [[0.00357031]\n",
            " [0.9961414 ]\n",
            " [0.99612975]\n",
            " [0.00587385]]\n",
            "Step: 9915 -> Loss: 0.004302913323044777 -> Predictions: [[0.00357029]\n",
            " [0.9961414 ]\n",
            " [0.99612975]\n",
            " [0.00587382]]\n",
            "Step: 9916 -> Loss: 0.004302895627915859 -> Predictions: [[0.00357027]\n",
            " [0.9961415 ]\n",
            " [0.99612975]\n",
            " [0.00587379]]\n",
            "Step: 9917 -> Loss: 0.004302876070141792 -> Predictions: [[0.00357026]\n",
            " [0.9961415 ]\n",
            " [0.99612975]\n",
            " [0.00587377]]\n",
            "Step: 9918 -> Loss: 0.004302853252738714 -> Predictions: [[0.00357024]\n",
            " [0.9961415 ]\n",
            " [0.99612975]\n",
            " [0.00587373]]\n",
            "Step: 9919 -> Loss: 0.0043028369545936584 -> Predictions: [[0.00357023]\n",
            " [0.9961415 ]\n",
            " [0.99612975]\n",
            " [0.00587371]]\n",
            "Step: 9920 -> Loss: 0.004302815534174442 -> Predictions: [[0.00357021]\n",
            " [0.9961415 ]\n",
            " [0.99612975]\n",
            " [0.00587367]]\n",
            "Step: 9921 -> Loss: 0.004302797839045525 -> Predictions: [[0.0035702 ]\n",
            " [0.9961415 ]\n",
            " [0.99612975]\n",
            " [0.00587365]]\n",
            "Step: 9922 -> Loss: 0.004302773624658585 -> Predictions: [[0.00357018]\n",
            " [0.9961415 ]\n",
            " [0.9961299 ]\n",
            " [0.00587361]]\n",
            "Step: 9923 -> Loss: 0.004302757326513529 -> Predictions: [[0.00357016]\n",
            " [0.9961415 ]\n",
            " [0.9961299 ]\n",
            " [0.00587359]]\n",
            "Step: 9924 -> Loss: 0.004302735906094313 -> Predictions: [[0.00357015]\n",
            " [0.9961416 ]\n",
            " [0.9961299 ]\n",
            " [0.00587356]]\n",
            "Step: 9925 -> Loss: 0.004302716348320246 -> Predictions: [[0.00357013]\n",
            " [0.9961416 ]\n",
            " [0.9961299 ]\n",
            " [0.00587353]]\n",
            "Step: 9926 -> Loss: 0.00430269492790103 -> Predictions: [[0.00357011]\n",
            " [0.9961416 ]\n",
            " [0.9961299 ]\n",
            " [0.0058735 ]]\n",
            "Step: 9927 -> Loss: 0.004302676767110825 -> Predictions: [[0.0035701 ]\n",
            " [0.9961416 ]\n",
            " [0.9961299 ]\n",
            " [0.00587347]]\n",
            "Step: 9928 -> Loss: 0.004302654881030321 -> Predictions: [[0.00357008]\n",
            " [0.9961416 ]\n",
            " [0.99613   ]\n",
            " [0.00587344]]\n",
            "Step: 9929 -> Loss: 0.0043026357889175415 -> Predictions: [[0.00357006]\n",
            " [0.9961416 ]\n",
            " [0.99613   ]\n",
            " [0.00587342]]\n",
            "Step: 9930 -> Loss: 0.004302616231143475 -> Predictions: [[0.00357005]\n",
            " [0.99614173]\n",
            " [0.99613   ]\n",
            " [0.00587338]]\n",
            "Step: 9931 -> Loss: 0.004302592948079109 -> Predictions: [[0.00357003]\n",
            " [0.99614173]\n",
            " [0.99613   ]\n",
            " [0.00587335]]\n",
            "Step: 9932 -> Loss: 0.004302574321627617 -> Predictions: [[0.00357002]\n",
            " [0.99614173]\n",
            " [0.99613   ]\n",
            " [0.00587332]]\n",
            "Step: 9933 -> Loss: 0.00430255476385355 -> Predictions: [[0.00357   ]\n",
            " [0.99614173]\n",
            " [0.99613   ]\n",
            " [0.00587329]]\n",
            "Step: 9934 -> Loss: 0.004302534740418196 -> Predictions: [[0.00356999]\n",
            " [0.99614173]\n",
            " [0.99613   ]\n",
            " [0.00587326]]\n",
            "Step: 9935 -> Loss: 0.004302515648305416 -> Predictions: [[0.00356997]\n",
            " [0.99614173]\n",
            " [0.9961301 ]\n",
            " [0.00587324]]\n",
            "Step: 9936 -> Loss: 0.004302494693547487 -> Predictions: [[0.00356995]\n",
            " [0.99614173]\n",
            " [0.9961301 ]\n",
            " [0.00587321]]\n",
            "Step: 9937 -> Loss: 0.004302474204450846 -> Predictions: [[0.00356993]\n",
            " [0.99614185]\n",
            " [0.9961301 ]\n",
            " [0.00587317]]\n",
            "Step: 9938 -> Loss: 0.004302453715354204 -> Predictions: [[0.00356992]\n",
            " [0.99614185]\n",
            " [0.9961301 ]\n",
            " [0.00587315]]\n",
            "Step: 9939 -> Loss: 0.004302432760596275 -> Predictions: [[0.0035699 ]\n",
            " [0.99614185]\n",
            " [0.9961301 ]\n",
            " [0.00587312]]\n",
            "Step: 9940 -> Loss: 0.004302414134144783 -> Predictions: [[0.00356988]\n",
            " [0.99614185]\n",
            " [0.9961301 ]\n",
            " [0.00587308]]\n",
            "Step: 9941 -> Loss: 0.0043023936450481415 -> Predictions: [[0.00356987]\n",
            " [0.99614185]\n",
            " [0.9961301 ]\n",
            " [0.00587306]]\n",
            "Step: 9942 -> Loss: 0.0043023754842579365 -> Predictions: [[0.00356985]\n",
            " [0.99614185]\n",
            " [0.9961302 ]\n",
            " [0.00587303]]\n",
            "Step: 9943 -> Loss: 0.004302354529500008 -> Predictions: [[0.00356984]\n",
            " [0.99614185]\n",
            " [0.9961302 ]\n",
            " [0.005873  ]]\n",
            "Step: 9944 -> Loss: 0.004302334971725941 -> Predictions: [[0.00356982]\n",
            " [0.99614197]\n",
            " [0.9961302 ]\n",
            " [0.00587297]]\n",
            "Step: 9945 -> Loss: 0.004302315879613161 -> Predictions: [[0.00356981]\n",
            " [0.99614197]\n",
            " [0.9961302 ]\n",
            " [0.00587294]]\n",
            "Step: 9946 -> Loss: 0.004302292130887508 -> Predictions: [[0.00356979]\n",
            " [0.99614197]\n",
            " [0.9961302 ]\n",
            " [0.00587291]]\n",
            "Step: 9947 -> Loss: 0.004302274435758591 -> Predictions: [[0.00356977]\n",
            " [0.99614197]\n",
            " [0.9961302 ]\n",
            " [0.00587288]]\n",
            "Step: 9948 -> Loss: 0.0043022530153393745 -> Predictions: [[0.00356976]\n",
            " [0.99614197]\n",
            " [0.9961302 ]\n",
            " [0.00587285]]\n",
            "Step: 9949 -> Loss: 0.004302233923226595 -> Predictions: [[0.00356974]\n",
            " [0.99614197]\n",
            " [0.99613035]\n",
            " [0.00587282]]\n",
            "Step: 9950 -> Loss: 0.004302213434129953 -> Predictions: [[0.00356972]\n",
            " [0.99614197]\n",
            " [0.99613035]\n",
            " [0.00587279]]\n",
            "Step: 9951 -> Loss: 0.0043021938763558865 -> Predictions: [[0.00356971]\n",
            " [0.9961421 ]\n",
            " [0.99613035]\n",
            " [0.00587276]]\n",
            "Step: 9952 -> Loss: 0.004302174784243107 -> Predictions: [[0.0035697 ]\n",
            " [0.9961421 ]\n",
            " [0.99613035]\n",
            " [0.00587273]]\n",
            "Step: 9953 -> Loss: 0.004302154295146465 -> Predictions: [[0.00356968]\n",
            " [0.9961421 ]\n",
            " [0.99613035]\n",
            " [0.00587271]]\n",
            "Step: 9954 -> Loss: 0.004302133806049824 -> Predictions: [[0.00356966]\n",
            " [0.9961421 ]\n",
            " [0.99613035]\n",
            " [0.00587267]]\n",
            "Step: 9955 -> Loss: 0.004302114713937044 -> Predictions: [[0.00356965]\n",
            " [0.9961421 ]\n",
            " [0.99613035]\n",
            " [0.00587265]]\n",
            "Step: 9956 -> Loss: 0.004302094224840403 -> Predictions: [[0.00356963]\n",
            " [0.9961421 ]\n",
            " [0.99613047]\n",
            " [0.00587262]]\n",
            "Step: 9957 -> Loss: 0.004302073270082474 -> Predictions: [[0.00356961]\n",
            " [0.9961421 ]\n",
            " [0.99613047]\n",
            " [0.00587259]]\n",
            "Step: 9958 -> Loss: 0.0043020546436309814 -> Predictions: [[0.0035696 ]\n",
            " [0.9961422 ]\n",
            " [0.99613047]\n",
            " [0.00587256]]\n",
            "Step: 9959 -> Loss: 0.004302033223211765 -> Predictions: [[0.00356958]\n",
            " [0.9961422 ]\n",
            " [0.99613047]\n",
            " [0.00587252]]\n",
            "Step: 9960 -> Loss: 0.004302014596760273 -> Predictions: [[0.00356956]\n",
            " [0.9961422 ]\n",
            " [0.99613047]\n",
            " [0.0058725 ]]\n",
            "Step: 9961 -> Loss: 0.004301995038986206 -> Predictions: [[0.00356955]\n",
            " [0.9961422 ]\n",
            " [0.99613047]\n",
            " [0.00587247]]\n",
            "Step: 9962 -> Loss: 0.0043019745498895645 -> Predictions: [[0.00356954]\n",
            " [0.9961422 ]\n",
            " [0.99613047]\n",
            " [0.00587244]]\n",
            "Step: 9963 -> Loss: 0.004301951266825199 -> Predictions: [[0.00356952]\n",
            " [0.9961422 ]\n",
            " [0.9961306 ]\n",
            " [0.0058724 ]]\n",
            "Step: 9964 -> Loss: 0.004301933106034994 -> Predictions: [[0.0035695 ]\n",
            " [0.9961422 ]\n",
            " [0.9961306 ]\n",
            " [0.00587238]]\n",
            "Step: 9965 -> Loss: 0.00430191308259964 -> Predictions: [[0.00356948]\n",
            " [0.9961423 ]\n",
            " [0.9961306 ]\n",
            " [0.00587235]]\n",
            "Step: 9966 -> Loss: 0.00430189399048686 -> Predictions: [[0.00356947]\n",
            " [0.9961423 ]\n",
            " [0.9961306 ]\n",
            " [0.00587232]]\n",
            "Step: 9967 -> Loss: 0.004301874898374081 -> Predictions: [[0.00356945]\n",
            " [0.9961423 ]\n",
            " [0.9961306 ]\n",
            " [0.0058723 ]]\n",
            "Step: 9968 -> Loss: 0.004301852080971003 -> Predictions: [[0.00356944]\n",
            " [0.9961423 ]\n",
            " [0.9961306 ]\n",
            " [0.00587226]]\n",
            "Step: 9969 -> Loss: 0.004301832523196936 -> Predictions: [[0.00356942]\n",
            " [0.9961423 ]\n",
            " [0.9961306 ]\n",
            " [0.00587224]]\n",
            "Step: 9970 -> Loss: 0.004301812965422869 -> Predictions: [[0.0035694]\n",
            " [0.9961423]\n",
            " [0.9961307]\n",
            " [0.0058722]]\n",
            "Step: 9971 -> Loss: 0.0043017929419875145 -> Predictions: [[0.00356938]\n",
            " [0.9961423 ]\n",
            " [0.9961307 ]\n",
            " [0.00587217]]\n",
            "Step: 9972 -> Loss: 0.004301770124584436 -> Predictions: [[0.00356937]\n",
            " [0.99614245]\n",
            " [0.9961307 ]\n",
            " [0.00587214]]\n",
            "Step: 9973 -> Loss: 0.004301751498132944 -> Predictions: [[0.00356936]\n",
            " [0.99614245]\n",
            " [0.9961307 ]\n",
            " [0.00587211]]\n",
            "Step: 9974 -> Loss: 0.0043017324060201645 -> Predictions: [[0.00356934]\n",
            " [0.99614245]\n",
            " [0.9961307 ]\n",
            " [0.00587209]]\n",
            "Step: 9975 -> Loss: 0.004301715176552534 -> Predictions: [[0.00356933]\n",
            " [0.99614245]\n",
            " [0.9961307 ]\n",
            " [0.00587206]]\n",
            "Step: 9976 -> Loss: 0.004301692824810743 -> Predictions: [[0.00356931]\n",
            " [0.99614245]\n",
            " [0.9961307 ]\n",
            " [0.00587203]]\n",
            "Step: 9977 -> Loss: 0.004301674198359251 -> Predictions: [[0.00356929]\n",
            " [0.99614245]\n",
            " [0.9961308 ]\n",
            " [0.005872  ]]\n",
            "Step: 9978 -> Loss: 0.004301654174923897 -> Predictions: [[0.00356927]\n",
            " [0.99614245]\n",
            " [0.9961308 ]\n",
            " [0.00587197]]\n",
            "Step: 9979 -> Loss: 0.004301633220165968 -> Predictions: [[0.00356926]\n",
            " [0.99614257]\n",
            " [0.9961308 ]\n",
            " [0.00587194]]\n",
            "Step: 9980 -> Loss: 0.004301613196730614 -> Predictions: [[0.00356925]\n",
            " [0.99614257]\n",
            " [0.9961308 ]\n",
            " [0.00587191]]\n",
            "Step: 9981 -> Loss: 0.004301590844988823 -> Predictions: [[0.00356923]\n",
            " [0.99614257]\n",
            " [0.9961308 ]\n",
            " [0.00587188]]\n",
            "Step: 9982 -> Loss: 0.004301573149859905 -> Predictions: [[0.00356921]\n",
            " [0.99614257]\n",
            " [0.9961308 ]\n",
            " [0.00587185]]\n",
            "Step: 9983 -> Loss: 0.004301553592085838 -> Predictions: [[0.00356919]\n",
            " [0.99614257]\n",
            " [0.99613094]\n",
            " [0.00587182]]\n",
            "Step: 9984 -> Loss: 0.004301534965634346 -> Predictions: [[0.00356918]\n",
            " [0.99614257]\n",
            " [0.99613094]\n",
            " [0.0058718 ]]\n",
            "Step: 9985 -> Loss: 0.004301508888602257 -> Predictions: [[0.00356916]\n",
            " [0.9961427 ]\n",
            " [0.99613094]\n",
            " [0.00587176]]\n",
            "Step: 9986 -> Loss: 0.004301491659134626 -> Predictions: [[0.00356914]\n",
            " [0.9961427 ]\n",
            " [0.99613094]\n",
            " [0.00587173]]\n",
            "Step: 9987 -> Loss: 0.004301472567021847 -> Predictions: [[0.00356912]\n",
            " [0.9961427 ]\n",
            " [0.99613094]\n",
            " [0.00587171]]\n",
            "Step: 9988 -> Loss: 0.0043014525435864925 -> Predictions: [[0.00356911]\n",
            " [0.9961427 ]\n",
            " [0.99613094]\n",
            " [0.00587168]]\n",
            "Step: 9989 -> Loss: 0.004301431123167276 -> Predictions: [[0.00356909]\n",
            " [0.9961427 ]\n",
            " [0.99613094]\n",
            " [0.00587165]]\n",
            "Step: 9990 -> Loss: 0.0043014115653932095 -> Predictions: [[0.00356908]\n",
            " [0.9961427 ]\n",
            " [0.99613106]\n",
            " [0.00587162]]\n",
            "Step: 9991 -> Loss: 0.0043013920076191425 -> Predictions: [[0.00356906]\n",
            " [0.9961427 ]\n",
            " [0.99613106]\n",
            " [0.0058716 ]]\n",
            "Step: 9992 -> Loss: 0.004301371984183788 -> Predictions: [[0.00356905]\n",
            " [0.9961428 ]\n",
            " [0.99613106]\n",
            " [0.00587156]]\n",
            "Step: 9993 -> Loss: 0.004301352892071009 -> Predictions: [[0.00356903]\n",
            " [0.9961428 ]\n",
            " [0.99613106]\n",
            " [0.00587154]]\n",
            "Step: 9994 -> Loss: 0.0043013328686356544 -> Predictions: [[0.00356901]\n",
            " [0.9961428 ]\n",
            " [0.99613106]\n",
            " [0.00587151]]\n",
            "Step: 9995 -> Loss: 0.004301315639168024 -> Predictions: [[0.003569  ]\n",
            " [0.9961428 ]\n",
            " [0.99613106]\n",
            " [0.00587149]]\n",
            "Step: 9996 -> Loss: 0.004301294218748808 -> Predictions: [[0.00356898]\n",
            " [0.9961428 ]\n",
            " [0.99613106]\n",
            " [0.00587146]]\n",
            "Step: 9997 -> Loss: 0.0043012723326683044 -> Predictions: [[0.00356897]\n",
            " [0.9961428 ]\n",
            " [0.9961312 ]\n",
            " [0.00587142]]\n",
            "Step: 9998 -> Loss: 0.004301254637539387 -> Predictions: [[0.00356895]\n",
            " [0.9961429 ]\n",
            " [0.9961312 ]\n",
            " [0.00587141]]\n",
            "Step: 9999 -> Loss: 0.0043012346141040325 -> Predictions: [[0.00356894]\n",
            " [0.9961429 ]\n",
            " [0.9961312 ]\n",
            " [0.00587137]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}