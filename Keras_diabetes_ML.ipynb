{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_diabetes_ML.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyDearGreatTeacher/AI4high/blob/master/Keras_diabetes_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REm6gPbdopKr",
        "colab_type": "text"
      },
      "source": [
        "# Keras_diabetes_NN\n",
        "\n",
        "使用類神經網路分類糖尿病\n",
        "\n",
        "\n",
        "單元學習主題:\n",
        "\n",
        "1.下載遠端CSV資料\n",
        "\n",
        "2.用Keras配置並編譯多層感知器模型\n",
        "\n",
        "3.用驗證資料集驗證Keras模型\n",
        "\n",
        "\n",
        "\n",
        "https://cnbeining.github.io/deep-learning-with-python-cn/3-multi-layer-perceptrons/ch7-develop-your-first-neural-network-with-keras.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTpaQ0xWo_gW",
        "colab_type": "text"
      },
      "source": [
        "# 資料集DataSet\n",
        "\n",
        "皮馬人糖尿病資料集（Pima Indians onset of diabetes）\n",
        "\n",
        "可在UCI的機器學習網站可以免費下載。\n",
        "\n",
        "https://www.kaggle.com/kumargh/pimaindiansdiabetescsv/version/1?login=true\n",
        "\n",
        "pima-indians-diabetes.csv\n",
        "\n",
        "已經放在底下網站\n",
        "\n",
        "https://raw.githubusercontent.com/MyDearGreatTeacher/AI4high/master/data/Pima%20Indians%20Diabetes%20Database/diabetes.csv\n",
        "\n",
        "資料集的內容是皮馬人的醫療記錄，以及過去5年內是否有糖尿病。所有的資料都是數位，問題是（是否有糖尿病是1或0），是二分類問題。\n",
        "\n",
        "\n",
        "資料的數量級不同，有8個屬性：\n",
        "\n",
        "1.懷孕次數\n",
        "\n",
        "2.2小時口服葡萄糖耐量試驗中的血漿葡萄糖濃度\n",
        "\n",
        "3.舒張壓（毫米汞柱）\n",
        "\n",
        "4.2小時血清胰島素（mu U/ml)\n",
        "\n",
        "5.體重指數（BMI）\n",
        "\n",
        "6.糖尿病血系功能\n",
        "\n",
        "7.年齡（年）\n",
        "\n",
        "8.類別：過去5年內是否有糖尿病==>只有兩個答案  binary-classification\n",
        "\n",
        "\n",
        "所有的資料都是數位，可以直接導入Keras。\n",
        "\n",
        "資料有768行，前5行的樣本長這樣：\n",
        "\n",
        "6,148,72,35,0,33.6,0.627,50,1\n",
        "\n",
        "1,85,66,29,0,26.6,0.351,31,0\n",
        "\n",
        "8,183,64,0,0,23.3,0.672,32,1\n",
        "\n",
        "1,89,66,23,94,28.1,0.167,21,0\n",
        "\n",
        "0,137,40,35,168,43.1,2.288,33,1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmGWatp7rfjA",
        "colab_type": "text"
      },
      "source": [
        "#  下載與檢視資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7OtGMn9nM-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d639eefc-9197-4507-ca7c-976a016b5604"
      },
      "source": [
        "!curl -O \"https://raw.githubusercontent.com/MyDearGreatTeacher/AI4high/master/data/Pima%20Indians%20Diabetes%20Database/diabetes.csv\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 23873  100 23873    0     0   144k      0 --:--:-- --:--:-- --:--:--  145k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wk_5gkBqMmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b5a6260-a96c-4381-c786-8e0a073d1579"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "diabetes.csv  iris.csv\tlogs  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70RQz5VmqPaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat diabetes.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFB1pwMkroaj",
        "colab_type": "text"
      },
      "source": [
        "# 讀取CSV "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA5LBmyHqYkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2uRTa8aqoVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load pima indians dataset\n",
        "dataframe = pd.read_csv(\"diabetes.csv\", header=None)\n",
        "dataset = dataframe.values\n",
        "#dataset = np.loadtxt(\"diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[1:,0:8]\n",
        "Y = dataset[1:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6JWpEUcrM6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1046
        },
        "outputId": "e625aec2-3851-49c2-95e1-cdf14bb2b47d"
      },
      "source": [
        "Y"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '0', '1', '0', '1', '0', '1', '0', '1', '1', '0', '1', '0',\n",
              "       '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1',\n",
              "       '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '1',\n",
              "       '1', '0', '0', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0',\n",
              "       '0', '1', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1',\n",
              "       '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0',\n",
              "       '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0',\n",
              "       '0', '0', '1', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1',\n",
              "       '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '1',\n",
              "       '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1',\n",
              "       '0', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '0', '0',\n",
              "       '0', '1', '1', '0', '0', '0', '1', '0', '1', '0', '1', '0', '0',\n",
              "       '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0',\n",
              "       '1', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1',\n",
              "       '0', '1', '0', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1',\n",
              "       '1', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0',\n",
              "       '0', '1', '1', '1', '1', '0', '0', '0', '1', '1', '0', '1', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1',\n",
              "       '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0',\n",
              "       '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '1', '0',\n",
              "       '0', '1', '0', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1',\n",
              "       '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '0',\n",
              "       '1', '0', '1', '0', '0', '1', '0', '1', '0', '1', '1', '1', '0',\n",
              "       '0', '1', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '1',\n",
              "       '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0',\n",
              "       '0', '0', '0', '0', '1', '1', '1', '0', '1', '1', '0', '0', '1',\n",
              "       '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0',\n",
              "       '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '0',\n",
              "       '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1',\n",
              "       '0', '1', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '1',\n",
              "       '0', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '0',\n",
              "       '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0',\n",
              "       '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0',\n",
              "       '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1',\n",
              "       '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1',\n",
              "       '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '1',\n",
              "       '0', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '0', '0',\n",
              "       '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '1', '0', '0', '0', '1', '1', '1', '1', '0', '0', '1',\n",
              "       '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '1',\n",
              "       '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0',\n",
              "       '1', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '0', '0',\n",
              "       '1', '1', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0',\n",
              "       '0', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '1', '0',\n",
              "       '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '1', '1',\n",
              "       '1', '1', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1',\n",
              "       '1', '0', '1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0',\n",
              "       '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1',\n",
              "       '1', '0', '0', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0',\n",
              "       '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1',\n",
              "       '0', '0', '1', '0', '0', '1', '0', '1', '1', '1', '0', '0', '1',\n",
              "       '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '1',\n",
              "       '0'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwRqmDYQrIZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "f374490a-320c-4aa1-8801-038b600a51f8"
      },
      "source": [
        "X"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['6', '148', '72', ..., '33.6', '0.627', '50'],\n",
              "       ['1', '85', '66', ..., '26.6', '0.351', '31'],\n",
              "       ['8', '183', '64', ..., '23.3', '0.672', '32'],\n",
              "       ...,\n",
              "       ['5', '121', '72', ..., '26.2', '0.245', '30'],\n",
              "       ['1', '126', '60', ..., '30.1', '0.349', '47'],\n",
              "       ['1', '93', '70', ..., '30.4', '0.315', '23']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC4yirmirPz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "f2385118-6186-472c-9d4d-40adf14bcb53"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, init='uniform', activation='relu')) \n",
        "model.add(Dense(8, init='uniform', activation='relu')) \n",
        "model.add(Dense(1, init='uniform', activation='sigmoid'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy0bq6crs58J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "40222d36-00c7-47d3-f3bd-be3ec8eb8b54"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yiHlXgVsPvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "                optimizer='adam', \n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zl8ZbzjsaAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5231
        },
        "outputId": "a74d70c4-c8e0-43a2-ad4c-cdf6dad37a6f"
      },
      "source": [
        "# Fit the model\n",
        "model.fit(X, Y, nb_epoch=150, batch_size=10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "768/768 [==============================] - 0s 420us/step - loss: 0.6811 - acc: 0.6250\n",
            "Epoch 2/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.6645 - acc: 0.6510\n",
            "Epoch 3/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.6570 - acc: 0.6510\n",
            "Epoch 4/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.6520 - acc: 0.6510\n",
            "Epoch 5/150\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.6411 - acc: 0.6589\n",
            "Epoch 6/150\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.6312 - acc: 0.6693\n",
            "Epoch 7/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.6322 - acc: 0.6758\n",
            "Epoch 8/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.6131 - acc: 0.6875\n",
            "Epoch 9/150\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.6015 - acc: 0.6927\n",
            "Epoch 10/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.5939 - acc: 0.6888\n",
            "Epoch 11/150\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.5887 - acc: 0.7018\n",
            "Epoch 12/150\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.5939 - acc: 0.6953\n",
            "Epoch 13/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.5828 - acc: 0.7018\n",
            "Epoch 14/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.5820 - acc: 0.6979\n",
            "Epoch 15/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.5869 - acc: 0.6979\n",
            "Epoch 16/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.5775 - acc: 0.7031\n",
            "Epoch 17/150\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.5748 - acc: 0.6875\n",
            "Epoch 18/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.5783 - acc: 0.7031\n",
            "Epoch 19/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.5781 - acc: 0.7018\n",
            "Epoch 20/150\n",
            "768/768 [==============================] - 0s 143us/step - loss: 0.5762 - acc: 0.6953\n",
            "Epoch 21/150\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.5719 - acc: 0.7122\n",
            "Epoch 22/150\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.5691 - acc: 0.7109\n",
            "Epoch 23/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.5719 - acc: 0.7070\n",
            "Epoch 24/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.5658 - acc: 0.7109\n",
            "Epoch 25/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.5652 - acc: 0.7018\n",
            "Epoch 26/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.5620 - acc: 0.7096\n",
            "Epoch 27/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.5697 - acc: 0.7096\n",
            "Epoch 28/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.5636 - acc: 0.7031\n",
            "Epoch 29/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.5650 - acc: 0.7148\n",
            "Epoch 30/150\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.5653 - acc: 0.7187\n",
            "Epoch 31/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.5612 - acc: 0.7201\n",
            "Epoch 32/150\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.5614 - acc: 0.7174\n",
            "Epoch 33/150\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.5583 - acc: 0.7044\n",
            "Epoch 34/150\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.5596 - acc: 0.7214\n",
            "Epoch 35/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.5584 - acc: 0.7292\n",
            "Epoch 36/150\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.5533 - acc: 0.7214\n",
            "Epoch 37/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.5553 - acc: 0.7292\n",
            "Epoch 38/150\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.5562 - acc: 0.7201\n",
            "Epoch 39/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.5549 - acc: 0.7201\n",
            "Epoch 40/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.5526 - acc: 0.7227\n",
            "Epoch 41/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.5509 - acc: 0.7188\n",
            "Epoch 42/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.5509 - acc: 0.7227\n",
            "Epoch 43/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.5495 - acc: 0.7253\n",
            "Epoch 44/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.5509 - acc: 0.7318\n",
            "Epoch 45/150\n",
            "768/768 [==============================] - 0s 143us/step - loss: 0.5524 - acc: 0.7383\n",
            "Epoch 46/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.5457 - acc: 0.7279\n",
            "Epoch 47/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.5443 - acc: 0.7253\n",
            "Epoch 48/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.5406 - acc: 0.7370\n",
            "Epoch 49/150\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.5405 - acc: 0.7435\n",
            "Epoch 50/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.5437 - acc: 0.7279\n",
            "Epoch 51/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.5357 - acc: 0.7305\n",
            "Epoch 52/150\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.5383 - acc: 0.7318\n",
            "Epoch 53/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.5405 - acc: 0.7409\n",
            "Epoch 54/150\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.5428 - acc: 0.7253\n",
            "Epoch 55/150\n",
            "768/768 [==============================] - 0s 136us/step - loss: 0.5372 - acc: 0.7487\n",
            "Epoch 56/150\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.5325 - acc: 0.7448\n",
            "Epoch 57/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.5355 - acc: 0.7435\n",
            "Epoch 58/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.5412 - acc: 0.7474\n",
            "Epoch 59/150\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.5312 - acc: 0.7513\n",
            "Epoch 60/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.5330 - acc: 0.7487\n",
            "Epoch 61/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.5332 - acc: 0.7370\n",
            "Epoch 62/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.5278 - acc: 0.7487\n",
            "Epoch 63/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.5267 - acc: 0.7565\n",
            "Epoch 64/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.5281 - acc: 0.7409\n",
            "Epoch 65/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.5329 - acc: 0.7526\n",
            "Epoch 66/150\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.5243 - acc: 0.7487\n",
            "Epoch 67/150\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.5250 - acc: 0.7526\n",
            "Epoch 68/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.5257 - acc: 0.7526\n",
            "Epoch 69/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.5202 - acc: 0.7578\n",
            "Epoch 70/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.5281 - acc: 0.7513\n",
            "Epoch 71/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.5280 - acc: 0.7422\n",
            "Epoch 72/150\n",
            "768/768 [==============================] - 0s 139us/step - loss: 0.5198 - acc: 0.7617\n",
            "Epoch 73/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.5146 - acc: 0.7526\n",
            "Epoch 74/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.5220 - acc: 0.7526\n",
            "Epoch 75/150\n",
            "768/768 [==============================] - 0s 136us/step - loss: 0.5208 - acc: 0.7539\n",
            "Epoch 76/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.5224 - acc: 0.7487\n",
            "Epoch 77/150\n",
            "768/768 [==============================] - 0s 138us/step - loss: 0.5195 - acc: 0.7552\n",
            "Epoch 78/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.5154 - acc: 0.7604\n",
            "Epoch 79/150\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.5112 - acc: 0.7565\n",
            "Epoch 80/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.5153 - acc: 0.7461\n",
            "Epoch 81/150\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.5077 - acc: 0.7643\n",
            "Epoch 82/150\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.5161 - acc: 0.7591\n",
            "Epoch 83/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.5120 - acc: 0.7526\n",
            "Epoch 84/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.5048 - acc: 0.7591\n",
            "Epoch 85/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.5157 - acc: 0.7539\n",
            "Epoch 86/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.5154 - acc: 0.7630\n",
            "Epoch 87/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.5069 - acc: 0.7552\n",
            "Epoch 88/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.5152 - acc: 0.7357\n",
            "Epoch 89/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.5050 - acc: 0.7487\n",
            "Epoch 90/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.5021 - acc: 0.7513\n",
            "Epoch 91/150\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.5024 - acc: 0.7539\n",
            "Epoch 92/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4969 - acc: 0.7552\n",
            "Epoch 93/150\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4989 - acc: 0.7695\n",
            "Epoch 94/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.5022 - acc: 0.7591\n",
            "Epoch 95/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.5066 - acc: 0.7682\n",
            "Epoch 96/150\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.5042 - acc: 0.7591\n",
            "Epoch 97/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4928 - acc: 0.7643\n",
            "Epoch 98/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4919 - acc: 0.7695\n",
            "Epoch 99/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4945 - acc: 0.7643\n",
            "Epoch 100/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4955 - acc: 0.7565\n",
            "Epoch 101/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4944 - acc: 0.7643\n",
            "Epoch 102/150\n",
            "768/768 [==============================] - 0s 146us/step - loss: 0.4972 - acc: 0.7643\n",
            "Epoch 103/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4967 - acc: 0.7656\n",
            "Epoch 104/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.5007 - acc: 0.7617\n",
            "Epoch 105/150\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4892 - acc: 0.7578\n",
            "Epoch 106/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4893 - acc: 0.7682\n",
            "Epoch 107/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4903 - acc: 0.7591\n",
            "Epoch 108/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4849 - acc: 0.7604\n",
            "Epoch 109/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4983 - acc: 0.7669\n",
            "Epoch 110/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4809 - acc: 0.7747\n",
            "Epoch 111/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4903 - acc: 0.7578\n",
            "Epoch 112/150\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4848 - acc: 0.7669\n",
            "Epoch 113/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4890 - acc: 0.7656\n",
            "Epoch 114/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4849 - acc: 0.7591\n",
            "Epoch 115/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4828 - acc: 0.7760\n",
            "Epoch 116/150\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.4865 - acc: 0.7734\n",
            "Epoch 117/150\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4787 - acc: 0.7617\n",
            "Epoch 118/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4862 - acc: 0.7565\n",
            "Epoch 119/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4814 - acc: 0.7734\n",
            "Epoch 120/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4817 - acc: 0.7656\n",
            "Epoch 121/150\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4800 - acc: 0.7591\n",
            "Epoch 122/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4848 - acc: 0.7630\n",
            "Epoch 123/150\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.4767 - acc: 0.7656\n",
            "Epoch 124/150\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4802 - acc: 0.7799\n",
            "Epoch 125/150\n",
            "768/768 [==============================] - 0s 138us/step - loss: 0.4776 - acc: 0.7773\n",
            "Epoch 126/150\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.4804 - acc: 0.7669\n",
            "Epoch 127/150\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4743 - acc: 0.7708\n",
            "Epoch 128/150\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4999 - acc: 0.7539\n",
            "Epoch 129/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4814 - acc: 0.7747\n",
            "Epoch 130/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4748 - acc: 0.7630\n",
            "Epoch 131/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4778 - acc: 0.7643\n",
            "Epoch 132/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4773 - acc: 0.7721\n",
            "Epoch 133/150\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4704 - acc: 0.7734\n",
            "Epoch 134/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4868 - acc: 0.7747\n",
            "Epoch 135/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4818 - acc: 0.7786\n",
            "Epoch 136/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4697 - acc: 0.7747\n",
            "Epoch 137/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4804 - acc: 0.7669\n",
            "Epoch 138/150\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4757 - acc: 0.7604\n",
            "Epoch 139/150\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4710 - acc: 0.7669\n",
            "Epoch 140/150\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4708 - acc: 0.7786\n",
            "Epoch 141/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4738 - acc: 0.7695\n",
            "Epoch 142/150\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4713 - acc: 0.7695\n",
            "Epoch 143/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4640 - acc: 0.7773\n",
            "Epoch 144/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4646 - acc: 0.7721\n",
            "Epoch 145/150\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4689 - acc: 0.7630\n",
            "Epoch 146/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4705 - acc: 0.7747\n",
            "Epoch 147/150\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4738 - acc: 0.7773\n",
            "Epoch 148/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4768 - acc: 0.7695\n",
            "Epoch 149/150\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4778 - acc: 0.7773\n",
            "Epoch 150/150\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4651 - acc: 0.7734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fae3493c438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axxD6NLYs0pl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31dfd71e-5d2d-4778-cecf-f6988a2da3f5"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 0s 85us/step\n",
            "acc: 77.34%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}